{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b635ea0",
   "metadata": {},
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42f7a8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kat\\anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Kat\\anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Kat\\anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Kat\\anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Kat\\anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Kat\\anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Kat\\anaconda3\\envs\\tensor\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Kat\\anaconda3\\envs\\tensor\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Kat\\anaconda3\\envs\\tensor\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Kat\\anaconda3\\envs\\tensor\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Kat\\anaconda3\\envs\\tensor\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Kat\\anaconda3\\envs\\tensor\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#activate tensor environment first!\n",
    "#import warnings #filtering out warnings so homework looks pretty\n",
    "#warnings.filterwarnings('ignore') #i do not recommend this for actual work \n",
    "import os\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras  \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affea3bb",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e733255",
   "metadata": {},
   "outputs": [],
   "source": [
    "blue=pd.read_csv('fad_blue_rnadata.csv').rename(columns={\"Unnamed: 0\": \"Cells\"})\n",
    "blue.set_index(\"Cells\", drop=True,inplace=True)\n",
    "blue=blue.T\n",
    "#^transpose because we want genes to be features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23bafd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=blue.index \n",
    "Y=blue['BlueFP']\n",
    "x=blue.drop(['BlueFP'],axis=1)\n",
    "#get top 200 genes from linear reg\n",
    "genestokeep=pd.read_csv('data/top200_genes.csv').drop(\"Unnamed: 0\",axis=1)['Genes']\n",
    "x2=x.loc[:, x.columns.isin(genestokeep)]\n",
    "genes=x2.columns\n",
    "#set x and y\n",
    "X=x2.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b866a90",
   "metadata": {},
   "source": [
    "# Try different model architectures\n",
    "\n",
    "Referenced this tutorial: https://machinelearningmastery.com/regression-tutorial-keras-deep-learning-library-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e3957d",
   "metadata": {},
   "source": [
    "## Code (Qi's tune_cnn.py, modified) and all outputs are shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a005e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using Qi's posted tune_cnn.py as reference\n",
    "from skopt import gp_minimize, dump, load\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.plots import plot_convergence\n",
    "from skopt.utils import use_named_args \n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65fb2e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using Qi's posted tune_cnn.py as reference\n",
    "#set kernel size to 3 and change filter_num to be a variable\n",
    "batch_size=500\n",
    "epochs=100\n",
    "def create_model(dropout, filter_num, num_dense_layers): \n",
    "    # Start construction of a Keras Sequential model.\n",
    "    model = Sequential()\n",
    "    model.add(Dense(X.shape[1], input_dim=X.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(int(filter_num), kernel_initializer='normal', activation='relu')) \n",
    "    model.add(Dropout(dropout))\n",
    "    for i in range(num_dense_layers):\n",
    "        \n",
    "        # Add the dense / fully-connected layer to the model.\n",
    "        # This has two hyper-parameters we want to optimize:\n",
    "        # The number of nodes and the activation function.\n",
    "        model.add(keras.layers.Dense(int(filter_num),\n",
    "                        activation='relu'))\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(int(filter_num), kernel_initializer='normal', activation='relu'))  \n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam') \n",
    "    return model\n",
    "\n",
    "log_path = './mnist_skopt_log'\n",
    "if not os.path.exists(log_path):\n",
    "    os.makedirs(log_path)\n",
    "result_path = './mnist_skopt_result'\n",
    "if not os.path.exists(result_path):\n",
    "    os.makedirs(result_path)\n",
    "\n",
    "def log_dir_name(dropout,\n",
    "                 filter_num,\n",
    "                 num_dense_layers):\n",
    "    # The dir-name for the TensorBoard log-dir.\n",
    "    s = os.path.join(log_path, \"dropout_{0:.0e}_filternum_{1}_dense_{2}/\")\n",
    "    \n",
    "    log_dir = s.format(dropout,\n",
    "                       filter_num,\n",
    "                       num_dense_layers)\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "   # plugins\\profile/datetime\n",
    "#had to make these folders manually due to windows issues\n",
    "    s2 = os.path.join(log_dir, \"plugins/\")\n",
    "    if not os.path.exists(s2):\n",
    "        os.makedirs(s2)\n",
    "    s3 = os.path.join(s2, \"profile/\")\n",
    "    if not os.path.exists(s3):\n",
    "        os.makedirs(s3)\n",
    "    datenow=datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "    s4 = os.path.join(s3, datenow)\n",
    "    if not os.path.exists(s4):\n",
    "        os.makedirs(s4)\n",
    "    return log_dir\n",
    "dim_dropout= Real(low=0.2, high=0.8, prior='log-uniform',\n",
    "                             name='dropout')\n",
    "dim_filter_num = Integer(low=10, high=300, name='filter_num')\n",
    "dim_num_dense_layers = Integer(low=1, high=20, name='num_dense_layers')\n",
    "dimensions = [dim_dropout, dim_filter_num, dim_num_dense_layers]\n",
    "@use_named_args(dimensions=dimensions)\n",
    "def fitness(dropout,filter_num, num_dense_layers):\n",
    "    # Print the hyper-parameters.\n",
    "    print('dropout: {0:.1e}'.format(dropout))\n",
    "    print('filter_num:', filter_num)\n",
    "    print('num_dense_layers:', num_dense_layers)\n",
    "    print()\n",
    "    # Create the neural network with these hyper-parameters.\n",
    "    model = create_model(dropout, filter_num,  num_dense_layers)\n",
    "     \n",
    "    # Dir-name for the TensorBoard log-files.\n",
    "    log_dir = log_dir_name(dropout,filter_num,  num_dense_layers)\n",
    "     \n",
    "    callback_log = keras.callbacks.TensorBoard(\n",
    "        log_dir=log_dir,\n",
    "        histogram_freq=0,\n",
    "        batch_size=200,\n",
    "        write_graph=True,\n",
    "        write_grads=False,\n",
    "        write_images=False)\n",
    "    \n",
    "    # Use Keras to train the model.\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        validation_split=0.1,\n",
    "                        callbacks=[callback_log])\n",
    "    # Get the classification accuracy on the validation-set\n",
    "    # after the last training-epoch.\n",
    "    m_s_e = history.history['loss'][-1]\n",
    "\n",
    "    # Print the classification accuracy.\n",
    "    print()\n",
    "    print(\"Mean squared error: {0:.2}\".format(m_s_e))\n",
    "    print()\n",
    "    \n",
    "    # Save the model if it improves on the best-found performance.\n",
    "    # We use the global keyword so we update the variable outside\n",
    "    # of this function.\n",
    "    global best_mean_squared_error\n",
    "\n",
    "    # If the classification accuracy of the saved model is improved ...\n",
    "    if m_s_e < best_mean_squared_error:\n",
    "        # Save the new model to harddisk.\n",
    "        model.save(path_best_model)\n",
    "        \n",
    "        # Update the classification accuracy.\n",
    "        best_mean_squared_error = m_s_e\n",
    "\n",
    "    # Delete the Keras model with these hyper-parameters from memory.\n",
    "    del model\n",
    "    \n",
    "    # Clear the Keras session, otherwise it will keep adding new\n",
    "    # models to the same TensorFlow graph each time we create\n",
    "    # a model with a different set of hyper-parameters.\n",
    "    K.clear_session()\n",
    "    \n",
    "    # NOTE: Scikit-optimize does minimization so it tries to\n",
    "    # find a set of hyper-parameters with the LOWEST fitness-value.\n",
    "    # Because we are interested in the HIGHEST classification\n",
    "    # accuracy, we need to negate this number so it can be minimized.\n",
    "    return m_s_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f21640e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_best_model = os.path.join(result_path+'best_model.keras')\n",
    "def print_and_plot(default_parameters):\n",
    "\n",
    "    # initial hyperparameters for search \n",
    "\n",
    "    # search by Gaussian Process Optimization\n",
    "    search_result = gp_minimize(func=fitness,\n",
    "                                dimensions=dimensions,\n",
    "                                acq_func='EI', # Expected Improvement.\n",
    "                                n_calls=50, # min n_calls=11\n",
    "                                x0=default_parameters)\n",
    "\n",
    "    # save the search result for future use\n",
    "    dump(search_result,result_path+'search_result.gz', compress=9)\n",
    "    # if you need to reload the optimization history, use the following command\n",
    "    #res_load = load(result_path+'search_result.gz')\n",
    "\n",
    "    # check the optimization result\n",
    "    plot_convergence(search_result)\n",
    "\n",
    "    # check the optimized solution\n",
    "    print('Best solution:')\n",
    "    print(search_result.x)\n",
    "\n",
    "    # Evaluate the performance of the best model on the test set\n",
    "    model_best = load_model(path_best_model)\n",
    "    score = model_best.evaluate(x_test, y_test, verbose=0)\n",
    "    #print('Test loss:', score[0])\n",
    "    #print('Test mse:', score[1])\n",
    "    print()\n",
    "    print('Score:')\n",
    "    print(score)\n",
    "    # check the optimization history by listing the combination of all x and \n",
    "    # its corresponding funtion value\n",
    "    #print(sorted(zip(search_result.func_vals, search_result.x_iters)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7bd502",
   "metadata": {},
   "source": [
    "# Initial conditions try 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20eb4516",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load and split data\n",
    "x_train_pre, x_test_pre, y_train, y_test = train_test_split(X, Y, test_size=0.15)\n",
    "scaler = StandardScaler().fit(x_train_pre) \n",
    "x_train = scaler.transform(x_train_pre) \n",
    "scaler = StandardScaler().fit(x_test_pre) \n",
    "x_test = scaler.transform(x_test_pre) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebd0814a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropout: 5.0e-01\n",
      "filter_num: 50\n",
      "num_dense_layers: 2\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Kat\\anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow\\python\\keras\\initializers.py:143: calling RandomNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\Kat\\anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 117us/sample - loss: 59.1655 - val_loss: 54.4682\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 57.8161 - val_loss: 52.4831\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 54.6309 - val_loss: 47.1189\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 47.0500 - val_loss: 36.0384\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 40.0864 - val_loss: 28.6142\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 37.2398 - val_loss: 28.8027\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 37.3626 - val_loss: 29.0863\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 34.6521 - val_loss: 29.2677\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 33.1541 - val_loss: 28.1277\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 31.9087 - val_loss: 26.2080\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 32.0571 - val_loss: 26.7584\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 29.9197 - val_loss: 26.9287\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 29.7960 - val_loss: 27.1407\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 28.7496 - val_loss: 26.4656\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 29.1433 - val_loss: 26.2825\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 26.0586 - val_loss: 26.3654\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 28.1617 - val_loss: 26.4613\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 27.5058 - val_loss: 26.9488\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 27.3172 - val_loss: 27.6434\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 27.0975 - val_loss: 27.8479\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 24.9859 - val_loss: 28.3674\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 23.0638 - val_loss: 29.0981\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 24.1579 - val_loss: 29.8218\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 22.4671 - val_loss: 30.4238\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 21.4600 - val_loss: 31.9798\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 21.5189 - val_loss: 33.3166\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 21.0546 - val_loss: 34.9360\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 19.2917 - val_loss: 38.0418\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 19.3267 - val_loss: 43.0671\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 17.7776 - val_loss: 45.6249\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 18.9834 - val_loss: 54.6711\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 20.3507 - val_loss: 63.0876\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 17.1273 - val_loss: 69.4041\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 17.7459 - val_loss: 79.6824\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 16.7174 - val_loss: 86.2119\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 16.7577 - val_loss: 93.7305\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 14.2647 - val_loss: 91.5831\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 15.5012 - val_loss: 96.1443\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 13.6396 - val_loss: 110.1910\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 12.1063 - val_loss: 127.1819\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 15.9557 - val_loss: 126.2011\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 11.4078 - val_loss: 124.8682\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 11.5097 - val_loss: 149.9619\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 12.1106 - val_loss: 159.0606\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 11.0755 - val_loss: 170.4500\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 11.1648 - val_loss: 183.7319\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 10.7018 - val_loss: 199.0991\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 10.4003 - val_loss: 214.6893\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 10.5425 - val_loss: 194.5063\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 11.1431 - val_loss: 199.6042\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 10.9918 - val_loss: 238.0690\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 10.0506 - val_loss: 228.7959\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 10.2068 - val_loss: 225.7218\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 9.6554 - val_loss: 261.8299\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 10.2892 - val_loss: 257.0941\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 11.7634 - val_loss: 240.7977\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 8.6169 - val_loss: 280.7431\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 8.4321 - val_loss: 298.9747\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 9.0292 - val_loss: 262.7017\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 9.6509 - val_loss: 301.0691\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 10.7384 - val_loss: 313.5148\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 13.1407 - val_loss: 231.4436\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 10.7857 - val_loss: 237.6734\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 11.5528 - val_loss: 230.1075\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 9.5638 - val_loss: 237.1982\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 9.7121 - val_loss: 267.9828\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 8.9572 - val_loss: 286.5656\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 12us/sample - loss: 8.5302 - val_loss: 300.8495\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 8.6013 - val_loss: 306.1015\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 7.7621 - val_loss: 379.6442\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 9.1582 - val_loss: 391.2026\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 8.3512 - val_loss: 311.8145\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 10.2642 - val_loss: 340.2305\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 8.9411 - val_loss: 360.1995\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 12.0601 - val_loss: 305.7825\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 8.3265 - val_loss: 292.0211\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 8.5089 - val_loss: 324.8306\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 7.5024 - val_loss: 322.9672\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 7.8653 - val_loss: 342.1666\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 7.5197 - val_loss: 382.1361\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 6.4145 - val_loss: 381.8309\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 7.4593 - val_loss: 405.7256\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 7.0560 - val_loss: 399.8856\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 7.0413 - val_loss: 378.6093\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 7.3261 - val_loss: 384.7007\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 8.8373 - val_loss: 355.4340\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 8.6525 - val_loss: 234.7985\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 10.1136 - val_loss: 264.0844\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 10.9895 - val_loss: 310.3242\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 9.8819 - val_loss: 273.8062\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 10.1954 - val_loss: 306.6664\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 8.5937 - val_loss: 374.9047\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 8.0919 - val_loss: 394.1362\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 10.1036 - val_loss: 347.3245\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 8.5096 - val_loss: 354.4387\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 8.0305 - val_loss: 367.7625\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 7.3718 - val_loss: 395.0542\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 6.9667 - val_loss: 413.6320\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 7.4504 - val_loss: 435.7285\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 7.3083 - val_loss: 433.7429\n",
      "\n",
      "Mean squared error: 7.3\n",
      "\n",
      "dropout: 3.4e-01\n",
      "filter_num: 133\n",
      "num_dense_layers: 11\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 1s 327us/sample - loss: 58.2502 - val_loss: 50.6366\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 45.8684 - val_loss: 44.6953\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 42.2968 - val_loss: 40.7204\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 39.5102 - val_loss: 41.9423\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 37.6183 - val_loss: 37.7316\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 35.4999 - val_loss: 42.3349\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 35.6665 - val_loss: 38.5536\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 32.7359 - val_loss: 37.7374\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 27.9944 - val_loss: 36.6770\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 26.7314 - val_loss: 32.0847\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 24.3700 - val_loss: 37.4781\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 25.7135 - val_loss: 32.7718\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 21.5273 - val_loss: 41.2839\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 20.2655 - val_loss: 32.8440\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 18.7624 - val_loss: 37.5064\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 18.8426 - val_loss: 39.2903\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 18.5841 - val_loss: 34.3837\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 20.0862 - val_loss: 40.5671\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 25.7842 - val_loss: 38.6603\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 20.7836 - val_loss: 36.9053\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 17.9277 - val_loss: 33.6766\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 19.4218 - val_loss: 35.9557\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 16.8788 - val_loss: 32.0123\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 18.0894 - val_loss: 37.8802\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 15.2216 - val_loss: 31.0783\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 15.3084 - val_loss: 38.0912\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 15.6361 - val_loss: 34.2026\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 13.7461 - val_loss: 35.6167\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 13.3096 - val_loss: 34.4583\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 16.6904 - val_loss: 39.2005\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 18.0914 - val_loss: 38.1605\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 15.8166 - val_loss: 31.8534\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 15.2826 - val_loss: 33.9419\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 12.2070 - val_loss: 34.3887\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 14.3727 - val_loss: 33.7138\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 13.6422 - val_loss: 36.1231\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 17.0727 - val_loss: 38.4910\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 13.9296 - val_loss: 32.9735\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 12.6369 - val_loss: 34.9529\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 14.6463 - val_loss: 34.0556\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 18.9276 - val_loss: 39.1897\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 45us/sample - loss: 14.1650 - val_loss: 32.5772\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 14.7834 - val_loss: 40.6126\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 15.0150 - val_loss: 34.7437\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 15.9436 - val_loss: 40.4515\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 29.4264 - val_loss: 45.7122\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 30.6589 - val_loss: 31.0925\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 18.5227 - val_loss: 35.1493\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 18.0384 - val_loss: 33.9232\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 16.6239 - val_loss: 36.0549\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 14.7522 - val_loss: 34.6534\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 21.1134 - val_loss: 38.3260\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 16.5511 - val_loss: 32.9873\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 18.1120 - val_loss: 36.4057\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 15.8669 - val_loss: 34.9010\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 13.5195 - val_loss: 37.2760\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 14.7801 - val_loss: 34.3416\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 43us/sample - loss: 14.4731 - val_loss: 35.4858\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 12.5483 - val_loss: 33.1434\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 12.6831 - val_loss: 34.2013\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 11.4286 - val_loss: 34.9551\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 12.4375 - val_loss: 34.7478\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 9.4651 - val_loss: 33.6218\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 10.9984 - val_loss: 33.4185\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 10.3795 - val_loss: 34.2490\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 12.1770 - val_loss: 35.2487\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 13.0212 - val_loss: 32.7094\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 10.2316 - val_loss: 35.8151\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 10.9549 - val_loss: 32.6695\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 21.3901 - val_loss: 42.2002\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 25.2298 - val_loss: 42.5744\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 18.4671 - val_loss: 30.8314\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 17.9629 - val_loss: 38.2938\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 19.9457 - val_loss: 37.4868\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 23.4860 - val_loss: 34.1970\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 13.7803 - val_loss: 34.2261\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 13.4776 - val_loss: 31.6351\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 10.3246 - val_loss: 34.1725\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 10.9000 - val_loss: 31.5942\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 12.3693 - val_loss: 34.1718\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 10.3748 - val_loss: 32.5540\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 11.6499 - val_loss: 35.1131\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 11.2728 - val_loss: 33.6805\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 9.1641 - val_loss: 33.2969\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 9.6948 - val_loss: 34.2771\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 10.1652 - val_loss: 32.8263\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 10.0462 - val_loss: 33.3001\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 10.4861 - val_loss: 32.2397\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 11.3780 - val_loss: 32.1549\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 9.2450 - val_loss: 33.2209\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 8.5498 - val_loss: 32.7021\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 13.6271 - val_loss: 38.1612\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 15.2682 - val_loss: 37.7244\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 11.0619 - val_loss: 30.2523\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 11.6327 - val_loss: 36.6740\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 15.9256 - val_loss: 37.6804\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 10.6241 - val_loss: 32.3845\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 11.7722 - val_loss: 37.8119\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 11.7828 - val_loss: 33.8996\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 10.7296 - val_loss: 36.8525\n",
      "\n",
      "Mean squared error: 1.1e+01\n",
      "\n",
      "dropout: 5.6e-01\n",
      "filter_num: 207\n",
      "num_dense_layers: 11\n",
      "\n",
      "WARNING:tensorflow:Large dropout rate: 0.560476 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.560476 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.560476 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.560476 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.560476 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 1s 360us/sample - loss: 55.0621 - val_loss: 53.0883\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 71us/sample - loss: 45.0293 - val_loss: 53.5540\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 70us/sample - loss: 42.9212 - val_loss: 52.2048\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 64us/sample - loss: 42.3979 - val_loss: 52.0773\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 75us/sample - loss: 40.6617 - val_loss: 52.0013\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 71us/sample - loss: 39.7380 - val_loss: 51.4004\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 70us/sample - loss: 38.6917 - val_loss: 50.8125\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 69us/sample - loss: 38.7295 - val_loss: 51.1487\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 36.7479 - val_loss: 50.0830\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 36.9962 - val_loss: 50.2232\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 35.4582 - val_loss: 50.3424\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 33.5410 - val_loss: 49.9002\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 34.1058 - val_loss: 50.1778\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 31.8958 - val_loss: 49.7055\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 62us/sample - loss: 29.7115 - val_loss: 49.5801\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 28.7845 - val_loss: 49.0363\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 32.5759 - val_loss: 48.9264\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 67us/sample - loss: 27.3412 - val_loss: 49.0024\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 26.4559 - val_loss: 47.7615\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 27.4759 - val_loss: 47.2276\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 28.8982 - val_loss: 47.9319\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 24.8590 - val_loss: 46.0410\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 70us/sample - loss: 27.3338 - val_loss: 46.7604\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 73us/sample - loss: 26.1932 - val_loss: 46.3302\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 75us/sample - loss: 25.6947 - val_loss: 45.2533\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 21.6383 - val_loss: 45.6311\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 67us/sample - loss: 17.2316 - val_loss: 44.6343\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 20.2885 - val_loss: 45.2680\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 63us/sample - loss: 17.8068 - val_loss: 45.7269\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 72us/sample - loss: 18.5588 - val_loss: 44.8678\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 67us/sample - loss: 19.0314 - val_loss: 45.6864\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 19.3032 - val_loss: 44.8779\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 17.1432 - val_loss: 44.9839\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 19.9429 - val_loss: 45.0332\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 62us/sample - loss: 25.3994 - val_loss: 43.3696\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 75us/sample - loss: 17.2160 - val_loss: 43.4285\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 64us/sample - loss: 16.1658 - val_loss: 43.3740\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 73us/sample - loss: 17.9422 - val_loss: 42.8072\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 67us/sample - loss: 15.8426 - val_loss: 44.0326\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 63us/sample - loss: 16.7541 - val_loss: 43.5988\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 72us/sample - loss: 16.6390 - val_loss: 43.9066\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 18.4896 - val_loss: 41.3548\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 21.8211 - val_loss: 43.4723\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 19.7585 - val_loss: 44.4120\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 67us/sample - loss: 17.5112 - val_loss: 39.6051\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 16.9910 - val_loss: 42.3876\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 67us/sample - loss: 15.8832 - val_loss: 42.9969\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 67us/sample - loss: 15.3076 - val_loss: 41.0580\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 65us/sample - loss: 17.5013 - val_loss: 42.7246\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 73us/sample - loss: 17.4801 - val_loss: 42.7519\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 15.5762 - val_loss: 41.7338\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 23.4230 - val_loss: 43.6580\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 67us/sample - loss: 17.9052 - val_loss: 42.1697\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 63us/sample - loss: 17.6141 - val_loss: 42.5975\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 73us/sample - loss: 14.4942 - val_loss: 43.1293\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 73us/sample - loss: 17.7055 - val_loss: 42.2177\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 72us/sample - loss: 17.3792 - val_loss: 42.8157\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 67us/sample - loss: 15.3444 - val_loss: 40.9540\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 65us/sample - loss: 22.5970 - val_loss: 43.8850\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 72us/sample - loss: 16.8452 - val_loss: 42.8302\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 19.6789 - val_loss: 42.9487\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 63us/sample - loss: 17.9492 - val_loss: 42.6636\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 74us/sample - loss: 21.2546 - val_loss: 43.6433\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 16.4634 - val_loss: 43.5511\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 18.2595 - val_loss: 39.6323\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 67us/sample - loss: 18.4460 - val_loss: 42.7799\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 63us/sample - loss: 16.5561 - val_loss: 41.6409\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 74us/sample - loss: 18.6762 - val_loss: 41.1017\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 64us/sample - loss: 17.2664 - val_loss: 42.6769\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 73us/sample - loss: 15.1304 - val_loss: 40.8834\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 23.1009 - val_loss: 43.0955\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 63us/sample - loss: 17.3554 - val_loss: 38.4132\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 74us/sample - loss: 26.6314 - val_loss: 43.4274\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 22.2919 - val_loss: 43.1417\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 22.1883 - val_loss: 40.5204\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 18.9064 - val_loss: 41.9625\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 16.6389 - val_loss: 39.6273\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 23.1208 - val_loss: 43.5811\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 67us/sample - loss: 18.4737 - val_loss: 42.1128\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 20.0728 - val_loss: 41.1852\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 67us/sample - loss: 16.0908 - val_loss: 42.6149\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 70us/sample - loss: 17.4752 - val_loss: 41.8319\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 68us/sample - loss: 17.7373 - val_loss: 41.9579\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 15.1803 - val_loss: 41.4379\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 14.4826 - val_loss: 41.5656\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 18.5507 - val_loss: 44.0234\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 67us/sample - loss: 16.9769 - val_loss: 40.7289\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 71us/sample - loss: 21.0332 - val_loss: 44.3516\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 72us/sample - loss: 16.5943 - val_loss: 42.1448\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 74us/sample - loss: 14.9613 - val_loss: 40.8435\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 75us/sample - loss: 15.2646 - val_loss: 41.4694\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 72us/sample - loss: 27.9249 - val_loss: 45.2244\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 74us/sample - loss: 19.7431 - val_loss: 41.4222\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 72us/sample - loss: 23.2644 - val_loss: 43.3656\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 16.4063 - val_loss: 43.0490\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 67us/sample - loss: 16.8930 - val_loss: 40.8145\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 17.6406 - val_loss: 44.0231\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 20.5569 - val_loss: 42.8035\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 15.9226 - val_loss: 40.4079\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 19.0062 - val_loss: 43.5786\n",
      "\n",
      "Mean squared error: 1.9e+01\n",
      "\n",
      "dropout: 2.4e-01\n",
      "filter_num: 162\n",
      "num_dense_layers: 9\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 1s 270us/sample - loss: 58.5315 - val_loss: 48.5110\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 49us/sample - loss: 44.3211 - val_loss: 33.0268\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 39.2618 - val_loss: 33.9314\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 49us/sample - loss: 36.4945 - val_loss: 29.0318\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 49us/sample - loss: 33.3737 - val_loss: 29.5630\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 31.8684 - val_loss: 27.1587\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 28.3848 - val_loss: 28.6759\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 25.7635 - val_loss: 29.4568\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 27.3807 - val_loss: 28.8113\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 23.9738 - val_loss: 29.0709\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 21.8126 - val_loss: 28.7542\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 56us/sample - loss: 19.4133 - val_loss: 31.6631\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 17.9535 - val_loss: 30.6223\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 19.7295 - val_loss: 30.6927\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 58us/sample - loss: 16.1054 - val_loss: 28.9487\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 13.9005 - val_loss: 30.1427\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 11.6498 - val_loss: 30.0859\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 13.0078 - val_loss: 32.3173\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 12.4644 - val_loss: 30.6434\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 12.3785 - val_loss: 30.7152\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 13.8175 - val_loss: 30.6332\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 49us/sample - loss: 15.3343 - val_loss: 27.6791\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 12.8494 - val_loss: 28.1393\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 10.5836 - val_loss: 27.6049\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 9.9962 - val_loss: 28.6745\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 10.0976 - val_loss: 30.0706\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 9.0637 - val_loss: 29.4766\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 9.3958 - val_loss: 34.3905\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 49us/sample - loss: 12.8776 - val_loss: 28.8511\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 49us/sample - loss: 9.1097 - val_loss: 30.8688\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 8.5260 - val_loss: 29.9832\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 12.5632 - val_loss: 31.0759\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 12.0301 - val_loss: 31.4957\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 17.1045 - val_loss: 32.1149\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 13.2456 - val_loss: 31.6576\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 9.6709 - val_loss: 31.2282\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 49us/sample - loss: 9.0320 - val_loss: 30.8345\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 49us/sample - loss: 8.4212 - val_loss: 30.6179\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 8.9990 - val_loss: 29.6202\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 56us/sample - loss: 10.0602 - val_loss: 28.9889\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 10.4053 - val_loss: 30.5472\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 49us/sample - loss: 8.2381 - val_loss: 32.6982\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 12.4021 - val_loss: 31.5396\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 8.9973 - val_loss: 30.4360\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 9.0384 - val_loss: 30.8366\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 7.2054 - val_loss: 30.8331\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 49us/sample - loss: 7.3365 - val_loss: 31.9880\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 9.7740 - val_loss: 32.4680\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 9.5408 - val_loss: 33.0988\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 9.9377 - val_loss: 33.9005\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 9.7104 - val_loss: 34.0969\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 7.9702 - val_loss: 33.1064\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 49us/sample - loss: 9.0029 - val_loss: 32.1693\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 7.8602 - val_loss: 31.8000\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 7.9551 - val_loss: 31.8297\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 7.9825 - val_loss: 31.6484\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 50us/sample - loss: 6.6470 - val_loss: 31.9034\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 6.7787 - val_loss: 32.5688\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 49us/sample - loss: 6.7349 - val_loss: 32.1284\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 49us/sample - loss: 8.1839 - val_loss: 31.0977\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 7.6995 - val_loss: 32.5349\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 9.1888 - val_loss: 31.8072\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 7.2672 - val_loss: 32.0127\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 7.4823 - val_loss: 31.8934\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 49us/sample - loss: 7.8321 - val_loss: 31.8799\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 7.5280 - val_loss: 31.9593\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 7.3425 - val_loss: 32.5238\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 49us/sample - loss: 8.2947 - val_loss: 33.5626\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 7.7929 - val_loss: 35.4417\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 11.7125 - val_loss: 35.0596\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 59us/sample - loss: 10.9134 - val_loss: 37.6138\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 7.5544 - val_loss: 34.1905\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 49us/sample - loss: 7.3616 - val_loss: 33.0326\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 6.4008 - val_loss: 32.0652\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 5.6206 - val_loss: 33.7663\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 49us/sample - loss: 5.5860 - val_loss: 34.7000\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 49us/sample - loss: 10.2452 - val_loss: 31.9784\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 8.1361 - val_loss: 33.2782\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 57us/sample - loss: 9.0445 - val_loss: 33.7160\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 5.5287 - val_loss: 32.4906\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 6.9096 - val_loss: 32.3540\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 5.9638 - val_loss: 32.0751\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 5.8555 - val_loss: 32.9292\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 5.2155 - val_loss: 33.4028\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 57us/sample - loss: 7.1354 - val_loss: 34.9682\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 8.0671 - val_loss: 33.9317\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 8.8430 - val_loss: 32.8017\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 6.1983 - val_loss: 32.9370\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 9.1053 - val_loss: 31.1772\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 6.2479 - val_loss: 30.9472\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 49us/sample - loss: 5.3490 - val_loss: 31.7847\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 6.6349 - val_loss: 31.8061\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 4.4646 - val_loss: 32.0135\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 4.6697 - val_loss: 31.9328\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 4.9683 - val_loss: 31.7788\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 4.6282 - val_loss: 32.2436\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 5.1833 - val_loss: 32.4145\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 6.3004 - val_loss: 30.9820\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 49us/sample - loss: 5.6237 - val_loss: 33.8722\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 13.6306 - val_loss: 40.6084\n",
      "\n",
      "Mean squared error: 1.4e+01\n",
      "\n",
      "dropout: 2.7e-01\n",
      "filter_num: 290\n",
      "num_dense_layers: 14\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 1s 459us/sample - loss: 53.6886 - val_loss: 41.7157\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 120us/sample - loss: 40.9988 - val_loss: 35.6470\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 126us/sample - loss: 38.9919 - val_loss: 34.4317\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 123us/sample - loss: 36.0979 - val_loss: 35.4499\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 124us/sample - loss: 31.9946 - val_loss: 36.0391\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 125us/sample - loss: 32.3329 - val_loss: 27.7288\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 124us/sample - loss: 32.1496 - val_loss: 31.1300\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 124us/sample - loss: 26.8468 - val_loss: 36.7134\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 121us/sample - loss: 24.2103 - val_loss: 35.8529\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 122us/sample - loss: 26.1625 - val_loss: 40.7141\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 119us/sample - loss: 33.0715 - val_loss: 40.3531\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 123us/sample - loss: 22.2726 - val_loss: 39.3963\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 123us/sample - loss: 31.9529 - val_loss: 45.7064\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 123us/sample - loss: 33.5645 - val_loss: 35.0686\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 122us/sample - loss: 24.6936 - val_loss: 33.8529\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 123us/sample - loss: 25.3174 - val_loss: 32.1939\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 124us/sample - loss: 20.0753 - val_loss: 29.9844\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 122us/sample - loss: 17.8218 - val_loss: 33.8987\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 122us/sample - loss: 15.4060 - val_loss: 32.5440\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 120us/sample - loss: 12.4119 - val_loss: 31.9324\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 125us/sample - loss: 14.2405 - val_loss: 33.9559\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 123us/sample - loss: 18.3953 - val_loss: 29.9643\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 122us/sample - loss: 16.8776 - val_loss: 32.1073\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 122us/sample - loss: 16.1068 - val_loss: 32.7523\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 128us/sample - loss: 15.4630 - val_loss: 34.0853\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 135us/sample - loss: 25.7276 - val_loss: 38.5703\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 130us/sample - loss: 20.1249 - val_loss: 30.6760\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 129us/sample - loss: 13.4911 - val_loss: 31.2032\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 123us/sample - loss: 15.5024 - val_loss: 30.9747\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 122us/sample - loss: 13.5326 - val_loss: 32.9975\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 122us/sample - loss: 14.0395 - val_loss: 30.7808\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 122us/sample - loss: 14.2793 - val_loss: 28.2736\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 123us/sample - loss: 12.4204 - val_loss: 31.3030\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 123us/sample - loss: 14.0373 - val_loss: 30.2953\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 123us/sample - loss: 10.7343 - val_loss: 29.9123\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 126us/sample - loss: 10.6995 - val_loss: 31.2280\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 121us/sample - loss: 11.7652 - val_loss: 29.1869\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 125us/sample - loss: 11.7141 - val_loss: 29.5096\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 120us/sample - loss: 12.6945 - val_loss: 36.2182\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 123us/sample - loss: 15.4459 - val_loss: 29.5458\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 126us/sample - loss: 12.0528 - val_loss: 29.4325\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 123us/sample - loss: 11.0652 - val_loss: 28.6849\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 123us/sample - loss: 11.0270 - val_loss: 30.9758\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 124us/sample - loss: 10.2400 - val_loss: 30.6433\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 123us/sample - loss: 12.2629 - val_loss: 31.5663\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 121us/sample - loss: 15.1867 - val_loss: 32.0559\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 122us/sample - loss: 13.1705 - val_loss: 36.1350\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 122us/sample - loss: 18.7875 - val_loss: 32.0700\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 123us/sample - loss: 15.8717 - val_loss: 33.8904\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 124us/sample - loss: 11.9945 - val_loss: 29.5233\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 122us/sample - loss: 14.9463 - val_loss: 31.3124\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 121us/sample - loss: 11.1086 - val_loss: 28.4110\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 121us/sample - loss: 9.4283 - val_loss: 28.8712\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 124us/sample - loss: 8.6101 - val_loss: 28.4805\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 122us/sample - loss: 9.0843 - val_loss: 28.4118\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 123us/sample - loss: 12.3842 - val_loss: 31.6560\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 123us/sample - loss: 13.5452 - val_loss: 33.6576\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 124us/sample - loss: 23.6917 - val_loss: 30.5707\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 122us/sample - loss: 12.1335 - val_loss: 30.4370\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 123us/sample - loss: 11.7917 - val_loss: 29.4101\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 124us/sample - loss: 10.8247 - val_loss: 31.0217\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 123us/sample - loss: 8.3437 - val_loss: 30.0082\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 122us/sample - loss: 13.8996 - val_loss: 28.0920\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 123us/sample - loss: 18.1178 - val_loss: 37.6295\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 124us/sample - loss: 22.1560 - val_loss: 32.5709\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 121us/sample - loss: 21.2923 - val_loss: 37.6269\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 122us/sample - loss: 26.1883 - val_loss: 28.8138\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 125us/sample - loss: 17.8166 - val_loss: 31.6437\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 122us/sample - loss: 16.1457 - val_loss: 29.3193\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 120us/sample - loss: 9.8563 - val_loss: 31.2220\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 120us/sample - loss: 10.2599 - val_loss: 28.2654\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 124us/sample - loss: 10.6628 - val_loss: 28.2117\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 122us/sample - loss: 12.3613 - val_loss: 30.9119\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 122us/sample - loss: 12.4441 - val_loss: 30.7752\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 121us/sample - loss: 11.2870 - val_loss: 30.4474\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 125us/sample - loss: 9.2656 - val_loss: 31.6173\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 134us/sample - loss: 19.5107 - val_loss: 35.0636\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 130us/sample - loss: 22.9107 - val_loss: 32.8680\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 131us/sample - loss: 19.0807 - val_loss: 38.1178\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 124us/sample - loss: 18.5017 - val_loss: 34.1549\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 123us/sample - loss: 19.9405 - val_loss: 36.7898\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 124us/sample - loss: 33.5482 - val_loss: 39.4193\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 122us/sample - loss: 37.7064 - val_loss: 33.3102\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 123us/sample - loss: 27.6138 - val_loss: 29.4380\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 123us/sample - loss: 26.5452 - val_loss: 36.6957\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 123us/sample - loss: 25.4664 - val_loss: 30.7375\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 126us/sample - loss: 14.7113 - val_loss: 38.7818\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 123us/sample - loss: 13.3638 - val_loss: 34.1156\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 123us/sample - loss: 13.0951 - val_loss: 33.7286\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 123us/sample - loss: 12.9080 - val_loss: 33.0348\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 118us/sample - loss: 9.9963 - val_loss: 33.7076\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 126us/sample - loss: 10.3426 - val_loss: 33.7881\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 123us/sample - loss: 8.4240 - val_loss: 31.8124\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 122us/sample - loss: 9.2357 - val_loss: 34.9834\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 124us/sample - loss: 13.3882 - val_loss: 32.8277\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 123us/sample - loss: 10.7066 - val_loss: 33.6700\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 124us/sample - loss: 15.1937 - val_loss: 31.9287\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 121us/sample - loss: 11.6658 - val_loss: 29.5321\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 122us/sample - loss: 8.4300 - val_loss: 28.1180\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 122us/sample - loss: 9.0976 - val_loss: 28.3734\n",
      "\n",
      "Mean squared error: 9.1\n",
      "\n",
      "dropout: 2.0e-01\n",
      "filter_num: 78\n",
      "num_dense_layers: 8\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 1s 231us/sample - loss: 59.2012 - val_loss: 54.2331\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 56.0296 - val_loss: 44.6893\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 43.8502 - val_loss: 31.6972\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 26us/sample - loss: 40.9400 - val_loss: 38.7360\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 39.6580 - val_loss: 31.9090\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 36.5745 - val_loss: 28.7441\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 33.7404 - val_loss: 32.8979\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 32.1173 - val_loss: 27.3620\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 29.5244 - val_loss: 26.3318\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 30.3700 - val_loss: 29.0777\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 30.3532 - val_loss: 31.5963\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 26.1042 - val_loss: 26.6303\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 24.6592 - val_loss: 29.0452\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 23.1847 - val_loss: 29.3402\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 22.1613 - val_loss: 28.9722\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 21.6244 - val_loss: 30.1452\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 19.2615 - val_loss: 30.6649\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 20.2644 - val_loss: 33.3481\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 21.6513 - val_loss: 33.6854\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 20.0509 - val_loss: 35.1777\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 14.9454 - val_loss: 35.8333\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 13.8033 - val_loss: 37.7995\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 13.4322 - val_loss: 36.6243\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 12.2300 - val_loss: 40.4520\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 10.7314 - val_loss: 39.2719\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 10.4600 - val_loss: 39.0119\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 10.0031 - val_loss: 42.7200\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 11.7935 - val_loss: 36.4180\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 12.1726 - val_loss: 39.7006\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 11.6670 - val_loss: 37.4231\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 9.3293 - val_loss: 41.3524\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 9.6802 - val_loss: 43.4533\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 11.8189 - val_loss: 42.9516\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 13.1358 - val_loss: 47.3402\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 16.3195 - val_loss: 43.0980\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 15.3581 - val_loss: 40.5400\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 10.6078 - val_loss: 50.2023\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 14.7738 - val_loss: 39.6900\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 11.6389 - val_loss: 48.2044\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 10.0854 - val_loss: 43.6571\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 9.0648 - val_loss: 46.2161\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 7.4080 - val_loss: 48.4586\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 8.0494 - val_loss: 43.5030\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 6.9262 - val_loss: 50.0506\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 8.6717 - val_loss: 40.5079\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 9.0902 - val_loss: 47.6163\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 9.2249 - val_loss: 40.0939\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 8.6266 - val_loss: 43.4031\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 9.6319 - val_loss: 40.3394\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 9.0696 - val_loss: 39.7133\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 6.8822 - val_loss: 43.0717\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 7.0733 - val_loss: 43.4540\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.6043 - val_loss: 48.4330\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 7.3888 - val_loss: 51.6949\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 9.9452 - val_loss: 46.7053\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 7.6386 - val_loss: 50.0754\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 6.2008 - val_loss: 42.6684\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 6.0871 - val_loss: 46.7507\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 7.6869 - val_loss: 42.0210\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 7.2183 - val_loss: 41.1732\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 6.5183 - val_loss: 41.3050\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 7.4460 - val_loss: 41.8917\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 7.0185 - val_loss: 43.9033\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.6655 - val_loss: 46.7818\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 6.2655 - val_loss: 45.1150\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 6.5237 - val_loss: 43.9672\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 7.5955 - val_loss: 42.4962\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.3412 - val_loss: 43.0158\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.5520 - val_loss: 43.1347\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 5.9642 - val_loss: 44.6761\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 5.5318 - val_loss: 42.1196\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 5.8707 - val_loss: 43.0278\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 6.8274 - val_loss: 43.0550\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 6.6058 - val_loss: 41.8973\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 6.4387 - val_loss: 51.2196\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 5.9456 - val_loss: 44.2731\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.8479 - val_loss: 49.7061\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 6.5302 - val_loss: 55.5408\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 29us/sample - loss: 12.0005 - val_loss: 45.2846\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 10.4751 - val_loss: 42.8241\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 9.8085 - val_loss: 44.3796\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 6.2563 - val_loss: 42.1647\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 6.7472 - val_loss: 47.7306\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.5536 - val_loss: 45.3613\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.7341 - val_loss: 46.3441\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.0243 - val_loss: 50.8166\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.5598 - val_loss: 45.7465\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.3327 - val_loss: 46.6502\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.1161 - val_loss: 42.8546\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.2248 - val_loss: 43.8773\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.5477 - val_loss: 47.2838\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.6097 - val_loss: 43.9989\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.1353 - val_loss: 45.4983\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.4601 - val_loss: 44.1155\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.5915 - val_loss: 43.4579\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.1809 - val_loss: 43.2852\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.3787 - val_loss: 46.4884\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 5.2002 - val_loss: 45.2233\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.4571 - val_loss: 43.7327\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 4.5724 - val_loss: 46.7510\n",
      "\n",
      "Mean squared error: 4.6\n",
      "\n",
      "dropout: 3.4e-01\n",
      "filter_num: 281\n",
      "num_dense_layers: 17\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 1s 543us/sample - loss: 57.5757 - val_loss: 50.8173\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 146us/sample - loss: 48.1524 - val_loss: 47.4463\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 148us/sample - loss: 43.2259 - val_loss: 47.0712\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 143us/sample - loss: 40.6595 - val_loss: 38.8327\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 140us/sample - loss: 39.0410 - val_loss: 45.2537\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 143us/sample - loss: 37.8645 - val_loss: 38.7354\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 138us/sample - loss: 32.8978 - val_loss: 36.2958\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 140us/sample - loss: 32.8311 - val_loss: 36.2573\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 142us/sample - loss: 28.4151 - val_loss: 40.8044\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 140us/sample - loss: 30.2146 - val_loss: 30.3292\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 142us/sample - loss: 30.2506 - val_loss: 41.2343\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 142us/sample - loss: 26.5976 - val_loss: 41.8755\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 143us/sample - loss: 25.1092 - val_loss: 33.8961\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 140us/sample - loss: 23.6067 - val_loss: 35.3163\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 143us/sample - loss: 21.7596 - val_loss: 39.1594\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 143us/sample - loss: 23.2264 - val_loss: 32.5228\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 144us/sample - loss: 30.0559 - val_loss: 44.2550\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 144us/sample - loss: 39.4228 - val_loss: 41.9813\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 144us/sample - loss: 38.9410 - val_loss: 47.0336\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 148us/sample - loss: 36.3111 - val_loss: 29.5198\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 152us/sample - loss: 34.1139 - val_loss: 43.7448\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 151us/sample - loss: 29.6760 - val_loss: 33.4719\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 151us/sample - loss: 26.5381 - val_loss: 34.2151\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 143us/sample - loss: 29.3789 - val_loss: 41.1677\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 145us/sample - loss: 25.9327 - val_loss: 32.8688\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 143us/sample - loss: 22.4026 - val_loss: 37.0328\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 142us/sample - loss: 20.9027 - val_loss: 30.8964\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 139us/sample - loss: 20.7545 - val_loss: 37.7950\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 143us/sample - loss: 20.0120 - val_loss: 32.9787\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 142us/sample - loss: 21.5359 - val_loss: 32.8005\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 142us/sample - loss: 19.5082 - val_loss: 32.7578\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 138us/sample - loss: 16.5990 - val_loss: 33.0545\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 140us/sample - loss: 17.6257 - val_loss: 30.5356\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 142us/sample - loss: 19.5167 - val_loss: 37.5657\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 144us/sample - loss: 21.3521 - val_loss: 36.8606\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 140us/sample - loss: 18.9008 - val_loss: 29.2461\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 142us/sample - loss: 22.2921 - val_loss: 33.5742\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 142us/sample - loss: 17.8372 - val_loss: 32.6201\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 142us/sample - loss: 15.1389 - val_loss: 32.6093\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 143us/sample - loss: 19.3817 - val_loss: 39.9705\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 139us/sample - loss: 88.5629 - val_loss: 46.2215\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 140us/sample - loss: 50.5401 - val_loss: 52.5838\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 143us/sample - loss: 56.9614 - val_loss: 53.0292\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 146us/sample - loss: 57.1639 - val_loss: 52.6329\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 142us/sample - loss: 56.5821 - val_loss: 51.5148\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 143us/sample - loss: 55.2634 - val_loss: 49.4361\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 141us/sample - loss: 52.6043 - val_loss: 45.0751\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 141us/sample - loss: 47.6104 - val_loss: 37.1076\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 142us/sample - loss: 44.8984 - val_loss: 36.3380\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 140us/sample - loss: 43.3727 - val_loss: 37.3638\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 140us/sample - loss: 36.9269 - val_loss: 27.3626\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 142us/sample - loss: 32.2215 - val_loss: 35.0491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 142us/sample - loss: 26.8137 - val_loss: 37.1689\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 139us/sample - loss: 29.3846 - val_loss: 31.0873\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 135us/sample - loss: 25.7178 - val_loss: 36.5760\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 127us/sample - loss: 26.0497 - val_loss: 28.8082\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 136us/sample - loss: 25.8181 - val_loss: 37.5170\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 137us/sample - loss: 23.3199 - val_loss: 31.4769\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 145us/sample - loss: 20.4048 - val_loss: 30.2443\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 143us/sample - loss: 19.1047 - val_loss: 36.5544\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 140us/sample - loss: 23.8490 - val_loss: 34.3095\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 141us/sample - loss: 28.9201 - val_loss: 42.7029\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 141us/sample - loss: 42.7385 - val_loss: 41.6754\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 139us/sample - loss: 34.4201 - val_loss: 30.6619\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 144us/sample - loss: 33.5482 - val_loss: 38.9473\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 146us/sample - loss: 36.8307 - val_loss: 37.6836\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 144us/sample - loss: 43.8439 - val_loss: 33.8863\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 138us/sample - loss: 27.8423 - val_loss: 35.7941\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 140us/sample - loss: 21.0743 - val_loss: 30.8519\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 138us/sample - loss: 22.0397 - val_loss: 34.3513\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 144us/sample - loss: 20.7576 - val_loss: 31.9658\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 141us/sample - loss: 19.2469 - val_loss: 30.8685\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 139us/sample - loss: 24.0014 - val_loss: 33.4553\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 138us/sample - loss: 30.1848 - val_loss: 37.8385\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 129us/sample - loss: 32.4291 - val_loss: 38.5879\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 132us/sample - loss: 23.5585 - val_loss: 29.3403\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 133us/sample - loss: 18.1870 - val_loss: 32.8276\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 137us/sample - loss: 33.9073 - val_loss: 36.2859\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 144us/sample - loss: 21.3304 - val_loss: 31.9462\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 142us/sample - loss: 25.0093 - val_loss: 33.7738\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 141us/sample - loss: 20.7431 - val_loss: 30.3597\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 142us/sample - loss: 18.1504 - val_loss: 30.8177\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 135us/sample - loss: 20.6652 - val_loss: 34.0366\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 129us/sample - loss: 19.1342 - val_loss: 32.5100\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 132us/sample - loss: 18.9444 - val_loss: 33.7560\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 132us/sample - loss: 19.6490 - val_loss: 31.0676\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 130us/sample - loss: 21.4880 - val_loss: 36.3617\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 137us/sample - loss: 21.2442 - val_loss: 35.1384\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 142us/sample - loss: 13.6052 - val_loss: 32.5734\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 142us/sample - loss: 22.3418 - val_loss: 35.6467\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 143us/sample - loss: 17.0795 - val_loss: 31.4661\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 139us/sample - loss: 17.8097 - val_loss: 32.0795\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 136us/sample - loss: 20.8197 - val_loss: 35.4276\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 133us/sample - loss: 24.3556 - val_loss: 30.2097\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 129us/sample - loss: 27.9475 - val_loss: 34.7323\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 132us/sample - loss: 23.7258 - val_loss: 30.3214\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 136us/sample - loss: 24.9209 - val_loss: 36.0696\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 140us/sample - loss: 30.6121 - val_loss: 40.0329\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 141us/sample - loss: 32.5079 - val_loss: 33.7041\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 142us/sample - loss: 19.3247 - val_loss: 28.3956\n",
      "\n",
      "Mean squared error: 1.9e+01\n",
      "\n",
      "dropout: 2.4e-01\n",
      "filter_num: 132\n",
      "num_dense_layers: 7\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 1s 233us/sample - loss: 59.0826 - val_loss: 52.9421\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 51.0618 - val_loss: 31.5457\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 42.3816 - val_loss: 36.9515\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 41.6635 - val_loss: 35.7144\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 36.9931 - val_loss: 27.4091\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 33.9250 - val_loss: 30.5824\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 31.3454 - val_loss: 26.2470\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 31.4750 - val_loss: 28.3670\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 27.9452 - val_loss: 26.8216\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 30.8439 - val_loss: 29.7417\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 26.1229 - val_loss: 29.1742\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 22.4484 - val_loss: 30.1430\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 19.7381 - val_loss: 29.1713\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 18.1772 - val_loss: 31.9943\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 19.1525 - val_loss: 30.5639\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 18.1334 - val_loss: 29.6223\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 14.8596 - val_loss: 29.4800\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 16.0507 - val_loss: 29.5358\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 13.4226 - val_loss: 29.2250\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 10.7180 - val_loss: 29.5954\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 11.3608 - val_loss: 28.9750\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 11.0730 - val_loss: 29.1424\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 12.0509 - val_loss: 30.8632\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 16.3343 - val_loss: 29.4290\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 12.5263 - val_loss: 29.6080\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 32us/sample - loss: 10.5807 - val_loss: 30.3361\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 10.9008 - val_loss: 31.6834\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 10.6145 - val_loss: 31.6304\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 9.4906 - val_loss: 31.0918\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 8.6967 - val_loss: 30.2118\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 8.9066 - val_loss: 30.2077\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 8.5734 - val_loss: 30.6979\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 9.2564 - val_loss: 29.6645\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 7.2513 - val_loss: 29.8458\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 8.4070 - val_loss: 30.0338\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 8.3140 - val_loss: 30.9902\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 9.8994 - val_loss: 32.3179\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 9.3038 - val_loss: 32.4095\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 11.5079 - val_loss: 32.5030\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 8.4446 - val_loss: 30.0253\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 7.9133 - val_loss: 29.7750\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 5.9978 - val_loss: 29.8339\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 7.3990 - val_loss: 29.8021\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 6.2618 - val_loss: 30.6309\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 8.1387 - val_loss: 31.3682\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 5.9790 - val_loss: 32.8651\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 6.9112 - val_loss: 32.8817\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 7.1587 - val_loss: 34.4165\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 6.4458 - val_loss: 32.1291\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 6.9860 - val_loss: 33.6520\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 8.1658 - val_loss: 34.1848\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 8.3361 - val_loss: 32.0755\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 6.7249 - val_loss: 32.9796\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 8.7737 - val_loss: 33.7746\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 10.1611 - val_loss: 31.8637\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 7.1335 - val_loss: 31.8177\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 6.4539 - val_loss: 32.1225\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 6.1604 - val_loss: 32.9817\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 7.4148 - val_loss: 32.4432\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 6.2907 - val_loss: 31.8518\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 7.1260 - val_loss: 30.1575\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 5.9882 - val_loss: 30.1816\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 6.6192 - val_loss: 31.0269\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 6.2654 - val_loss: 32.4075\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 5.6725 - val_loss: 32.9663\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 5.2365 - val_loss: 34.2006\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 5.6410 - val_loss: 33.9571\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 5.0875 - val_loss: 33.8387\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 6.4349 - val_loss: 32.7733\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 5.7275 - val_loss: 32.8178\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 5.9425 - val_loss: 31.6849\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 5.6525 - val_loss: 32.0005\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 5.0046 - val_loss: 31.7936\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 4.8686 - val_loss: 32.8233\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 4.6310 - val_loss: 33.6236\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 4.8987 - val_loss: 32.7718\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 4.2578 - val_loss: 32.3365\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 4.2154 - val_loss: 32.4341\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 4.8259 - val_loss: 32.3408\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 5.7677 - val_loss: 31.6561\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 5.7651 - val_loss: 32.1965\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 7.5190 - val_loss: 30.9478\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 6.1578 - val_loss: 31.3960\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 5.9966 - val_loss: 32.5503\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 6.8186 - val_loss: 32.5964\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 8.7066 - val_loss: 31.1542\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 7.3363 - val_loss: 32.2924\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 5.9011 - val_loss: 33.8129\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 5.5376 - val_loss: 32.5038\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 5.0704 - val_loss: 32.9088\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 4.6173 - val_loss: 32.8515\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 3.8826 - val_loss: 33.0360\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 4.7855 - val_loss: 33.5968\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 4.4680 - val_loss: 32.9411\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 4.5489 - val_loss: 31.9328\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 4.6648 - val_loss: 32.0548\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 4.1697 - val_loss: 32.0547\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 4.4378 - val_loss: 31.8322\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 5.4101 - val_loss: 31.3298\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 5.2025 - val_loss: 32.6649\n",
      "\n",
      "Mean squared error: 5.2\n",
      "\n",
      "dropout: 3.0e-01\n",
      "filter_num: 272\n",
      "num_dense_layers: 16\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 1s 490us/sample - loss: 54.6891 - val_loss: 49.4801\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 114us/sample - loss: 44.2501 - val_loss: 44.3852\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 113us/sample - loss: 40.2465 - val_loss: 44.4801\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 112us/sample - loss: 38.5792 - val_loss: 33.1156\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 114us/sample - loss: 35.1385 - val_loss: 33.2710\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 118us/sample - loss: 33.3774 - val_loss: 40.1196\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 120us/sample - loss: 30.1461 - val_loss: 38.6457\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 122us/sample - loss: 29.4996 - val_loss: 32.1204\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 122us/sample - loss: 24.3127 - val_loss: 32.3556\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 121us/sample - loss: 24.7507 - val_loss: 36.5484\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 114us/sample - loss: 26.9350 - val_loss: 40.0143\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 106us/sample - loss: 26.7471 - val_loss: 39.2033\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 113us/sample - loss: 24.2177 - val_loss: 30.5965\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 114us/sample - loss: 22.6952 - val_loss: 36.7925\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 112us/sample - loss: 27.6025 - val_loss: 40.3522\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 117us/sample - loss: 22.5164 - val_loss: 40.7483\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 103us/sample - loss: 31.7054 - val_loss: 35.1813\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 120us/sample - loss: 28.0749 - val_loss: 41.8749\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 112us/sample - loss: 34.2969 - val_loss: 40.5776\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 110us/sample - loss: 41.2689 - val_loss: 47.6137\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 112us/sample - loss: 43.8662 - val_loss: 40.6996\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 110us/sample - loss: 27.3473 - val_loss: 31.1448\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 108us/sample - loss: 16.9892 - val_loss: 30.4990\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 113us/sample - loss: 23.7067 - val_loss: 39.2036\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 105us/sample - loss: 26.4926 - val_loss: 29.2955\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 117us/sample - loss: 15.4638 - val_loss: 36.2495\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 111us/sample - loss: 17.2263 - val_loss: 31.3298\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 110us/sample - loss: 17.3053 - val_loss: 32.3338\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 111us/sample - loss: 13.9310 - val_loss: 36.1572\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 108us/sample - loss: 21.5056 - val_loss: 31.0643\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 115us/sample - loss: 16.8914 - val_loss: 36.0145\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 112us/sample - loss: 19.6457 - val_loss: 38.1094\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 111us/sample - loss: 20.9208 - val_loss: 31.4635\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 114us/sample - loss: 19.2844 - val_loss: 38.4267\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 115us/sample - loss: 17.6496 - val_loss: 32.5061\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 111us/sample - loss: 18.9836 - val_loss: 39.5041\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 112us/sample - loss: 24.1820 - val_loss: 30.1154\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 105us/sample - loss: 21.6676 - val_loss: 40.9070\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 112us/sample - loss: 23.5525 - val_loss: 30.2721\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 111us/sample - loss: 18.2454 - val_loss: 38.8403\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 106us/sample - loss: 19.5844 - val_loss: 38.9168\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 112us/sample - loss: 27.8209 - val_loss: 44.1384\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 110us/sample - loss: 36.6438 - val_loss: 37.0086\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 112us/sample - loss: 21.8123 - val_loss: 33.0456\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 112us/sample - loss: 16.4383 - val_loss: 30.6780\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 109us/sample - loss: 19.6062 - val_loss: 40.1233\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 112us/sample - loss: 28.6191 - val_loss: 33.0252\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 112us/sample - loss: 15.7470 - val_loss: 34.0807\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 111us/sample - loss: 13.7998 - val_loss: 31.4923\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 109us/sample - loss: 22.8816 - val_loss: 32.9560\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 109us/sample - loss: 13.7514 - val_loss: 33.6992\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 115us/sample - loss: 14.1959 - val_loss: 31.2372\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 111us/sample - loss: 12.5337 - val_loss: 31.8547\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 110us/sample - loss: 19.3091 - val_loss: 35.1115\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 111us/sample - loss: 17.2589 - val_loss: 34.7519\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 107us/sample - loss: 14.2111 - val_loss: 36.1940\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 113us/sample - loss: 11.6083 - val_loss: 33.8631\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 111us/sample - loss: 17.0407 - val_loss: 37.1456\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 105us/sample - loss: 16.4765 - val_loss: 33.5950\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 115us/sample - loss: 16.3416 - val_loss: 30.6533\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 112us/sample - loss: 20.9487 - val_loss: 37.8177\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 116us/sample - loss: 14.4380 - val_loss: 35.8974\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 125us/sample - loss: 21.6324 - val_loss: 32.2675\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 120us/sample - loss: 14.2891 - val_loss: 35.5292\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 119us/sample - loss: 14.0862 - val_loss: 34.7898\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 123us/sample - loss: 16.9616 - val_loss: 32.0383\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 111us/sample - loss: 14.9383 - val_loss: 36.6498\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 110us/sample - loss: 17.5723 - val_loss: 33.7622\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 110us/sample - loss: 20.6621 - val_loss: 33.1969\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 109us/sample - loss: 15.6096 - val_loss: 36.7123\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 114us/sample - loss: 20.8600 - val_loss: 32.9847\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 111us/sample - loss: 13.8852 - val_loss: 31.9808\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 109us/sample - loss: 20.6706 - val_loss: 39.8798\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 114us/sample - loss: 24.5297 - val_loss: 33.0480\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 110us/sample - loss: 18.7522 - val_loss: 36.5450\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 110us/sample - loss: 60.1496 - val_loss: 47.0189\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 109us/sample - loss: 50.0969 - val_loss: 46.8727\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 114us/sample - loss: 49.3635 - val_loss: 44.0079\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 111us/sample - loss: 44.6524 - val_loss: 37.2728\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 111us/sample - loss: 36.1846 - val_loss: 29.9649\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 108us/sample - loss: 20.2250 - val_loss: 32.2173\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 109us/sample - loss: 17.4905 - val_loss: 34.2890\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 112us/sample - loss: 17.2451 - val_loss: 33.2011\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 110us/sample - loss: 17.0942 - val_loss: 34.7630\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 111us/sample - loss: 31.7075 - val_loss: 38.2044\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 107us/sample - loss: 29.4065 - val_loss: 32.3913\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 112us/sample - loss: 24.8338 - val_loss: 35.5743\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 109us/sample - loss: 21.5229 - val_loss: 33.9804\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 113us/sample - loss: 16.8700 - val_loss: 34.6614\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 108us/sample - loss: 17.2409 - val_loss: 35.7158\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 113us/sample - loss: 17.9170 - val_loss: 34.0714\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 112us/sample - loss: 16.7357 - val_loss: 33.8589\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 110us/sample - loss: 18.1487 - val_loss: 33.9602\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 107us/sample - loss: 12.1757 - val_loss: 32.3372\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 109us/sample - loss: 19.2526 - val_loss: 32.9820\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 111us/sample - loss: 15.0944 - val_loss: 33.1699\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 114us/sample - loss: 17.3223 - val_loss: 32.8712\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 110us/sample - loss: 17.1622 - val_loss: 33.8631\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 104us/sample - loss: 12.9427 - val_loss: 33.8527\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 111us/sample - loss: 21.1476 - val_loss: 36.4659\n",
      "\n",
      "Mean squared error: 2.1e+01\n",
      "\n",
      "dropout: 2.2e-01\n",
      "filter_num: 204\n",
      "num_dense_layers: 16\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 1s 496us/sample - loss: 54.9310 - val_loss: 35.4990\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 80us/sample - loss: 48.2474 - val_loss: 51.2186\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 83us/sample - loss: 49.7231 - val_loss: 36.1724\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 83us/sample - loss: 42.8993 - val_loss: 44.3391\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 83us/sample - loss: 41.2867 - val_loss: 32.6991\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 80us/sample - loss: 37.6334 - val_loss: 38.6309\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 81us/sample - loss: 34.4645 - val_loss: 32.0343\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 86us/sample - loss: 31.8684 - val_loss: 30.9779\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 82us/sample - loss: 28.3472 - val_loss: 35.6393\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 79us/sample - loss: 28.4495 - val_loss: 35.3665\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 80us/sample - loss: 26.6567 - val_loss: 35.6630\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 83us/sample - loss: 26.7016 - val_loss: 28.9542\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 79us/sample - loss: 21.6586 - val_loss: 32.3857\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 83us/sample - loss: 21.9938 - val_loss: 37.7012\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 84us/sample - loss: 20.9903 - val_loss: 37.7281\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 86us/sample - loss: 33.9691 - val_loss: 41.5464\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 83us/sample - loss: 23.2006 - val_loss: 36.5718\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 80us/sample - loss: 21.3590 - val_loss: 41.1418\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 82us/sample - loss: 26.9470 - val_loss: 40.4668\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 83us/sample - loss: 21.0043 - val_loss: 30.9887\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 79us/sample - loss: 21.3510 - val_loss: 30.7096\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 80us/sample - loss: 19.2548 - val_loss: 30.3791\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 85us/sample - loss: 22.8849 - val_loss: 40.0242\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 79us/sample - loss: 31.7884 - val_loss: 32.6484\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 74us/sample - loss: 22.3288 - val_loss: 31.4581\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 88us/sample - loss: 22.6689 - val_loss: 30.3326\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 77us/sample - loss: 19.5037 - val_loss: 31.9964\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 90us/sample - loss: 19.0279 - val_loss: 30.1873\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 83us/sample - loss: 18.2883 - val_loss: 37.2721\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 76us/sample - loss: 32.6098 - val_loss: 41.4795\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 91us/sample - loss: 29.8713 - val_loss: 29.8701\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 85us/sample - loss: 15.5666 - val_loss: 31.0351\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 74us/sample - loss: 12.3904 - val_loss: 30.8460\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 85us/sample - loss: 16.5165 - val_loss: 31.3967\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 78us/sample - loss: 14.9401 - val_loss: 31.3705\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 78us/sample - loss: 14.2645 - val_loss: 32.1695\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 82us/sample - loss: 11.4063 - val_loss: 32.3983\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 82us/sample - loss: 11.8253 - val_loss: 32.2474\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 81us/sample - loss: 14.7359 - val_loss: 32.9601\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 80us/sample - loss: 13.7409 - val_loss: 30.5364\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 85us/sample - loss: 12.0254 - val_loss: 30.3459\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 83us/sample - loss: 10.5232 - val_loss: 30.7635\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 80us/sample - loss: 11.0861 - val_loss: 30.8929\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 79us/sample - loss: 9.9562 - val_loss: 31.2343\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 80us/sample - loss: 9.4096 - val_loss: 31.5505\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 79us/sample - loss: 10.5186 - val_loss: 31.3187\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 80us/sample - loss: 9.9726 - val_loss: 33.4186\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 78us/sample - loss: 10.6731 - val_loss: 31.4723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 84us/sample - loss: 11.6384 - val_loss: 33.4187\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 84us/sample - loss: 13.2405 - val_loss: 33.3825\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 80us/sample - loss: 14.3249 - val_loss: 31.1810\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 81us/sample - loss: 10.8794 - val_loss: 34.1905\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 81us/sample - loss: 11.4394 - val_loss: 31.6983\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 83us/sample - loss: 10.7197 - val_loss: 32.6853\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 75us/sample - loss: 9.7893 - val_loss: 31.3379\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 86us/sample - loss: 8.5907 - val_loss: 32.5719\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 83us/sample - loss: 8.8626 - val_loss: 31.0713\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 84us/sample - loss: 9.4971 - val_loss: 32.3221\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 86us/sample - loss: 9.2200 - val_loss: 32.7520\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 81us/sample - loss: 10.2223 - val_loss: 33.0189\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 89us/sample - loss: 8.7950 - val_loss: 32.5971\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 80us/sample - loss: 9.1730 - val_loss: 32.0168\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 79us/sample - loss: 9.0920 - val_loss: 32.1878\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 83us/sample - loss: 6.8913 - val_loss: 42.5439\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 84us/sample - loss: 18.4932 - val_loss: 39.3107\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 76us/sample - loss: 18.2998 - val_loss: 35.3680\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 86us/sample - loss: 28.6236 - val_loss: 40.3132\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 80us/sample - loss: 43.1860 - val_loss: 48.2421\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 76us/sample - loss: 51.7856 - val_loss: 47.6605\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 91us/sample - loss: 49.5352 - val_loss: 39.1577\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 81us/sample - loss: 39.2917 - val_loss: 29.3340\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 85us/sample - loss: 28.6919 - val_loss: 29.6742\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 87us/sample - loss: 21.9778 - val_loss: 33.2976\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 90us/sample - loss: 19.3135 - val_loss: 30.2918\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 90us/sample - loss: 21.6622 - val_loss: 30.4951\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 91us/sample - loss: 21.6861 - val_loss: 30.1998\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 92us/sample - loss: 18.2659 - val_loss: 29.6474\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 82us/sample - loss: 14.3902 - val_loss: 29.8220\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 81us/sample - loss: 18.5991 - val_loss: 33.8094\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 84us/sample - loss: 17.2124 - val_loss: 40.7709\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 82us/sample - loss: 21.2031 - val_loss: 32.2472\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 74us/sample - loss: 14.7279 - val_loss: 32.9345\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 73us/sample - loss: 16.3538 - val_loss: 29.6652\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 86us/sample - loss: 18.3829 - val_loss: 28.6737\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 79us/sample - loss: 13.5440 - val_loss: 27.7476\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 79us/sample - loss: 19.6243 - val_loss: 28.7973\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 82us/sample - loss: 14.0221 - val_loss: 30.6639\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 83us/sample - loss: 13.1412 - val_loss: 28.4180\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 80us/sample - loss: 11.1342 - val_loss: 29.0372\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 75us/sample - loss: 8.7457 - val_loss: 27.3460\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 88us/sample - loss: 12.7570 - val_loss: 28.9279\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 83us/sample - loss: 11.4007 - val_loss: 30.7832\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 83us/sample - loss: 11.9824 - val_loss: 29.4212\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 80us/sample - loss: 11.2362 - val_loss: 28.5717\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 80us/sample - loss: 9.8072 - val_loss: 29.0209\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 80us/sample - loss: 8.2479 - val_loss: 30.1719\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 80us/sample - loss: 9.6160 - val_loss: 31.0762\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 74us/sample - loss: 23.8648 - val_loss: 35.2801\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 84us/sample - loss: 20.6773 - val_loss: 29.7492\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 82us/sample - loss: 17.5383 - val_loss: 30.1128\n",
      "\n",
      "Mean squared error: 1.8e+01\n",
      "\n",
      "dropout: 4.4e-01\n",
      "filter_num: 221\n",
      "num_dense_layers: 20\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 1s 565us/sample - loss: 54.8620 - val_loss: 52.2634\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 109us/sample - loss: 48.4805 - val_loss: 53.7690\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 105us/sample - loss: 44.9856 - val_loss: 50.4178\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 109us/sample - loss: 43.4630 - val_loss: 51.8840\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 103us/sample - loss: 40.1189 - val_loss: 49.3867\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 104us/sample - loss: 39.1256 - val_loss: 50.9711\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 103us/sample - loss: 41.0618 - val_loss: 49.7743\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 95us/sample - loss: 41.3219 - val_loss: 50.7636\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 107us/sample - loss: 43.9106 - val_loss: 50.4750\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 108us/sample - loss: 35.6902 - val_loss: 45.8284\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 110us/sample - loss: 36.8014 - val_loss: 49.1088\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 112us/sample - loss: 36.3322 - val_loss: 46.2033\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 113us/sample - loss: 30.7106 - val_loss: 47.6087\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 112us/sample - loss: 29.4558 - val_loss: 47.6822\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 100us/sample - loss: 30.1186 - val_loss: 46.3809\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 105us/sample - loss: 40.4012 - val_loss: 48.5575\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 106us/sample - loss: 30.9458 - val_loss: 46.0692\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 103us/sample - loss: 31.8808 - val_loss: 47.7008\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 99us/sample - loss: 28.9904 - val_loss: 43.8595\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 104us/sample - loss: 31.4290 - val_loss: 47.3521\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 108us/sample - loss: 31.6050 - val_loss: 41.7115\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 107us/sample - loss: 32.7441 - val_loss: 46.4042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 106us/sample - loss: 29.4154 - val_loss: 44.5891\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 98us/sample - loss: 23.2022 - val_loss: 43.2557\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 103us/sample - loss: 26.2553 - val_loss: 43.1875\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 104us/sample - loss: 44.6436 - val_loss: 46.6639\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 102us/sample - loss: 34.0262 - val_loss: 44.5351\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 102us/sample - loss: 26.6011 - val_loss: 43.7642\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 99us/sample - loss: 28.9767 - val_loss: 43.3948\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 107us/sample - loss: 24.6487 - val_loss: 43.4914\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 104us/sample - loss: 20.7657 - val_loss: 37.7250\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 105us/sample - loss: 33.5086 - val_loss: 46.1613\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 97us/sample - loss: 28.1588 - val_loss: 41.4013\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 109us/sample - loss: 27.5097 - val_loss: 43.1546\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 104us/sample - loss: 24.0183 - val_loss: 42.0604\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 106us/sample - loss: 25.5577 - val_loss: 44.9852\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 104us/sample - loss: 30.8366 - val_loss: 44.1834\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 103us/sample - loss: 25.0187 - val_loss: 44.6410\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 104us/sample - loss: 34.1279 - val_loss: 48.3927\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 105us/sample - loss: 40.3756 - val_loss: 44.0357\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 104us/sample - loss: 38.6015 - val_loss: 45.4254\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 109us/sample - loss: 40.5880 - val_loss: 47.7708\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 104us/sample - loss: 43.7833 - val_loss: 44.9679\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 107us/sample - loss: 35.1963 - val_loss: 37.2823\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 102us/sample - loss: 25.9923 - val_loss: 40.5869\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 106us/sample - loss: 27.3433 - val_loss: 37.4518\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 103us/sample - loss: 25.4005 - val_loss: 42.2021\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 105us/sample - loss: 28.6024 - val_loss: 40.6629\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 105us/sample - loss: 25.8107 - val_loss: 41.1435\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 108us/sample - loss: 24.7215 - val_loss: 40.1335\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 105us/sample - loss: 23.1044 - val_loss: 40.7938\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 105us/sample - loss: 26.8861 - val_loss: 40.9171\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 102us/sample - loss: 20.2464 - val_loss: 40.9441\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 106us/sample - loss: 23.5285 - val_loss: 39.9827\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 103us/sample - loss: 28.7028 - val_loss: 41.6943\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 105us/sample - loss: 24.2182 - val_loss: 41.7580\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 102us/sample - loss: 29.3909 - val_loss: 43.0372\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 106us/sample - loss: 22.0050 - val_loss: 37.8689\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 105us/sample - loss: 24.0966 - val_loss: 42.5333\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 107us/sample - loss: 23.4657 - val_loss: 37.9028\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 104us/sample - loss: 23.4150 - val_loss: 42.5935\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 105us/sample - loss: 24.2309 - val_loss: 39.3313\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 103us/sample - loss: 26.6218 - val_loss: 43.8376\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 108us/sample - loss: 24.1574 - val_loss: 38.7293\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 105us/sample - loss: 25.1126 - val_loss: 42.0300\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 105us/sample - loss: 22.1628 - val_loss: 40.0540\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 105us/sample - loss: 24.5211 - val_loss: 41.2311\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 104us/sample - loss: 22.1670 - val_loss: 39.8726\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 101us/sample - loss: 22.3634 - val_loss: 40.7047\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 109us/sample - loss: 23.8377 - val_loss: 41.5647\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 117us/sample - loss: 21.7292 - val_loss: 40.2734\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 116us/sample - loss: 19.7231 - val_loss: 41.0702\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 116us/sample - loss: 21.7608 - val_loss: 39.1729\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 112us/sample - loss: 31.2926 - val_loss: 44.7175\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 98us/sample - loss: 36.0051 - val_loss: 44.8572\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 110us/sample - loss: 33.3902 - val_loss: 38.8650\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 101us/sample - loss: 62.0224 - val_loss: 43.2859\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 109us/sample - loss: 38.5258 - val_loss: 46.1234\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 105us/sample - loss: 42.0713 - val_loss: 43.9272\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 105us/sample - loss: 31.7736 - val_loss: 39.3223\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 103us/sample - loss: 28.3789 - val_loss: 42.9917\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 104us/sample - loss: 90.3675 - val_loss: 44.1730\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 107us/sample - loss: 37.2837 - val_loss: 45.9331\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 104us/sample - loss: 34.8520 - val_loss: 36.9029\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 104us/sample - loss: 31.0900 - val_loss: 45.0504\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 103us/sample - loss: 29.0279 - val_loss: 39.1559\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 103us/sample - loss: 41.8524 - val_loss: 43.5942\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 102us/sample - loss: 29.5775 - val_loss: 36.4779\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 102us/sample - loss: 40.1245 - val_loss: 43.4642\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 102us/sample - loss: 34.3201 - val_loss: 40.2873\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 100us/sample - loss: 26.6107 - val_loss: 39.1019\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 105us/sample - loss: 26.0086 - val_loss: 40.2859\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 100us/sample - loss: 29.5933 - val_loss: 38.4521\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 98us/sample - loss: 31.1819 - val_loss: 40.6369\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 105us/sample - loss: 29.3943 - val_loss: 42.9384\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 104us/sample - loss: 26.3029 - val_loss: 37.8233\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 103us/sample - loss: 38.8791 - val_loss: 42.7648\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 106us/sample - loss: 33.9501 - val_loss: 42.1245\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 102us/sample - loss: 30.3080 - val_loss: 40.2401\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 102us/sample - loss: 31.7347 - val_loss: 44.5996\n",
      "\n",
      "Mean squared error: 3.2e+01\n",
      "\n",
      "dropout: 2.0e-01\n",
      "filter_num: 300\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 113us/sample - loss: 50.4356 - val_loss: 32.0676\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 41.2632 - val_loss: 30.8990\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 37.5883 - val_loss: 30.0634\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 34.0202 - val_loss: 27.8571\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 30.3749 - val_loss: 27.3993\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 28.8186 - val_loss: 26.8582\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 26.5559 - val_loss: 27.8347\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 23.3321 - val_loss: 28.6572\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 22.5599 - val_loss: 30.0323\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 19.7938 - val_loss: 29.3358\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 18.4802 - val_loss: 31.0580\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 15.2938 - val_loss: 30.7409\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 13.4699 - val_loss: 31.9815\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 11.3013 - val_loss: 34.8850\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 10.1459 - val_loss: 32.1635\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 9.5631 - val_loss: 38.3931\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 8.8145 - val_loss: 36.9706\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 8.0279 - val_loss: 38.1473\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 7.8744 - val_loss: 47.7832\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 7.5766 - val_loss: 37.0750\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 6.8815 - val_loss: 38.8122\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.7964 - val_loss: 35.0649\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.0592 - val_loss: 35.1009\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.3566 - val_loss: 37.7888\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.6226 - val_loss: 36.5701\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.2455 - val_loss: 41.3117\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.3353 - val_loss: 35.0198\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.1945 - val_loss: 39.9980\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.7061 - val_loss: 37.0535\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 4.0730 - val_loss: 39.1215\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.1524 - val_loss: 39.8323\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.7162 - val_loss: 36.6517\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 3.0265 - val_loss: 40.4602\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.9051 - val_loss: 38.5294\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.9178 - val_loss: 42.0041\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 3.0945 - val_loss: 40.5810\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.5815 - val_loss: 41.6411\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.4437 - val_loss: 40.5494\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 2.0826 - val_loss: 42.0598\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.1079 - val_loss: 39.1792\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.3060 - val_loss: 41.7463\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.1054 - val_loss: 40.4941\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.9814 - val_loss: 40.8012\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.0521 - val_loss: 38.9310\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.1610 - val_loss: 37.9845\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 2.3064 - val_loss: 39.3329\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.0336 - val_loss: 37.7137\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.0021 - val_loss: 38.5273\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 1.8908 - val_loss: 38.6742\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.2177 - val_loss: 40.8648\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.3946 - val_loss: 37.6752\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.1675 - val_loss: 41.8506\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.0008 - val_loss: 38.3367\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.1097 - val_loss: 42.4953\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.5331 - val_loss: 37.0159\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.2302 - val_loss: 40.1784\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.1570 - val_loss: 36.2568\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.1593 - val_loss: 40.5011\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.0389 - val_loss: 39.3129\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.9462 - val_loss: 38.6034\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 1.6903 - val_loss: 37.3585\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.8117 - val_loss: 38.1953\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.9004 - val_loss: 39.8525\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.6640 - val_loss: 36.9187\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.8597 - val_loss: 38.6735\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.9933 - val_loss: 37.7056\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.2462 - val_loss: 39.8615\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.8364 - val_loss: 37.7837\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 2.3621 - val_loss: 41.5571\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.6043 - val_loss: 38.4514\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.8137 - val_loss: 39.8486\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.8273 - val_loss: 37.5000\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.8562 - val_loss: 37.6717\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 1.4829 - val_loss: 38.9467\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.4639 - val_loss: 39.0232\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.3706 - val_loss: 39.5255\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 1.2955 - val_loss: 39.3326\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 1.1981 - val_loss: 37.2005\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 1.1080 - val_loss: 37.6705\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.1086 - val_loss: 37.7673\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 1.0896 - val_loss: 37.9996\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.0878 - val_loss: 37.3599\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 1.3797 - val_loss: 36.7543\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.0848 - val_loss: 36.4386\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.2380 - val_loss: 36.7169\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.3673 - val_loss: 38.0672\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 1.4847 - val_loss: 37.5841\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.6294 - val_loss: 38.5990\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.3792 - val_loss: 36.8658\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.4212 - val_loss: 39.4830\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.5753 - val_loss: 37.4767\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 1.2531 - val_loss: 37.2324\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.3191 - val_loss: 35.7892\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.1787 - val_loss: 36.6713\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.1510 - val_loss: 36.0999\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 0.9960 - val_loss: 37.5672\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 1.1132 - val_loss: 34.7206\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.3110 - val_loss: 36.9214\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 1.0751 - val_loss: 36.0580\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 1.2581 - val_loss: 37.5024\n",
      "\n",
      "Mean squared error: 1.3\n",
      "\n",
      "dropout: 2.0e-01\n",
      "filter_num: 10\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 91us/sample - loss: 59.3518 - val_loss: 55.0807\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 59.1701 - val_loss: 54.8148\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 58.8611 - val_loss: 54.3609\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 58.3416 - val_loss: 53.6208\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 57.4430 - val_loss: 52.4008\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 56.0100 - val_loss: 50.4449\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 53.8518 - val_loss: 47.5330\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 50.3487 - val_loss: 43.2613\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 46.2856 - val_loss: 37.7960\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 40.8423 - val_loss: 32.2216\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 37.4841 - val_loss: 28.6061\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 33.6667 - val_loss: 27.4777\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 32.6822 - val_loss: 26.7453\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 31.0575 - val_loss: 26.5176\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 30.2610 - val_loss: 26.7644\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 30.4139 - val_loss: 26.2227\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 30.8047 - val_loss: 25.6018\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 29.1228 - val_loss: 25.7370\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 27.8369 - val_loss: 25.7380\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 27.4628 - val_loss: 25.8407\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 26.8188 - val_loss: 25.7325\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 27.4371 - val_loss: 25.6436\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 26.6344 - val_loss: 25.7836\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 26.2759 - val_loss: 25.8349\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 26.7793 - val_loss: 25.8609\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 25.9137 - val_loss: 25.9523\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 24.9750 - val_loss: 26.0758\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 27.9867 - val_loss: 26.1949\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 24.4710 - val_loss: 26.2989\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 23.7788 - val_loss: 26.5248\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 23.4770 - val_loss: 26.5364\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 24.7133 - val_loss: 26.5862\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 24.0626 - val_loss: 26.8563\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 21.3979 - val_loss: 26.9241\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 25.1031 - val_loss: 27.0386\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 24.2077 - val_loss: 27.0627\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 22.5590 - val_loss: 27.2348\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 23.4416 - val_loss: 27.5122\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 22.2322 - val_loss: 27.9263\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 21.4708 - val_loss: 29.0114\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 22.1052 - val_loss: 30.2260\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 21.2979 - val_loss: 31.6491\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 23.4387 - val_loss: 31.8427\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 22.3475 - val_loss: 32.2928\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 9us/sample - loss: 21.0408 - val_loss: 33.2319\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 20.0696 - val_loss: 34.6488\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 19.2509 - val_loss: 36.1485\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 19.3334 - val_loss: 37.3524\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 18.8093 - val_loss: 37.7976\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 18.6540 - val_loss: 39.0361\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 18.9804 - val_loss: 41.2104\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 18.0129 - val_loss: 43.2072\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 16.7314 - val_loss: 45.7237\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 16.3444 - val_loss: 48.2191\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 16.7394 - val_loss: 50.8159\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 16.5784 - val_loss: 53.9398\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 15.2625 - val_loss: 56.9158\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 15.1342 - val_loss: 59.7380\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 13.8477 - val_loss: 63.8851\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 13.6480 - val_loss: 67.3479\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 14.0109 - val_loss: 73.6779\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 14.5610 - val_loss: 86.1855\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 12.8152 - val_loss: 91.6038\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 15.9830 - val_loss: 94.9637\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 14.1354 - val_loss: 100.9959\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 11.6696 - val_loss: 107.3830\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 12.9179 - val_loss: 117.3002\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 10.1920 - val_loss: 123.2677\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 12.6030 - val_loss: 129.7157\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 10.6856 - val_loss: 132.9897\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 11.4738 - val_loss: 138.7410\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 10.5564 - val_loss: 147.0584\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 10.4749 - val_loss: 152.8803\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 10.2989 - val_loss: 158.4871\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 9.5232 - val_loss: 165.5541\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 9.8793 - val_loss: 166.5833\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 8.1817 - val_loss: 169.0415\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 10.4638 - val_loss: 165.7565\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 9.4671 - val_loss: 166.8011\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 11.2513 - val_loss: 171.2784\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 10.3118 - val_loss: 183.1473\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 8.9142 - val_loss: 197.3393\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 9.3568 - val_loss: 211.9427\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 7.5732 - val_loss: 223.8568\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 8.6436 - val_loss: 223.1837\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 8.6373 - val_loss: 228.5356\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 8.1815 - val_loss: 226.7916\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 7.1630 - val_loss: 209.8280\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 8.7711 - val_loss: 212.5148\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 7.2841 - val_loss: 225.4623\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 8.9406 - val_loss: 238.7649\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 8.2071 - val_loss: 255.3351\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 8.1573 - val_loss: 279.0205\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 7.6458 - val_loss: 295.0767\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 9.2758 - val_loss: 300.7697\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 7.0020 - val_loss: 294.3481\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 6.1831 - val_loss: 270.4039\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 7.9478 - val_loss: 265.2666\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 6.9368 - val_loss: 270.1767\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 6.8057 - val_loss: 277.6440\n",
      "\n",
      "Mean squared error: 6.8\n",
      "\n",
      "dropout: 2.0e-01\n",
      "filter_num: 300\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kat\\anaconda3\\envs\\tensor\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 112us/sample - loss: 51.7759 - val_loss: 31.9532\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 39.8983 - val_loss: 29.7963\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 35.8988 - val_loss: 28.0847\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 33.0093 - val_loss: 27.1023\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 30.0069 - val_loss: 26.6018\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 26.6898 - val_loss: 27.3068\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 23.9030 - val_loss: 29.9346\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 21.8219 - val_loss: 29.8298\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 20.0362 - val_loss: 35.2509\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 17.9955 - val_loss: 32.2438\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 15.5938 - val_loss: 34.2795\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 13.7167 - val_loss: 35.3768\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 12.0625 - val_loss: 40.5295\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 9.6583 - val_loss: 43.7013\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 9.4794 - val_loss: 57.4874\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 8.6463 - val_loss: 37.9058\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 9.7603 - val_loss: 78.2539\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 9.6701 - val_loss: 36.9653\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 11.7639 - val_loss: 64.3217\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 9.9449 - val_loss: 36.8088\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 11.5082 - val_loss: 40.2213\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 8.6587 - val_loss: 49.4066\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 7.3139 - val_loss: 40.8112\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 6.7765 - val_loss: 63.2312\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.6203 - val_loss: 42.8805\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 6.2634 - val_loss: 47.7247\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.8838 - val_loss: 51.7612\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 4.2575 - val_loss: 46.4883\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.9817 - val_loss: 49.0779\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.3521 - val_loss: 46.4926\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.7942 - val_loss: 45.5397\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.1107 - val_loss: 46.8674\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.2494 - val_loss: 56.7299\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.1995 - val_loss: 53.7090\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 8.6986 - val_loss: 49.4323\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.4516 - val_loss: 47.7121\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.9342 - val_loss: 42.7259\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.4763 - val_loss: 43.5240\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.8886 - val_loss: 47.1074\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.5571 - val_loss: 44.1294\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 3.2236 - val_loss: 50.3819\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.1576 - val_loss: 45.8896\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.5648 - val_loss: 50.9632\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.7876 - val_loss: 47.3806\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.3791 - val_loss: 52.8798\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.3826 - val_loss: 48.1982\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.5739 - val_loss: 52.8596\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.1823 - val_loss: 51.2401\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.1839 - val_loss: 50.1977\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.2630 - val_loss: 49.2424\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.0772 - val_loss: 49.9141\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.6449 - val_loss: 50.7793\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.6512 - val_loss: 50.2978\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.7510 - val_loss: 49.9275\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.0667 - val_loss: 51.2363\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.8021 - val_loss: 48.8963\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.9703 - val_loss: 48.4331\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.5968 - val_loss: 50.8731\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.6144 - val_loss: 51.6934\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.2423 - val_loss: 51.3806\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.6215 - val_loss: 49.7298\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.0696 - val_loss: 50.5969\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.9793 - val_loss: 50.5890\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.6331 - val_loss: 51.3849\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.6781 - val_loss: 50.9750\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.6895 - val_loss: 50.3833\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.9340 - val_loss: 50.2189\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.7313 - val_loss: 48.9177\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.8337 - val_loss: 48.6989\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.9960 - val_loss: 47.8885\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.7077 - val_loss: 49.5816\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.4365 - val_loss: 48.4572\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.1016 - val_loss: 48.7901\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.7463 - val_loss: 49.9536\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 2.5059 - val_loss: 50.9731\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.9352 - val_loss: 49.8281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.7299 - val_loss: 50.3409\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 1.3708 - val_loss: 49.9438\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.8452 - val_loss: 52.2134\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.7744 - val_loss: 50.1463\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.3185 - val_loss: 52.2331\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.5984 - val_loss: 49.0660\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.5355 - val_loss: 49.8062\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.4533 - val_loss: 47.2400\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.1538 - val_loss: 47.8754\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.1081 - val_loss: 48.6415\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.5266 - val_loss: 49.2831\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.2049 - val_loss: 49.0511\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 1.7663 - val_loss: 50.3829\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.4900 - val_loss: 49.8377\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 1.3897 - val_loss: 49.7861\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.5095 - val_loss: 47.0678\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.6274 - val_loss: 49.9792\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.2973 - val_loss: 50.8816\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.6099 - val_loss: 48.6748\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.1537 - val_loss: 55.1256\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 7.7944 - val_loss: 52.5733\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.7455 - val_loss: 50.1452\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.1216 - val_loss: 51.8299\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.5012 - val_loss: 47.3679\n",
      "\n",
      "Mean squared error: 2.5\n",
      "\n",
      "dropout: 2.0e-01\n",
      "filter_num: 300\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kat\\anaconda3\\envs\\tensor\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 110us/sample - loss: 53.2248 - val_loss: 32.3167\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 39.7436 - val_loss: 29.2839\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 36.3736 - val_loss: 28.2304\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 33.6701 - val_loss: 26.0726\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 30.9075 - val_loss: 25.8707\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 28.4335 - val_loss: 26.3067\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 25.5220 - val_loss: 27.6146\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 23.4398 - val_loss: 30.5360\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 21.1392 - val_loss: 30.7841\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 19.8826 - val_loss: 34.6154\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 17.1548 - val_loss: 31.6580\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 16.1223 - val_loss: 35.0807\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 14.3186 - val_loss: 30.8455\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 12.5754 - val_loss: 39.6686\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 10.8634 - val_loss: 31.2975\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 10.2852 - val_loss: 42.4544\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 8.6094 - val_loss: 33.7985\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 7.1227 - val_loss: 42.4353\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 7.0629 - val_loss: 35.9927\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.8942 - val_loss: 39.7583\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.7087 - val_loss: 35.3079\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 5.0085 - val_loss: 36.1037\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 5.4902 - val_loss: 38.5238\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.2214 - val_loss: 36.4326\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.6444 - val_loss: 38.6516\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 4.6017 - val_loss: 37.8836\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 4.0892 - val_loss: 40.2761\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 3.8231 - val_loss: 38.6030\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.8109 - val_loss: 35.9314\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 3.3400 - val_loss: 35.7450\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.7189 - val_loss: 40.5418\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 3.8442 - val_loss: 33.8429\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 3.4281 - val_loss: 38.1048\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 2.9024 - val_loss: 35.3853\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.5962 - val_loss: 36.8447\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 2.4250 - val_loss: 35.6502\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 2.3469 - val_loss: 37.6173\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.2381 - val_loss: 34.6329\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.2290 - val_loss: 37.3076\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.1180 - val_loss: 37.8361\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 1.8862 - val_loss: 38.6305\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.6318 - val_loss: 36.3746\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 2.7078 - val_loss: 39.5084\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 2.0184 - val_loss: 37.1534\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 2.0197 - val_loss: 37.5414\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 1.6954 - val_loss: 35.7348\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.0044 - val_loss: 36.0586\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.9710 - val_loss: 37.1326\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.7340 - val_loss: 36.5144\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.8608 - val_loss: 34.3944\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.8762 - val_loss: 37.2566\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.4010 - val_loss: 36.3265\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.9288 - val_loss: 37.8136\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.3147 - val_loss: 34.4445\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 2.2933 - val_loss: 40.6163\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 2.4155 - val_loss: 34.0397\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.6656 - val_loss: 41.4366\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.2344 - val_loss: 34.5252\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.9160 - val_loss: 38.5295\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.7578 - val_loss: 35.6890\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.7433 - val_loss: 37.3156\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.7440 - val_loss: 40.1562\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 4.3132 - val_loss: 39.7496\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.0568 - val_loss: 39.3095\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.2391 - val_loss: 35.4090\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.6577 - val_loss: 39.9432\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.9888 - val_loss: 37.4485\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 1.6508 - val_loss: 39.4544\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.3520 - val_loss: 38.0427\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.3237 - val_loss: 38.1306\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.6882 - val_loss: 36.4861\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.4369 - val_loss: 36.7319\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.2942 - val_loss: 38.5369\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.2462 - val_loss: 40.6459\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.0394 - val_loss: 39.1207\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.0708 - val_loss: 39.0832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.1662 - val_loss: 38.0570\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 0.9993 - val_loss: 38.8352\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 1.1045 - val_loss: 38.5243\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 1.0653 - val_loss: 39.2700\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.2451 - val_loss: 38.1541\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.1104 - val_loss: 38.2963\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.0918 - val_loss: 42.0170\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.7361 - val_loss: 38.3717\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.1635 - val_loss: 42.8044\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.6300 - val_loss: 35.0353\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.4091 - val_loss: 40.6573\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.4833 - val_loss: 35.6284\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.0466 - val_loss: 41.3308\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.4669 - val_loss: 38.0594\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 1.3636 - val_loss: 39.4335\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.8475 - val_loss: 38.1467\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.4439 - val_loss: 36.0241\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.3817 - val_loss: 38.9895\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.7501 - val_loss: 38.4319\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.5466 - val_loss: 41.7045\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.5047 - val_loss: 36.8416\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.4239 - val_loss: 37.2296\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 1.3406 - val_loss: 35.8502\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.0810 - val_loss: 38.2330\n",
      "\n",
      "Mean squared error: 1.1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kat\\anaconda3\\envs\\tensor\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropout: 2.0e-01\n",
      "filter_num: 300\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 111us/sample - loss: 53.9591 - val_loss: 33.7542\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 41.3397 - val_loss: 30.5167\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 38.3407 - val_loss: 30.4475\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 34.3811 - val_loss: 28.2716\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 31.9806 - val_loss: 26.8558\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 28.7127 - val_loss: 27.3757\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 25.8084 - val_loss: 30.3431\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 24.0008 - val_loss: 30.7014\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 21.8123 - val_loss: 30.2031\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 19.1575 - val_loss: 35.6377\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 16.9697 - val_loss: 31.6805\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 14.7641 - val_loss: 34.3558\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 13.2154 - val_loss: 35.1360\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 11.4296 - val_loss: 44.5318\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 11.3578 - val_loss: 38.0861\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 10.6739 - val_loss: 50.2132\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 10.3046 - val_loss: 40.0675\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 9.9166 - val_loss: 46.4380\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 8.3340 - val_loss: 40.5117\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 7.7484 - val_loss: 40.3644\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.9363 - val_loss: 44.9231\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.8376 - val_loss: 43.7993\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.5194 - val_loss: 47.6490\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.7596 - val_loss: 46.7508\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.4638 - val_loss: 51.2764\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 4.6646 - val_loss: 48.0779\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 4.7869 - val_loss: 50.3305\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.1628 - val_loss: 46.5263\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.1945 - val_loss: 47.7356\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.4027 - val_loss: 49.0283\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.1741 - val_loss: 45.1644\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.1437 - val_loss: 50.9009\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.8431 - val_loss: 44.2249\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 4.0273 - val_loss: 50.5141\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.1393 - val_loss: 44.4994\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.7801 - val_loss: 52.3466\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.6412 - val_loss: 44.2163\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.6335 - val_loss: 44.4783\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.6310 - val_loss: 39.0810\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.9866 - val_loss: 45.6703\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.0529 - val_loss: 46.0302\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.4677 - val_loss: 49.7389\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.9861 - val_loss: 45.6207\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.8002 - val_loss: 45.4674\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.6811 - val_loss: 43.0327\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.8143 - val_loss: 47.1694\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.7995 - val_loss: 42.9633\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.8281 - val_loss: 46.8779\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.9680 - val_loss: 42.4383\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.6021 - val_loss: 47.4720\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 2.3607 - val_loss: 40.4841\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.2742 - val_loss: 43.2319\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.9514 - val_loss: 41.8817\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.8895 - val_loss: 43.7391\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.0489 - val_loss: 42.6040\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.8843 - val_loss: 43.0635\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.7283 - val_loss: 42.4890\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.1705 - val_loss: 42.2046\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.6694 - val_loss: 42.8041\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.8122 - val_loss: 44.5380\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 1.6831 - val_loss: 44.8153\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.7351 - val_loss: 44.4689\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.6006 - val_loss: 44.4555\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.5083 - val_loss: 45.5728\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.5524 - val_loss: 44.1828\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.2955 - val_loss: 44.8064\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.4558 - val_loss: 42.6933\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.6483 - val_loss: 43.7100\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.6476 - val_loss: 43.6779\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 1.6008 - val_loss: 43.6098\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.7501 - val_loss: 45.5675\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 1.5336 - val_loss: 45.8085\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.4271 - val_loss: 47.2371\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.3953 - val_loss: 45.9071\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.2736 - val_loss: 44.3417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.3574 - val_loss: 44.7529\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 1.1160 - val_loss: 44.8095\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.2149 - val_loss: 44.7322\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.1813 - val_loss: 45.6947\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.3756 - val_loss: 44.3278\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.2260 - val_loss: 40.6980\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.6302 - val_loss: 43.6482\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.7090 - val_loss: 42.3852\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.4873 - val_loss: 46.8475\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.7491 - val_loss: 43.8768\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.4735 - val_loss: 44.2781\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.1492 - val_loss: 42.7598\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.2194 - val_loss: 47.1253\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.1507 - val_loss: 43.6212\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.3175 - val_loss: 48.8248\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.7454 - val_loss: 43.3533\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.2071 - val_loss: 46.0513\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.1108 - val_loss: 41.1225\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.6594 - val_loss: 45.6042\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.7025 - val_loss: 42.3741\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.3182 - val_loss: 47.6301\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.3803 - val_loss: 43.6834\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.9193 - val_loss: 46.0726\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.7292 - val_loss: 42.9081\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 1.2816 - val_loss: 45.2041\n",
      "\n",
      "Mean squared error: 1.3\n",
      "\n",
      "dropout: 2.0e-01\n",
      "filter_num: 211\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 104us/sample - loss: 54.8065 - val_loss: 36.3409\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 41.4447 - val_loss: 30.4459\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 37.9304 - val_loss: 28.7077\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 35.0739 - val_loss: 27.9134\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 31.9815 - val_loss: 26.3392\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 30.9875 - val_loss: 25.5323\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 27.9843 - val_loss: 26.2384\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 25.8602 - val_loss: 27.3291\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 24.3057 - val_loss: 27.1224\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 22.5440 - val_loss: 28.9360\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 20.6524 - val_loss: 30.0821\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 19.3784 - val_loss: 32.0573\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 18.0828 - val_loss: 33.8780\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 15.2719 - val_loss: 34.0301\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 14.1101 - val_loss: 34.8791\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 12.3904 - val_loss: 40.5406\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 12.2483 - val_loss: 34.3834\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 10.8904 - val_loss: 40.0175\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 9.0759 - val_loss: 38.7866\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 7.7093 - val_loss: 38.9675\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 7.5534 - val_loss: 43.2386\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 6.9734 - val_loss: 36.2880\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 8.3339 - val_loss: 41.3403\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 7.5796 - val_loss: 36.0121\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 6.6750 - val_loss: 42.4912\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 6.7392 - val_loss: 38.7409\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 6.1185 - val_loss: 39.6126\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 5.1679 - val_loss: 43.7810\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 4.7628 - val_loss: 41.1688\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 4.8561 - val_loss: 48.4982\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 4.7293 - val_loss: 38.6911\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 4.6373 - val_loss: 42.1322\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 4.7805 - val_loss: 38.1721\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 4.7147 - val_loss: 45.3603\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 4.6967 - val_loss: 44.5174\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 4.8143 - val_loss: 47.6663\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 4.0836 - val_loss: 43.3898\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.0140 - val_loss: 45.0139\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.7265 - val_loss: 42.7530\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 3.1674 - val_loss: 45.0595\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.9062 - val_loss: 44.3088\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.8230 - val_loss: 44.1602\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.6237 - val_loss: 43.1062\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.6869 - val_loss: 48.5573\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.8883 - val_loss: 47.0917\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.7257 - val_loss: 49.5375\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.5049 - val_loss: 44.4173\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.8224 - val_loss: 48.2141\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.5110 - val_loss: 43.8571\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.2799 - val_loss: 49.0780\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.3678 - val_loss: 44.7339\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.1607 - val_loss: 48.3949\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.1284 - val_loss: 43.3205\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.3733 - val_loss: 51.3037\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.3434 - val_loss: 46.8900\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.5704 - val_loss: 53.7476\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.1390 - val_loss: 47.8022\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.8126 - val_loss: 49.8531\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.0221 - val_loss: 43.3339\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.0389 - val_loss: 46.0639\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.0802 - val_loss: 44.5159\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.1873 - val_loss: 46.9153\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.2067 - val_loss: 47.2472\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.8791 - val_loss: 48.9325\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.7869 - val_loss: 45.1525\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.7973 - val_loss: 48.5819\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.3998 - val_loss: 43.9584\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.8306 - val_loss: 49.0955\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.3380 - val_loss: 45.8051\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.9688 - val_loss: 50.8075\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.9325 - val_loss: 46.2835\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.8312 - val_loss: 46.7530\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.8619 - val_loss: 44.3094\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.8647 - val_loss: 45.6408\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.8170 - val_loss: 46.3446\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.6896 - val_loss: 44.5767\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.8741 - val_loss: 45.9313\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.6571 - val_loss: 42.3999\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.7253 - val_loss: 46.1339\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.7404 - val_loss: 41.4889\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.0304 - val_loss: 40.4266\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.4241 - val_loss: 39.0445\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.4283 - val_loss: 38.1399\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.3233 - val_loss: 41.1345\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.7123 - val_loss: 43.7333\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.8167 - val_loss: 47.9804\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.8551 - val_loss: 44.5812\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.1374 - val_loss: 50.7636\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.1000 - val_loss: 41.3982\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.4301 - val_loss: 46.3116\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.8040 - val_loss: 41.2222\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.8312 - val_loss: 45.8394\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.7641 - val_loss: 41.7170\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.8398 - val_loss: 45.2069\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.7770 - val_loss: 42.4398\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.8417 - val_loss: 47.2024\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.8645 - val_loss: 43.9349\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.5139 - val_loss: 44.0321\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.3137 - val_loss: 43.9815\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.6069 - val_loss: 42.4706\n",
      "\n",
      "Mean squared error: 1.6\n",
      "\n",
      "dropout: 2.0e-01\n",
      "filter_num: 300\n",
      "num_dense_layers: 2\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 139us/sample - loss: 51.3128 - val_loss: 32.7780\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 40.8522 - val_loss: 35.3650\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 40.4347 - val_loss: 30.0018\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 36.6072 - val_loss: 27.3285\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 31.5799 - val_loss: 27.5332\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 28.6904 - val_loss: 27.3265\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 26.7354 - val_loss: 27.1964\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 23.3220 - val_loss: 30.1547\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 21.0626 - val_loss: 29.8012\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 19.1352 - val_loss: 33.6676\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 15.9835 - val_loss: 31.4467\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 14.2482 - val_loss: 36.5530\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 11.5997 - val_loss: 35.2193\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 11.3133 - val_loss: 34.6420\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 8.7242 - val_loss: 36.5318\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 7.8353 - val_loss: 38.1425\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 6.6463 - val_loss: 33.1525\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 6.5233 - val_loss: 32.0897\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 6.8607 - val_loss: 44.2476\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 7.0699 - val_loss: 33.8053\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 7.1073 - val_loss: 34.2758\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 7.1654 - val_loss: 32.7940\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 5.7285 - val_loss: 33.5935\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 33us/sample - loss: 5.3399 - val_loss: 37.6921\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 5.4802 - val_loss: 33.2404\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 5.2397 - val_loss: 39.8448\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 5.6880 - val_loss: 33.5586\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 4.5181 - val_loss: 37.4650\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 4.1818 - val_loss: 34.7849\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 4.3997 - val_loss: 36.7114\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 4.3231 - val_loss: 35.1529\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 4.1911 - val_loss: 34.4090\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 3.7379 - val_loss: 42.2177\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 4.2509 - val_loss: 37.5471\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 4.2973 - val_loss: 40.0922\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 3.8493 - val_loss: 35.7391\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 3.8885 - val_loss: 37.2275\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 3.3264 - val_loss: 37.0880\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 3.5978 - val_loss: 35.2605\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 3.9642 - val_loss: 37.0309\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 3.3773 - val_loss: 34.8224\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 3.1753 - val_loss: 36.1529\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 2.9025 - val_loss: 36.7402\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 2.6900 - val_loss: 35.4250\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 2.3435 - val_loss: 38.3788\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 2.9729 - val_loss: 36.5885\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 4.4750 - val_loss: 38.2800\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 4.3806 - val_loss: 34.7092\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 3.3609 - val_loss: 39.2507\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 2.7525 - val_loss: 35.0297\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 2.5477 - val_loss: 37.3301\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 2.6738 - val_loss: 33.9403\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 2.0536 - val_loss: 34.9856\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 1.9734 - val_loss: 34.5712\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 2.0121 - val_loss: 36.1217\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 1.7778 - val_loss: 36.9585\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 1.7623 - val_loss: 37.7632\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 1.9852 - val_loss: 37.6475\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 1.9927 - val_loss: 37.9801\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 2.4581 - val_loss: 37.4608\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 3.2047 - val_loss: 36.9965\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 4.0972 - val_loss: 40.4315\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 4.0492 - val_loss: 36.2869\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 5.0545 - val_loss: 40.6974\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 3.3871 - val_loss: 38.3843\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 2.4410 - val_loss: 40.0329\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 2.3769 - val_loss: 40.0046\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 2.7719 - val_loss: 38.5455\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 1.9133 - val_loss: 40.0024\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 2.0961 - val_loss: 36.3191\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 1.8218 - val_loss: 38.3730\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 1.4146 - val_loss: 37.1395\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 1.5270 - val_loss: 36.6334\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 2.5820 - val_loss: 39.5008\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 2.4196 - val_loss: 37.2779\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 2.2948 - val_loss: 42.0994\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 2.6211 - val_loss: 39.1718\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 2.5115 - val_loss: 41.3332\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 1.9925 - val_loss: 38.8653\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 1.6472 - val_loss: 39.8322\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 2.1089 - val_loss: 36.5783\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 1.6464 - val_loss: 39.1114\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 1.6462 - val_loss: 38.4008\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 1.7105 - val_loss: 40.9805\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 1.6436 - val_loss: 39.2454\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 1.5281 - val_loss: 38.0392\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 1.4183 - val_loss: 39.6258\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 1.3332 - val_loss: 38.8078\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 1.8160 - val_loss: 39.0888\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 1.6074 - val_loss: 45.8294\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 7.5041 - val_loss: 41.2612\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 12.2840 - val_loss: 35.1290\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 5.0850 - val_loss: 40.5652\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 3.1322 - val_loss: 42.3921\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 3.3365 - val_loss: 43.1739\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 2.8845 - val_loss: 39.7820\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 2.9800 - val_loss: 38.7711\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 2.1425 - val_loss: 41.2517\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 1.6475 - val_loss: 39.7228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 2.1271 - val_loss: 42.0866\n",
      "\n",
      "Mean squared error: 2.1\n",
      "\n",
      "dropout: 3.3e-01\n",
      "filter_num: 300\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 112us/sample - loss: 51.3537 - val_loss: 31.7666\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 41.9596 - val_loss: 30.7822\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 37.2886 - val_loss: 29.5988\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 34.6984 - val_loss: 27.0335\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 31.2174 - val_loss: 26.6288\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 29.5067 - val_loss: 26.6553\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 26.4140 - val_loss: 30.2061\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 23.9348 - val_loss: 29.0510\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 22.8669 - val_loss: 31.8926\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 20.5824 - val_loss: 31.0569\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 18.5264 - val_loss: 32.1093\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 16.2337 - val_loss: 34.2642\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 16.3084 - val_loss: 32.3220\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 13.9206 - val_loss: 44.5715\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 12.3062 - val_loss: 34.5869\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 10.7581 - val_loss: 39.1439\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 8.9833 - val_loss: 41.6249\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 8.2391 - val_loss: 39.7042\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 7.9660 - val_loss: 42.3861\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 6.8897 - val_loss: 40.3314\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 6.5762 - val_loss: 41.1722\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 6.3946 - val_loss: 38.5256\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 5.8184 - val_loss: 39.0256\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.8034 - val_loss: 40.6223\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.8708 - val_loss: 44.5997\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 6.3960 - val_loss: 38.6084\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.3665 - val_loss: 45.8963\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 11.6196 - val_loss: 37.8677\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 9.8264 - val_loss: 38.7710\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 7.3286 - val_loss: 43.2855\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.2660 - val_loss: 37.7515\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.7733 - val_loss: 43.2321\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.0585 - val_loss: 42.0835\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.8887 - val_loss: 42.5006\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.4932 - val_loss: 41.2524\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.6229 - val_loss: 43.5346\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.7889 - val_loss: 41.2995\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.5360 - val_loss: 40.1970\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.6645 - val_loss: 39.8615\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.3658 - val_loss: 39.7669\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.7479 - val_loss: 42.5874\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.4098 - val_loss: 43.1494\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.1186 - val_loss: 45.9732\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.1164 - val_loss: 41.5142\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.7412 - val_loss: 41.8929\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.6089 - val_loss: 41.0378\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.5885 - val_loss: 41.1031\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.4562 - val_loss: 40.8590\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 2.7413 - val_loss: 41.9505\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.4292 - val_loss: 44.0356\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 2.6522 - val_loss: 43.9585\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.6330 - val_loss: 44.7806\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.3451 - val_loss: 42.0905\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.1185 - val_loss: 44.6259\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.1083 - val_loss: 43.9300\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.3069 - val_loss: 42.5892\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.6047 - val_loss: 40.2899\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.3516 - val_loss: 39.6727\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.9179 - val_loss: 40.0096\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 3.0300 - val_loss: 38.3962\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 4.8768 - val_loss: 35.3462\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.0986 - val_loss: 35.7037\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.6285 - val_loss: 34.6172\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.9125 - val_loss: 36.5741\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.4166 - val_loss: 36.0864\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.2305 - val_loss: 41.0066\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 3.1924 - val_loss: 38.2393\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 3.0830 - val_loss: 38.9166\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.8938 - val_loss: 38.6866\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.0232 - val_loss: 36.3557\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.5696 - val_loss: 38.0382\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.8226 - val_loss: 37.1998\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.2064 - val_loss: 37.2933\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.5528 - val_loss: 39.7959\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.9195 - val_loss: 38.9542\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.5077 - val_loss: 42.6031\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.5806 - val_loss: 41.7452\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.3382 - val_loss: 43.7788\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.3025 - val_loss: 41.8752\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.8329 - val_loss: 41.4158\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.9586 - val_loss: 39.9776\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.0141 - val_loss: 43.9861\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.7327 - val_loss: 44.5537\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 3.0688 - val_loss: 46.0065\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.6534 - val_loss: 44.1949\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.8884 - val_loss: 41.5262\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.8928 - val_loss: 43.2362\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.9604 - val_loss: 42.7778\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 1.7051 - val_loss: 43.2204\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.7650 - val_loss: 42.6369\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.7643 - val_loss: 46.1508\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.9055 - val_loss: 45.1748\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 2.6417 - val_loss: 42.4687\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.9297 - val_loss: 43.8509\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.7929 - val_loss: 41.9742\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.6513 - val_loss: 46.8929\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.5779 - val_loss: 45.6784\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.4823 - val_loss: 48.3341\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.5098 - val_loss: 44.7776\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.7026 - val_loss: 44.4204\n",
      "\n",
      "Mean squared error: 1.7\n",
      "\n",
      "dropout: 6.7e-01\n",
      "filter_num: 10\n",
      "num_dense_layers: 13\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 1s 315us/sample - loss: 59.3763 - val_loss: 55.1713\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 59.2957 - val_loss: 55.0973\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 59.0865 - val_loss: 55.0156\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 59.0532 - val_loss: 54.9272\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 59.0037 - val_loss: 54.8395\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 58.8795 - val_loss: 54.7503\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 58.7029 - val_loss: 54.6598\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 59.4545 - val_loss: 54.5798\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 58.5247 - val_loss: 54.5113\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 59.5314 - val_loss: 54.4472\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 58.3678 - val_loss: 54.3841\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 59.8495 - val_loss: 54.3242\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 58.3963 - val_loss: 54.2564\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 58.0496 - val_loss: 54.1785\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 58.1021 - val_loss: 54.0929\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 58.1245 - val_loss: 54.0069\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 58.1252 - val_loss: 53.9221\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 57.6587 - val_loss: 53.8317\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 57.6588 - val_loss: 53.7318\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 57.7346 - val_loss: 53.6252\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 59.6693 - val_loss: 53.5575\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 57.5021 - val_loss: 53.4629\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 57.7071 - val_loss: 53.3698\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 57.3074 - val_loss: 53.2677\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 57.3330 - val_loss: 53.1669\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 57.2453 - val_loss: 53.0532\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 57.8919 - val_loss: 52.9786\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 56.8856 - val_loss: 52.8778\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 57.9117 - val_loss: 52.8013\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 56.5687 - val_loss: 52.7141\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 56.4834 - val_loss: 52.6119\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 56.7297 - val_loss: 52.5252\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 56.6075 - val_loss: 52.4113\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 56.2407 - val_loss: 52.2757\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 55.8581 - val_loss: 52.1153\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 55.8509 - val_loss: 51.9402\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 55.9251 - val_loss: 51.7512\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 55.8655 - val_loss: 51.5695\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 56.7330 - val_loss: 51.4306\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 55.4778 - val_loss: 51.2518\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 60.1524 - val_loss: 51.1394\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 54.9648 - val_loss: 51.1056\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 55.0026 - val_loss: 50.9840\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 55.0903 - val_loss: 50.8321\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 55.0381 - val_loss: 50.6447\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 54.1830 - val_loss: 50.4405\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 54.4236 - val_loss: 50.1930\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 17us/sample - loss: 54.0972 - val_loss: 49.9351\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 54.0247 - val_loss: 49.6826\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 53.9637 - val_loss: 49.4328\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 52.4981 - val_loss: 49.1683\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 53.1902 - val_loss: 48.8702\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 53.1773 - val_loss: 48.6458\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 53.8363 - val_loss: 48.5550\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 52.7452 - val_loss: 48.3952\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 52.7155 - val_loss: 48.1258\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 53.1616 - val_loss: 47.8846\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 51.9454 - val_loss: 47.5709\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 51.6379 - val_loss: 47.2569\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 50.9478 - val_loss: 46.8623\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 51.8073 - val_loss: 46.4308\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 50.1843 - val_loss: 46.3548\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 50.9937 - val_loss: 46.0734\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 50.2605 - val_loss: 45.7379\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 57.4148 - val_loss: 45.6841\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 50.5424 - val_loss: 45.5881\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 49.9143 - val_loss: 45.3087\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 49.9051 - val_loss: 45.0141\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 52.8132 - val_loss: 44.8210\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 49.5982 - val_loss: 44.5876\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 49.5066 - val_loss: 44.2584\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 49.5971 - val_loss: 43.8936\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 49.4615 - val_loss: 43.5579\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 49.4264 - val_loss: 43.3198\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 48.3076 - val_loss: 42.9863\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 49.0627 - val_loss: 42.6708\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 49.2285 - val_loss: 42.3792\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 48.4834 - val_loss: 42.1193\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 48.1684 - val_loss: 41.8055\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 48.9187 - val_loss: 41.5725\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 52.3471 - val_loss: 41.6230\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 48.4445 - val_loss: 41.7818\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 48.0062 - val_loss: 41.7477\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 48.4930 - val_loss: 41.5847\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 48.3701 - val_loss: 41.4174\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 48.0014 - val_loss: 41.2449\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 47.3066 - val_loss: 41.0368\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 47.1903 - val_loss: 40.8338\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 47.5971 - val_loss: 40.5944\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 46.8242 - val_loss: 40.3510\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 47.8989 - val_loss: 40.1990\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 47.0756 - val_loss: 40.0563\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 50.3259 - val_loss: 40.0764\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 47.5643 - val_loss: 40.0550\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 46.6578 - val_loss: 39.9868\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 46.1823 - val_loss: 39.8476\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 47.5206 - val_loss: 39.7480\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 46.7698 - val_loss: 39.6592\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 47.6053 - val_loss: 39.5563\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 46.8914 - val_loss: 39.4487\n",
      "\n",
      "Mean squared error: 4.7e+01\n",
      "\n",
      "dropout: 2.0e-01\n",
      "filter_num: 10\n",
      "num_dense_layers: 5\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 156us/sample - loss: 59.3870 - val_loss: 55.1762\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 59.3249 - val_loss: 55.1086\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 59.2603 - val_loss: 55.0336\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 59.1871 - val_loss: 54.9471\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 59.0982 - val_loss: 54.8384\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 58.9719 - val_loss: 54.6869\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 58.7819 - val_loss: 54.4521\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 58.4581 - val_loss: 54.0385\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 57.8376 - val_loss: 53.2475\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 56.5711 - val_loss: 51.6968\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 54.2751 - val_loss: 48.7048\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 50.6438 - val_loss: 43.4625\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 45.4312 - val_loss: 36.0808\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 40.9645 - val_loss: 31.0575\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 40.4532 - val_loss: 31.4673\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 38.3947 - val_loss: 32.8425\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 37.5717 - val_loss: 32.6688\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 35.8369 - val_loss: 30.9624\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 32.2676 - val_loss: 28.9513\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 35.5532 - val_loss: 29.7438\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 32.4874 - val_loss: 30.9204\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 12us/sample - loss: 33.0233 - val_loss: 31.5909\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 34.7480 - val_loss: 31.7547\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 32.2505 - val_loss: 30.1910\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 32.0994 - val_loss: 30.2983\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 32.1310 - val_loss: 31.0989\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 28.3982 - val_loss: 31.5109\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 33.9042 - val_loss: 31.3437\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 30.4049 - val_loss: 31.2474\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 30.0153 - val_loss: 31.2738\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 32.3181 - val_loss: 31.4640\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 29.0184 - val_loss: 31.8095\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 29.8605 - val_loss: 32.2435\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 28.4858 - val_loss: 31.8151\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 24.9037 - val_loss: 30.7147\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 25.4805 - val_loss: 29.9704\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 27.8368 - val_loss: 30.9444\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 28.3738 - val_loss: 31.7783\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 27.0235 - val_loss: 32.4917\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 28.4850 - val_loss: 32.1936\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 24.0044 - val_loss: 31.4023\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 25.7033 - val_loss: 31.2570\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 24.8675 - val_loss: 31.4791\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 23.0700 - val_loss: 32.4834\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 23.7610 - val_loss: 32.5526\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 21.0265 - val_loss: 31.7319\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 23.4449 - val_loss: 31.9090\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 23.0595 - val_loss: 33.2105\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 19.4735 - val_loss: 34.2329\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 21.4900 - val_loss: 34.2445\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - ETA: 0s - loss: 17.76 - 0s 12us/sample - loss: 21.8079 - val_loss: 34.8787\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 22.0308 - val_loss: 36.5492\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 23.0341 - val_loss: 38.0138\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 23.1178 - val_loss: 39.1431\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 19.5411 - val_loss: 40.4763\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 17.9212 - val_loss: 42.6030\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 20.4890 - val_loss: 45.4745\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 21.9865 - val_loss: 46.3705\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 19.8501 - val_loss: 52.3688\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 17.1842 - val_loss: 55.0055\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 18.4503 - val_loss: 58.1753\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 17.7757 - val_loss: 61.9310\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 16.6593 - val_loss: 60.6317\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 17.3611 - val_loss: 61.5739\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 16.9564 - val_loss: 69.0647\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 15.8725 - val_loss: 75.3311\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 17.2891 - val_loss: 82.4083\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 16.9977 - val_loss: 101.9450\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 15.9337 - val_loss: 98.6580\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 15.1491 - val_loss: 102.4751\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 15.2523 - val_loss: 108.4332\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 14.5562 - val_loss: 102.3498\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 17.2983 - val_loss: 94.0031\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 12.0344 - val_loss: 102.6973\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 16.5515 - val_loss: 111.4390\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 14.5605 - val_loss: 113.5287\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 18.0126 - val_loss: 106.2005\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 14.3889 - val_loss: 94.0228\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 13.5640 - val_loss: 94.6855\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 15.1615 - val_loss: 103.9206\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 13.1316 - val_loss: 111.6570\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 14.9309 - val_loss: 117.9272\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 15.4322 - val_loss: 108.5282\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 12.5797 - val_loss: 117.3647\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 14.9926 - val_loss: 121.6903\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 15.2232 - val_loss: 117.2242\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 11.6046 - val_loss: 121.8514\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 13.5727 - val_loss: 123.7455\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 13.6770 - val_loss: 133.6980\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 12.9752 - val_loss: 139.8217\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 10.6440 - val_loss: 130.3728\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 11.3647 - val_loss: 137.4354\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 10.3432 - val_loss: 130.2751\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 11.9936 - val_loss: 104.5503\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 12.1502 - val_loss: 99.1921\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 13.9500 - val_loss: 103.9808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 13.9397 - val_loss: 107.3966\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 11.7072 - val_loss: 110.5892\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 12.5759 - val_loss: 116.9497\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 13.0941 - val_loss: 127.7880\n",
      "\n",
      "Mean squared error: 1.3e+01\n",
      "\n",
      "dropout: 2.0e-01\n",
      "filter_num: 300\n",
      "num_dense_layers: 13\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 1s 423us/sample - loss: 68.4099 - val_loss: 45.3402\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 121us/sample - loss: 53.5334 - val_loss: 54.2341\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 114us/sample - loss: 58.2464 - val_loss: 54.0665\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 111us/sample - loss: 58.0378 - val_loss: 53.4212\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 118us/sample - loss: 57.0497 - val_loss: 50.7837\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 113us/sample - loss: 47.4537 - val_loss: 31.3162\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 116us/sample - loss: 43.9295 - val_loss: 40.8245\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 114us/sample - loss: 39.3214 - val_loss: 28.5701\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 114us/sample - loss: 37.7027 - val_loss: 33.1078\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 114us/sample - loss: 34.6153 - val_loss: 27.3834\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 115us/sample - loss: 27.8748 - val_loss: 28.6247\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 117us/sample - loss: 29.6954 - val_loss: 37.2045\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 117us/sample - loss: 27.2607 - val_loss: 29.9964\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 112us/sample - loss: 32.6672 - val_loss: 37.0657\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 116us/sample - loss: 28.1049 - val_loss: 28.4643\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 120us/sample - loss: 28.2980 - val_loss: 28.9035\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 117us/sample - loss: 23.4095 - val_loss: 31.8002\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 124us/sample - loss: 25.0232 - val_loss: 31.2146\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 122us/sample - loss: 22.5273 - val_loss: 29.9934\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 122us/sample - loss: 21.1184 - val_loss: 34.3788\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 116us/sample - loss: 18.8474 - val_loss: 29.4072\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 114us/sample - loss: 17.1261 - val_loss: 29.6307\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 113us/sample - loss: 14.9525 - val_loss: 31.9801\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 114us/sample - loss: 12.0857 - val_loss: 29.3624\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 112us/sample - loss: 11.6680 - val_loss: 29.7141\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 114us/sample - loss: 11.9325 - val_loss: 28.9626\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 115us/sample - loss: 11.0596 - val_loss: 36.1213\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 112us/sample - loss: 13.5362 - val_loss: 36.3994\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 115us/sample - loss: 13.4132 - val_loss: 30.5351\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 117us/sample - loss: 10.8871 - val_loss: 30.0748\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 115us/sample - loss: 9.6658 - val_loss: 30.8336\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 114us/sample - loss: 10.7448 - val_loss: 32.3430\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 113us/sample - loss: 8.2633 - val_loss: 30.7442\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 115us/sample - loss: 9.6893 - val_loss: 29.8307\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 111us/sample - loss: 8.3788 - val_loss: 30.5866\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 115us/sample - loss: 19.6477 - val_loss: 34.1373\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 114us/sample - loss: 18.4552 - val_loss: 29.3894\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 113us/sample - loss: 12.3424 - val_loss: 30.1339\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 114us/sample - loss: 11.4654 - val_loss: 31.1799\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 115us/sample - loss: 11.5555 - val_loss: 32.3991\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 112us/sample - loss: 8.9633 - val_loss: 35.2395\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 114us/sample - loss: 10.5108 - val_loss: 32.7951\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 112us/sample - loss: 7.8649 - val_loss: 31.8463\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 115us/sample - loss: 9.4220 - val_loss: 30.3878\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 112us/sample - loss: 7.4392 - val_loss: 31.2807\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 116us/sample - loss: 7.4366 - val_loss: 32.2734\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 111us/sample - loss: 9.1863 - val_loss: 30.3357\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 116us/sample - loss: 7.6528 - val_loss: 33.7477\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 120us/sample - loss: 14.3444 - val_loss: 37.2823\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 114us/sample - loss: 15.7943 - val_loss: 31.9339\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 113us/sample - loss: 13.4412 - val_loss: 32.1748\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 109us/sample - loss: 13.9907 - val_loss: 31.2025\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 115us/sample - loss: 7.0228 - val_loss: 30.8791\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 117us/sample - loss: 7.1947 - val_loss: 31.9637\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 117us/sample - loss: 8.5522 - val_loss: 31.0960\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 114us/sample - loss: 11.1914 - val_loss: 30.3513\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 111us/sample - loss: 6.8765 - val_loss: 31.9614\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 113us/sample - loss: 7.5013 - val_loss: 31.2883\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 116us/sample - loss: 6.8499 - val_loss: 31.5277\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 114us/sample - loss: 6.7492 - val_loss: 33.0265\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 112us/sample - loss: 8.4337 - val_loss: 30.9767\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 113us/sample - loss: 11.1878 - val_loss: 33.3803\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 114us/sample - loss: 10.3146 - val_loss: 30.4153\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 110us/sample - loss: 11.1047 - val_loss: 34.4622\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 112us/sample - loss: 15.4589 - val_loss: 30.0462\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 117us/sample - loss: 7.0521 - val_loss: 31.9411\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 112us/sample - loss: 7.1994 - val_loss: 31.8155\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 121us/sample - loss: 8.4535 - val_loss: 30.0532\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 112us/sample - loss: 6.3312 - val_loss: 33.3874\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 116us/sample - loss: 10.3236 - val_loss: 30.1212\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 121us/sample - loss: 6.9156 - val_loss: 35.4684\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 122us/sample - loss: 10.4106 - val_loss: 31.0866\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 118us/sample - loss: 8.2926 - val_loss: 34.1085\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 121us/sample - loss: 8.4212 - val_loss: 31.0012\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 118us/sample - loss: 8.1352 - val_loss: 29.2596\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 115us/sample - loss: 6.2425 - val_loss: 31.5183\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 114us/sample - loss: 6.3894 - val_loss: 30.8596\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 113us/sample - loss: 6.9743 - val_loss: 30.8202\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 112us/sample - loss: 25.4755 - val_loss: 39.1669\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 115us/sample - loss: 36.4997 - val_loss: 32.0888\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 116us/sample - loss: 23.0044 - val_loss: 33.4291\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 116us/sample - loss: 18.1292 - val_loss: 35.6025\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 114us/sample - loss: 13.9735 - val_loss: 33.7400\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 112us/sample - loss: 9.2815 - val_loss: 29.0242\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 113us/sample - loss: 11.5567 - val_loss: 30.4708\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 116us/sample - loss: 14.3431 - val_loss: 29.7612\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 112us/sample - loss: 9.8033 - val_loss: 31.2623\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 112us/sample - loss: 10.9379 - val_loss: 31.1908\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 113us/sample - loss: 9.1233 - val_loss: 30.9191\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 114us/sample - loss: 9.1284 - val_loss: 30.7028\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 109us/sample - loss: 5.7806 - val_loss: 32.1780\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 114us/sample - loss: 7.9385 - val_loss: 33.4144\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 117us/sample - loss: 34.4161 - val_loss: 42.7858\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 113us/sample - loss: 46.7934 - val_loss: 43.0050\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 113us/sample - loss: 46.5472 - val_loss: 39.5005\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 114us/sample - loss: 39.8784 - val_loss: 30.5179\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 110us/sample - loss: 23.8875 - val_loss: 31.0821\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 113us/sample - loss: 15.7499 - val_loss: 35.3914\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 116us/sample - loss: 12.9486 - val_loss: 32.1902\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 115us/sample - loss: 14.4381 - val_loss: 29.7598\n",
      "\n",
      "Mean squared error: 1.4e+01\n",
      "\n",
      "dropout: 2.6e-01\n",
      "filter_num: 300\n",
      "num_dense_layers: 2\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 132us/sample - loss: 50.0053 - val_loss: 31.6190\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 40.1321 - val_loss: 32.3136\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 36.2832 - val_loss: 27.8864\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 33.6903 - val_loss: 28.1681\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 31.4042 - val_loss: 26.9304\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 28.6214 - val_loss: 27.3184\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 24.8873 - val_loss: 28.6075\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 21.7458 - val_loss: 33.2347\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 20.7508 - val_loss: 33.5257\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 18.4288 - val_loss: 44.0166\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 17.1733 - val_loss: 32.6576\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 15.2776 - val_loss: 34.3696\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 13.2000 - val_loss: 40.1781\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 11.9618 - val_loss: 34.8920\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 9.9955 - val_loss: 42.7155\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 9.5523 - val_loss: 33.0613\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 9.3577 - val_loss: 43.4625\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 8.8381 - val_loss: 34.2520\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 7.0773 - val_loss: 40.8287\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 6.8921 - val_loss: 33.9653\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 6.7251 - val_loss: 47.5350\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 7.6576 - val_loss: 34.4821\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 7.3210 - val_loss: 44.7837\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 7.6289 - val_loss: 33.4067\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 9.8507 - val_loss: 41.4557\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 6.6351 - val_loss: 34.8957\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 5.5085 - val_loss: 35.1055\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 5.0514 - val_loss: 35.0961\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 6.0956 - val_loss: 35.0247\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 5.4638 - val_loss: 36.1378\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 5.1783 - val_loss: 34.2367\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 4.7608 - val_loss: 37.3715\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 4.1548 - val_loss: 37.7393\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 3.9020 - val_loss: 40.2641\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 4.4424 - val_loss: 37.5303\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 4.5668 - val_loss: 44.2510\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 8.0451 - val_loss: 35.8961\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 7.2085 - val_loss: 37.8077\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 7.7091 - val_loss: 35.9717\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 10.1003 - val_loss: 36.6410\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 7.3633 - val_loss: 40.3326\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 4.9448 - val_loss: 39.2240\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 5.1573 - val_loss: 43.7483\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 32us/sample - loss: 4.0238 - val_loss: 38.0253\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 3.8088 - val_loss: 43.4401\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 3.9412 - val_loss: 39.0328\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 3.1632 - val_loss: 43.2647\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 3.9121 - val_loss: 38.6126\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 3.5414 - val_loss: 40.2548\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 3.1951 - val_loss: 40.4961\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 3.1328 - val_loss: 38.2718\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 2.8231 - val_loss: 41.0332\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 2.6755 - val_loss: 38.3171\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 2.6575 - val_loss: 38.9416\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 2.7758 - val_loss: 36.3249\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 2.2830 - val_loss: 37.8130\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 2.3215 - val_loss: 37.0939\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 2.5492 - val_loss: 39.5396\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 2.0271 - val_loss: 38.3989\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 2.4488 - val_loss: 40.0500\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 2.5788 - val_loss: 38.6303\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 2.2925 - val_loss: 41.6981\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 3.3594 - val_loss: 38.0810\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 3.3682 - val_loss: 40.5517\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 3.4025 - val_loss: 37.9381\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 2.5911 - val_loss: 39.3229\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 2.1789 - val_loss: 40.8954\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 2.4443 - val_loss: 40.5028\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 2.5320 - val_loss: 41.5743\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 2.1945 - val_loss: 39.7531\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 2.0053 - val_loss: 41.3655\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 2.0573 - val_loss: 39.9944\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 2.1490 - val_loss: 42.6376\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 2.0880 - val_loss: 40.2774\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 2.0067 - val_loss: 42.0698\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 2.0874 - val_loss: 39.8275\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 2.2191 - val_loss: 40.7702\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 2.4771 - val_loss: 37.5247\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 1.6669 - val_loss: 39.4350\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 2.0270 - val_loss: 37.8832\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 2.8797 - val_loss: 40.4565\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 2.5535 - val_loss: 38.0880\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 2.3183 - val_loss: 41.9929\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 1.8780 - val_loss: 38.8554\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 2.4342 - val_loss: 38.4485\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 2.4382 - val_loss: 37.9097\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 2.9776 - val_loss: 38.0419\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 2.8255 - val_loss: 37.5275\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 2.3273 - val_loss: 37.1712\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 2.2855 - val_loss: 37.0813\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 1.9533 - val_loss: 41.5980\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 2.4281 - val_loss: 37.8025\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 2.0839 - val_loss: 39.0252\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 3.2323 - val_loss: 37.1607\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 3.1038 - val_loss: 37.0256\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 2.0572 - val_loss: 39.5023\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 2.0367 - val_loss: 38.4404\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 1.7368 - val_loss: 38.7531\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 1.8707 - val_loss: 39.0809\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 1.7009 - val_loss: 39.3263\n",
      "\n",
      "Mean squared error: 1.7\n",
      "\n",
      "dropout: 8.0e-01\n",
      "filter_num: 10\n",
      "num_dense_layers: 7\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 1s 202us/sample - loss: 59.3439 - val_loss: 55.1692\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 59.3319 - val_loss: 55.0993\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 59.2289 - val_loss: 55.0264\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 59.2011 - val_loss: 54.9520\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 59.0737 - val_loss: 54.8756\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 59.0812 - val_loss: 54.8046\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 58.9062 - val_loss: 54.7282\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 62.3582 - val_loss: 54.6653\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 58.8779 - val_loss: 54.6002\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 58.7379 - val_loss: 54.5346\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 58.6805 - val_loss: 54.4671\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 58.6365 - val_loss: 54.3971\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 58.4976 - val_loss: 54.3242\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 58.4997 - val_loss: 54.2475\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 58.5296 - val_loss: 54.1762\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 58.1221 - val_loss: 54.0966\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 57.7675 - val_loss: 54.0012\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 13us/sample - loss: 58.8463 - val_loss: 53.9306\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 58.3786 - val_loss: 53.8730\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 62.4331 - val_loss: 53.8367\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 57.9836 - val_loss: 53.7825\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 58.0579 - val_loss: 53.7219\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 58.1166 - val_loss: 53.6634\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 60.5909 - val_loss: 53.6124\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 58.5809 - val_loss: 53.5795\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 57.9336 - val_loss: 53.5368\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 57.5341 - val_loss: 53.4790\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 57.8171 - val_loss: 53.4114\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 57.8821 - val_loss: 53.3432\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 57.6584 - val_loss: 53.2713\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 57.5368 - val_loss: 53.1991\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 57.6600 - val_loss: 53.1276\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 57.4559 - val_loss: 53.0537\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 57.2841 - val_loss: 52.9655\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 57.1749 - val_loss: 52.8804\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 58.4610 - val_loss: 52.8151\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 57.0878 - val_loss: 52.7636\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 57.2726 - val_loss: 52.7050\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 57.0168 - val_loss: 52.6408\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 56.9518 - val_loss: 52.5712\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 56.8836 - val_loss: 52.4970\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 56.7193 - val_loss: 52.4174\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 56.6886 - val_loss: 52.3331\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 56.6942 - val_loss: 52.2456\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 56.5564 - val_loss: 52.1547\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 55.7941 - val_loss: 52.0535\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 56.3148 - val_loss: 51.9503\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 55.9636 - val_loss: 51.8393\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 55.9028 - val_loss: 51.7175\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 56.0374 - val_loss: 51.5975\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 55.8409 - val_loss: 51.4758\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 56.0444 - val_loss: 51.3609\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 57.3546 - val_loss: 51.2966\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 55.3187 - val_loss: 51.2401\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 55.8202 - val_loss: 51.1517\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 55.3197 - val_loss: 51.0376\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 55.4338 - val_loss: 50.8997\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 55.4544 - val_loss: 50.7600\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 56.4613 - val_loss: 50.6961\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 55.1343 - val_loss: 50.5995\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 54.9302 - val_loss: 50.4877\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 53.9584 - val_loss: 50.3283\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 54.8320 - val_loss: 50.1254\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 54.5526 - val_loss: 49.9197\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 54.3988 - val_loss: 49.7137\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 54.2293 - val_loss: 49.5101\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 53.8614 - val_loss: 49.3546\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 53.9215 - val_loss: 49.1648\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 54.1505 - val_loss: 48.9760\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 53.3256 - val_loss: 48.7529\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 53.4024 - val_loss: 48.4963\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 53.4980 - val_loss: 48.2416\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 52.8682 - val_loss: 47.9752\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 53.4851 - val_loss: 47.7689\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 56.4486 - val_loss: 47.7400\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 52.6637 - val_loss: 47.6788\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 52.4423 - val_loss: 47.4871\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 52.0654 - val_loss: 47.2295\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 52.6136 - val_loss: 46.9627\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 52.5815 - val_loss: 46.7227\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 51.7750 - val_loss: 46.4942\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 52.3292 - val_loss: 46.2237\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 51.8342 - val_loss: 45.9330\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 50.9694 - val_loss: 45.6404\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 51.3751 - val_loss: 45.3407\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 54.4397 - val_loss: 45.1551\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 50.7917 - val_loss: 45.0981\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 51.0285 - val_loss: 44.9582\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 52.1937 - val_loss: 44.8919\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 50.8536 - val_loss: 44.7429\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 50.4152 - val_loss: 44.5190\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 50.6588 - val_loss: 44.2601\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 13us/sample - loss: 50.9907 - val_loss: 44.0498\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 50.2348 - val_loss: 43.8213\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 49.7156 - val_loss: 43.5673\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 49.5961 - val_loss: 43.2826\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 49.9589 - val_loss: 42.9999\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 49.3451 - val_loss: 42.7785\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 46.8183 - val_loss: 42.5344\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 49.3296 - val_loss: 42.2306\n",
      "\n",
      "Mean squared error: 4.9e+01\n",
      "\n",
      "dropout: 3.8e-01\n",
      "filter_num: 300\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 117us/sample - loss: 55.7180 - val_loss: 35.7409\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 42.6113 - val_loss: 30.2018\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 38.4944 - val_loss: 30.4392\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 35.6980 - val_loss: 27.1388\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 32.9591 - val_loss: 26.2401\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 30.5594 - val_loss: 25.8605\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 27.3295 - val_loss: 26.6442\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 24.3903 - val_loss: 27.8962\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 22.4730 - val_loss: 29.8477\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 21.2858 - val_loss: 31.1152\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 18.7647 - val_loss: 33.1521\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 17.4812 - val_loss: 36.5409\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 14.8924 - val_loss: 35.6318\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 13.1919 - val_loss: 37.2011\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 12.2731 - val_loss: 36.0406\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 10.3634 - val_loss: 38.4288\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 9.2079 - val_loss: 39.3336\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 8.3594 - val_loss: 38.3343\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 8.0882 - val_loss: 42.5807\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 6.8069 - val_loss: 42.9277\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.3582 - val_loss: 40.8485\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.5151 - val_loss: 44.4041\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 6.6949 - val_loss: 39.9711\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 5.9732 - val_loss: 41.5931\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 5.0005 - val_loss: 47.1382\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.6517 - val_loss: 40.9652\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.1631 - val_loss: 48.0794\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.5803 - val_loss: 40.7367\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.7226 - val_loss: 46.8052\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.8524 - val_loss: 42.6374\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.5228 - val_loss: 43.8555\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 6.6526 - val_loss: 40.2709\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 5.3591 - val_loss: 41.5934\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.1561 - val_loss: 39.7135\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.3943 - val_loss: 46.4079\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.1672 - val_loss: 42.2985\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 3.4694 - val_loss: 46.7242\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.6743 - val_loss: 41.1844\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 3.8142 - val_loss: 45.8086\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.5367 - val_loss: 44.1060\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.0194 - val_loss: 44.9796\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.5806 - val_loss: 48.6288\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.9895 - val_loss: 51.9366\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 8.7330 - val_loss: 53.1970\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.0661 - val_loss: 46.4717\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 3.7534 - val_loss: 46.6707\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 3.2513 - val_loss: 47.8139\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 2.6025 - val_loss: 49.0778\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.1995 - val_loss: 48.8067\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.6961 - val_loss: 46.4845\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.9149 - val_loss: 49.1535\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.0555 - val_loss: 50.1270\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.0230 - val_loss: 52.7836\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.0514 - val_loss: 57.0290\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 3.4254 - val_loss: 55.0675\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.7534 - val_loss: 53.1525\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 2.9410 - val_loss: 51.0050\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.7508 - val_loss: 51.7366\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 2.7461 - val_loss: 54.8497\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.2687 - val_loss: 56.8100\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.7922 - val_loss: 60.1040\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.8000 - val_loss: 54.6454\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.2613 - val_loss: 53.8666\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 2.7458 - val_loss: 51.8319\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.1856 - val_loss: 52.1212\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.5038 - val_loss: 51.2125\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.1198 - val_loss: 51.3222\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.4219 - val_loss: 52.9283\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.1597 - val_loss: 53.2018\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 2.1251 - val_loss: 52.1520\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.2052 - val_loss: 54.3418\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.0564 - val_loss: 49.9250\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 2.6412 - val_loss: 53.7477\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.7530 - val_loss: 49.2687\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.2791 - val_loss: 50.3842\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.3243 - val_loss: 48.7514\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 1.9886 - val_loss: 50.1345\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 1.8604 - val_loss: 50.8603\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 1.9874 - val_loss: 48.8421\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 2.3406 - val_loss: 51.1711\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.9483 - val_loss: 46.8574\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 2.0439 - val_loss: 49.8888\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 2.1577 - val_loss: 51.5011\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.8138 - val_loss: 52.2507\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.8984 - val_loss: 49.9378\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.7806 - val_loss: 50.0151\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.0453 - val_loss: 49.7421\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 1.7992 - val_loss: 54.2703\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.4811 - val_loss: 51.4748\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.6800 - val_loss: 59.5217\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.6620 - val_loss: 54.6209\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.4181 - val_loss: 55.2500\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.3518 - val_loss: 49.8552\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.2819 - val_loss: 52.6610\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.2179 - val_loss: 53.8211\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.7338 - val_loss: 54.2504\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.1387 - val_loss: 57.2828\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.2176 - val_loss: 49.5760\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 3.0772 - val_loss: 53.0689\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.4506 - val_loss: 48.3287\n",
      "\n",
      "Mean squared error: 3.5\n",
      "\n",
      "dropout: 3.1e-01\n",
      "filter_num: 89\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 99us/sample - loss: 58.3516 - val_loss: 51.1299\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 53.1476 - val_loss: 41.4150\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 42.2912 - val_loss: 29.4371\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 38.3533 - val_loss: 28.2029\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 35.9724 - val_loss: 27.7135\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 33.0286 - val_loss: 26.7856\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 31.1939 - val_loss: 26.1472\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 30.7895 - val_loss: 25.8210\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 29.1351 - val_loss: 25.8201\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 26.7765 - val_loss: 26.3089\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 26.6005 - val_loss: 26.4663\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 25.2840 - val_loss: 26.5943\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 23.9820 - val_loss: 28.2253\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 22.5493 - val_loss: 30.8689\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 22.0946 - val_loss: 31.3155\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 20.5318 - val_loss: 32.3989\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 19.0790 - val_loss: 37.5411\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 18.9037 - val_loss: 35.4896\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 16.8565 - val_loss: 39.6489\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 16.8304 - val_loss: 41.5555\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 15.0259 - val_loss: 46.7944\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 14.0337 - val_loss: 50.5946\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 13.5484 - val_loss: 61.0749\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 12.2576 - val_loss: 65.9385\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 11.1715 - val_loss: 77.4459\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 9.6698 - val_loss: 80.3054\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 10.1239 - val_loss: 74.6480\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 10.0940 - val_loss: 91.9621\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 9.0107 - val_loss: 84.3599\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 7.9750 - val_loss: 99.9024\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 7.4557 - val_loss: 101.7213\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 6.6998 - val_loss: 103.6091\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 6.4345 - val_loss: 116.5939\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 5.8801 - val_loss: 117.1200\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 6.1969 - val_loss: 118.5433\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 5.2500 - val_loss: 115.8396\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 6.2824 - val_loss: 117.2733\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 5.0549 - val_loss: 119.0674\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 5.5485 - val_loss: 113.6493\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 5.2627 - val_loss: 126.1638\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 13us/sample - loss: 5.3372 - val_loss: 115.5325\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 4.9865 - val_loss: 125.4676\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 4.5537 - val_loss: 124.3021\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 4.6107 - val_loss: 138.6474\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 5.3867 - val_loss: 163.5194\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 6.1198 - val_loss: 151.3164\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 5.7819 - val_loss: 151.7592\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 5.8776 - val_loss: 134.4147\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 4.8508 - val_loss: 138.6292\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.8674 - val_loss: 138.2211\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 4.7109 - val_loss: 140.9316\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 4.9582 - val_loss: 170.9267\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 5.0843 - val_loss: 154.8070\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 4.8633 - val_loss: 159.6786\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 4.4580 - val_loss: 168.8556\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 4.2294 - val_loss: 155.1196\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 3.7072 - val_loss: 168.9430\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 3.6895 - val_loss: 169.6354\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 3.2625 - val_loss: 169.4505\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 3.2750 - val_loss: 176.6452\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 3.7518 - val_loss: 162.0699\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 3.3410 - val_loss: 176.0609\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 2.9307 - val_loss: 185.3941\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 3.2010 - val_loss: 189.9417\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 3.3156 - val_loss: 172.5699\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.9768 - val_loss: 183.5038\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 3.1859 - val_loss: 184.5894\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 3.1068 - val_loss: 200.2602\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 3.3702 - val_loss: 194.0994\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 3.1714 - val_loss: 191.0170\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 2.9735 - val_loss: 193.8894\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 2.6216 - val_loss: 183.9180\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 3.5874 - val_loss: 157.1614\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 4.1794 - val_loss: 170.5500\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 3.9610 - val_loss: 162.9781\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 4.6281 - val_loss: 183.3999\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 4.4368 - val_loss: 187.9265\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 3.3809 - val_loss: 181.0103\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 3.4923 - val_loss: 180.1228\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 3.0979 - val_loss: 182.9428\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 2.5419 - val_loss: 192.8136\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 2.7610 - val_loss: 206.4032\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 2.8296 - val_loss: 207.5207\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 2.7524 - val_loss: 204.3681\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 2.5345 - val_loss: 195.7641\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 2.7856 - val_loss: 186.6995\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 2.5557 - val_loss: 187.0027\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 2.9398 - val_loss: 176.3720\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 2.8789 - val_loss: 171.2325\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 2.6836 - val_loss: 183.6740\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 2.2707 - val_loss: 183.2537\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 2.5239 - val_loss: 203.0414\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 2.7044 - val_loss: 198.0856\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 2.7690 - val_loss: 211.3735\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 4.7663 - val_loss: 178.4204\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 3.4377 - val_loss: 183.9711\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 3.0818 - val_loss: 193.5275\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 2.5904 - val_loss: 179.1510\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 3.5869 - val_loss: 190.9110\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 3.9650 - val_loss: 167.5627\n",
      "\n",
      "Mean squared error: 4.0\n",
      "\n",
      "dropout: 3.7e-01\n",
      "filter_num: 300\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 118us/sample - loss: 50.9942 - val_loss: 31.3508\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 41.3441 - val_loss: 30.5826\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 37.9684 - val_loss: 32.8227\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 35.4861 - val_loss: 27.3194\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 31.9115 - val_loss: 26.5556\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 29.3626 - val_loss: 26.9492\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 27.3621 - val_loss: 27.7634\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 24.7670 - val_loss: 29.2125\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 21.6734 - val_loss: 30.9775\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 20.3264 - val_loss: 33.0273\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 19.5728 - val_loss: 33.0644\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 17.6364 - val_loss: 32.7093\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 15.2348 - val_loss: 35.6459\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 13.4876 - val_loss: 34.1382\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 25us/sample - loss: 12.8736 - val_loss: 38.3861\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 12.3746 - val_loss: 36.9515\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 10.6342 - val_loss: 39.1492\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 8.8193 - val_loss: 38.8660\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 7.8637 - val_loss: 39.2196\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 7.3379 - val_loss: 35.3036\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 9.2403 - val_loss: 39.1194\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 8.2018 - val_loss: 34.7732\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 7.7390 - val_loss: 38.3008\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 8.2717 - val_loss: 34.8975\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 8.2331 - val_loss: 34.5070\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 7.8682 - val_loss: 32.2929\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.6880 - val_loss: 38.5331\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.5891 - val_loss: 38.6478\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 6.4833 - val_loss: 37.5103\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.8506 - val_loss: 36.6320\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.9775 - val_loss: 36.3580\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.6998 - val_loss: 36.7622\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.7613 - val_loss: 37.9812\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.9810 - val_loss: 35.5371\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 4.9490 - val_loss: 36.7500\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.0544 - val_loss: 35.4051\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.1128 - val_loss: 36.9522\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 4.3102 - val_loss: 37.1561\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.0681 - val_loss: 36.9628\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.8315 - val_loss: 39.8472\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.8499 - val_loss: 38.3831\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 3.7077 - val_loss: 39.5263\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.5783 - val_loss: 37.9914\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 3.4556 - val_loss: 37.1081\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.2449 - val_loss: 38.0911\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.8173 - val_loss: 37.8467\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.7714 - val_loss: 39.7989\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 4.2029 - val_loss: 38.2034\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.4540 - val_loss: 39.8122\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.2201 - val_loss: 39.3972\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.5057 - val_loss: 40.6344\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 3.9416 - val_loss: 41.6090\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.5271 - val_loss: 40.2704\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.7054 - val_loss: 40.3202\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.9832 - val_loss: 39.3858\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 2.8396 - val_loss: 37.9246\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.5248 - val_loss: 38.8010\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 2.6092 - val_loss: 38.3624\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.5143 - val_loss: 41.0264\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.7987 - val_loss: 39.3603\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.8607 - val_loss: 39.9569\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 2.9546 - val_loss: 38.9984\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.7596 - val_loss: 37.9199\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.7920 - val_loss: 37.8546\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 4.7181 - val_loss: 38.4768\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.7255 - val_loss: 38.6220\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.2595 - val_loss: 39.2713\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 3.5451 - val_loss: 39.4442\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.9269 - val_loss: 38.7714\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 3.0519 - val_loss: 38.5930\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 3.2749 - val_loss: 37.5714\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 2.8052 - val_loss: 37.9107\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.4474 - val_loss: 37.2227\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.6119 - val_loss: 38.7285\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.6258 - val_loss: 39.0857\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.5726 - val_loss: 39.0010\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.3457 - val_loss: 39.8735\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 2.5275 - val_loss: 38.7775\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.3395 - val_loss: 39.5886\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 1.8581 - val_loss: 39.8751\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.4534 - val_loss: 37.9153\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.3297 - val_loss: 37.5847\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.1735 - val_loss: 36.4238\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 2.4289 - val_loss: 35.4525\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.8170 - val_loss: 38.5720\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.5875 - val_loss: 38.1695\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 2.4165 - val_loss: 40.0605\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 2.5054 - val_loss: 37.9736\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.0511 - val_loss: 38.3206\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 1.8695 - val_loss: 37.9304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 1.8618 - val_loss: 38.2700\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.5801 - val_loss: 37.7768\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.2956 - val_loss: 40.0238\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.4877 - val_loss: 37.6494\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.2376 - val_loss: 38.7588\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.8488 - val_loss: 38.6418\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 2.1245 - val_loss: 39.0201\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.7376 - val_loss: 40.6448\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.0571 - val_loss: 38.8561\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.7100 - val_loss: 38.7107\n",
      "\n",
      "Mean squared error: 1.7\n",
      "\n",
      "dropout: 2.6e-01\n",
      "filter_num: 300\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 110us/sample - loss: 50.2712 - val_loss: 32.9388\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 40.4542 - val_loss: 32.2087\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 37.7346 - val_loss: 29.9788\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 33.6711 - val_loss: 28.0213\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 31.2793 - val_loss: 27.3640\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 27.9341 - val_loss: 28.2676\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 25.4887 - val_loss: 28.6339\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 23.7641 - val_loss: 32.6468\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 22.5440 - val_loss: 32.0993\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 20.1955 - val_loss: 36.5421\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 19.6530 - val_loss: 35.2522\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 17.1730 - val_loss: 35.3848\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 15.0679 - val_loss: 40.8619\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 13.0344 - val_loss: 36.4065\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 12.2813 - val_loss: 49.0477\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 10.9152 - val_loss: 40.9056\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 10.1045 - val_loss: 51.4032\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 8.5824 - val_loss: 44.5380\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 7.7235 - val_loss: 51.2491\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 6.7404 - val_loss: 47.1889\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 5.8275 - val_loss: 53.1465\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 6.0316 - val_loss: 48.8581\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.1448 - val_loss: 54.5052\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.4297 - val_loss: 50.6250\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.2563 - val_loss: 58.7896\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.6458 - val_loss: 50.0021\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.3477 - val_loss: 57.6154\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.6371 - val_loss: 49.7903\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.6998 - val_loss: 59.9314\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.3540 - val_loss: 50.6120\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.9513 - val_loss: 57.0126\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 3.3560 - val_loss: 52.5768\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.9483 - val_loss: 57.8961\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.5011 - val_loss: 57.2170\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.5062 - val_loss: 63.6646\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.3226 - val_loss: 55.9090\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 3.3489 - val_loss: 62.6060\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.3177 - val_loss: 59.3432\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.9990 - val_loss: 64.5354\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.9231 - val_loss: 58.9942\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 2.7868 - val_loss: 62.9876\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.8532 - val_loss: 60.0732\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 2.6141 - val_loss: 58.5932\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.8452 - val_loss: 63.8631\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 2.5636 - val_loss: 59.0456\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.9264 - val_loss: 65.0942\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.0042 - val_loss: 59.2201\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.3989 - val_loss: 64.8824\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.5664 - val_loss: 57.9481\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.9696 - val_loss: 64.3025\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.4447 - val_loss: 56.4375\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 2.4152 - val_loss: 60.1980\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.6265 - val_loss: 59.8026\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.3359 - val_loss: 50.2323\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 3.7189 - val_loss: 56.9107\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 3.0539 - val_loss: 54.3488\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.4863 - val_loss: 61.5783\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.1076 - val_loss: 58.9683\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.7855 - val_loss: 63.7188\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.9820 - val_loss: 61.9311\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.0379 - val_loss: 56.7723\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.0825 - val_loss: 59.9767\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.7706 - val_loss: 58.0003\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.7388 - val_loss: 65.7550\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.7775 - val_loss: 59.6288\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.6732 - val_loss: 65.5653\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.5184 - val_loss: 61.5007\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.5861 - val_loss: 66.0302\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.5842 - val_loss: 61.0588\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 1.9690 - val_loss: 65.9073\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.8031 - val_loss: 59.7744\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.6021 - val_loss: 62.1291\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.5083 - val_loss: 61.5280\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 1.7513 - val_loss: 61.7437\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.6979 - val_loss: 63.5162\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.6916 - val_loss: 61.3871\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.8742 - val_loss: 60.4433\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.2036 - val_loss: 59.6213\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 1.4848 - val_loss: 58.6888\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 1.6235 - val_loss: 57.6203\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 1.7339 - val_loss: 50.1988\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 6.6440 - val_loss: 54.3942\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 6.4952 - val_loss: 49.2435\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 5.2644 - val_loss: 71.5114\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.3257 - val_loss: 56.5113\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 3.9321 - val_loss: 67.2281\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.7378 - val_loss: 61.3649\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 2.3889 - val_loss: 74.0641\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.3142 - val_loss: 59.6213\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.3568 - val_loss: 77.3964\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.8874 - val_loss: 64.7342\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 1.8400 - val_loss: 76.8103\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.8547 - val_loss: 65.8813\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.9475 - val_loss: 71.6285\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.4602 - val_loss: 72.3071\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 1.3921 - val_loss: 74.2380\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 1.6609 - val_loss: 74.6050\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.6004 - val_loss: 71.1734\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.4835 - val_loss: 67.7980\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.9996 - val_loss: 67.3465\n",
      "\n",
      "Mean squared error: 2.0\n",
      "\n",
      "dropout: 2.0e-01\n",
      "filter_num: 300\n",
      "num_dense_layers: 7\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 1s 261us/sample - loss: 52.8836 - val_loss: 32.7286\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 70us/sample - loss: 39.9337 - val_loss: 31.1589\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 62us/sample - loss: 37.1005 - val_loss: 27.8724\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 71us/sample - loss: 32.4950 - val_loss: 28.0180\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 29.7862 - val_loss: 28.2426\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 28.2570 - val_loss: 29.4927\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 23.8309 - val_loss: 33.7644\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 32.5775 - val_loss: 28.5061\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 24.8052 - val_loss: 31.2275\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 67us/sample - loss: 22.2669 - val_loss: 35.3365\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 67us/sample - loss: 17.0999 - val_loss: 31.9853\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 67us/sample - loss: 15.9334 - val_loss: 34.1771\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 67us/sample - loss: 14.1526 - val_loss: 35.2327\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 67us/sample - loss: 15.1686 - val_loss: 30.1219\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 11.3462 - val_loss: 32.6073\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 9.5497 - val_loss: 33.3492\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 63us/sample - loss: 9.1876 - val_loss: 33.1032\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 71us/sample - loss: 10.8308 - val_loss: 34.0528\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 65us/sample - loss: 9.8406 - val_loss: 30.9501\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 67us/sample - loss: 8.9501 - val_loss: 31.6653\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 67us/sample - loss: 10.4320 - val_loss: 49.9902\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 15.2433 - val_loss: 37.2198\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 14.8321 - val_loss: 37.7142\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 65us/sample - loss: 10.7908 - val_loss: 33.8179\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 10.2368 - val_loss: 33.9282\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 8.7197 - val_loss: 35.4675\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 8.0228 - val_loss: 32.5247\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 67us/sample - loss: 8.2166 - val_loss: 33.8631\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 67us/sample - loss: 7.0493 - val_loss: 33.2490\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 6.4416 - val_loss: 34.5374\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 6.4540 - val_loss: 31.4083\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 70us/sample - loss: 9.2769 - val_loss: 34.1782\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 71us/sample - loss: 7.7431 - val_loss: 32.5487\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 72us/sample - loss: 7.3326 - val_loss: 34.5459\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 73us/sample - loss: 5.8776 - val_loss: 33.8924\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 71us/sample - loss: 7.0030 - val_loss: 31.9045\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 71us/sample - loss: 5.5621 - val_loss: 34.8038\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 70us/sample - loss: 5.8543 - val_loss: 33.5755\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 67us/sample - loss: 6.0620 - val_loss: 32.2901\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 67us/sample - loss: 5.6091 - val_loss: 32.7348\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 5.4748 - val_loss: 33.1245\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 67us/sample - loss: 4.9944 - val_loss: 32.8137\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 67us/sample - loss: 6.6330 - val_loss: 38.7794\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 9.3034 - val_loss: 32.2921\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 7.6476 - val_loss: 31.4454\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 10.9496 - val_loss: 31.4588\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 6.7070 - val_loss: 31.2836\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 5.0865 - val_loss: 32.4629\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 67us/sample - loss: 4.5553 - val_loss: 31.3975\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 4.5858 - val_loss: 31.8551\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 65us/sample - loss: 4.7547 - val_loss: 30.8967\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 4.7720 - val_loss: 33.0352\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 64us/sample - loss: 4.6204 - val_loss: 32.7572\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 4.1295 - val_loss: 30.5882\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 4.1248 - val_loss: 30.3887\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 4.6744 - val_loss: 30.8038\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 65us/sample - loss: 5.1433 - val_loss: 32.2427\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 67us/sample - loss: 5.0549 - val_loss: 31.5955\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 67us/sample - loss: 5.0761 - val_loss: 32.2119\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 62us/sample - loss: 4.7214 - val_loss: 32.2788\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 3.9432 - val_loss: 31.2794\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 4.0516 - val_loss: 31.4319\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 3.7438 - val_loss: 30.9476\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 3.3838 - val_loss: 35.4912\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 5.2420 - val_loss: 31.9917\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 5.0991 - val_loss: 32.3909\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 67us/sample - loss: 9.4415 - val_loss: 30.4876\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 4.8583 - val_loss: 31.2757\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 67us/sample - loss: 4.7344 - val_loss: 33.1465\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 4.5797 - val_loss: 31.5133\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 4.0882 - val_loss: 30.8088\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 3.7183 - val_loss: 34.9462\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 67us/sample - loss: 4.4860 - val_loss: 32.6099\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 5.4106 - val_loss: 31.0827\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 3.6088 - val_loss: 32.1414\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 4.1209 - val_loss: 32.2838\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 4.8469 - val_loss: 31.8785\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 67us/sample - loss: 4.4334 - val_loss: 31.5525\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 67us/sample - loss: 4.5067 - val_loss: 32.8565\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 4.2565 - val_loss: 34.4574\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 4.6625 - val_loss: 32.4368\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 67us/sample - loss: 4.6018 - val_loss: 33.4310\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 67us/sample - loss: 4.4020 - val_loss: 32.5370\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 4.0615 - val_loss: 31.2979\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 10.4400 - val_loss: 30.5428\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 7.9234 - val_loss: 32.2780\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 7.5790 - val_loss: 37.3640\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 67us/sample - loss: 5.1296 - val_loss: 32.4226\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 65us/sample - loss: 4.9697 - val_loss: 30.9667\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 5.9517 - val_loss: 32.9523\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 5.7107 - val_loss: 31.2371\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 5.1497 - val_loss: 30.8999\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 67us/sample - loss: 7.9936 - val_loss: 31.6277\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 65us/sample - loss: 6.2715 - val_loss: 33.0155\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 6.7532 - val_loss: 31.8697\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 67us/sample - loss: 6.3659 - val_loss: 30.1377\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 5.1793 - val_loss: 31.2857\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 67us/sample - loss: 3.9234 - val_loss: 31.6672\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 3.7115 - val_loss: 31.1200\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 67us/sample - loss: 3.8829 - val_loss: 31.9856\n",
      "\n",
      "Mean squared error: 3.9\n",
      "\n",
      "dropout: 8.0e-01\n",
      "filter_num: 300\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 121us/sample - loss: 46.5420 - val_loss: 35.5360\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 42.2266 - val_loss: 38.0218\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 40.7068 - val_loss: 40.7054\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 38.4804 - val_loss: 36.8630\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 37.6715 - val_loss: 34.7148\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 35.0019 - val_loss: 35.9269\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 34.2319 - val_loss: 36.2472\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 31.3888 - val_loss: 33.0417\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 31.6703 - val_loss: 31.3473\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 30.0550 - val_loss: 36.1119\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 29.0134 - val_loss: 36.4061\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 28.9714 - val_loss: 32.9219\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 26us/sample - loss: 26.8948 - val_loss: 31.4186\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 26.4777 - val_loss: 32.8124\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 24.4027 - val_loss: 34.0958\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 24.5966 - val_loss: 33.9924\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 23.6036 - val_loss: 33.7478\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 23.7600 - val_loss: 33.7105\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 20.6378 - val_loss: 34.1098\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 22.3487 - val_loss: 35.1516\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 20.5232 - val_loss: 35.4865\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 16.5815 - val_loss: 36.8510\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 16.3056 - val_loss: 38.2101\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 15.2540 - val_loss: 40.0864\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 16.0949 - val_loss: 41.2691\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 14.8341 - val_loss: 43.2068\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 13.9081 - val_loss: 49.1804\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 15.4731 - val_loss: 50.7653\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 13.3092 - val_loss: 53.6155\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 13.7040 - val_loss: 59.4194\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 13.0734 - val_loss: 61.7051\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 13.0775 - val_loss: 58.3823\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 12.5446 - val_loss: 66.3113\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 12.8588 - val_loss: 74.6575\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 10.5533 - val_loss: 71.4152\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 11.8614 - val_loss: 81.0827\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 11.2803 - val_loss: 88.2032\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 10.8448 - val_loss: 91.3397\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 9.4971 - val_loss: 94.2197\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 10.5554 - val_loss: 89.5995\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 9.4562 - val_loss: 82.2897\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 11.0770 - val_loss: 77.6749\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 10.1151 - val_loss: 87.4061\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 11.0080 - val_loss: 83.7636\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 10.9059 - val_loss: 78.4028\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 9.8029 - val_loss: 87.9176\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 10.1283 - val_loss: 97.4966\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 8.8867 - val_loss: 98.3236\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 10.6282 - val_loss: 113.8078\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 9.9011 - val_loss: 115.4232\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 9.8031 - val_loss: 126.6515\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 10.7035 - val_loss: 117.7114\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 8.8248 - val_loss: 108.8219\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 9.5137 - val_loss: 104.3203\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 9.5592 - val_loss: 119.9685\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 8.8666 - val_loss: 115.8389\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 10.4558 - val_loss: 99.6404\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 8.9583 - val_loss: 111.8101\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 9.0459 - val_loss: 117.2974\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 8.4943 - val_loss: 100.7411\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 7.9259 - val_loss: 107.7345\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 7.9179 - val_loss: 113.0221\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 7.7514 - val_loss: 110.6355\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.9901 - val_loss: 107.9368\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 7.4292 - val_loss: 112.7696\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 8.1088 - val_loss: 110.8412\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 7.7039 - val_loss: 91.1714\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 9.0174 - val_loss: 113.4975\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 11.2067 - val_loss: 105.6606\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 7.1751 - val_loss: 91.9521\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 8.3457 - val_loss: 103.0102\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 8.7208 - val_loss: 110.6074\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 8.4106 - val_loss: 121.0405\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 8.3686 - val_loss: 118.4436\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 8.6938 - val_loss: 109.7807\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 8.1861 - val_loss: 112.6454\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 9.8855 - val_loss: 98.7191\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 7.7999 - val_loss: 96.6722\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 7.9813 - val_loss: 119.1474\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 8.8638 - val_loss: 114.4484\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 10.1770 - val_loss: 94.7193\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 7.6428 - val_loss: 102.4907\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 8.3128 - val_loss: 107.8907\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 6.8965 - val_loss: 121.7707\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 7.3775 - val_loss: 116.3648\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 7.2817 - val_loss: 107.7766\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 7.6418 - val_loss: 96.8262\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 24us/sample - loss: 10.8625 - val_loss: 98.1318\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 7.6063 - val_loss: 92.9244\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.5700 - val_loss: 94.7676\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 7.7850 - val_loss: 104.2413\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 7.7806 - val_loss: 104.5446\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.8981 - val_loss: 94.3882\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.4136 - val_loss: 100.0068\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 6.9131 - val_loss: 113.8540\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 6.3150 - val_loss: 114.6983\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 7.4319 - val_loss: 115.8014\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.1354 - val_loss: 113.0403\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 7.1465 - val_loss: 105.3679\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 7.5685 - val_loss: 109.3032\n",
      "\n",
      "Mean squared error: 7.6\n",
      "\n",
      "dropout: 2.0e-01\n",
      "filter_num: 279\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 110us/sample - loss: 54.1194 - val_loss: 33.7824\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 41.2063 - val_loss: 31.2073\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 37.2949 - val_loss: 30.2117\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 34.1635 - val_loss: 28.3637\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 31.2206 - val_loss: 27.0336\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 28.2218 - val_loss: 26.9428\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 25.5046 - val_loss: 29.0798\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 22.8904 - val_loss: 29.5525\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 20.8892 - val_loss: 34.0058\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 19.0531 - val_loss: 33.6156\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 16.9073 - val_loss: 34.1610\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 14.5310 - val_loss: 32.6668\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 12.4038 - val_loss: 33.0296\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 11.0885 - val_loss: 36.5915\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 9.3141 - val_loss: 33.5398\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 8.5088 - val_loss: 35.5452\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 7.1742 - val_loss: 38.3335\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 7.1955 - val_loss: 34.7935\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 8.0224 - val_loss: 47.5588\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 7.7552 - val_loss: 34.9764\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 6.8756 - val_loss: 44.3050\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 7.8219 - val_loss: 33.8454\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 6.3092 - val_loss: 38.1699\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 4.8148 - val_loss: 34.6565\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 4.6339 - val_loss: 40.0636\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 4.3151 - val_loss: 36.3229\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 4.0052 - val_loss: 38.5683\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 3.8790 - val_loss: 37.9526\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 3.5255 - val_loss: 38.9777\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 3.1100 - val_loss: 41.3197\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 3.5425 - val_loss: 38.4726\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 3.2134 - val_loss: 37.9941\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.7224 - val_loss: 35.3146\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.6355 - val_loss: 38.6293\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.6830 - val_loss: 36.0711\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.6219 - val_loss: 41.0553\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.7032 - val_loss: 36.5849\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.7922 - val_loss: 42.0138\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.2076 - val_loss: 37.5937\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.1274 - val_loss: 41.6834\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.0868 - val_loss: 37.1624\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.0534 - val_loss: 40.2579\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.9524 - val_loss: 36.7477\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.9298 - val_loss: 38.2668\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.3281 - val_loss: 36.4923\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.8808 - val_loss: 38.0903\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.8451 - val_loss: 37.4152\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.7487 - val_loss: 39.4288\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 1.5455 - val_loss: 36.4239\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.5780 - val_loss: 38.9028\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 1.7860 - val_loss: 36.1805\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.6554 - val_loss: 39.3326\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.0846 - val_loss: 37.3510\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.7019 - val_loss: 39.4611\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.5896 - val_loss: 37.5346\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.8967 - val_loss: 36.1666\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.4011 - val_loss: 38.5747\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.0254 - val_loss: 36.1260\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.9264 - val_loss: 42.1413\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.3339 - val_loss: 35.3263\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 3.5735 - val_loss: 39.5994\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.0704 - val_loss: 35.2733\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.5149 - val_loss: 36.4856\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.7557 - val_loss: 34.1905\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.4905 - val_loss: 36.7755\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.1745 - val_loss: 34.2705\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.7052 - val_loss: 37.5227\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.2856 - val_loss: 35.7098\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.0955 - val_loss: 38.9071\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.6330 - val_loss: 35.7450\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.7434 - val_loss: 37.1224\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.6468 - val_loss: 35.8932\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.6415 - val_loss: 37.3177\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.3748 - val_loss: 36.9445\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.3820 - val_loss: 38.6100\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.2653 - val_loss: 37.5403\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.2019 - val_loss: 37.2808\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.2578 - val_loss: 36.7083\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.2254 - val_loss: 35.6746\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.2768 - val_loss: 37.7935\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.3655 - val_loss: 36.6958\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.2650 - val_loss: 37.1486\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.4474 - val_loss: 33.4327\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 5.1572 - val_loss: 35.0928\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 5.6962 - val_loss: 33.3065\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 4.7400 - val_loss: 38.0573\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.4240 - val_loss: 35.8089\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.9460 - val_loss: 37.9158\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.0471 - val_loss: 35.7179\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.4918 - val_loss: 37.1342\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.7017 - val_loss: 36.4437\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.1610 - val_loss: 39.7226\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.4341 - val_loss: 38.1676\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.1815 - val_loss: 37.2585\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.3600 - val_loss: 35.2164\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.2366 - val_loss: 35.9910\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 0.9791 - val_loss: 36.7852\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.1438 - val_loss: 37.3580\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 0.8984 - val_loss: 36.5265\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.3610 - val_loss: 34.5186\n",
      "\n",
      "Mean squared error: 1.4\n",
      "\n",
      "dropout: 2.0e-01\n",
      "filter_num: 52\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 94us/sample - loss: 58.9163 - val_loss: 53.2918\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 56.6376 - val_loss: 49.1244\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 51.7403 - val_loss: 40.8987\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 43.3380 - val_loss: 30.4184\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 35.7957 - val_loss: 28.1849\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 36.2266 - val_loss: 26.9504\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 32.0905 - val_loss: 26.5764\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 31.2619 - val_loss: 26.4866\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 30.6361 - val_loss: 25.6428\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 29.0344 - val_loss: 25.3492\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 28.0033 - val_loss: 25.4645\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 27.2148 - val_loss: 25.2975\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 26.1076 - val_loss: 25.3683\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 26.2389 - val_loss: 25.8291\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 24.7355 - val_loss: 25.6374\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 24.7515 - val_loss: 25.8334\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 24.4774 - val_loss: 26.7269\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 23.6505 - val_loss: 28.0479\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 22.6166 - val_loss: 27.6430\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 22.3721 - val_loss: 28.2084\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 20.6104 - val_loss: 32.4789\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 21.0357 - val_loss: 33.2632\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 19.6932 - val_loss: 31.9236\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 20.1733 - val_loss: 34.5889\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 19.0235 - val_loss: 41.3717\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 17.7491 - val_loss: 41.2547\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 18.1703 - val_loss: 45.3954\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 16.1241 - val_loss: 52.3349\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 15.3935 - val_loss: 59.3312\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 14.1225 - val_loss: 61.9680\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 12.8799 - val_loss: 76.4719\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 12.1391 - val_loss: 82.8503\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 10.8644 - val_loss: 101.1038\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 10.0034 - val_loss: 127.4575\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 8.9644 - val_loss: 141.1430\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 12us/sample - loss: 9.6239 - val_loss: 149.1194\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 8.6072 - val_loss: 177.6656\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 7.6019 - val_loss: 162.3519\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 9.0200 - val_loss: 196.8313\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 7.7352 - val_loss: 209.3831\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 6.8481 - val_loss: 199.0730\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 6.1709 - val_loss: 238.0788\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 6.2339 - val_loss: 240.6751\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 5.7210 - val_loss: 233.6630\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 5.8242 - val_loss: 251.0515\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 5.2040 - val_loss: 234.8879\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 5.6490 - val_loss: 245.4433\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 5.3470 - val_loss: 253.2044\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 4.4535 - val_loss: 254.0468\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 4.6706 - val_loss: 280.2372\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 4.6817 - val_loss: 285.8824\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 4.0446 - val_loss: 304.1296\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 4.1443 - val_loss: 302.2154\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 4.4346 - val_loss: 272.9719\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 4.5859 - val_loss: 283.9130\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 4.2750 - val_loss: 278.6165\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 3.9457 - val_loss: 307.9643\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 3.4099 - val_loss: 324.3286\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 3.8547 - val_loss: 334.6414\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 4.4865 - val_loss: 306.7615\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 4.1244 - val_loss: 315.6224\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 3.6122 - val_loss: 308.2227\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 4.6192 - val_loss: 280.0897\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 4.4951 - val_loss: 302.4041\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 4.3890 - val_loss: 306.0683\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 4.6140 - val_loss: 334.8419\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 3.7754 - val_loss: 331.8681\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 3.3451 - val_loss: 320.9547\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 3.5838 - val_loss: 322.3386\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 3.6836 - val_loss: 309.6080\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 3.1160 - val_loss: 342.2192\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 3.9853 - val_loss: 338.3469\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 3.2233 - val_loss: 354.5931\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 3.6447 - val_loss: 346.0805\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 3.3424 - val_loss: 344.5197\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 3.1143 - val_loss: 366.5320\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 3.5998 - val_loss: 335.0691\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 3.3668 - val_loss: 368.1747\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 3.2472 - val_loss: 366.8975\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 3.1865 - val_loss: 366.3059\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 3.9460 - val_loss: 406.2636\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 3.4035 - val_loss: 364.9109\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 3.5328 - val_loss: 366.4079\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 3.7508 - val_loss: 384.1467\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 3.3141 - val_loss: 331.7167\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 3.2225 - val_loss: 364.2130\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 2.4161 - val_loss: 367.5683\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 2.3739 - val_loss: 352.9025\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 2.1376 - val_loss: 360.1985\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 2.0102 - val_loss: 363.7422\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 2.4190 - val_loss: 352.5796\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 2.5085 - val_loss: 367.1776\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 2.3359 - val_loss: 395.6202\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 2.2812 - val_loss: 395.1690\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 2.3589 - val_loss: 418.3410\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 3.4126 - val_loss: 389.4285\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 3.0830 - val_loss: 374.0558\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 2.6046 - val_loss: 351.5943\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 2.6700 - val_loss: 370.4448\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 3.0956 - val_loss: 392.9430\n",
      "\n",
      "Mean squared error: 3.1\n",
      "\n",
      "dropout: 2.0e-01\n",
      "filter_num: 116\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 98us/sample - loss: 58.6119 - val_loss: 50.7903\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 52.2071 - val_loss: 38.9157\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 40.2019 - val_loss: 31.1928\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 40.1732 - val_loss: 28.6520\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 34.1273 - val_loss: 27.6817\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 32.3111 - val_loss: 27.4364\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 31.0937 - val_loss: 25.9931\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 28.0575 - val_loss: 25.8210\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 27.6535 - val_loss: 26.0186\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 14us/sample - loss: 26.1241 - val_loss: 25.3677\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 24.9554 - val_loss: 25.9207\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 23.5917 - val_loss: 26.6859\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 21.4711 - val_loss: 28.1646\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 21.5358 - val_loss: 29.3182\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 19.0111 - val_loss: 33.4075\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 18.4666 - val_loss: 34.2267\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 17.8115 - val_loss: 37.9450\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 15.6753 - val_loss: 40.3240\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 14.5164 - val_loss: 43.6238\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 12.8925 - val_loss: 45.8718\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 12.5565 - val_loss: 52.8236\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 10.5677 - val_loss: 60.9955\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 9.4345 - val_loss: 70.7026\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 7.8454 - val_loss: 76.9734\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 7.4875 - val_loss: 75.8781\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 7.1058 - val_loss: 82.9244\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 6.6127 - val_loss: 85.6207\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 5.7763 - val_loss: 98.5046\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 5.3311 - val_loss: 98.4673\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 5.3391 - val_loss: 107.7391\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.9012 - val_loss: 97.1844\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 5.6371 - val_loss: 100.9740\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.9532 - val_loss: 94.7299\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.6429 - val_loss: 108.6052\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.5241 - val_loss: 98.0646\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.9346 - val_loss: 111.1657\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.5387 - val_loss: 100.1462\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.0739 - val_loss: 114.1225\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.1174 - val_loss: 105.5814\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.1555 - val_loss: 118.7747\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 3.9468 - val_loss: 110.6707\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.2675 - val_loss: 122.4873\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 3.5705 - val_loss: 118.5082\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.1397 - val_loss: 122.1223\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 3.0582 - val_loss: 113.0221\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 3.4345 - val_loss: 130.8517\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 5.9949 - val_loss: 124.7354\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 5.6671 - val_loss: 130.4682\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 7.3579 - val_loss: 112.5754\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 3.7267 - val_loss: 107.1465\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.1163 - val_loss: 116.7359\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.1693 - val_loss: 105.4336\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 3.9687 - val_loss: 106.5694\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 3.7319 - val_loss: 99.9872\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.3432 - val_loss: 111.6184\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.9867 - val_loss: 108.9164\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.1016 - val_loss: 130.1447\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 3.3977 - val_loss: 127.4754\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 3.6141 - val_loss: 129.5127\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.2894 - val_loss: 116.4955\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.6105 - val_loss: 116.1171\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.4082 - val_loss: 118.5375\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.3282 - val_loss: 118.8710\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.1527 - val_loss: 114.2894\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.2603 - val_loss: 116.2721\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.1837 - val_loss: 127.2316\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.6121 - val_loss: 123.2313\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.6143 - val_loss: 120.7854\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.3625 - val_loss: 114.5641\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.1600 - val_loss: 123.0314\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.1355 - val_loss: 118.8875\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.2443 - val_loss: 122.3616\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 1.9977 - val_loss: 121.0091\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.0535 - val_loss: 127.8034\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 1.7387 - val_loss: 130.1059\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 1.8780 - val_loss: 127.3849\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 1.9612 - val_loss: 125.8557\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.8560 - val_loss: 128.2829\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 1.9708 - val_loss: 122.5658\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 1.9970 - val_loss: 122.7093\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 1.9523 - val_loss: 117.5639\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 1.5707 - val_loss: 117.6544\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.7285 - val_loss: 123.5245\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.0969 - val_loss: 128.1855\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.1547 - val_loss: 118.6216\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.0593 - val_loss: 121.5424\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 1.8413 - val_loss: 122.8042\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 1.8572 - val_loss: 123.4594\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 1.6140 - val_loss: 122.7757\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 1.6859 - val_loss: 126.2573\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 1.5255 - val_loss: 121.2552\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 1.5415 - val_loss: 120.4239\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 1.4618 - val_loss: 120.6103\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 1.7563 - val_loss: 122.8750\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.3997 - val_loss: 125.5582\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.4321 - val_loss: 123.2202\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 1.8700 - val_loss: 105.0245\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 1.5600 - val_loss: 107.7620\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 1.5901 - val_loss: 105.4614\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 1.8710 - val_loss: 111.1707\n",
      "\n",
      "Mean squared error: 1.9\n",
      "\n",
      "dropout: 2.0e-01\n",
      "filter_num: 300\n",
      "num_dense_layers: 3\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 162us/sample - loss: 53.4674 - val_loss: 32.2420\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 41.2758 - val_loss: 33.1557\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 37.6871 - val_loss: 27.5083\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 33.7159 - val_loss: 27.3165\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 30.6128 - val_loss: 25.7299\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 26.6568 - val_loss: 26.9716\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 23.3305 - val_loss: 30.2158\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 20.8962 - val_loss: 41.3114\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 18.4398 - val_loss: 39.4644\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 18.2715 - val_loss: 31.4769\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 17.5119 - val_loss: 41.1113\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 14.4947 - val_loss: 33.1150\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 10.8641 - val_loss: 43.7407\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 9.9266 - val_loss: 34.8698\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 9.1221 - val_loss: 38.4248\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 7.3330 - val_loss: 37.5454\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 7.1386 - val_loss: 37.2393\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 6.4751 - val_loss: 35.8914\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 5.8569 - val_loss: 33.4565\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 6.4532 - val_loss: 36.3968\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 5.4848 - val_loss: 40.5274\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 6.7356 - val_loss: 34.7635\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 6.6205 - val_loss: 34.4882\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 6.6949 - val_loss: 38.3855\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 6.8829 - val_loss: 32.4466\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 7.2230 - val_loss: 34.5039\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 4.9604 - val_loss: 40.2330\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 4.2790 - val_loss: 37.7751\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 4.8640 - val_loss: 40.7935\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 4.6736 - val_loss: 37.0134\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 4.9113 - val_loss: 38.2706\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 4.5323 - val_loss: 41.9787\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 4.1851 - val_loss: 37.0241\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 3.7541 - val_loss: 42.0932\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 5.7258 - val_loss: 37.5700\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 5.5222 - val_loss: 47.0732\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 5.0776 - val_loss: 35.4235\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 3.2747 - val_loss: 37.0720\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 3.1670 - val_loss: 34.7973\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 43us/sample - loss: 3.5799 - val_loss: 33.0667\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 3.6087 - val_loss: 34.3196\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 3.8323 - val_loss: 33.7934\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 3.7732 - val_loss: 34.6848\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 3.5536 - val_loss: 37.7264\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 3.7046 - val_loss: 34.5067\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 3.4406 - val_loss: 36.8739\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 3.2055 - val_loss: 35.5761\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 2.6429 - val_loss: 35.7112\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 2.5024 - val_loss: 37.7445\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 2.6344 - val_loss: 41.2671\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 3.4305 - val_loss: 34.7136\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 2.5191 - val_loss: 38.6662\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 3.6089 - val_loss: 35.4180\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 42us/sample - loss: 2.7448 - val_loss: 37.6378\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 2.9602 - val_loss: 36.8354\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 2.8625 - val_loss: 35.5463\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 2.9242 - val_loss: 37.0421\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 2.4215 - val_loss: 36.1878\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 38us/sample - loss: 2.4393 - val_loss: 35.9464\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 2.9073 - val_loss: 37.5618\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 2.4468 - val_loss: 34.4908\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 2.2090 - val_loss: 38.2546\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 2.1383 - val_loss: 35.7862\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 2.1971 - val_loss: 40.4646\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 2.3281 - val_loss: 40.6094\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 1.8599 - val_loss: 37.5751\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 2.1697 - val_loss: 38.9356\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 2.1150 - val_loss: 35.8145\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 1.8533 - val_loss: 37.6065\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 2.3836 - val_loss: 35.4481\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 2.0342 - val_loss: 37.5580\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 2.1672 - val_loss: 33.9326\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 1.9906 - val_loss: 36.6160\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 2.0945 - val_loss: 33.9456\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 1.9785 - val_loss: 39.0935\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 2.1964 - val_loss: 36.5788\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 2.5581 - val_loss: 38.4663\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 42us/sample - loss: 2.4079 - val_loss: 34.0328\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 2.5810 - val_loss: 34.3237\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 2.5924 - val_loss: 36.3467\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 42us/sample - loss: 2.1331 - val_loss: 35.4720\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 42us/sample - loss: 2.4034 - val_loss: 34.8787\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 2.6452 - val_loss: 38.0165\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 42us/sample - loss: 3.3333 - val_loss: 35.0567\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 2.1212 - val_loss: 35.0806\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 1.8464 - val_loss: 43.1727\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 3.5915 - val_loss: 36.0588\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 3.5451 - val_loss: 40.5069\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 42us/sample - loss: 3.8270 - val_loss: 35.3734\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 4.1693 - val_loss: 41.2581\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 2.8723 - val_loss: 36.8935\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 2.5412 - val_loss: 40.3280\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 3.4932 - val_loss: 36.9307\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 2.6284 - val_loss: 36.6106\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 2.5571 - val_loss: 38.4098\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 2.4305 - val_loss: 36.0797\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 2.3489 - val_loss: 42.0181\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 2.4273 - val_loss: 35.2885\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 2.6656 - val_loss: 43.4994\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 2.2741 - val_loss: 35.5704\n",
      "\n",
      "Mean squared error: 2.3\n",
      "\n",
      "dropout: 3.0e-01\n",
      "filter_num: 288\n",
      "num_dense_layers: 5\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 1s 205us/sample - loss: 49.4217 - val_loss: 32.7067\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 41.6229 - val_loss: 35.2280\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 38.0730 - val_loss: 31.8175\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 34.4586 - val_loss: 29.4328\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 30.8329 - val_loss: 26.0262\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 27.9357 - val_loss: 27.9495\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 26.0555 - val_loss: 28.8396\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 21.9342 - val_loss: 32.0174\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 18.8427 - val_loss: 34.0146\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 16.5953 - val_loss: 32.5937\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 16.4775 - val_loss: 32.5605\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 15.0123 - val_loss: 43.2784\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 14.9256 - val_loss: 34.7024\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 13.5722 - val_loss: 33.4964\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 12.2676 - val_loss: 43.2394\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 13.4139 - val_loss: 32.4207\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 12.8610 - val_loss: 52.9290\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 17.2402 - val_loss: 36.1560\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 16.8956 - val_loss: 46.5509\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 14.1734 - val_loss: 32.7627\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 13.0193 - val_loss: 52.0787\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 13.5078 - val_loss: 35.0675\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 13.1325 - val_loss: 53.5560\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 12.6774 - val_loss: 34.3254\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 10.7737 - val_loss: 46.8737\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 11.1067 - val_loss: 35.5838\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 12.3519 - val_loss: 41.8109\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 9.4805 - val_loss: 34.3735\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 9.1926 - val_loss: 39.6595\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 7.5718 - val_loss: 36.5368\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 6.7464 - val_loss: 39.6910\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 6.1727 - val_loss: 36.6886\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 45us/sample - loss: 10.1499 - val_loss: 32.8109\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 7.3179 - val_loss: 34.9031\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 6.4843 - val_loss: 35.5915\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 7.2316 - val_loss: 38.4142\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 6.0632 - val_loss: 41.7442\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 6.2952 - val_loss: 38.6481\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 5.7059 - val_loss: 42.5120\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 5.6531 - val_loss: 39.6440\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 5.8937 - val_loss: 38.8544\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 5.4431 - val_loss: 35.3379\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 6.7567 - val_loss: 34.6377\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 9.0407 - val_loss: 32.9484\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 6.5551 - val_loss: 36.3516\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 6.9036 - val_loss: 35.3057\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 6.5699 - val_loss: 36.8938\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 7.0364 - val_loss: 37.6453\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 5.7477 - val_loss: 37.4014\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 5.7157 - val_loss: 38.0071\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 5.9301 - val_loss: 41.4345\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 7.5174 - val_loss: 35.4486\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 6.0250 - val_loss: 40.9798\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 6.5110 - val_loss: 35.1910\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 5.9900 - val_loss: 34.0310\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 9.9729 - val_loss: 33.0783\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 8.1708 - val_loss: 33.1485\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 9.3432 - val_loss: 37.5175\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 7.1665 - val_loss: 36.4756\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 43us/sample - loss: 6.2309 - val_loss: 35.5631\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 6.0242 - val_loss: 39.6863\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 5.7837 - val_loss: 36.1239\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 5.1737 - val_loss: 38.3119\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 7.2426 - val_loss: 37.9311\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 6.5341 - val_loss: 39.4228\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 5.1048 - val_loss: 38.7828\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 8.0351 - val_loss: 34.5708\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 11.1263 - val_loss: 34.1617\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 7.4421 - val_loss: 34.3868\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 8.5502 - val_loss: 35.8448\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 7.9235 - val_loss: 35.5183\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 19.2594 - val_loss: 37.3162\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 11.7567 - val_loss: 45.7575\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 9.1362 - val_loss: 38.3084\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 8.1600 - val_loss: 43.9576\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 6.6819 - val_loss: 42.0609\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 6.7409 - val_loss: 37.9836\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 7.5044 - val_loss: 47.6716\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 7.7350 - val_loss: 38.3171\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 6.5576 - val_loss: 44.3306\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 6.6948 - val_loss: 38.2668\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 5.3739 - val_loss: 46.5477\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 5.8982 - val_loss: 38.6375\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 5.3592 - val_loss: 40.0378\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 5.1672 - val_loss: 40.3651\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 4.6738 - val_loss: 39.7391\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 4.4671 - val_loss: 42.4495\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 5.9314 - val_loss: 41.7352\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 5.7290 - val_loss: 41.4809\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 4.9287 - val_loss: 38.5411\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 4.6340 - val_loss: 41.5224\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 4.6677 - val_loss: 45.4206\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 8.0544 - val_loss: 41.5753\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 49us/sample - loss: 12.2533 - val_loss: 40.0916\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 49us/sample - loss: 9.0443 - val_loss: 41.6094\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 5.4811 - val_loss: 38.8950\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 57us/sample - loss: 6.0958 - val_loss: 42.1567\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 6.4964 - val_loss: 43.7812\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 5.1039 - val_loss: 41.2739\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 5.1597 - val_loss: 46.4487\n",
      "\n",
      "Mean squared error: 5.2\n",
      "\n",
      "dropout: 2.0e-01\n",
      "filter_num: 240\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 112us/sample - loss: 53.7860 - val_loss: 34.7679\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 40.7563 - val_loss: 29.6986\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 37.0781 - val_loss: 30.9763\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 35.1071 - val_loss: 27.2375\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 31.8396 - val_loss: 26.5935\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 29.2254 - val_loss: 26.1715\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 19us/sample - loss: 26.3532 - val_loss: 26.5653\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 25.1316 - val_loss: 27.1864\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 23.0887 - val_loss: 28.6370\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 21.2439 - val_loss: 29.6844\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 19.2124 - val_loss: 31.6849\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 19.5821 - val_loss: 30.4706\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 19.1688 - val_loss: 29.6325\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 15.9459 - val_loss: 40.0096\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 14.2737 - val_loss: 31.3021\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 13.6432 - val_loss: 35.6393\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 11.2682 - val_loss: 38.2418\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 9.8054 - val_loss: 34.6920\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 8.4678 - val_loss: 35.8565\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 7.9962 - val_loss: 40.1246\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 8.4507 - val_loss: 33.7663\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 7.9347 - val_loss: 37.3142\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 7.1020 - val_loss: 36.3710\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 6.1038 - val_loss: 38.7801\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 5.7049 - val_loss: 35.7862\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 5.6819 - val_loss: 36.0977\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.8530 - val_loss: 40.2479\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.3876 - val_loss: 38.7055\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.8058 - val_loss: 38.1381\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.7998 - val_loss: 37.3490\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.6694 - val_loss: 36.7858\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.0014 - val_loss: 39.6650\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.2707 - val_loss: 37.0759\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.8712 - val_loss: 41.2389\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.0774 - val_loss: 37.6520\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.4892 - val_loss: 40.5701\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.2437 - val_loss: 36.6663\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.3002 - val_loss: 41.9083\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.0110 - val_loss: 38.3476\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.8596 - val_loss: 43.6413\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.9317 - val_loss: 37.0241\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.8726 - val_loss: 41.2182\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.2398 - val_loss: 38.7821\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.1395 - val_loss: 41.9787\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.1601 - val_loss: 38.3884\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.0852 - val_loss: 38.4784\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.6102 - val_loss: 38.9093\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.6551 - val_loss: 40.5593\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.7415 - val_loss: 40.0027\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.4639 - val_loss: 38.7837\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.0393 - val_loss: 41.7705\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.0438 - val_loss: 38.4771\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.9463 - val_loss: 41.4692\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.8865 - val_loss: 38.9852\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.5485 - val_loss: 40.4150\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.7037 - val_loss: 38.0331\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.7715 - val_loss: 39.7809\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.6616 - val_loss: 38.9854\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.7446 - val_loss: 38.7895\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.9134 - val_loss: 38.9713\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.9582 - val_loss: 40.6825\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.6748 - val_loss: 41.1776\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.5027 - val_loss: 40.0347\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.4857 - val_loss: 42.6304\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.4800 - val_loss: 42.6960\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.4447 - val_loss: 39.7135\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.6357 - val_loss: 42.0323\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.4807 - val_loss: 38.5174\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.6619 - val_loss: 42.2244\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.6412 - val_loss: 36.2018\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.0696 - val_loss: 39.0121\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.0920 - val_loss: 37.4113\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.5276 - val_loss: 44.3070\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.8724 - val_loss: 38.6592\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.8279 - val_loss: 44.7026\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.8653 - val_loss: 38.7278\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.0418 - val_loss: 46.2537\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.9705 - val_loss: 36.2663\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.4009 - val_loss: 43.4199\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.8396 - val_loss: 39.4188\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.5093 - val_loss: 45.1090\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.8491 - val_loss: 38.7714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.0574 - val_loss: 43.7468\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.2749 - val_loss: 39.8491\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.9583 - val_loss: 42.5830\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.5761 - val_loss: 40.3439\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 0.9656 - val_loss: 41.9975\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.1670 - val_loss: 39.6197\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.0550 - val_loss: 40.4035\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.0941 - val_loss: 42.1474\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.0386 - val_loss: 41.1487\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 0.9021 - val_loss: 40.8669\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 0.8875 - val_loss: 40.1521\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.0850 - val_loss: 41.1339\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 0.9695 - val_loss: 42.5142\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 0.9472 - val_loss: 39.6502\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.0057 - val_loss: 42.3366\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.3778 - val_loss: 41.7290\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.7213 - val_loss: 41.3697\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.5345 - val_loss: 38.3191\n",
      "\n",
      "Mean squared error: 1.5\n",
      "\n",
      "dropout: 5.0e-01\n",
      "filter_num: 113\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 103us/sample - loss: 57.1000 - val_loss: 48.0440\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 48.5816 - val_loss: 33.9322\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 39.5021 - val_loss: 29.0686\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 37.6624 - val_loss: 29.2244\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 35.3797 - val_loss: 28.7789\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 33.3330 - val_loss: 26.2221\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 31.3966 - val_loss: 25.4873\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 30.3306 - val_loss: 25.4937\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 27.6896 - val_loss: 25.6524\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 26.9456 - val_loss: 26.0454\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 27.0536 - val_loss: 26.4670\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 25.8621 - val_loss: 27.3083\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 24.3928 - val_loss: 28.7655\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 24.0418 - val_loss: 30.2991\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 23.8893 - val_loss: 30.8736\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 20.9407 - val_loss: 32.7742\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 20.3914 - val_loss: 35.3940\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 20.0424 - val_loss: 37.8273\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 19.3081 - val_loss: 39.9857\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 17.7419 - val_loss: 47.5410\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 15.9420 - val_loss: 47.2134\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 16.7504 - val_loss: 67.1898\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 14.9409 - val_loss: 67.1442\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 13.4375 - val_loss: 69.1013\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 13.5366 - val_loss: 81.3259\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 11.7051 - val_loss: 83.7812\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 9.9762 - val_loss: 85.8763\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 9.3785 - val_loss: 104.8855\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 9.4171 - val_loss: 119.6254\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 8.9568 - val_loss: 135.7937\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 8.3812 - val_loss: 150.5137\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 8.0719 - val_loss: 164.2141\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 7.3768 - val_loss: 175.3945\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 7.4141 - val_loss: 173.3976\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 6.7519 - val_loss: 182.6847\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 6.6397 - val_loss: 172.5412\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 6.5990 - val_loss: 184.4498\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 6.2438 - val_loss: 192.0796\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 6.4262 - val_loss: 198.2259\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 6.2851 - val_loss: 209.3262\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 6.7495 - val_loss: 200.2260\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 6.3640 - val_loss: 192.6710\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 6.6731 - val_loss: 193.6874\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 6.8946 - val_loss: 194.8196\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 6.5808 - val_loss: 193.9130\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 5.7604 - val_loss: 208.5884\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 5.0922 - val_loss: 206.3216\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 5.2990 - val_loss: 221.6809\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 5.8625 - val_loss: 217.9935\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 5.3577 - val_loss: 218.6172\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 6.2283 - val_loss: 222.7674\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.8407 - val_loss: 221.2404\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.8373 - val_loss: 230.5508\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.8996 - val_loss: 233.8271\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.2075 - val_loss: 236.9465\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.6945 - val_loss: 247.7809\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 14us/sample - loss: 5.6820 - val_loss: 245.7350\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 5.2814 - val_loss: 249.6536\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 5.1461 - val_loss: 229.4728\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.9253 - val_loss: 199.8990\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.9961 - val_loss: 218.8637\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 5.3373 - val_loss: 220.1414\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.6802 - val_loss: 254.9682\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 5.6407 - val_loss: 271.7488\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.7971 - val_loss: 255.0255\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 5.1417 - val_loss: 285.0305\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 5.2932 - val_loss: 246.6544\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.6963 - val_loss: 264.5789\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.2948 - val_loss: 253.9115\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.1184 - val_loss: 262.5414\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.5216 - val_loss: 262.8244\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 4.1541 - val_loss: 268.8859\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.5932 - val_loss: 308.9243\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.9909 - val_loss: 259.4533\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 6.3907 - val_loss: 222.3780\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 5.7585 - val_loss: 255.3250\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 7.0104 - val_loss: 207.0884\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 5.6775 - val_loss: 225.6495\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.9734 - val_loss: 255.9107\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 5.0072 - val_loss: 243.7823\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.8198 - val_loss: 293.3106\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.7194 - val_loss: 271.4864\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.8855 - val_loss: 261.2899\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 4.1962 - val_loss: 291.2351\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.5912 - val_loss: 248.6667\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.6354 - val_loss: 259.4021\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.3799 - val_loss: 243.9698\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.3578 - val_loss: 254.6164\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.5611 - val_loss: 238.4061\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.5513 - val_loss: 254.5577\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 3.2383 - val_loss: 262.8658\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.8737 - val_loss: 295.4184\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.5527 - val_loss: 271.7824\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 3.7383 - val_loss: 286.8115\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.0107 - val_loss: 282.2894\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 4.5501 - val_loss: 255.6755\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.3774 - val_loss: 297.2874\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 3.7720 - val_loss: 271.7400\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.1674 - val_loss: 292.0771\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 3.5032 - val_loss: 290.9933\n",
      "\n",
      "Mean squared error: 3.5\n",
      "\n",
      "dropout: 3.9e-01\n",
      "filter_num: 153\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 113us/sample - loss: 56.9708 - val_loss: 45.6405\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 45.2369 - val_loss: 31.0234\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 41.4178 - val_loss: 29.7588\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 36.8839 - val_loss: 31.1751\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 35.8708 - val_loss: 28.3032\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 32.6453 - val_loss: 26.9218\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 30.7153 - val_loss: 26.6502\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 29.0198 - val_loss: 25.9750\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 27.3540 - val_loss: 26.6410\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 28.7761 - val_loss: 29.0802\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 24.6907 - val_loss: 26.5384\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 23.6779 - val_loss: 27.2069\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 22.8813 - val_loss: 29.6667\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 21.6386 - val_loss: 29.0090\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 21.1034 - val_loss: 30.7079\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 18.7457 - val_loss: 33.2996\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 18.2913 - val_loss: 34.0382\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 17.6284 - val_loss: 37.8334\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 16.3809 - val_loss: 39.6560\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 14.7371 - val_loss: 44.6866\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 14.3802 - val_loss: 50.6141\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 14.0734 - val_loss: 48.0856\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 13.1042 - val_loss: 66.9935\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 11.4732 - val_loss: 53.8105\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 11.5179 - val_loss: 65.8502\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 10.3467 - val_loss: 72.3440\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 10.2154 - val_loss: 69.7095\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 9.3969 - val_loss: 77.5403\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 8.9067 - val_loss: 75.2499\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 7.4951 - val_loss: 75.3487\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 19us/sample - loss: 6.8419 - val_loss: 83.1328\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 7.3324 - val_loss: 75.2763\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 7.7585 - val_loss: 74.5583\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 6.7069 - val_loss: 82.1539\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 6.7614 - val_loss: 82.5976\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 6.1092 - val_loss: 99.1283\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 6.2637 - val_loss: 94.8661\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 5.6934 - val_loss: 105.1731\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 5.6169 - val_loss: 101.4388\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 5.0656 - val_loss: 100.6403\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 5.3334 - val_loss: 97.3934\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.8419 - val_loss: 101.8327\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.6168 - val_loss: 95.3220\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.8059 - val_loss: 106.5644\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 6.6205 - val_loss: 95.3571\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 5.3904 - val_loss: 93.3628\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.8851 - val_loss: 97.4065\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.7445 - val_loss: 93.7590\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.4855 - val_loss: 100.9979\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 4.3299 - val_loss: 107.5008\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.1123 - val_loss: 107.6726\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.4415 - val_loss: 112.8896\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 4.4784 - val_loss: 111.8260\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 3.5421 - val_loss: 114.3561\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 3.8348 - val_loss: 126.5050\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.8081 - val_loss: 116.1978\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.6841 - val_loss: 120.5105\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.6741 - val_loss: 107.1234\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.0846 - val_loss: 109.4283\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 5.0777 - val_loss: 98.0714\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.2232 - val_loss: 94.3598\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.9130 - val_loss: 104.3088\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.8458 - val_loss: 101.4845\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 3.4689 - val_loss: 117.2708\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 3.6823 - val_loss: 105.9816\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 7.5951 - val_loss: 85.5303\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 6.4850 - val_loss: 108.8271\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 5.4183 - val_loss: 96.1903\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 5.1512 - val_loss: 114.1325\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 4.8024 - val_loss: 120.0153\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 4.4300 - val_loss: 107.6292\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 4.0609 - val_loss: 116.4008\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 3.6483 - val_loss: 114.9429\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.2141 - val_loss: 119.5372\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 3.5001 - val_loss: 127.1145\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 3.7562 - val_loss: 117.6794\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.5177 - val_loss: 129.2099\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 3.9332 - val_loss: 121.7271\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.8372 - val_loss: 131.6895\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 3.4860 - val_loss: 135.1297\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 3.0007 - val_loss: 140.1717\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 3.4800 - val_loss: 137.1944\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.8679 - val_loss: 132.3011\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.7089 - val_loss: 131.8900\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.3125 - val_loss: 126.8033\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 2.7360 - val_loss: 133.5630\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.0133 - val_loss: 118.3590\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 3.4362 - val_loss: 106.9232\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 3.0306 - val_loss: 117.2149\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 3.2485 - val_loss: 112.5432\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 2.9910 - val_loss: 118.8617\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 3.1851 - val_loss: 116.0380\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 2.7346 - val_loss: 112.9858\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.6968 - val_loss: 113.9339\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.4660 - val_loss: 113.7039\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.7927 - val_loss: 123.6555\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 2.3359 - val_loss: 126.6990\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 2.0701 - val_loss: 133.6755\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.2329 - val_loss: 127.5029\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 2.1987 - val_loss: 132.4082\n",
      "\n",
      "Mean squared error: 2.2\n",
      "\n",
      "dropout: 2.0e-01\n",
      "filter_num: 300\n",
      "num_dense_layers: 5\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 1s 209us/sample - loss: 52.6333 - val_loss: 33.0416\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 43.4556 - val_loss: 38.6434\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 39.4729 - val_loss: 28.8902\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 61us/sample - loss: 35.9737 - val_loss: 30.8175\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 52us/sample - loss: 33.0161 - val_loss: 26.8115\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 29.2281 - val_loss: 26.3540\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 25.5724 - val_loss: 28.0304\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 21.6257 - val_loss: 40.1654\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 21.4041 - val_loss: 30.8265\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 16.6114 - val_loss: 32.5076\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 14.1770 - val_loss: 39.8147\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 12.7665 - val_loss: 34.4319\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 12.2145 - val_loss: 31.4497\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 16.1517 - val_loss: 33.9991\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 11.7043 - val_loss: 30.1803\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 10.3708 - val_loss: 30.1574\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 9.6493 - val_loss: 33.3662\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 8.4836 - val_loss: 28.7588\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 7.5487 - val_loss: 29.0173\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 7.6352 - val_loss: 32.2757\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 7.5647 - val_loss: 31.1059\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 6.1918 - val_loss: 37.2164\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 6.4076 - val_loss: 31.3815\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 5.9151 - val_loss: 29.7642\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 6.4315 - val_loss: 29.7963\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 5.6381 - val_loss: 29.9308\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 5.6421 - val_loss: 32.9228\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 5.9710 - val_loss: 31.5314\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 6.8023 - val_loss: 31.7802\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 5.3448 - val_loss: 31.2566\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 5.7705 - val_loss: 30.3592\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 6.0100 - val_loss: 30.3260\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 5.8242 - val_loss: 29.5022\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 5.0218 - val_loss: 30.2414\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 5.0045 - val_loss: 31.9544\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 5.5448 - val_loss: 29.6422\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 5.4882 - val_loss: 30.5270\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 7.3891 - val_loss: 34.0198\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 7.2469 - val_loss: 29.7764\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 4.9781 - val_loss: 29.3530\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 5.3411 - val_loss: 29.2783\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 11.2246 - val_loss: 37.0259\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 13.5239 - val_loss: 34.9438\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 15.1773 - val_loss: 53.0850\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 9.9878 - val_loss: 31.6568\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 8.3500 - val_loss: 35.2398\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 5.9996 - val_loss: 29.1341\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 5.9068 - val_loss: 29.3737\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 5.6335 - val_loss: 29.9248\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 57us/sample - loss: 5.8042 - val_loss: 33.0899\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 5.5750 - val_loss: 37.3768\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 6.3757 - val_loss: 30.8679\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 6.0889 - val_loss: 33.6318\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 6.0295 - val_loss: 30.5089\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 5.4607 - val_loss: 33.5357\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 4.4550 - val_loss: 31.7019\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 4.2252 - val_loss: 31.8925\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 3.5719 - val_loss: 32.8035\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 3.5103 - val_loss: 32.4310\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 3.6389 - val_loss: 31.7150\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 3.0253 - val_loss: 31.5793\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 3.6072 - val_loss: 32.3741\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 4.3655 - val_loss: 31.0435\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 4.2728 - val_loss: 35.0586\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 3.3549 - val_loss: 31.0971\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 3.6555 - val_loss: 33.9163\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 3.3016 - val_loss: 31.6861\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 3.4406 - val_loss: 30.2321\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 4.3489 - val_loss: 31.0897\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 3.3082 - val_loss: 31.4838\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 3.0651 - val_loss: 31.1865\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 2.9127 - val_loss: 30.7644\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 57us/sample - loss: 3.1722 - val_loss: 30.5440\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 56us/sample - loss: 2.8672 - val_loss: 31.4479\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 58us/sample - loss: 3.3889 - val_loss: 31.0193\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 58us/sample - loss: 2.9544 - val_loss: 33.7234\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 2.8941 - val_loss: 31.4926\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 64us/sample - loss: 2.7786 - val_loss: 34.0542\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 57us/sample - loss: 3.4513 - val_loss: 31.4758\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 57us/sample - loss: 3.1004 - val_loss: 31.8361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 56us/sample - loss: 2.6530 - val_loss: 34.7631\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 57us/sample - loss: 3.0927 - val_loss: 31.5102\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 2.4910 - val_loss: 35.5763\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 3.8287 - val_loss: 31.5405\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 3.4326 - val_loss: 34.5585\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 4.3404 - val_loss: 30.2308\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 4.0745 - val_loss: 33.8535\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 4.3805 - val_loss: 29.3681\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 4.6106 - val_loss: 37.2126\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 3.6889 - val_loss: 30.9445\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 3.9270 - val_loss: 36.2304\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 3.3811 - val_loss: 31.1124\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 4.0241 - val_loss: 31.5179\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 3.4324 - val_loss: 31.5759\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 3.3733 - val_loss: 32.0407\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 3.3294 - val_loss: 31.5360\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 2.5066 - val_loss: 33.3533\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 3.2735 - val_loss: 30.9493\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 3.4574 - val_loss: 37.3521\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 3.8686 - val_loss: 31.0504\n",
      "\n",
      "Mean squared error: 3.9\n",
      "\n",
      "dropout: 3.6e-01\n",
      "filter_num: 300\n",
      "num_dense_layers: 12\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 1s 413us/sample - loss: 55.7498 - val_loss: 50.6752\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 106us/sample - loss: 49.4718 - val_loss: 51.5909\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 103us/sample - loss: 45.7295 - val_loss: 44.3913\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 107us/sample - loss: 40.7350 - val_loss: 44.4667\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 103us/sample - loss: 38.1950 - val_loss: 42.3547\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 107us/sample - loss: 36.2337 - val_loss: 37.9017\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 98us/sample - loss: 31.9438 - val_loss: 39.0368\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 105us/sample - loss: 32.9540 - val_loss: 29.9617\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 111us/sample - loss: 31.6960 - val_loss: 41.2882\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 106us/sample - loss: 27.8608 - val_loss: 33.2816\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 104us/sample - loss: 26.5778 - val_loss: 33.4717\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 114us/sample - loss: 23.1828 - val_loss: 33.5446\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 112us/sample - loss: 26.0954 - val_loss: 42.2892\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 111us/sample - loss: 22.1232 - val_loss: 33.3408\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 114us/sample - loss: 20.3367 - val_loss: 34.4953\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 111us/sample - loss: 19.1718 - val_loss: 37.3473\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 117us/sample - loss: 17.6277 - val_loss: 33.7030\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 107us/sample - loss: 19.8754 - val_loss: 34.0273\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 106us/sample - loss: 17.0244 - val_loss: 35.5347\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 103us/sample - loss: 18.1183 - val_loss: 34.8189\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 104us/sample - loss: 13.1724 - val_loss: 35.6461\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 97us/sample - loss: 17.9866 - val_loss: 36.7335\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 104us/sample - loss: 17.2518 - val_loss: 36.6988\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 105us/sample - loss: 15.0084 - val_loss: 33.1767\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 102us/sample - loss: 18.2280 - val_loss: 35.5795\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 108us/sample - loss: 15.4201 - val_loss: 40.1352\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 109us/sample - loss: 17.3820 - val_loss: 31.4206\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 107us/sample - loss: 18.2968 - val_loss: 39.2558\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 109us/sample - loss: 30.8978 - val_loss: 42.1039\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 113us/sample - loss: 23.8383 - val_loss: 32.0413\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 105us/sample - loss: 25.2325 - val_loss: 43.7049\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 105us/sample - loss: 30.2190 - val_loss: 32.3986\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 98us/sample - loss: 25.0184 - val_loss: 39.1220\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 103us/sample - loss: 20.4250 - val_loss: 29.3602\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 104us/sample - loss: 20.5343 - val_loss: 39.0911\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 101us/sample - loss: 17.2361 - val_loss: 31.0937\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 110us/sample - loss: 22.1848 - val_loss: 40.8369\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 104us/sample - loss: 18.3095 - val_loss: 30.4541\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 105us/sample - loss: 25.2909 - val_loss: 41.4512\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 100us/sample - loss: 21.7727 - val_loss: 28.8400\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 104us/sample - loss: 14.2622 - val_loss: 37.1968\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 104us/sample - loss: 15.9712 - val_loss: 31.0833\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 103us/sample - loss: 20.0047 - val_loss: 40.2523\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 102us/sample - loss: 20.7325 - val_loss: 31.6061\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 99us/sample - loss: 17.6070 - val_loss: 37.3437\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 102us/sample - loss: 13.6988 - val_loss: 31.4724\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 105us/sample - loss: 15.6278 - val_loss: 35.1778\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 103us/sample - loss: 14.8803 - val_loss: 33.8436\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 94us/sample - loss: 13.0978 - val_loss: 36.7769\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 103us/sample - loss: 13.4367 - val_loss: 34.4580\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 105us/sample - loss: 12.1367 - val_loss: 34.7029\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 104us/sample - loss: 11.5782 - val_loss: 32.3375\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 104us/sample - loss: 11.3063 - val_loss: 34.8868\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 103us/sample - loss: 13.7610 - val_loss: 33.6054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 103us/sample - loss: 12.7502 - val_loss: 36.2671\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 103us/sample - loss: 11.3936 - val_loss: 33.3987\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 103us/sample - loss: 12.0020 - val_loss: 36.4777\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 103us/sample - loss: 12.1088 - val_loss: 36.8107\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 104us/sample - loss: 12.7958 - val_loss: 31.0206\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 99us/sample - loss: 10.2896 - val_loss: 36.8282\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 106us/sample - loss: 10.8046 - val_loss: 31.3448\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 103us/sample - loss: 11.8435 - val_loss: 35.4052\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 104us/sample - loss: 9.8047 - val_loss: 33.3960\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 106us/sample - loss: 11.9476 - val_loss: 36.9303\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 105us/sample - loss: 12.0421 - val_loss: 34.5040\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 103us/sample - loss: 10.2265 - val_loss: 34.4475\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 101us/sample - loss: 8.9817 - val_loss: 35.9922\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 104us/sample - loss: 8.3386 - val_loss: 34.0808\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 104us/sample - loss: 10.0965 - val_loss: 35.1319\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 97us/sample - loss: 12.0925 - val_loss: 36.9995\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 106us/sample - loss: 12.6786 - val_loss: 32.4476\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 102us/sample - loss: 14.1083 - val_loss: 35.0936\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 105us/sample - loss: 13.0110 - val_loss: 35.9414\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 103us/sample - loss: 17.0510 - val_loss: 33.9879\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 103us/sample - loss: 12.3235 - val_loss: 36.2605\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 105us/sample - loss: 24.7255 - val_loss: 35.1970\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 102us/sample - loss: 21.3085 - val_loss: 35.5301\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 104us/sample - loss: 18.3551 - val_loss: 33.8948\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 102us/sample - loss: 16.5531 - val_loss: 33.4649\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 102us/sample - loss: 18.7650 - val_loss: 36.2290\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 103us/sample - loss: 13.0901 - val_loss: 31.7976\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 102us/sample - loss: 19.8442 - val_loss: 35.4168\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 107us/sample - loss: 16.6719 - val_loss: 38.6633\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 105us/sample - loss: 26.2548 - val_loss: 41.0411\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 105us/sample - loss: 22.1024 - val_loss: 32.5617\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 104us/sample - loss: 21.6693 - val_loss: 41.6578\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 109us/sample - loss: 23.6448 - val_loss: 33.5194\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 114us/sample - loss: 17.0288 - val_loss: 36.9927\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 113us/sample - loss: 16.3157 - val_loss: 34.4418\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 107us/sample - loss: 14.4634 - val_loss: 34.6406\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 108us/sample - loss: 12.3578 - val_loss: 35.9822\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 101us/sample - loss: 11.8566 - val_loss: 36.2329\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 102us/sample - loss: 15.0159 - val_loss: 38.4798\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 102us/sample - loss: 19.7666 - val_loss: 32.8670\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 103us/sample - loss: 13.4481 - val_loss: 34.2952\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 105us/sample - loss: 12.6507 - val_loss: 33.1337\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 102us/sample - loss: 10.6300 - val_loss: 33.2340\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 104us/sample - loss: 11.0479 - val_loss: 33.3384\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 105us/sample - loss: 8.9588 - val_loss: 33.4726\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 104us/sample - loss: 15.7259 - val_loss: 36.5794\n",
      "\n",
      "Mean squared error: 1.6e+01\n",
      "\n",
      "dropout: 3.8e-01\n",
      "filter_num: 123\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 98us/sample - loss: 58.1051 - val_loss: 49.9276\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 51.1491 - val_loss: 37.4699\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 39.9345 - val_loss: 30.7716\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 40.1900 - val_loss: 28.7473\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 35.8217 - val_loss: 30.6203\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 35.1399 - val_loss: 28.0061\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 32.5459 - val_loss: 26.2460\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 31.2050 - val_loss: 25.8024\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 28.7268 - val_loss: 25.7581\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 27.6742 - val_loss: 25.7630\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 26.2308 - val_loss: 25.9250\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 25.0361 - val_loss: 26.5272\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 24.1181 - val_loss: 29.9588\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 23.2141 - val_loss: 30.7505\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 23.1337 - val_loss: 31.3312\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 21.4892 - val_loss: 37.4736\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 20.8426 - val_loss: 42.6300\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 18.3145 - val_loss: 39.3400\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 17.5667 - val_loss: 52.2455\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 17.2842 - val_loss: 54.9284\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 15.7666 - val_loss: 52.8963\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 13.7394 - val_loss: 74.2888\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 13.7035 - val_loss: 70.9409\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 12.7963 - val_loss: 81.9601\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 11.8630 - val_loss: 97.5907\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 11.3010 - val_loss: 95.8338\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 9.7561 - val_loss: 109.6390\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 16us/sample - loss: 9.4032 - val_loss: 132.7635\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 9.1500 - val_loss: 146.1860\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 8.0809 - val_loss: 153.5233\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 7.3671 - val_loss: 158.4179\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 6.6326 - val_loss: 176.5634\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 7.1259 - val_loss: 158.9544\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 6.7153 - val_loss: 178.8240\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 6.5929 - val_loss: 173.6614\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 6.3774 - val_loss: 193.0418\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 5.7189 - val_loss: 199.3744\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 5.8872 - val_loss: 208.6147\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.7814 - val_loss: 218.9173\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.9288 - val_loss: 210.0546\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 5.1825 - val_loss: 200.2101\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 5.0783 - val_loss: 196.5250\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 5.4377 - val_loss: 185.0958\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - ETA: 0s - loss: 4.947 - 0s 14us/sample - loss: 5.2376 - val_loss: 190.8477\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 5.2538 - val_loss: 190.8545\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.6793 - val_loss: 202.7201\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.6838 - val_loss: 197.6635\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.1918 - val_loss: 198.5251\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.2370 - val_loss: 192.2302\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.3916 - val_loss: 199.6134\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.3570 - val_loss: 189.5634\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.3195 - val_loss: 199.7547\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 3.7850 - val_loss: 208.2701\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.6244 - val_loss: 195.5221\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.4964 - val_loss: 215.7387\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.3388 - val_loss: 200.7116\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.7117 - val_loss: 203.8604\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.6311 - val_loss: 213.2523\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 3.8940 - val_loss: 235.2444\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.7863 - val_loss: 234.5578\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.8002 - val_loss: 222.3721\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.5871 - val_loss: 238.9661\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 5.3521 - val_loss: 238.2864\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 5.4157 - val_loss: 230.1857\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.3281 - val_loss: 249.2711\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.1552 - val_loss: 216.0145\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.6501 - val_loss: 239.7055\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.7603 - val_loss: 233.6151\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.3614 - val_loss: 233.0304\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.2096 - val_loss: 259.9631\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.8290 - val_loss: 187.4902\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 7.3451 - val_loss: 167.9547\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 5.5323 - val_loss: 184.1007\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 5.2943 - val_loss: 181.9888\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.5405 - val_loss: 217.3087\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.8673 - val_loss: 219.5125\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.1938 - val_loss: 248.0229\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.6744 - val_loss: 241.5519\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.7138 - val_loss: 231.4877\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 3.6777 - val_loss: 209.8036\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.8041 - val_loss: 210.1965\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.6898 - val_loss: 202.0885\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 3.6639 - val_loss: 224.4068\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.4594 - val_loss: 222.4813\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.1120 - val_loss: 228.2747\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.6374 - val_loss: 242.0253\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.6570 - val_loss: 239.7532\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.7129 - val_loss: 232.4655\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.3119 - val_loss: 243.5041\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.3906 - val_loss: 225.4096\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.1007 - val_loss: 225.1042\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.5038 - val_loss: 259.7319\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.0803 - val_loss: 244.0299\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.8333 - val_loss: 260.9913\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.9270 - val_loss: 268.5695\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.9709 - val_loss: 255.4564\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.3536 - val_loss: 273.6782\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.1162 - val_loss: 241.0110\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.5938 - val_loss: 258.3268\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.9861 - val_loss: 263.8192\n",
      "\n",
      "Mean squared error: 3.0\n",
      "\n",
      "dropout: 4.5e-01\n",
      "filter_num: 300\n",
      "num_dense_layers: 3\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 160us/sample - loss: 49.3525 - val_loss: 31.8345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 42.6411 - val_loss: 39.3880\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 39.9600 - val_loss: 33.6462\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 36.5373 - val_loss: 29.8560\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 33.4359 - val_loss: 29.8477\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 31.9923 - val_loss: 27.8877\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 29.4219 - val_loss: 29.2328\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 27.0861 - val_loss: 29.3938\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 24.8802 - val_loss: 31.4660\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 23.5590 - val_loss: 32.2467\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 20.6819 - val_loss: 32.3551\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 19.8711 - val_loss: 34.3910\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 18.9499 - val_loss: 34.4525\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 17.4033 - val_loss: 35.8015\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 14.5266 - val_loss: 35.3230\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 13.6639 - val_loss: 36.8819\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 12.7162 - val_loss: 37.5343\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 42us/sample - loss: 12.8206 - val_loss: 38.6359\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 10.2290 - val_loss: 40.4183\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 9.7552 - val_loss: 41.9000\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 10.2711 - val_loss: 42.4468\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 9.0160 - val_loss: 45.2538\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 8.5856 - val_loss: 45.0892\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 8.9820 - val_loss: 44.4917\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 9.1364 - val_loss: 44.1507\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 9.1870 - val_loss: 38.2554\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 8.8767 - val_loss: 42.0410\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 9.9789 - val_loss: 42.0869\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 8.6719 - val_loss: 54.3195\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 8.4105 - val_loss: 44.4300\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 43us/sample - loss: 8.3644 - val_loss: 41.9401\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 8.3017 - val_loss: 38.8726\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 7.0820 - val_loss: 38.1843\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 7.5449 - val_loss: 40.7700\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 6.5637 - val_loss: 43.3238\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 6.9538 - val_loss: 44.0958\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 7.4107 - val_loss: 42.2417\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 6.4722 - val_loss: 40.9734\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 7.8013 - val_loss: 38.2916\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 6.7049 - val_loss: 46.7570\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 10.1103 - val_loss: 39.3282\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 9.6041 - val_loss: 47.8664\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 11.3890 - val_loss: 39.7719\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 6.2550 - val_loss: 45.8021\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 7.7102 - val_loss: 40.2369\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 42us/sample - loss: 6.2622 - val_loss: 44.3307\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 43us/sample - loss: 6.1266 - val_loss: 40.3331\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 43us/sample - loss: 6.0148 - val_loss: 45.0167\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 42us/sample - loss: 5.3717 - val_loss: 40.6132\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 42us/sample - loss: 5.2089 - val_loss: 45.1128\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 5.1102 - val_loss: 44.2278\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 42us/sample - loss: 4.8500 - val_loss: 50.7017\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 5.5404 - val_loss: 43.0158\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 4.4757 - val_loss: 48.6668\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 42us/sample - loss: 5.4325 - val_loss: 42.5803\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 42us/sample - loss: 4.6804 - val_loss: 46.4848\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 6.1560 - val_loss: 47.1350\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 13.6630 - val_loss: 44.8359\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 42us/sample - loss: 19.8482 - val_loss: 41.7935\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 15.6245 - val_loss: 53.9740\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 10.3854 - val_loss: 43.2738\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 11.8376 - val_loss: 53.0742\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 10.4072 - val_loss: 47.9188\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 10.2034 - val_loss: 55.8078\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 8.5660 - val_loss: 52.3986\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 10.5983 - val_loss: 53.6264\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 9.1220 - val_loss: 48.4973\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 7.1821 - val_loss: 55.7350\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 6.5413 - val_loss: 50.1747\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 7.8476 - val_loss: 54.8769\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 6.4455 - val_loss: 49.4106\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 7.8437 - val_loss: 50.6834\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 5.9221 - val_loss: 52.3583\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 6.9442 - val_loss: 46.7714\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 8.2188 - val_loss: 51.7245\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 6.1040 - val_loss: 47.5552\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 40us/sample - loss: 7.3902 - val_loss: 45.5949\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 6.8961 - val_loss: 51.0126\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 7.8272 - val_loss: 45.0417\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 7.6217 - val_loss: 55.9972\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 6.3260 - val_loss: 47.8438\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 7.4673 - val_loss: 59.1065\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 6.0217 - val_loss: 57.0222\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 5.5437 - val_loss: 60.8096\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 6.2379 - val_loss: 52.4062\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 5.9852 - val_loss: 58.3783\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 6.9733 - val_loss: 52.0612\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 4.9140 - val_loss: 57.1050\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 4.9368 - val_loss: 51.8378\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 5.2890 - val_loss: 49.3822\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 6.0027 - val_loss: 52.7945\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 6.4241 - val_loss: 52.6811\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 6.2045 - val_loss: 49.5831\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 6.3949 - val_loss: 47.1740\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 5.6172 - val_loss: 46.9079\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 4.6284 - val_loss: 47.6600\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 5.0387 - val_loss: 48.9558\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 4.6020 - val_loss: 49.4423\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 4.4288 - val_loss: 54.1206\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 42us/sample - loss: 4.1522 - val_loss: 51.8368\n",
      "\n",
      "Mean squared error: 4.2\n",
      "\n",
      "dropout: 2.0e-01\n",
      "filter_num: 10\n",
      "num_dense_layers: 7\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 196us/sample - loss: 59.3803 - val_loss: 55.1628\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 59.3010 - val_loss: 55.0684\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 59.2021 - val_loss: 54.9308\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 59.0459 - val_loss: 54.6933\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 58.7178 - val_loss: 54.2535\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 58.2185 - val_loss: 53.4212\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 57.1209 - val_loss: 51.6838\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 54.8544 - val_loss: 48.1234\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 50.9291 - val_loss: 41.7253\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 46.0890 - val_loss: 33.6358\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 44.8980 - val_loss: 31.7620\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 42.9931 - val_loss: 33.9365\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 41.9628 - val_loss: 34.1373\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 40.0819 - val_loss: 32.5749\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 39.4091 - val_loss: 30.2627\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 40.0820 - val_loss: 31.1751\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 36.8436 - val_loss: 31.8832\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 40.0449 - val_loss: 31.8919\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 36.7750 - val_loss: 31.3630\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 34.6763 - val_loss: 29.7629\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 33.3620 - val_loss: 28.2613\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 33.7867 - val_loss: 29.3478\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 33.4563 - val_loss: 31.9921\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 34.8783 - val_loss: 30.7819\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 35.5624 - val_loss: 29.0624\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 35.9153 - val_loss: 29.4245\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 33.8486 - val_loss: 31.1501\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 35.2904 - val_loss: 30.6655\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 32.2835 - val_loss: 30.1684\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 33.1177 - val_loss: 31.0055\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 30.6386 - val_loss: 29.5468\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 30.4364 - val_loss: 29.2175\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 28.1910 - val_loss: 28.4419\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 33.4420 - val_loss: 28.9142\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 32.0866 - val_loss: 29.8802\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 30.4324 - val_loss: 31.6241\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 28.0398 - val_loss: 31.1317\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 28.0906 - val_loss: 29.5895\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 28.9658 - val_loss: 30.1266\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 26.3997 - val_loss: 31.7794\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 26.7354 - val_loss: 31.5577\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 28.5087 - val_loss: 31.9801\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 24.5689 - val_loss: 31.5701\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 21.2038 - val_loss: 31.5504\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 23.9015 - val_loss: 32.0956\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 21.6969 - val_loss: 32.7819\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 22.9019 - val_loss: 33.4990\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 23.6992 - val_loss: 35.0253\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 25.2816 - val_loss: 35.5177\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 21.3235 - val_loss: 34.9141\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 13us/sample - loss: 18.7373 - val_loss: 35.5730\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 21.2466 - val_loss: 37.1755\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 18.9639 - val_loss: 39.3003\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 17.7940 - val_loss: 40.8456\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 24.5790 - val_loss: 40.4192\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 20.6609 - val_loss: 38.8513\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 20.1117 - val_loss: 36.5082\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 21.6500 - val_loss: 35.5465\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 19.6696 - val_loss: 37.6548\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 23.6104 - val_loss: 39.2803\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 19.0590 - val_loss: 40.3838\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 19.5803 - val_loss: 40.9625\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 16.5041 - val_loss: 40.9735\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 16.0884 - val_loss: 41.8044\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 17.0065 - val_loss: 42.2274\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 18.5542 - val_loss: 43.6387\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 19.5613 - val_loss: 44.3724\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 20.0610 - val_loss: 45.0081\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 17.8742 - val_loss: 45.3660\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 15.7355 - val_loss: 41.3405\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 17.7608 - val_loss: 39.8108\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 18.2798 - val_loss: 39.0513\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 18.0830 - val_loss: 39.2721\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 17.2010 - val_loss: 40.6231\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 15.2266 - val_loss: 41.3500\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 15.4099 - val_loss: 42.1486\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 16.5734 - val_loss: 43.7069\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 15.5619 - val_loss: 43.6036\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 19.1492 - val_loss: 41.8859\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 18.9301 - val_loss: 40.7093\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 16.0379 - val_loss: 40.3631\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 19.2042 - val_loss: 42.8097\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 17.6254 - val_loss: 42.9169\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 15.8572 - val_loss: 43.9672\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 16.3460 - val_loss: 45.4467\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 14.5795 - val_loss: 47.2544\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 13.5169 - val_loss: 48.2862\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 16.7745 - val_loss: 48.1274\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 17.0496 - val_loss: 48.3346\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 16.5857 - val_loss: 45.4222\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 14.9289 - val_loss: 44.4021\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 14.6987 - val_loss: 44.3457\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 14.8673 - val_loss: 44.3988\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 14.0316 - val_loss: 44.0987\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 12.9906 - val_loss: 44.2854\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 13.9735 - val_loss: 44.5970\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 13.2323 - val_loss: 45.0636\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 14.2381 - val_loss: 46.2557\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 13.0944 - val_loss: 46.5803\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 12.6627 - val_loss: 46.4831\n",
      "\n",
      "Mean squared error: 1.3e+01\n",
      "\n",
      "dropout: 2.0e-01\n",
      "filter_num: 126\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 103us/sample - loss: 58.5107 - val_loss: 50.2945\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 51.9138 - val_loss: 37.6034\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 40.5663 - val_loss: 30.4291\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 38.4862 - val_loss: 28.2009\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 34.6303 - val_loss: 28.5454\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 32.9003 - val_loss: 25.9876\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 30.9766 - val_loss: 25.9136\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 28.6580 - val_loss: 25.7994\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 26.9718 - val_loss: 26.4466\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 25.0020 - val_loss: 27.2537\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 23.8916 - val_loss: 28.5133\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 22.6018 - val_loss: 29.2205\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 21.5750 - val_loss: 32.5709\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 20.0726 - val_loss: 35.1468\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 19.1689 - val_loss: 43.4140\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 18.6574 - val_loss: 42.9648\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 16.1762 - val_loss: 55.1090\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 15.6730 - val_loss: 58.7356\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 13.2935 - val_loss: 64.7258\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 11.1249 - val_loss: 79.8010\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 10.1735 - val_loss: 83.1391\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 9.1130 - val_loss: 98.4760\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 7.7993 - val_loss: 98.7959\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 7.2424 - val_loss: 119.8163\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 15us/sample - loss: 6.5863 - val_loss: 119.7463\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 6.3767 - val_loss: 151.7642\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 5.9460 - val_loss: 147.1169\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 6.3265 - val_loss: 145.3202\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 5.7092 - val_loss: 140.5633\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 5.1763 - val_loss: 153.3885\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.6461 - val_loss: 158.4615\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.5458 - val_loss: 175.9141\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.3328 - val_loss: 166.8512\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.0929 - val_loss: 173.8626\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.5673 - val_loss: 174.1230\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 3.2960 - val_loss: 178.1864\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.2716 - val_loss: 190.7557\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.9029 - val_loss: 159.7057\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.1025 - val_loss: 173.2287\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.1583 - val_loss: 159.4730\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.5566 - val_loss: 191.2602\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.2667 - val_loss: 164.7897\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 3.4988 - val_loss: 176.6818\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.1583 - val_loss: 171.9033\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 2.7030 - val_loss: 186.1729\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.5451 - val_loss: 179.5133\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.7165 - val_loss: 193.8934\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.4935 - val_loss: 192.2736\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.2347 - val_loss: 203.5934\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.3886 - val_loss: 211.7112\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 2.8439 - val_loss: 210.6716\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 3.4062 - val_loss: 219.7444\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.7820 - val_loss: 189.9332\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.3397 - val_loss: 199.2349\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 2.8421 - val_loss: 178.6773\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.9317 - val_loss: 196.1357\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 2.4405 - val_loss: 188.3987\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.3010 - val_loss: 213.0005\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 2.6529 - val_loss: 203.7309\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 2.3627 - val_loss: 214.6952\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.0078 - val_loss: 203.1451\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.7641 - val_loss: 205.1848\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 1.9296 - val_loss: 212.8723\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 1.8751 - val_loss: 218.2911\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 1.8309 - val_loss: 230.7951\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 1.9509 - val_loss: 208.3968\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.6521 - val_loss: 216.4619\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.8416 - val_loss: 195.0408\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.8595 - val_loss: 223.3282\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.0522 - val_loss: 207.1171\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.1219 - val_loss: 235.1167\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.9455 - val_loss: 217.5538\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.6009 - val_loss: 232.4049\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.7044 - val_loss: 221.9250\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.0921 - val_loss: 223.6284\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 1.5757 - val_loss: 211.5730\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.5971 - val_loss: 213.1320\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.7298 - val_loss: 192.4741\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.5522 - val_loss: 207.9518\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.4072 - val_loss: 209.9122\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.5975 - val_loss: 218.3771\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.5107 - val_loss: 207.0582\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.3748 - val_loss: 205.6776\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.5178 - val_loss: 210.7704\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.4996 - val_loss: 194.9053\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.1556 - val_loss: 199.3794\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.1714 - val_loss: 176.2500\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.3326 - val_loss: 201.8953\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.0307 - val_loss: 182.3157\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.8058 - val_loss: 192.0241\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 1.8527 - val_loss: 183.8045\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 1.5607 - val_loss: 195.7188\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.6821 - val_loss: 174.4445\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.9686 - val_loss: 189.8522\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 1.6893 - val_loss: 183.4999\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.6865 - val_loss: 207.3995\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 1.7652 - val_loss: 176.8228\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.0720 - val_loss: 209.6296\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.1422 - val_loss: 183.3867\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.8687 - val_loss: 232.0033\n",
      "\n",
      "Mean squared error: 1.9\n",
      "\n",
      "dropout: 2.0e-01\n",
      "filter_num: 160\n",
      "num_dense_layers: 3\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 139us/sample - loss: 56.7353 - val_loss: 42.9668\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 43.1468 - val_loss: 30.5719\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 38.4598 - val_loss: 32.6591\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 36.5275 - val_loss: 27.9456\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 32.7549 - val_loss: 26.8350\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 30.3205 - val_loss: 26.6250\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 27.3619 - val_loss: 26.5272\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 27.1282 - val_loss: 26.9237\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 24.0286 - val_loss: 28.2905\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 23.0530 - val_loss: 28.7375\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 21.5601 - val_loss: 31.3981\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 19.2191 - val_loss: 30.6226\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 17.8259 - val_loss: 41.9443\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 18.0665 - val_loss: 36.0924\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 17.1389 - val_loss: 45.3948\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 14.7314 - val_loss: 44.1090\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 12.5462 - val_loss: 56.7988\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 10.8490 - val_loss: 52.0215\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 9.9360 - val_loss: 58.6604\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 9.2121 - val_loss: 52.4351\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 8.3585 - val_loss: 60.3192\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 8.4048 - val_loss: 56.7774\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 9.4145 - val_loss: 58.5520\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 10.5024 - val_loss: 57.9790\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 8.6623 - val_loss: 72.9720\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 7.3491 - val_loss: 60.9065\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 7.3922 - val_loss: 66.3473\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 6.6221 - val_loss: 67.6766\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 6.5654 - val_loss: 64.0958\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 5.8787 - val_loss: 69.3980\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 6.0686 - val_loss: 63.3450\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 5.3722 - val_loss: 63.7977\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 5.1709 - val_loss: 61.7277\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.9298 - val_loss: 64.3840\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 4.7616 - val_loss: 58.5664\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 4.4447 - val_loss: 67.8415\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 4.5442 - val_loss: 64.8741\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.9488 - val_loss: 76.1722\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 4.2696 - val_loss: 61.9203\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 4.3298 - val_loss: 78.3934\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 4.0945 - val_loss: 65.4332\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 3.7435 - val_loss: 71.9617\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.4879 - val_loss: 74.6625\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 4.0274 - val_loss: 79.5368\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.6978 - val_loss: 70.9629\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 4.7048 - val_loss: 75.5669\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 4.6254 - val_loss: 59.4578\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 4.3997 - val_loss: 69.5679\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 3.8413 - val_loss: 64.3842\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 3.5948 - val_loss: 74.4723\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 4.1466 - val_loss: 66.0421\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 3.6301 - val_loss: 68.9241\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 3.7805 - val_loss: 65.0331\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.8399 - val_loss: 65.9965\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 3.0432 - val_loss: 63.5984\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 3.8735 - val_loss: 71.9250\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.7435 - val_loss: 64.0718\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 4.0861 - val_loss: 77.3496\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.5053 - val_loss: 68.8015\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.5345 - val_loss: 73.8803\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.6422 - val_loss: 71.5547\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.5937 - val_loss: 74.5292\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.7643 - val_loss: 73.1482\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.7252 - val_loss: 76.4325\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.2099 - val_loss: 77.5912\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.2612 - val_loss: 71.8429\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.8213 - val_loss: 72.1720\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.0495 - val_loss: 69.6264\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.4993 - val_loss: 68.4814\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.2997 - val_loss: 74.3198\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.4349 - val_loss: 66.4093\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.5418 - val_loss: 76.6739\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.1529 - val_loss: 72.3292\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.4897 - val_loss: 80.8826\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.6345 - val_loss: 66.6186\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.9249 - val_loss: 82.6017\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.0875 - val_loss: 67.2981\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.3752 - val_loss: 75.1694\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.6110 - val_loss: 76.3296\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 3.2402 - val_loss: 72.1733\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.3875 - val_loss: 76.4345\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.1001 - val_loss: 77.6758\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.8115 - val_loss: 76.2676\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.9027 - val_loss: 95.4483\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 4.3144 - val_loss: 69.1243\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 3.5535 - val_loss: 92.4887\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 3.5220 - val_loss: 65.9416\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.2608 - val_loss: 78.1249\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.0156 - val_loss: 76.3652\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.7777 - val_loss: 85.3460\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.6731 - val_loss: 84.9753\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 2.3830 - val_loss: 88.8661\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 3.1149 - val_loss: 67.8135\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 3.3723 - val_loss: 79.4333\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 3.1224 - val_loss: 69.4930\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.0835 - val_loss: 85.7292\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.6658 - val_loss: 69.3589\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.4917 - val_loss: 79.3328\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.6991 - val_loss: 66.5096\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.3926 - val_loss: 76.6929\n",
      "\n",
      "Mean squared error: 2.4\n",
      "\n",
      "dropout: 2.4e-01\n",
      "filter_num: 300\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 112us/sample - loss: 50.8531 - val_loss: 32.1239\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 41.8821 - val_loss: 30.3497\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 37.1461 - val_loss: 29.6621\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 34.6079 - val_loss: 26.6777\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 30.6118 - val_loss: 25.9632\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 28.0923 - val_loss: 25.8111\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 25.7031 - val_loss: 28.0150\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 24.1897 - val_loss: 28.0483\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 21.8623 - val_loss: 32.9620\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 19.8325 - val_loss: 30.5460\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 20.7623 - val_loss: 32.0814\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 17.4814 - val_loss: 37.7630\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 15.7498 - val_loss: 34.9489\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 13.8006 - val_loss: 46.0838\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 12.6480 - val_loss: 39.1068\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 11.3498 - val_loss: 42.2361\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 8.8257 - val_loss: 40.9115\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 8.9572 - val_loss: 45.7818\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 7.5939 - val_loss: 46.6700\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 6.8458 - val_loss: 46.7833\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.2633 - val_loss: 45.2126\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 5.4413 - val_loss: 48.0268\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.2113 - val_loss: 43.3019\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.9046 - val_loss: 47.2366\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.4339 - val_loss: 50.7940\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 4.5938 - val_loss: 50.9778\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.0368 - val_loss: 57.4176\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.2555 - val_loss: 54.0234\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.8744 - val_loss: 58.4020\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.8577 - val_loss: 51.1811\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.0174 - val_loss: 54.5434\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.8907 - val_loss: 48.9185\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.4668 - val_loss: 53.9143\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 3.2847 - val_loss: 51.4840\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.2596 - val_loss: 50.0584\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 3.2197 - val_loss: 54.3044\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 2.8962 - val_loss: 51.8761\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.7542 - val_loss: 50.9282\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.5602 - val_loss: 54.7205\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 2.6800 - val_loss: 49.4754\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.6531 - val_loss: 56.2360\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.4929 - val_loss: 52.4585\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.6362 - val_loss: 51.5241\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.2385 - val_loss: 50.4367\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 2.4610 - val_loss: 52.7697\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 2.2601 - val_loss: 50.6730\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 2.0930 - val_loss: 51.1398\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.9590 - val_loss: 52.3566\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.9720 - val_loss: 51.6366\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.4449 - val_loss: 54.8504\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.2108 - val_loss: 58.1461\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 2.2008 - val_loss: 56.6239\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.4942 - val_loss: 57.5670\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.3799 - val_loss: 55.5070\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 2.1755 - val_loss: 56.0690\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 2.1503 - val_loss: 56.2238\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.0205 - val_loss: 58.1580\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.9902 - val_loss: 57.0131\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.8609 - val_loss: 55.4149\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.9177 - val_loss: 53.1338\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.9110 - val_loss: 53.5330\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 3.1072 - val_loss: 52.6497\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 2.5311 - val_loss: 54.7996\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.9736 - val_loss: 59.2847\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.0635 - val_loss: 55.1280\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 1.8680 - val_loss: 55.9464\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.6220 - val_loss: 53.0911\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 1.7704 - val_loss: 51.9713\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 1.6399 - val_loss: 58.6742\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 1.4171 - val_loss: 52.7245\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.6217 - val_loss: 60.9006\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 1.4301 - val_loss: 59.8496\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.4753 - val_loss: 56.9053\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 1.3327 - val_loss: 55.7529\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.9911 - val_loss: 51.6907\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.4477 - val_loss: 52.4277\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.8836 - val_loss: 58.7045\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.0324 - val_loss: 54.5398\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 2.1694 - val_loss: 61.8981\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.8959 - val_loss: 57.0991\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.7512 - val_loss: 58.8059\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.6102 - val_loss: 57.9271\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 1.8993 - val_loss: 52.7055\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 2.0952 - val_loss: 65.1087\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 1.8996 - val_loss: 51.8152\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.1854 - val_loss: 64.0570\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.9168 - val_loss: 49.3159\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.1657 - val_loss: 62.8644\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 2.1252 - val_loss: 49.3489\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 1.9295 - val_loss: 62.6761\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 2.0260 - val_loss: 51.2866\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 1.6313 - val_loss: 60.7444\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.7343 - val_loss: 53.4467\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 1.6257 - val_loss: 62.6126\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 1.6450 - val_loss: 51.1329\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.5408 - val_loss: 56.7731\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.3887 - val_loss: 56.0645\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.3716 - val_loss: 54.4090\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.4006 - val_loss: 60.1055\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.4196 - val_loss: 53.2410\n",
      "\n",
      "Mean squared error: 1.4\n",
      "\n",
      "dropout: 2.0e-01\n",
      "filter_num: 205\n",
      "num_dense_layers: 6\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 1s 216us/sample - loss: 57.3840 - val_loss: 39.5761\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 41.8756 - val_loss: 37.6774\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 41.9934 - val_loss: 31.8960\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 34.5689 - val_loss: 27.5610\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 31.9777 - val_loss: 25.7770\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 27.7033 - val_loss: 28.3863\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 26.8742 - val_loss: 33.9038\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 25.1534 - val_loss: 30.4953\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 21.0532 - val_loss: 29.5816\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 19.3968 - val_loss: 29.9966\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 18.3735 - val_loss: 30.9925\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 16.5373 - val_loss: 31.9901\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 18.2269 - val_loss: 30.5453\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 14.4402 - val_loss: 31.3967\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 12.0794 - val_loss: 36.8412\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 11.5277 - val_loss: 32.4583\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 12.5039 - val_loss: 33.6408\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 12.1091 - val_loss: 32.1163\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 10.4473 - val_loss: 32.9119\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 9.6437 - val_loss: 40.8369\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 10.6319 - val_loss: 32.8243\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 38us/sample - loss: 8.6828 - val_loss: 33.4835\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 8.0585 - val_loss: 35.9640\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 7.2637 - val_loss: 34.3044\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 6.6660 - val_loss: 34.6873\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 8.1654 - val_loss: 32.1517\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - ETA: 0s - loss: 8.148 - 0s 39us/sample - loss: 8.2043 - val_loss: 36.6693\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 7.2741 - val_loss: 32.6296\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 6.5065 - val_loss: 40.8759\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 8.7064 - val_loss: 33.7501\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 8.5867 - val_loss: 43.6536\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 9.0034 - val_loss: 31.7054\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 9.3279 - val_loss: 43.8210\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 8.8082 - val_loss: 35.0112\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 23.3607 - val_loss: 37.9784\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 25.9649 - val_loss: 38.8227\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 18.4356 - val_loss: 39.4605\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 14.1136 - val_loss: 30.6785\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 8.7591 - val_loss: 30.9291\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 10.3391 - val_loss: 31.8373\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 8.7246 - val_loss: 34.3942\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 6.8784 - val_loss: 35.2054\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 6.9318 - val_loss: 37.6617\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 5.5998 - val_loss: 35.9749\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 5.4629 - val_loss: 38.2049\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 5.0926 - val_loss: 36.8525\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 5.0582 - val_loss: 37.5063\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 4.9232 - val_loss: 37.2895\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 4.7797 - val_loss: 37.2490\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 5.1953 - val_loss: 36.1466\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 4.5130 - val_loss: 33.5366\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 8.7960 - val_loss: 35.3771\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 6.7043 - val_loss: 34.0703\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 5.5111 - val_loss: 37.1461\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 5.2256 - val_loss: 35.7401\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 4.7839 - val_loss: 35.2244\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 4.9145 - val_loss: 39.4423\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 4.3986 - val_loss: 40.6326\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 6.2436 - val_loss: 38.6063\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 6.2933 - val_loss: 35.5799\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 7.9609 - val_loss: 35.0806\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 5.2894 - val_loss: 41.4627\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 4.1635 - val_loss: 36.0811\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 4.6801 - val_loss: 37.7952\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 5.0740 - val_loss: 36.1122\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 4.9202 - val_loss: 39.7488\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 5.4697 - val_loss: 35.9320\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 5.1559 - val_loss: 38.4307\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 7.7277 - val_loss: 35.9948\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 6.7362 - val_loss: 39.6702\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 5.2303 - val_loss: 37.2620\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 5.5901 - val_loss: 34.9780\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 4.4978 - val_loss: 34.5375\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 3.8811 - val_loss: 34.1105\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 4.4799 - val_loss: 36.3562\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 4.2733 - val_loss: 37.7043\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 4.2531 - val_loss: 37.1361\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 4.0010 - val_loss: 37.9333\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 4.9736 - val_loss: 35.0965\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 4.9909 - val_loss: 34.9193\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 3.7115 - val_loss: 36.0374\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 3.8007 - val_loss: 35.0434\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 2.9768 - val_loss: 38.5047\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 3.7390 - val_loss: 34.1503\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 3.8998 - val_loss: 38.4049\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 3.4165 - val_loss: 34.6892\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 3.5577 - val_loss: 38.0163\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 3.5670 - val_loss: 35.7254\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 3.5862 - val_loss: 37.7805\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 2.7673 - val_loss: 34.7752\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 3.5019 - val_loss: 36.1038\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 3.3650 - val_loss: 37.0773\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 3.6007 - val_loss: 33.8781\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 7.9618 - val_loss: 36.7433\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 5.6083 - val_loss: 35.4387\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 4.5814 - val_loss: 40.2307\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 40us/sample - loss: 4.7322 - val_loss: 35.5778\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 3.8451 - val_loss: 38.2307\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 3.5234 - val_loss: 35.5600\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 3.5204 - val_loss: 40.4675\n",
      "\n",
      "Mean squared error: 3.5\n",
      "\n",
      "dropout: 2.0e-01\n",
      "filter_num: 10\n",
      "num_dense_layers: 10\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 1s 258us/sample - loss: 59.3824 - val_loss: 55.1717\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 59.3201 - val_loss: 55.0991\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 59.2497 - val_loss: 55.0179\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 59.1725 - val_loss: 54.9258\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 59.0849 - val_loss: 54.8194\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 58.9811 - val_loss: 54.6923\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 58.8535 - val_loss: 54.5362\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 58.7016 - val_loss: 54.3404\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 58.5002 - val_loss: 54.0865\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 58.2274 - val_loss: 53.7191\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 57.7507 - val_loss: 53.0567\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 56.8694 - val_loss: 51.5675\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 54.2163 - val_loss: 47.7099\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 50.4509 - val_loss: 39.0203\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 47.7587 - val_loss: 34.8704\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 44.6858 - val_loss: 37.2766\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 43.0865 - val_loss: 37.4373\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 41.9827 - val_loss: 33.8771\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 39.9266 - val_loss: 34.8447\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 42.3786 - val_loss: 37.4134\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 40.0095 - val_loss: 36.2939\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 37.4164 - val_loss: 33.0919\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 37.7755 - val_loss: 31.5881\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 38.0893 - val_loss: 34.7015\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 35.9884 - val_loss: 35.0689\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 34.9632 - val_loss: 32.0962\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 35.9040 - val_loss: 31.2107\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 32.4219 - val_loss: 33.7763\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 35.4039 - val_loss: 36.4984\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 33.8776 - val_loss: 34.8252\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 34.8909 - val_loss: 32.8601\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 35.5163 - val_loss: 34.4989\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 32.5224 - val_loss: 34.3181\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 31.8137 - val_loss: 32.1692\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 30.6044 - val_loss: 31.0645\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 30.5838 - val_loss: 31.5007\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 31.9043 - val_loss: 32.3853\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 28.3856 - val_loss: 32.3958\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 30.8717 - val_loss: 32.5473\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 32.2161 - val_loss: 32.5715\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 29.4248 - val_loss: 31.1733\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 29.2512 - val_loss: 30.1435\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 28.9526 - val_loss: 30.0877\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 30.2147 - val_loss: 31.2666\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 29.1110 - val_loss: 33.3822\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 28.4520 - val_loss: 33.3038\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 25.5463 - val_loss: 32.1936\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 31.8169 - val_loss: 32.9815\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 28.0495 - val_loss: 33.1318\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 26.9244 - val_loss: 31.7686\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 26.1792 - val_loss: 31.4136\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 32.0335 - val_loss: 32.1048\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 24.5673 - val_loss: 32.0198\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 28.7119 - val_loss: 31.4714\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 27.1647 - val_loss: 31.5014\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 26.7020 - val_loss: 32.6074\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 24.0967 - val_loss: 32.4975\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 21.8903 - val_loss: 32.4662\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 24.5120 - val_loss: 32.6868\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 21.7268 - val_loss: 33.5456\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 23.2274 - val_loss: 33.8851\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 20.9779 - val_loss: 33.7777\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 19.4616 - val_loss: 33.5899\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 21.1318 - val_loss: 33.8927\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 22.2027 - val_loss: 34.1042\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 21.9996 - val_loss: 34.4929\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 24.2206 - val_loss: 34.7871\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 21.7036 - val_loss: 35.1017\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 23.0587 - val_loss: 35.6563\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 20.7221 - val_loss: 35.9178\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 15us/sample - loss: 20.2226 - val_loss: 36.0112\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 21.9145 - val_loss: 35.9970\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 20.8509 - val_loss: 35.9686\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 22.9469 - val_loss: 35.1276\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 20.1891 - val_loss: 34.1479\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 21.1109 - val_loss: 34.0969\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 22.0574 - val_loss: 35.0015\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 19.8833 - val_loss: 35.8744\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 16.5789 - val_loss: 36.4072\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 24.6728 - val_loss: 37.2320\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 19.5313 - val_loss: 38.0687\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 19.3075 - val_loss: 38.7524\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 21.4912 - val_loss: 39.9378\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 21.7461 - val_loss: 41.8307\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 19.7182 - val_loss: 42.3997\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 21.3188 - val_loss: 41.8629\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 21.1663 - val_loss: 41.5040\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 19.9170 - val_loss: 41.6491\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 23.2781 - val_loss: 42.5261\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 18.8306 - val_loss: 42.3891\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 20.3048 - val_loss: 40.5970\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 18.6134 - val_loss: 39.3437\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 17.6539 - val_loss: 39.4472\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 18.0183 - val_loss: 40.1138\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 19.8458 - val_loss: 41.5035\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 17.0037 - val_loss: 42.1490\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 16.4335 - val_loss: 41.8167\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 16.9218 - val_loss: 41.9978\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 15.5479 - val_loss: 43.1319\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 20.9166 - val_loss: 41.7295\n",
      "\n",
      "Mean squared error: 2.1e+01\n",
      "\n",
      "dropout: 2.2e-01\n",
      "filter_num: 196\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 101us/sample - loss: 56.6749 - val_loss: 42.6369\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 42.3359 - val_loss: 32.6131\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 41.1952 - val_loss: 29.5433\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 36.7838 - val_loss: 30.0321\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 33.6236 - val_loss: 26.0488\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 31.9253 - val_loss: 25.3555\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 29.3556 - val_loss: 24.9783\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 27.4693 - val_loss: 24.8988\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 25.4200 - val_loss: 25.4197\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 23.5553 - val_loss: 26.2742\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 22.2658 - val_loss: 27.0153\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 20.7571 - val_loss: 28.8072\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 19.6867 - val_loss: 29.7078\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 17.8794 - val_loss: 33.5195\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 16.2944 - val_loss: 35.0429\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 14.0169 - val_loss: 38.6559\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 13.0221 - val_loss: 41.9635\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 11.1347 - val_loss: 39.4059\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 9.5510 - val_loss: 43.4324\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 8.6410 - val_loss: 42.2665\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 7.5699 - val_loss: 44.8837\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 6.3559 - val_loss: 47.0594\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 6.3559 - val_loss: 50.0466\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 5.7543 - val_loss: 52.5835\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 5.2299 - val_loss: 46.5451\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.8631 - val_loss: 51.8484\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.7266 - val_loss: 48.6473\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 4.7756 - val_loss: 53.8336\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 4.8895 - val_loss: 50.6129\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.4610 - val_loss: 54.8658\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 4.8032 - val_loss: 47.1286\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 3.9418 - val_loss: 50.7932\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 3.6208 - val_loss: 52.3733\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.1693 - val_loss: 55.4069\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 4.0455 - val_loss: 54.7024\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 3.9683 - val_loss: 51.8197\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 6.3328 - val_loss: 51.7751\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 6.4749 - val_loss: 48.6411\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 4.7852 - val_loss: 53.2831\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.3301 - val_loss: 54.8593\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 3.8543 - val_loss: 51.1691\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 3.4165 - val_loss: 51.2198\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 3.4875 - val_loss: 50.4075\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.7393 - val_loss: 56.9440\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.6771 - val_loss: 59.6220\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.4187 - val_loss: 64.1017\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 3.2201 - val_loss: 56.9610\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.2298 - val_loss: 59.9583\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.5431 - val_loss: 57.8744\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.3788 - val_loss: 63.5806\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.5098 - val_loss: 63.4196\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.7474 - val_loss: 62.0917\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.5408 - val_loss: 57.8888\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.6146 - val_loss: 55.7517\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.5078 - val_loss: 55.6418\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.4168 - val_loss: 53.8243\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 3.1307 - val_loss: 52.8299\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.5898 - val_loss: 52.0612\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 3.1789 - val_loss: 57.7647\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.8463 - val_loss: 58.0454\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.5539 - val_loss: 59.4076\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.3864 - val_loss: 59.3620\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.2620 - val_loss: 61.3500\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.3062 - val_loss: 64.9638\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.6238 - val_loss: 58.3694\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.7747 - val_loss: 63.4093\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.9571 - val_loss: 60.6818\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.9684 - val_loss: 60.8344\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.0148 - val_loss: 57.2340\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.8787 - val_loss: 56.7691\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 3.1715 - val_loss: 55.2111\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.7841 - val_loss: 57.3505\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.4837 - val_loss: 58.6426\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.2561 - val_loss: 58.4921\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.9574 - val_loss: 61.5716\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.9912 - val_loss: 61.5429\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.7529 - val_loss: 64.8375\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.6570 - val_loss: 60.1796\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.7064 - val_loss: 65.7646\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.4798 - val_loss: 64.6192\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.5846 - val_loss: 64.3289\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 1.7704 - val_loss: 62.6381\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.7270 - val_loss: 63.0725\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.7610 - val_loss: 61.2790\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.6126 - val_loss: 63.3013\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.3788 - val_loss: 62.5768\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.3198 - val_loss: 63.7028\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.2078 - val_loss: 62.9576\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 1.3692 - val_loss: 63.2365\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.2795 - val_loss: 63.5789\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.1620 - val_loss: 63.0940\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.2816 - val_loss: 61.8993\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 1.1468 - val_loss: 62.4941\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.3663 - val_loss: 62.9856\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.1895 - val_loss: 65.2753\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.2540 - val_loss: 64.6865\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 1.0235 - val_loss: 64.5023\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.1651 - val_loss: 64.5229\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.8257 - val_loss: 70.4853\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.1961 - val_loss: 63.8156\n",
      "\n",
      "Mean squared error: 1.2\n",
      "\n",
      "dropout: 5.3e-01\n",
      "filter_num: 300\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 135us/sample - loss: 51.7683 - val_loss: 32.7956\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 41.3120 - val_loss: 31.7047\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 38.5557 - val_loss: 32.4782\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 35.7926 - val_loss: 28.6363\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 33.2416 - val_loss: 27.1572\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 30.9179 - val_loss: 26.7507\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 29.2652 - val_loss: 27.3346\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 27.1966 - val_loss: 27.4182\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 24.9758 - val_loss: 28.2639\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 24.6956 - val_loss: 28.9635\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 21.2029 - val_loss: 31.4861\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 20.1506 - val_loss: 30.2838\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 18.5503 - val_loss: 33.9856\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 17.4347 - val_loss: 35.3059\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 15.0954 - val_loss: 35.9897\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 12.4082 - val_loss: 40.7375\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 11.7059 - val_loss: 42.2149\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 11.1932 - val_loss: 49.8589\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 25us/sample - loss: 10.5831 - val_loss: 47.5688\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 9.3577 - val_loss: 45.3426\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 8.9317 - val_loss: 56.6008\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 8.7105 - val_loss: 52.6799\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 8.7757 - val_loss: 64.9481\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 8.6111 - val_loss: 70.0731\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 8.5011 - val_loss: 72.3839\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 9.3112 - val_loss: 72.7398\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 9.3117 - val_loss: 75.4818\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 8.0625 - val_loss: 75.9882\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 7.3915 - val_loss: 74.7488\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 7.1046 - val_loss: 76.7684\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 6.7444 - val_loss: 76.3300\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.9898 - val_loss: 89.1479\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 6.2361 - val_loss: 82.9976\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.9408 - val_loss: 96.0894\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 7.0649 - val_loss: 85.4687\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 6.7236 - val_loss: 86.2423\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 7.1656 - val_loss: 80.9267\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 5.1617 - val_loss: 78.4722\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.1874 - val_loss: 81.1094\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 4.6732 - val_loss: 87.5420\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.7301 - val_loss: 97.6648\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.4941 - val_loss: 103.5800\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.9676 - val_loss: 103.8267\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.7707 - val_loss: 106.5178\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.5778 - val_loss: 108.6997\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.1837 - val_loss: 98.7903\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 4.4065 - val_loss: 102.9626\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.1372 - val_loss: 94.3520\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.1336 - val_loss: 92.7056\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.3798 - val_loss: 92.0180\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.7625 - val_loss: 101.7834\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.2144 - val_loss: 101.7724\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.5317 - val_loss: 86.0335\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.3264 - val_loss: 94.5536\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.2397 - val_loss: 70.5687\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.3889 - val_loss: 100.4499\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 6.6576 - val_loss: 87.3257\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 7.2047 - val_loss: 95.9667\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 8.0463 - val_loss: 98.8884\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.5553 - val_loss: 71.8464\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.3105 - val_loss: 78.4107\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.9369 - val_loss: 75.7943\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.4072 - val_loss: 94.5513\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.2097 - val_loss: 93.8019\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.9105 - val_loss: 106.9074\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 4.0572 - val_loss: 102.0843\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.4804 - val_loss: 104.6703\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.4513 - val_loss: 99.3650\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 5.2394 - val_loss: 84.1068\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.2618 - val_loss: 100.2418\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 3.7930 - val_loss: 83.7753\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 4.2424 - val_loss: 101.6158\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.5988 - val_loss: 90.2621\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 4.5995 - val_loss: 79.2641\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 4.4225 - val_loss: 105.6301\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.8480 - val_loss: 93.3077\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 4.0854 - val_loss: 104.3912\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 3.6864 - val_loss: 96.5429\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.8918 - val_loss: 105.5953\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.7644 - val_loss: 104.5733\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.8209 - val_loss: 105.1323\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 4.5003 - val_loss: 108.4964\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.6114 - val_loss: 121.6594\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.9994 - val_loss: 116.1517\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.2649 - val_loss: 128.3462\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.3289 - val_loss: 122.9537\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.5241 - val_loss: 114.9819\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 3.6177 - val_loss: 132.1934\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 3.0541 - val_loss: 118.4254\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.5590 - val_loss: 125.9168\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.2550 - val_loss: 148.0759\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.4779 - val_loss: 134.9663\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 4.1452 - val_loss: 147.9593\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.8893 - val_loss: 138.5267\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 3.7186 - val_loss: 113.2524\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.9687 - val_loss: 130.6935\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.4161 - val_loss: 125.6199\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.1615 - val_loss: 123.4194\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.7019 - val_loss: 138.8485\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 2.7634 - val_loss: 129.1554\n",
      "\n",
      "Mean squared error: 2.8\n",
      "\n",
      "Best solution:\n",
      "[0.20000000000000004, 300, 1]\n",
      "WARNING:tensorflow:From C:\\Users\\Kat\\anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\Kat\\anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "\n",
      "Score:\n",
      "48.051293003943655\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_mean_squared_error = 9999999999999999\n",
    "default_parameters =[0.5, 50, 2]\n",
    "#dropout, filter_num, num_dense_layers\n",
    "print_and_plot(default_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c102186e",
   "metadata": {},
   "source": [
    "# Initial conditions try 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97e91374",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load and split data\n",
    "x_train_pre, x_test_pre, y_train, y_test = train_test_split(X, Y, test_size=0.15)\n",
    "scaler = StandardScaler().fit(x_train_pre) \n",
    "x_train = scaler.transform(x_train_pre) \n",
    "scaler = StandardScaler().fit(x_test_pre) \n",
    "x_test = scaler.transform(x_test_pre) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fc79c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropout: 6.0e-01\n",
      "filter_num: 200\n",
      "num_dense_layers: 5\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 1s 213us/sample - loss: 58.0074 - val_loss: 31.3154\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 48.0330 - val_loss: 32.3033\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 44.9351 - val_loss: 32.8246\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 42.4627 - val_loss: 30.3939\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 39.9504 - val_loss: 30.8511\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 39.5297 - val_loss: 31.0915\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 37.2679 - val_loss: 28.6328\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 35.8229 - val_loss: 28.6983\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 34.7233 - val_loss: 29.4272\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 32.9826 - val_loss: 28.7810\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 30.3965 - val_loss: 27.4923\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 31.0319 - val_loss: 27.9487\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 28.8982 - val_loss: 29.6631\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 28.6162 - val_loss: 27.6613\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 28.7021 - val_loss: 27.6185\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 25.2709 - val_loss: 27.5835\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 26.0061 - val_loss: 25.5397\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 24.3960 - val_loss: 27.8996\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 19.7962 - val_loss: 27.9082\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 21.0765 - val_loss: 26.8645\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 20.1483 - val_loss: 27.6435\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 19.5188 - val_loss: 27.2652\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 19.8418 - val_loss: 26.7352\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 17.6906 - val_loss: 27.7330\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 18.1481 - val_loss: 27.1302\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 17.3725 - val_loss: 24.9350\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 20.2239 - val_loss: 27.3909\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 16.9629 - val_loss: 25.3674\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 17.9222 - val_loss: 27.7207\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 21.1037 - val_loss: 26.6339\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 16.2955 - val_loss: 23.5752\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 19.8317 - val_loss: 26.7337\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 16.3549 - val_loss: 25.1095\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 16.6122 - val_loss: 25.1525\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 16.1765 - val_loss: 25.1373\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 13.3954 - val_loss: 24.5244\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 11.4006 - val_loss: 23.9791\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 13.9665 - val_loss: 25.3203\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 16.5607 - val_loss: 25.8372\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 12.8434 - val_loss: 24.6235\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 13.5446 - val_loss: 24.7377\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 14.0567 - val_loss: 25.6386\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 18.5532 - val_loss: 26.6525\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 19.8754 - val_loss: 24.5584\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 17.7470 - val_loss: 23.1636\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 17.7551 - val_loss: 23.7034\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 13.7616 - val_loss: 23.7645\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 13.3778 - val_loss: 24.5087\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 13.4013 - val_loss: 25.2169\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 13.9477 - val_loss: 24.1833\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 13.8759 - val_loss: 24.3026\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 13.0984 - val_loss: 25.6585\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 12.7449 - val_loss: 24.3736\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 11.8273 - val_loss: 23.8146\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 13.8210 - val_loss: 24.4933\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 14.7620 - val_loss: 25.9290\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 14.1125 - val_loss: 24.6589\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 13.7419 - val_loss: 23.1655\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 12.5093 - val_loss: 24.2005\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 17.5420 - val_loss: 25.7131\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 16.5044 - val_loss: 27.5027\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 18.4128 - val_loss: 25.3656\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 16.1101 - val_loss: 25.6549\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 15.6507 - val_loss: 26.4443\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 16.1978 - val_loss: 26.2119\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 18.5333 - val_loss: 25.1816\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 11.3387 - val_loss: 24.1820\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 13.1935 - val_loss: 24.6658\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 10.6097 - val_loss: 25.4956\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 13.6212 - val_loss: 25.1619\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 11.6282 - val_loss: 25.1088\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 10.1383 - val_loss: 25.5201\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 12.7588 - val_loss: 25.2778\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 12.5194 - val_loss: 25.7569\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 34us/sample - loss: 10.5890 - val_loss: 26.0194\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 9.4018 - val_loss: 26.5272\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 9.8682 - val_loss: 26.6261\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 15.4827 - val_loss: 26.3915\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 12.2046 - val_loss: 26.6702\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 13.0115 - val_loss: 26.6776\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 14.0020 - val_loss: 26.7815\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 14.0208 - val_loss: 25.5978\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 11.5762 - val_loss: 25.7262\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 12.6467 - val_loss: 26.1979\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 10.5482 - val_loss: 26.1367\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 12.3129 - val_loss: 26.0111\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 10.2344 - val_loss: 25.9403\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 14.0359 - val_loss: 25.8725\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 11.2619 - val_loss: 24.5802\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 12.2509 - val_loss: 25.0194\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 11.9335 - val_loss: 26.4898\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 13.6888 - val_loss: 25.2644\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 10.5760 - val_loss: 23.9847\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 11.7576 - val_loss: 24.3892\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 14.4631 - val_loss: 24.7338\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 13.1309 - val_loss: 24.2122\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 11.8085 - val_loss: 24.4686\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 11.3565 - val_loss: 25.1687\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 10.3962 - val_loss: 25.3755\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 12.1933 - val_loss: 25.7121\n",
      "\n",
      "Mean squared error: 1.2e+01\n",
      "\n",
      "dropout: 7.5e-01\n",
      "filter_num: 34\n",
      "num_dense_layers: 4\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 149us/sample - loss: 64.1570 - val_loss: 37.9978\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 63.4443 - val_loss: 37.8011\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 61.9414 - val_loss: 37.3727\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 59.6094 - val_loss: 36.4787\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 56.1370 - val_loss: 35.1372\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 55.2918 - val_loss: 34.1808\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 52.3193 - val_loss: 33.9183\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 54.6057 - val_loss: 34.3229\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 51.8996 - val_loss: 34.8143\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 51.4745 - val_loss: 35.0747\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 51.8874 - val_loss: 35.1417\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 49.7772 - val_loss: 34.7461\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 50.8081 - val_loss: 34.3092\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 49.1205 - val_loss: 34.0856\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 45.4368 - val_loss: 33.7386\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 60.0693 - val_loss: 34.0199\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 46.5122 - val_loss: 34.1180\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 46.3544 - val_loss: 34.1161\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 48.5761 - val_loss: 34.2805\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 46.0740 - val_loss: 34.1382\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 45.1900 - val_loss: 33.8696\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 45.7298 - val_loss: 33.5299\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 44.3242 - val_loss: 32.9528\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 48.3130 - val_loss: 32.5490\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 43.1416 - val_loss: 32.4434\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 45.1615 - val_loss: 32.7796\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 41.1139 - val_loss: 32.8800\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 46.2552 - val_loss: 32.8264\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 43.4262 - val_loss: 32.6590\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 43.5298 - val_loss: 32.5622\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 45.3276 - val_loss: 32.5386\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 41.6956 - val_loss: 32.2255\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 46.4915 - val_loss: 32.0285\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 44.3740 - val_loss: 31.9659\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 43.8547 - val_loss: 32.0265\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 44.9520 - val_loss: 32.4827\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 43.8571 - val_loss: 32.5877\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 42.3673 - val_loss: 32.2407\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 41.1009 - val_loss: 31.7235\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 39.0279 - val_loss: 31.0258\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 40.6390 - val_loss: 30.6657\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 41.3503 - val_loss: 30.5987\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 44.5815 - val_loss: 30.8960\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 44.0712 - val_loss: 31.0681\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 41.5122 - val_loss: 30.8999\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 39.4685 - val_loss: 30.5414\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 38.6296 - val_loss: 30.1017\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 50.9644 - val_loss: 30.3679\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 13us/sample - loss: 37.1273 - val_loss: 30.4517\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 38.8144 - val_loss: 30.1919\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 42.1965 - val_loss: 29.8794\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 38.5522 - val_loss: 29.5558\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 37.0780 - val_loss: 29.4175\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 38.4994 - val_loss: 29.5245\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 38.3900 - val_loss: 29.4931\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 38.1319 - val_loss: 29.4613\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 36.7808 - val_loss: 29.2687\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 38.4516 - val_loss: 29.1684\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 36.3536 - val_loss: 29.2262\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 37.2312 - val_loss: 28.9836\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 41.0305 - val_loss: 28.9823\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 34.0204 - val_loss: 28.8904\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 36.4952 - val_loss: 28.5545\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 37.9704 - val_loss: 27.8021\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 37.4875 - val_loss: 27.5557\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 37.9475 - val_loss: 27.7489\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 41.5127 - val_loss: 28.1970\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 34.1388 - val_loss: 28.2511\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 36.6957 - val_loss: 27.9479\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 39.5683 - val_loss: 27.9665\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 34.7096 - val_loss: 27.8988\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 33.1142 - val_loss: 27.5334\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 31.9993 - val_loss: 27.0325\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 31.9777 - val_loss: 26.6339\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 34.3805 - val_loss: 26.9572\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 32.8691 - val_loss: 27.5760\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 33.5449 - val_loss: 27.6684\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 35.9623 - val_loss: 27.5796\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 35.6222 - val_loss: 27.3243\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 33.7702 - val_loss: 27.1646\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 32.8795 - val_loss: 26.8111\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 34.0630 - val_loss: 26.5861\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 31.0204 - val_loss: 26.4089\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 32.1575 - val_loss: 26.4020\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 28.4651 - val_loss: 26.4244\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 31.7131 - val_loss: 26.1527\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 32.5686 - val_loss: 26.2100\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 28.7520 - val_loss: 26.5636\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 36.7727 - val_loss: 26.5924\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 30.8883 - val_loss: 26.2823\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 29.9962 - val_loss: 25.7304\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 33.6786 - val_loss: 25.5693\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 32.9419 - val_loss: 25.8915\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 40.2012 - val_loss: 26.4426\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 43.0253 - val_loss: 26.6513\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 30.0997 - val_loss: 26.7349\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 30.4324 - val_loss: 26.5012\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 31.4414 - val_loss: 25.9896\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 31.6013 - val_loss: 25.5223\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 35.7004 - val_loss: 25.3469\n",
      "\n",
      "Mean squared error: 3.6e+01\n",
      "\n",
      "dropout: 7.8e-01\n",
      "filter_num: 106\n",
      "num_dense_layers: 5\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 184us/sample - loss: 60.4579 - val_loss: 37.6327\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 51.5134 - val_loss: 37.0168\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 50.2503 - val_loss: 36.8800\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 49.4825 - val_loss: 37.0288\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 47.1701 - val_loss: 36.9753\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 46.9863 - val_loss: 36.8271\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 48.0665 - val_loss: 36.6963\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 46.1210 - val_loss: 36.6039\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 45.5703 - val_loss: 36.5067\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 44.8034 - val_loss: 36.3274\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 43.4925 - val_loss: 36.1709\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 44.6304 - val_loss: 36.0117\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 43.6910 - val_loss: 35.8960\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 44.2390 - val_loss: 35.8207\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 42.1047 - val_loss: 35.7086\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 39.4349 - val_loss: 35.4912\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 42.0767 - val_loss: 35.3660\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 40.2173 - val_loss: 35.2594\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 40.6487 - val_loss: 35.0818\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 38.2562 - val_loss: 34.8567\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 40.9513 - val_loss: 34.7224\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 41.4335 - val_loss: 34.5784\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 22us/sample - loss: 37.5812 - val_loss: 34.3051\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 38.8615 - val_loss: 34.0336\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 38.2022 - val_loss: 33.8947\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 30.8064 - val_loss: 33.7240\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 36.6645 - val_loss: 33.4849\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 31.9359 - val_loss: 33.4603\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 33.3555 - val_loss: 33.2510\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 36.5202 - val_loss: 33.0945\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 36.3138 - val_loss: 32.9122\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 34.2226 - val_loss: 32.9644\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 33.9094 - val_loss: 32.6979\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 33.1490 - val_loss: 32.4722\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 32.4410 - val_loss: 32.1729\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 36.2717 - val_loss: 32.0130\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 34.5062 - val_loss: 32.0738\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 30.7670 - val_loss: 31.9083\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 34.3425 - val_loss: 31.6457\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 34.3399 - val_loss: 31.5635\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 32.1013 - val_loss: 31.5342\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 29.7164 - val_loss: 31.1735\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 31.8762 - val_loss: 30.7747\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 32.2663 - val_loss: 30.3740\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 28.5811 - val_loss: 30.2874\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 30.4312 - val_loss: 30.2071\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 29.8866 - val_loss: 30.1368\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 27.6928 - val_loss: 29.9560\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 29.7192 - val_loss: 29.7714\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 24.8114 - val_loss: 29.4677\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 29.2995 - val_loss: 29.3045\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 29.3684 - val_loss: 29.0706\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 25.7967 - val_loss: 28.8694\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 31.0205 - val_loss: 28.7668\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 27.9806 - val_loss: 28.9702\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 28.0479 - val_loss: 28.8800\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 27.5151 - val_loss: 28.5457\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 25.5576 - val_loss: 28.5833\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 23.5816 - val_loss: 28.3344\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 26.0367 - val_loss: 28.1226\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 32.8436 - val_loss: 28.3439\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 24.3294 - val_loss: 28.2145\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 27.5887 - val_loss: 27.9170\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 26.6429 - val_loss: 27.7419\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 24.5003 - val_loss: 27.5741\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 25.3275 - val_loss: 27.2528\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 29.4424 - val_loss: 27.3428\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 27.2219 - val_loss: 27.6918\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 22.4697 - val_loss: 27.7079\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 25.2575 - val_loss: 27.3898\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 25.2461 - val_loss: 27.0307\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 28.2177 - val_loss: 27.1732\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 24.6295 - val_loss: 27.3164\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 22.6395 - val_loss: 27.3404\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 23.5084 - val_loss: 27.2549\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 27.5831 - val_loss: 27.2531\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 21.1287 - val_loss: 27.3841\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 24.8769 - val_loss: 27.3575\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 21.7466 - val_loss: 27.0735\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 25.5705 - val_loss: 27.0220\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 23.6286 - val_loss: 27.2852\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 25.3916 - val_loss: 27.4165\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 22.5440 - val_loss: 27.6183\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 25.4418 - val_loss: 27.5773\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 25.0200 - val_loss: 27.3821\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 25.8046 - val_loss: 27.2108\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 24.5628 - val_loss: 27.0133\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 25.7003 - val_loss: 26.9816\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 24.3123 - val_loss: 26.6793\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 24.1980 - val_loss: 26.9473\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 24.4750 - val_loss: 27.3587\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 40.1039 - val_loss: 27.9714\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 25.4067 - val_loss: 27.8764\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 22.5977 - val_loss: 27.4081\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 21.9568 - val_loss: 26.9018\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 18.3415 - val_loss: 26.6779\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 22.7474 - val_loss: 26.5618\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 23us/sample - loss: 25.2110 - val_loss: 26.8558\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 21.6331 - val_loss: 27.1333\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 23.5314 - val_loss: 27.0861\n",
      "\n",
      "Mean squared error: 2.4e+01\n",
      "\n",
      "dropout: 7.7e-01\n",
      "filter_num: 67\n",
      "num_dense_layers: 5\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 170us/sample - loss: 59.6078 - val_loss: 37.6079\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 53.4710 - val_loss: 36.9670\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 51.8988 - val_loss: 36.9144\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 51.9559 - val_loss: 37.0639\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 51.0035 - val_loss: 37.0367\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 50.2839 - val_loss: 36.9258\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 49.2329 - val_loss: 36.7306\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 51.1873 - val_loss: 36.5850\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 46.6865 - val_loss: 36.5168\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 48.6027 - val_loss: 36.4167\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 47.2881 - val_loss: 36.2171\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 43.0848 - val_loss: 36.0074\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 47.2445 - val_loss: 36.0097\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 45.3704 - val_loss: 35.9212\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 43.3356 - val_loss: 35.7269\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 42.2192 - val_loss: 35.5221\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 44.1715 - val_loss: 35.4562\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 42.6611 - val_loss: 35.4603\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 41.0567 - val_loss: 35.2906\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 40.2913 - val_loss: 35.0247\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 40.8815 - val_loss: 34.7655\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 41.8974 - val_loss: 34.6192\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 43.1258 - val_loss: 34.8127\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 40.9024 - val_loss: 34.8083\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 40.2646 - val_loss: 34.5899\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 36.0967 - val_loss: 34.2146\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 38.2004 - val_loss: 33.8426\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 37.8865 - val_loss: 33.6750\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 39.1952 - val_loss: 33.7009\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 39.0331 - val_loss: 33.6073\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 36.0861 - val_loss: 33.5032\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 36.5272 - val_loss: 33.1856\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 38.4519 - val_loss: 33.0773\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 36.2046 - val_loss: 33.0833\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 38.6695 - val_loss: 32.9872\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 35.5128 - val_loss: 32.7181\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 36.4376 - val_loss: 32.2812\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 35.7108 - val_loss: 31.9013\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 36.7729 - val_loss: 31.6012\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 32.6085 - val_loss: 31.6356\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 36.4227 - val_loss: 31.7104\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 36.8576 - val_loss: 31.5391\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 32.6149 - val_loss: 31.1363\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 32.7548 - val_loss: 30.7545\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 34.0627 - val_loss: 30.6993\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 28.8685 - val_loss: 30.5329\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 34.1342 - val_loss: 30.5357\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 36.1143 - val_loss: 30.4954\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 28.7771 - val_loss: 30.3431\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 31.3312 - val_loss: 29.8953\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 30.6623 - val_loss: 29.6471\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 33.9236 - val_loss: 29.5538\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 32.8511 - val_loss: 29.3078\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 29.4137 - val_loss: 28.9527\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 28.1503 - val_loss: 28.4851\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 31.5544 - val_loss: 28.3843\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 45.0807 - val_loss: 28.9351\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 27.7056 - val_loss: 29.0538\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 31.3037 - val_loss: 28.8486\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 31.5038 - val_loss: 28.6265\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 27.8280 - val_loss: 28.2610\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 30.9862 - val_loss: 27.8928\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 34.0227 - val_loss: 27.8854\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 29.3538 - val_loss: 27.8615\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 28.2242 - val_loss: 27.8387\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 29.5349 - val_loss: 27.6608\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 32.6133 - val_loss: 27.8089\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 28.3248 - val_loss: 27.7249\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 27.7384 - val_loss: 27.4701\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 26.7436 - val_loss: 27.2228\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 33.3204 - val_loss: 27.1407\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 19us/sample - loss: 29.9240 - val_loss: 27.3880\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 28.3727 - val_loss: 27.3289\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 27.7863 - val_loss: 27.0243\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 29.2687 - val_loss: 26.7991\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 33.1151 - val_loss: 27.2212\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 31.3538 - val_loss: 27.4764\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 25.4335 - val_loss: 27.2928\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 28.8575 - val_loss: 26.9973\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 25.1077 - val_loss: 26.7764\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 30.0885 - val_loss: 26.7937\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 24.7069 - val_loss: 26.7577\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 30.3988 - val_loss: 26.7586\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 38.0332 - val_loss: 26.8397\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 24.9707 - val_loss: 27.0719\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 27.6648 - val_loss: 27.0473\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 28.6460 - val_loss: 26.7005\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 28.1770 - val_loss: 26.3995\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 24.0243 - val_loss: 26.3210\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 25.2017 - val_loss: 26.2876\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 43.4860 - val_loss: 26.9352\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 25.1849 - val_loss: 27.0617\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 26.5915 - val_loss: 26.8636\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 32.4846 - val_loss: 26.7578\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 26.4413 - val_loss: 26.5841\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 26.4804 - val_loss: 26.2999\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 27.7920 - val_loss: 26.4724\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 27.9966 - val_loss: 26.6659\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 23.5557 - val_loss: 26.6936\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 31.5101 - val_loss: 27.1817\n",
      "\n",
      "Mean squared error: 3.2e+01\n",
      "\n",
      "dropout: 4.6e-01\n",
      "filter_num: 175\n",
      "num_dense_layers: 18\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 1s 492us/sample - loss: 63.1327 - val_loss: 37.2561\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 78us/sample - loss: 51.1263 - val_loss: 36.7004\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 76us/sample - loss: 53.2972 - val_loss: 36.4165\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 79us/sample - loss: 48.5541 - val_loss: 34.4273\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 84us/sample - loss: 47.0686 - val_loss: 35.2443\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 77us/sample - loss: 43.5921 - val_loss: 33.3175\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 78us/sample - loss: 46.0515 - val_loss: 34.2113\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 78us/sample - loss: 42.7890 - val_loss: 33.2563\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 79us/sample - loss: 41.4231 - val_loss: 32.6748\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 79us/sample - loss: 39.9117 - val_loss: 33.3850\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 78us/sample - loss: 39.9283 - val_loss: 32.1092\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 79us/sample - loss: 36.1520 - val_loss: 31.8829\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 79us/sample - loss: 35.9862 - val_loss: 32.6536\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 78us/sample - loss: 33.7954 - val_loss: 31.9488\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 78us/sample - loss: 31.1670 - val_loss: 31.3749\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 82us/sample - loss: 30.3265 - val_loss: 31.0420\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 77us/sample - loss: 28.9154 - val_loss: 31.3794\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 83us/sample - loss: 27.4756 - val_loss: 30.9371\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 77us/sample - loss: 29.6929 - val_loss: 31.1384\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 78us/sample - loss: 27.8317 - val_loss: 28.5215\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 72us/sample - loss: 31.1427 - val_loss: 29.9289\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 83us/sample - loss: 27.6389 - val_loss: 29.2875\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 80us/sample - loss: 22.8495 - val_loss: 29.4501\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 77us/sample - loss: 26.8829 - val_loss: 30.2597\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 75us/sample - loss: 27.7352 - val_loss: 29.0892\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 77us/sample - loss: 32.2206 - val_loss: 29.4424\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 80us/sample - loss: 22.1052 - val_loss: 28.2359\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 73us/sample - loss: 25.2004 - val_loss: 29.0945\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 83us/sample - loss: 23.3284 - val_loss: 29.0468\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 78us/sample - loss: 24.4775 - val_loss: 28.0249\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 77us/sample - loss: 64.2310 - val_loss: 30.5225\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 77us/sample - loss: 28.1454 - val_loss: 28.1827\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 78us/sample - loss: 29.7919 - val_loss: 30.8402\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 80us/sample - loss: 30.6482 - val_loss: 28.4695\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 77us/sample - loss: 26.3146 - val_loss: 28.2786\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 80us/sample - loss: 25.3831 - val_loss: 29.2793\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 77us/sample - loss: 22.6649 - val_loss: 27.6899\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 79us/sample - loss: 30.5937 - val_loss: 29.8740\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 73us/sample - loss: 30.5400 - val_loss: 29.3531\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 83us/sample - loss: 25.4818 - val_loss: 26.1763\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 80us/sample - loss: 30.7046 - val_loss: 30.1792\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 73us/sample - loss: 31.1107 - val_loss: 28.0681\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 83us/sample - loss: 26.3637 - val_loss: 27.1388\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 78us/sample - loss: 24.2621 - val_loss: 28.4466\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 80us/sample - loss: 28.3380 - val_loss: 28.9625\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 78us/sample - loss: 24.3147 - val_loss: 27.9458\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 79us/sample - loss: 24.0134 - val_loss: 29.3035\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 87us/sample - loss: 27.9113 - val_loss: 28.6066\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 79us/sample - loss: 24.2404 - val_loss: 27.5224\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 83us/sample - loss: 23.5656 - val_loss: 27.9377\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 77us/sample - loss: 20.3334 - val_loss: 26.7525\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 79us/sample - loss: 37.7335 - val_loss: 30.9874\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 77us/sample - loss: 36.5878 - val_loss: 30.8858\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 77us/sample - loss: 28.8122 - val_loss: 26.8799\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 78us/sample - loss: 24.7606 - val_loss: 28.0530\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 80us/sample - loss: 19.4232 - val_loss: 28.0004\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 78us/sample - loss: 25.2235 - val_loss: 28.4828\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 78us/sample - loss: 21.0161 - val_loss: 28.3149\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 74us/sample - loss: 23.0078 - val_loss: 28.5115\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 77us/sample - loss: 36.8226 - val_loss: 29.6097\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 82us/sample - loss: 28.9931 - val_loss: 29.1470\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 76us/sample - loss: 22.1269 - val_loss: 26.4975\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 80us/sample - loss: 21.4508 - val_loss: 28.6473\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 78us/sample - loss: 25.3017 - val_loss: 27.6055\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 78us/sample - loss: 20.8633 - val_loss: 27.6706\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 77us/sample - loss: 24.9190 - val_loss: 28.1233\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 78us/sample - loss: 37.6088 - val_loss: 27.6328\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 78us/sample - loss: 26.3251 - val_loss: 27.6705\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 77us/sample - loss: 21.5038 - val_loss: 27.5865\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 86us/sample - loss: 24.3143 - val_loss: 28.2909\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 84us/sample - loss: 23.0936 - val_loss: 26.8244\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 86us/sample - loss: 23.1018 - val_loss: 27.6160\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 85us/sample - loss: 22.6554 - val_loss: 27.3421\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 84us/sample - loss: 19.9357 - val_loss: 26.9362\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 78us/sample - loss: 20.0066 - val_loss: 27.7061\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 77us/sample - loss: 31.3271 - val_loss: 29.3411\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 77us/sample - loss: 26.9620 - val_loss: 26.9616\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 77us/sample - loss: 23.9611 - val_loss: 28.6987\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 78us/sample - loss: 24.4062 - val_loss: 26.8328\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 78us/sample - loss: 24.2135 - val_loss: 26.9545\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 80us/sample - loss: 20.0795 - val_loss: 27.7168\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 77us/sample - loss: 21.8062 - val_loss: 27.7299\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 80us/sample - loss: 19.8520 - val_loss: 28.1138\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 78us/sample - loss: 35.8501 - val_loss: 30.4018\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 80us/sample - loss: 27.1005 - val_loss: 27.0243\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 78us/sample - loss: 25.7796 - val_loss: 28.6162\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 78us/sample - loss: 21.1615 - val_loss: 28.5508\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 79us/sample - loss: 22.1423 - val_loss: 28.6242\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 77us/sample - loss: 22.9943 - val_loss: 29.2256\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 79us/sample - loss: 20.6333 - val_loss: 26.5740\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 77us/sample - loss: 27.4228 - val_loss: 30.8275\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 82us/sample - loss: 39.3582 - val_loss: 31.4268\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 77us/sample - loss: 33.1220 - val_loss: 27.9451\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 80us/sample - loss: 38.5325 - val_loss: 29.0889\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 78us/sample - loss: 28.2352 - val_loss: 29.5436\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 78us/sample - loss: 21.5514 - val_loss: 26.6382\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 81us/sample - loss: 23.0258 - val_loss: 29.0990\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 77us/sample - loss: 24.3383 - val_loss: 28.1760\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 80us/sample - loss: 21.4729 - val_loss: 26.8365\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 79us/sample - loss: 25.0886 - val_loss: 28.8527\n",
      "\n",
      "Mean squared error: 2.5e+01\n",
      "\n",
      "dropout: 5.6e-01\n",
      "filter_num: 45\n",
      "num_dense_layers: 13\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 1s 333us/sample - loss: 64.0762 - val_loss: 38.0185\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 63.1263 - val_loss: 37.8730\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 59.8819 - val_loss: 37.5699\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 55.3993 - val_loss: 37.0735\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 55.8584 - val_loss: 37.0495\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 52.3149 - val_loss: 37.0362\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 53.1232 - val_loss: 36.8723\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 51.5526 - val_loss: 36.5959\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 51.3499 - val_loss: 36.3476\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 48.4887 - val_loss: 36.1921\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 50.8541 - val_loss: 36.1409\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 51.1408 - val_loss: 36.1329\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 48.6051 - val_loss: 35.9522\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 50.2825 - val_loss: 35.7551\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 47.6755 - val_loss: 35.4585\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 49.5159 - val_loss: 35.1260\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 45.0330 - val_loss: 35.0366\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 46.9551 - val_loss: 34.9859\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 46.6290 - val_loss: 34.7971\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 25us/sample - loss: 47.6252 - val_loss: 34.5178\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 45.2870 - val_loss: 34.3436\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 45.5109 - val_loss: 34.4503\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 44.4603 - val_loss: 34.3053\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 43.9314 - val_loss: 33.9394\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 42.9188 - val_loss: 33.7643\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 43.9950 - val_loss: 33.8985\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 44.4557 - val_loss: 33.6516\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 43.3332 - val_loss: 33.2267\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 44.9202 - val_loss: 33.0593\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 41.0967 - val_loss: 32.8377\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 42.1609 - val_loss: 32.8555\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 39.7514 - val_loss: 32.5724\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 41.0644 - val_loss: 32.4030\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 39.9381 - val_loss: 32.0802\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 36.3715 - val_loss: 31.8325\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 39.2622 - val_loss: 31.7639\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 41.1114 - val_loss: 31.6536\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 42.2588 - val_loss: 31.6670\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 42.0180 - val_loss: 32.0722\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 41.6862 - val_loss: 31.6795\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 37.6905 - val_loss: 30.9170\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 39.9368 - val_loss: 30.6406\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 40.4093 - val_loss: 30.6904\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 35.8157 - val_loss: 30.6038\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 38.5567 - val_loss: 30.3334\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 38.8284 - val_loss: 29.9194\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 37.1750 - val_loss: 29.7010\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 34.3288 - val_loss: 29.2300\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 37.5167 - val_loss: 29.2483\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 36.1648 - val_loss: 29.4470\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 34.7297 - val_loss: 29.5211\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 34.7979 - val_loss: 28.9132\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 34.8394 - val_loss: 28.5222\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 38.3680 - val_loss: 28.7028\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 32.8085 - val_loss: 28.5847\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 38.4397 - val_loss: 28.4682\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 29.7911 - val_loss: 28.1368\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 38.4584 - val_loss: 28.4857\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 35.2433 - val_loss: 28.6041\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 36.1359 - val_loss: 28.7981\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 33.6189 - val_loss: 28.5648\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 33.1046 - val_loss: 28.3592\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 36.6062 - val_loss: 28.1842\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 29.4982 - val_loss: 27.7460\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 28.2162 - val_loss: 28.0441\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 36.5070 - val_loss: 28.3310\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 32.0796 - val_loss: 27.8432\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 29.9120 - val_loss: 27.3295\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 31.5344 - val_loss: 27.6469\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 33.7699 - val_loss: 28.1346\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 31.5835 - val_loss: 28.2695\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 35.4367 - val_loss: 27.8044\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 28.7734 - val_loss: 26.9810\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 45.5381 - val_loss: 27.8737\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 32.1007 - val_loss: 29.5594\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 38.7622 - val_loss: 29.7647\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 37.6324 - val_loss: 29.1968\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 35.0683 - val_loss: 28.1096\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 35.3388 - val_loss: 27.7852\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 33.1885 - val_loss: 27.8707\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 31.0686 - val_loss: 27.7481\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 29.8591 - val_loss: 27.2447\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 33.5012 - val_loss: 27.2228\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 37.2963 - val_loss: 27.7762\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 30.6087 - val_loss: 28.2387\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 32.8415 - val_loss: 29.0303\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 35.3571 - val_loss: 28.6067\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 39.1972 - val_loss: 28.4325\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 31.1652 - val_loss: 28.2872\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 35.9310 - val_loss: 28.3708\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 36.9591 - val_loss: 28.3855\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 38.1345 - val_loss: 28.4487\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 33.2089 - val_loss: 28.3449\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 35.2813 - val_loss: 28.1659\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 26us/sample - loss: 31.2792 - val_loss: 27.9050\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 35.2587 - val_loss: 27.6191\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 33.5883 - val_loss: 27.2294\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 37.1316 - val_loss: 27.4564\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 34.0502 - val_loss: 27.6970\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 33.9894 - val_loss: 27.6474\n",
      "\n",
      "Mean squared error: 3.4e+01\n",
      "\n",
      "dropout: 5.6e-01\n",
      "filter_num: 34\n",
      "num_dense_layers: 16\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 1s 386us/sample - loss: 63.7835 - val_loss: 38.0012\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 62.0934 - val_loss: 37.7727\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 59.4580 - val_loss: 37.4972\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 61.2478 - val_loss: 37.4767\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 58.0476 - val_loss: 37.3733\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 56.0838 - val_loss: 37.2601\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 56.7848 - val_loss: 37.1691\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 55.5456 - val_loss: 37.0307\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 55.4714 - val_loss: 36.8615\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 54.4655 - val_loss: 36.6627\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 54.7153 - val_loss: 36.5154\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 53.9568 - val_loss: 36.4600\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 52.8799 - val_loss: 36.2648\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 55.8358 - val_loss: 36.1990\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 63.4225 - val_loss: 36.2723\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 54.7914 - val_loss: 36.2953\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 54.0341 - val_loss: 36.1244\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 54.3763 - val_loss: 35.8364\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 52.3190 - val_loss: 35.5096\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 53.5414 - val_loss: 35.2017\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 54.1390 - val_loss: 35.1112\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 50.1890 - val_loss: 35.1110\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 51.2781 - val_loss: 34.9669\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 50.3583 - val_loss: 34.6481\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 51.1962 - val_loss: 34.4038\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 49.1623 - val_loss: 34.1135\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 49.0604 - val_loss: 33.7864\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 57.3785 - val_loss: 34.0851\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 48.0191 - val_loss: 34.0565\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 46.4266 - val_loss: 33.6284\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 47.8564 - val_loss: 33.2276\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 49.7104 - val_loss: 33.3006\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 48.3597 - val_loss: 33.8743\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 53.8900 - val_loss: 34.1184\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 49.7492 - val_loss: 33.9524\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 47.6896 - val_loss: 33.5280\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 47.8285 - val_loss: 32.9658\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 46.8480 - val_loss: 32.4954\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 52.9267 - val_loss: 33.0027\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 44.4940 - val_loss: 33.0996\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 47.5676 - val_loss: 32.8257\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 48.8667 - val_loss: 32.5967\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 63.4962 - val_loss: 33.0357\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 47.0128 - val_loss: 33.1354\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 44.3925 - val_loss: 32.8518\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 45.9884 - val_loss: 32.3824\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 47.3334 - val_loss: 31.9285\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 47.3734 - val_loss: 31.5731\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 44.0122 - val_loss: 31.6742\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 43.8218 - val_loss: 31.8626\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 44.7798 - val_loss: 31.7843\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 42.2899 - val_loss: 31.5296\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 42.7884 - val_loss: 31.1686\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 45.5193 - val_loss: 31.1158\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 40.1040 - val_loss: 31.1280\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 43.0182 - val_loss: 31.1009\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 44.9767 - val_loss: 30.9650\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 43.6505 - val_loss: 30.7245\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 44.9893 - val_loss: 30.4993\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 42.9026 - val_loss: 30.1040\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 40.7548 - val_loss: 29.6283\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 41.4507 - val_loss: 29.7421\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 35.6220 - val_loss: 29.6742\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 225.1104 - val_loss: 29.6833\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 43.3350 - val_loss: 30.8200\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 47.3570 - val_loss: 31.2581\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 44.6276 - val_loss: 31.1940\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 43.1177 - val_loss: 30.7758\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 26us/sample - loss: 39.1571 - val_loss: 30.1575\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 45.0505 - val_loss: 29.6255\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 38.9714 - val_loss: 29.0706\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 40.2238 - val_loss: 28.8316\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 42.7341 - val_loss: 28.7189\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 46.3277 - val_loss: 29.3545\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 43.0449 - val_loss: 29.3714\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 40.9437 - val_loss: 29.1813\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 43.6620 - val_loss: 28.6981\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 49.0821 - val_loss: 29.0505\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 42.5755 - val_loss: 29.7450\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 42.9704 - val_loss: 30.1339\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 42.3230 - val_loss: 30.0742\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 42.5318 - val_loss: 29.8353\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 45.7455 - val_loss: 29.7125\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 43.8852 - val_loss: 29.7467\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 44.3507 - val_loss: 29.5168\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 41.3585 - val_loss: 28.8934\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 41.6219 - val_loss: 28.6304\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 43.4561 - val_loss: 28.7676\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 42.6062 - val_loss: 29.2839\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 42.1049 - val_loss: 29.4354\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 41.3515 - val_loss: 29.3936\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 46.8694 - val_loss: 29.5559\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 42.2075 - val_loss: 29.4105\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 40.3887 - val_loss: 29.2679\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 39.5986 - val_loss: 29.0658\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 41.3687 - val_loss: 28.9469\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 49.1530 - val_loss: 29.4193\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 37.2961 - val_loss: 29.5845\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 40.2526 - val_loss: 29.3566\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 40.7496 - val_loss: 29.0695\n",
      "\n",
      "Mean squared error: 4.1e+01\n",
      "\n",
      "dropout: 6.9e-01\n",
      "filter_num: 97\n",
      "num_dense_layers: 6\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 194us/sample - loss: 63.2988 - val_loss: 37.6950\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 56.5239 - val_loss: 36.3782\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 50.6116 - val_loss: 35.6567\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 48.7261 - val_loss: 35.9553\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 49.6989 - val_loss: 36.2118\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 47.9153 - val_loss: 35.9422\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 47.8567 - val_loss: 35.7853\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 47.3349 - val_loss: 35.6307\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 44.6168 - val_loss: 35.6347\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 44.7576 - val_loss: 35.5589\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 43.3812 - val_loss: 35.5184\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 43.3561 - val_loss: 35.0778\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 42.0398 - val_loss: 34.9818\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 42.1544 - val_loss: 34.9189\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 40.6635 - val_loss: 34.4676\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 37.5412 - val_loss: 34.2260\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 40.0288 - val_loss: 34.3050\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 38.4134 - val_loss: 34.2124\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 39.0374 - val_loss: 34.3405\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 36.6313 - val_loss: 34.0704\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 35.4027 - val_loss: 33.7417\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 37.3732 - val_loss: 33.6494\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 34.1827 - val_loss: 33.6038\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 35.3050 - val_loss: 33.3082\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 34.9726 - val_loss: 33.2757\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 35.5840 - val_loss: 32.8653\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 32.8818 - val_loss: 32.8969\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 31.2863 - val_loss: 32.8162\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 33.6986 - val_loss: 32.5961\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 30.4092 - val_loss: 32.4082\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 27.9104 - val_loss: 32.0218\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 26.7825 - val_loss: 31.5482\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 29.8651 - val_loss: 31.5207\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 28.9238 - val_loss: 31.1822\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 30.7236 - val_loss: 31.3639\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 33.2202 - val_loss: 31.7133\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 30.9987 - val_loss: 31.4050\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 30.8737 - val_loss: 30.7176\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 31.3108 - val_loss: 30.3944\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 25.0951 - val_loss: 30.2938\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 27.4615 - val_loss: 29.6396\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 25.7137 - val_loss: 29.3465\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 25us/sample - loss: 24.8033 - val_loss: 29.4167\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 28.3280 - val_loss: 29.4897\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 22.1529 - val_loss: 29.3172\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 24.6282 - val_loss: 28.9732\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 24.8879 - val_loss: 28.7213\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 24.0877 - val_loss: 28.6727\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 23.1082 - val_loss: 27.9747\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 30.3388 - val_loss: 27.8459\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 26.2021 - val_loss: 28.6789\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 26.6214 - val_loss: 28.5440\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 21.0610 - val_loss: 28.0502\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 22.3087 - val_loss: 27.4991\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 26.6197 - val_loss: 27.2769\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 25.4631 - val_loss: 27.4975\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 24.5778 - val_loss: 27.5129\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 21.3123 - val_loss: 26.8817\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 24.5654 - val_loss: 26.8832\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 21.3366 - val_loss: 27.5253\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 20.6383 - val_loss: 27.9049\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 22.0058 - val_loss: 27.5302\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 21.0428 - val_loss: 27.2850\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 27.0964 - val_loss: 27.2018\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 22.8881 - val_loss: 27.5390\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 24.3784 - val_loss: 27.6632\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 19.7895 - val_loss: 27.3461\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 22.1884 - val_loss: 26.4243\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 25.0079 - val_loss: 26.0857\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 29.5186 - val_loss: 27.5449\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 25.1196 - val_loss: 28.9044\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 31.8210 - val_loss: 28.8532\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 24.9906 - val_loss: 27.8714\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 23.3142 - val_loss: 26.9400\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 27.3702 - val_loss: 27.2060\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 25.2411 - val_loss: 27.7555\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 21.9284 - val_loss: 27.7215\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 34.6806 - val_loss: 27.8424\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 21.6166 - val_loss: 27.0092\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 19.0650 - val_loss: 26.0245\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 22.2953 - val_loss: 26.4749\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 19.7942 - val_loss: 26.9289\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 21.4162 - val_loss: 26.7488\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 21.5159 - val_loss: 26.5500\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 26.3857 - val_loss: 27.2897\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 21.8653 - val_loss: 27.1615\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 25.2812 - val_loss: 26.7777\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 22.9812 - val_loss: 26.8602\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 24.2070 - val_loss: 27.4273\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 20.9677 - val_loss: 27.3298\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 22.3865 - val_loss: 26.9248\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 20.6609 - val_loss: 27.1105\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 19.2150 - val_loss: 27.4449\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 19.5558 - val_loss: 27.1608\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 19.1437 - val_loss: 26.6772\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 15.6652 - val_loss: 26.4164\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 24.4772 - val_loss: 26.9026\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 19.5006 - val_loss: 27.2144\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 18.6637 - val_loss: 26.4374\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 24.4357 - val_loss: 26.9719\n",
      "\n",
      "Mean squared error: 2.4e+01\n",
      "\n",
      "dropout: 7.6e-01\n",
      "filter_num: 217\n",
      "num_dense_layers: 4\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 164us/sample - loss: 51.5933 - val_loss: 34.9046\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 48.1228 - val_loss: 35.9654\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 45.8345 - val_loss: 35.7435\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 45.7202 - val_loss: 35.3646\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 44.0314 - val_loss: 35.1723\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 41.9388 - val_loss: 35.0270\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 40.5771 - val_loss: 34.9173\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 38.9228 - val_loss: 34.4221\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 40.0057 - val_loss: 34.3040\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 38.6072 - val_loss: 34.2752\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 36.9753 - val_loss: 34.2857\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 38.1264 - val_loss: 34.5451\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 36.5198 - val_loss: 34.1116\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 33.8672 - val_loss: 33.8442\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 35.0344 - val_loss: 34.1868\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 32.2936 - val_loss: 34.5803\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 34us/sample - loss: 31.5228 - val_loss: 34.4164\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 31.1770 - val_loss: 34.2753\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 31.8537 - val_loss: 34.2280\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 28.9661 - val_loss: 34.2934\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 30.3249 - val_loss: 33.5034\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 28.6105 - val_loss: 33.4545\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 27.6065 - val_loss: 33.6218\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 29.6507 - val_loss: 33.5327\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 29.7985 - val_loss: 32.8550\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 25.3911 - val_loss: 32.1582\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 27.3491 - val_loss: 32.4125\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 26.1226 - val_loss: 32.3874\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 24.1147 - val_loss: 32.0128\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 24.3467 - val_loss: 32.0348\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 25.0011 - val_loss: 31.6882\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 23.3753 - val_loss: 31.3062\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 22.4412 - val_loss: 30.6135\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 25.8258 - val_loss: 30.9851\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 21.5388 - val_loss: 30.7149\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 19.4181 - val_loss: 29.5493\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 21.4141 - val_loss: 29.8448\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 21.9094 - val_loss: 30.0477\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 24.5555 - val_loss: 30.1256\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 22.3613 - val_loss: 30.3463\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 21.2935 - val_loss: 29.0560\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 20.6645 - val_loss: 28.4348\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 22.9189 - val_loss: 28.4105\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 20.2352 - val_loss: 28.3831\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 22.1149 - val_loss: 28.5050\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 21.4824 - val_loss: 28.1657\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 18.4600 - val_loss: 27.9131\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 16.3418 - val_loss: 27.4088\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 20.2367 - val_loss: 27.5708\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 18.9146 - val_loss: 27.7383\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 19.0315 - val_loss: 27.9716\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 18.0538 - val_loss: 27.4633\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 22.1015 - val_loss: 27.3429\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 16.5712 - val_loss: 27.7848\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 19.0145 - val_loss: 27.6129\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 20.4392 - val_loss: 27.7721\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 15.8130 - val_loss: 27.8618\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 15.8927 - val_loss: 26.9531\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 21.9513 - val_loss: 26.9038\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 17.2419 - val_loss: 27.5083\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 17.0329 - val_loss: 27.5487\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 19.0283 - val_loss: 27.0223\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 18.6635 - val_loss: 27.2131\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 15.9263 - val_loss: 26.9002\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 16.9125 - val_loss: 26.8962\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 15.8837 - val_loss: 27.1751\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 15.7466 - val_loss: 27.1938\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 13.3253 - val_loss: 27.1343\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 14.5226 - val_loss: 27.0892\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 14.4547 - val_loss: 27.2795\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 13.7167 - val_loss: 27.5337\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 13.8297 - val_loss: 27.4937\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 14.1261 - val_loss: 27.2540\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 14.1856 - val_loss: 26.9552\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 14.9232 - val_loss: 27.0780\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 14.5759 - val_loss: 27.1042\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 15.6756 - val_loss: 26.9606\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 17.9062 - val_loss: 27.0231\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 14.3631 - val_loss: 27.1870\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 14.2422 - val_loss: 27.5763\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 15.5301 - val_loss: 27.3700\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 17.3173 - val_loss: 27.4099\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 15.8057 - val_loss: 27.2811\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 15.5904 - val_loss: 27.3624\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 17.2821 - val_loss: 27.3650\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 15.1469 - val_loss: 26.9945\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 14.6453 - val_loss: 27.3004\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 18.2956 - val_loss: 27.6585\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 18.9641 - val_loss: 27.5206\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 17.4311 - val_loss: 27.3389\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 18.8651 - val_loss: 27.7740\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 29us/sample - loss: 16.4897 - val_loss: 27.6466\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 14.5455 - val_loss: 27.2248\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 14.1212 - val_loss: 26.9437\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 14.6978 - val_loss: 27.0681\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 16.3420 - val_loss: 27.4150\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 16.5089 - val_loss: 27.2026\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 15.8663 - val_loss: 27.0121\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 17.0865 - val_loss: 27.4252\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 17.1366 - val_loss: 27.8357\n",
      "\n",
      "Mean squared error: 1.7e+01\n",
      "\n",
      "dropout: 3.9e-01\n",
      "filter_num: 57\n",
      "num_dense_layers: 7\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 1s 211us/sample - loss: 63.9751 - val_loss: 37.7595\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 62.1003 - val_loss: 35.7471\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 54.9193 - val_loss: 26.9637\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 48.0939 - val_loss: 23.5598\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 44.3373 - val_loss: 25.2914\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 43.2697 - val_loss: 24.4688\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 41.2862 - val_loss: 23.6564\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 37.9236 - val_loss: 23.1195\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 38.2978 - val_loss: 23.5648\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 38.4641 - val_loss: 22.7271\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 35.5387 - val_loss: 20.9035\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 36.2356 - val_loss: 24.5814\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 33.5921 - val_loss: 24.7661\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 32.9542 - val_loss: 23.0494\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 31.7838 - val_loss: 21.0317\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 32.5736 - val_loss: 23.7293\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 28.8114 - val_loss: 25.8619\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 30.2671 - val_loss: 24.8085\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 28.3832 - val_loss: 22.5196\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 28.9575 - val_loss: 22.3523\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 28.9122 - val_loss: 22.9429\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 27.3776 - val_loss: 24.5549\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 27.3121 - val_loss: 23.9508\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 26.8919 - val_loss: 23.5078\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 22.2958 - val_loss: 22.7119\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 24.7855 - val_loss: 22.8412\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 20.4833 - val_loss: 23.2379\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 18.6608 - val_loss: 23.1030\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 18.0723 - val_loss: 23.3665\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 21.0796 - val_loss: 25.4259\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 20.1062 - val_loss: 23.8774\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 17.9650 - val_loss: 22.3139\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 15.7598 - val_loss: 24.0381\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 18.9881 - val_loss: 23.0922\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 19.6003 - val_loss: 23.1991\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 14.8335 - val_loss: 24.3045\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 16.2371 - val_loss: 23.0362\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 16.2018 - val_loss: 24.4289\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 16.8653 - val_loss: 23.8609\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 15.1701 - val_loss: 23.6788\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 16.6830 - val_loss: 26.9319\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 19.5259 - val_loss: 25.6875\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 16.2916 - val_loss: 23.4823\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 19.7190 - val_loss: 25.6884\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 16.6628 - val_loss: 25.6611\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 17.6758 - val_loss: 23.2780\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 14.5638 - val_loss: 23.7372\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 15.9107 - val_loss: 23.7798\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 16.4327 - val_loss: 23.6807\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 13.9404 - val_loss: 23.7300\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 19.5168 - val_loss: 24.7519\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 15.4826 - val_loss: 23.5851\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 19.6405 - val_loss: 23.3858\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 14.8866 - val_loss: 24.3505\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 14.8006 - val_loss: 23.6174\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 14.7235 - val_loss: 24.5106\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 11.7113 - val_loss: 24.6130\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 13.9475 - val_loss: 24.6144\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 13.5413 - val_loss: 24.4206\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 12.1764 - val_loss: 24.2351\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 13.8325 - val_loss: 25.5524\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 14.9151 - val_loss: 26.2821\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 15.8756 - val_loss: 25.1186\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 11.8327 - val_loss: 23.7517\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 14.2756 - val_loss: 24.9383\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 21us/sample - loss: 16.2035 - val_loss: 24.7629\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 15.6379 - val_loss: 24.2600\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 14.4673 - val_loss: 23.9478\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 11.9852 - val_loss: 22.9744\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 12.8821 - val_loss: 23.7502\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 12.0694 - val_loss: 24.1304\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 10.3444 - val_loss: 24.3718\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 12.0830 - val_loss: 25.1497\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 12.0336 - val_loss: 25.3996\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 13.9802 - val_loss: 24.7137\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 9.8441 - val_loss: 24.4703\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 12.1149 - val_loss: 25.6179\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 14.1148 - val_loss: 24.9427\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 11.4914 - val_loss: 24.0355\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 11.9107 - val_loss: 25.2404\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 11.1005 - val_loss: 26.0113\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 10.1260 - val_loss: 25.5692\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 11.3673 - val_loss: 25.5312\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 12.4551 - val_loss: 25.7717\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 12.0370 - val_loss: 25.5950\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 10.6636 - val_loss: 25.0663\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 12.5758 - val_loss: 24.4872\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 10.7920 - val_loss: 24.2159\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 11.5766 - val_loss: 25.2360\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 11.3424 - val_loss: 26.0438\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 12.8061 - val_loss: 25.2324\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 15.2364 - val_loss: 25.1111\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 11.8387 - val_loss: 24.9719\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 11.4385 - val_loss: 24.4134\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 14.0593 - val_loss: 24.4832\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 11.8776 - val_loss: 24.5984\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 11.4588 - val_loss: 23.7439\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 13.4974 - val_loss: 24.0514\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 10.6079 - val_loss: 23.5519\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 10.1144 - val_loss: 23.0319\n",
      "\n",
      "Mean squared error: 1e+01\n",
      "\n",
      "dropout: 5.5e-01\n",
      "filter_num: 82\n",
      "num_dense_layers: 17\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 1s 433us/sample - loss: 63.5037 - val_loss: 37.9101\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 58.3166 - val_loss: 37.4340\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 52.6617 - val_loss: 37.1365\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 43us/sample - loss: 53.5799 - val_loss: 37.0283\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 53.2225 - val_loss: 36.8680\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 43us/sample - loss: 49.9601 - val_loss: 36.4835\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 51.2268 - val_loss: 36.0893\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 51.0344 - val_loss: 35.9610\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 51.1374 - val_loss: 35.8578\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 49.9051 - val_loss: 35.5775\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 49.3236 - val_loss: 35.2871\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 47.6835 - val_loss: 35.0769\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 43us/sample - loss: 46.3263 - val_loss: 35.0684\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 46.2398 - val_loss: 34.9515\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 46.5803 - val_loss: 34.6568\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 42.7264 - val_loss: 34.1790\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 40.6678 - val_loss: 33.8550\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 43us/sample - loss: 45.2935 - val_loss: 33.9048\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 43us/sample - loss: 45.8126 - val_loss: 34.0665\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 43us/sample - loss: 40.9865 - val_loss: 33.4804\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 43.2838 - val_loss: 33.0643\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 43us/sample - loss: 42.0936 - val_loss: 33.5755\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 43us/sample - loss: 40.6851 - val_loss: 33.3377\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 43us/sample - loss: 40.7602 - val_loss: 32.6606\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 43us/sample - loss: 41.3743 - val_loss: 32.7079\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 40.7899 - val_loss: 32.7799\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 43us/sample - loss: 41.2195 - val_loss: 32.5193\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 44.1388 - val_loss: 32.5655\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 40.0119 - val_loss: 32.3501\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 43us/sample - loss: 40.6123 - val_loss: 32.0039\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 43.4882 - val_loss: 32.1614\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 36.8010 - val_loss: 32.1080\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 43us/sample - loss: 38.2094 - val_loss: 31.7307\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 43us/sample - loss: 36.7158 - val_loss: 31.0748\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 43us/sample - loss: 34.1447 - val_loss: 30.7437\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 43us/sample - loss: 35.9226 - val_loss: 30.4927\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 35.9778 - val_loss: 30.6971\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 36.0665 - val_loss: 30.9902\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 33.7376 - val_loss: 30.7174\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 44us/sample - loss: 34.2571 - val_loss: 30.3557\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 35.4155 - val_loss: 30.0616\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 43us/sample - loss: 35.4690 - val_loss: 29.9253\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 43us/sample - loss: 35.5098 - val_loss: 29.9348\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 32.2257 - val_loss: 29.4636\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 43us/sample - loss: 43.0384 - val_loss: 30.3717\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 42us/sample - loss: 33.3239 - val_loss: 30.0089\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 30.9788 - val_loss: 29.3966\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 42us/sample - loss: 36.2052 - val_loss: 30.0806\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 36.5844 - val_loss: 30.3706\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 34.6135 - val_loss: 29.7691\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 35.7252 - val_loss: 29.6679\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 43us/sample - loss: 30.5859 - val_loss: 29.2373\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 29.1415 - val_loss: 29.1341\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 43us/sample - loss: 31.5946 - val_loss: 29.0697\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 34.0992 - val_loss: 28.9392\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 43us/sample - loss: 29.5847 - val_loss: 28.3036\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 43us/sample - loss: 30.0462 - val_loss: 28.1771\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 33.9712 - val_loss: 28.6073\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 30.9656 - val_loss: 27.8978\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 31.6649 - val_loss: 27.8310\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 43us/sample - loss: 29.5690 - val_loss: 28.5443\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 25.7687 - val_loss: 28.3221\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 26.5084 - val_loss: 28.1033\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 30.2260 - val_loss: 28.6342\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 30.3579 - val_loss: 28.5404\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 32.7886 - val_loss: 28.1719\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 43us/sample - loss: 29.3058 - val_loss: 28.1314\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 43us/sample - loss: 33.6245 - val_loss: 28.1294\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 30.9272 - val_loss: 29.9254\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 32.9938 - val_loss: 29.7997\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 35.6473 - val_loss: 29.4194\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 33.3344 - val_loss: 29.8111\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 28.8373 - val_loss: 29.5584\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 33.9958 - val_loss: 29.8379\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 43us/sample - loss: 30.6464 - val_loss: 30.1496\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 31.2363 - val_loss: 30.2486\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 43us/sample - loss: 41.0559 - val_loss: 30.7561\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 33.9120 - val_loss: 31.8292\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 38.0863 - val_loss: 31.5011\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 43us/sample - loss: 34.0130 - val_loss: 29.4923\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 35.9041 - val_loss: 29.4748\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 43us/sample - loss: 34.9748 - val_loss: 30.6192\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 35.9913 - val_loss: 30.5001\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 32.9310 - val_loss: 29.1921\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 43us/sample - loss: 39.0813 - val_loss: 28.5714\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 28.8599 - val_loss: 29.0937\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 29.1930 - val_loss: 29.3824\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 30.8680 - val_loss: 29.2900\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 31.5651 - val_loss: 29.4471\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 31.1652 - val_loss: 28.9635\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 33.2565 - val_loss: 28.7612\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 33.0233 - val_loss: 29.5356\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 36.3961 - val_loss: 31.2184\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 43us/sample - loss: 43.4764 - val_loss: 31.0915\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 40.3017 - val_loss: 29.8711\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 33.7274 - val_loss: 28.0678\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 88.0801 - val_loss: 29.4112\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 34.6770 - val_loss: 30.6036\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 33.2525 - val_loss: 30.2492\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 36.1694 - val_loss: 29.5378\n",
      "\n",
      "Mean squared error: 3.6e+01\n",
      "\n",
      "dropout: 2.6e-01\n",
      "filter_num: 130\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 101us/sample - loss: 62.8147 - val_loss: 33.2417\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 53.8220 - val_loss: 23.0963\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 42.8967 - val_loss: 24.8002\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 40.1830 - val_loss: 20.2356\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 37.9504 - val_loss: 19.5815\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 35.5650 - val_loss: 19.2946\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 32.9685 - val_loss: 20.4917\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 31.5793 - val_loss: 18.4650\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 30.5274 - val_loss: 18.1292\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 28.1936 - val_loss: 20.4763\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 27.2713 - val_loss: 19.5979\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 25.9062 - val_loss: 20.1412\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 24.7520 - val_loss: 21.1907\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 17us/sample - loss: 24.3843 - val_loss: 22.9033\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 22.3347 - val_loss: 22.0773\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 21.5750 - val_loss: 23.9551\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 19.9137 - val_loss: 24.3288\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 18.8384 - val_loss: 30.0151\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 18.2229 - val_loss: 27.5746\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 18.2405 - val_loss: 24.3090\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 14.9249 - val_loss: 37.5541\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 17.7816 - val_loss: 30.3300\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 15.5976 - val_loss: 25.3803\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 15.7062 - val_loss: 32.3650\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 13.5450 - val_loss: 37.4379\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 11.8624 - val_loss: 31.5728\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 10.4854 - val_loss: 34.7253\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 9.6163 - val_loss: 39.8982\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 8.2463 - val_loss: 38.8740\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 7.8579 - val_loss: 42.6104\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 7.4124 - val_loss: 44.2180\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 6.9044 - val_loss: 40.4433\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 6.5578 - val_loss: 42.2252\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 5.6401 - val_loss: 44.7830\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 5.8979 - val_loss: 43.5882\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 5.7829 - val_loss: 44.4798\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 5.1038 - val_loss: 43.5582\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 5.4021 - val_loss: 42.4132\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.8626 - val_loss: 42.3565\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.6404 - val_loss: 42.1085\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.6516 - val_loss: 41.9443\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.4021 - val_loss: 45.4340\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.8135 - val_loss: 44.7029\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.9002 - val_loss: 42.4198\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.2984 - val_loss: 40.7875\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.2898 - val_loss: 44.5096\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 3.8540 - val_loss: 44.6638\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.4258 - val_loss: 43.0396\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.6592 - val_loss: 38.4633\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.8618 - val_loss: 34.5644\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.7775 - val_loss: 36.2583\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.9633 - val_loss: 33.8070\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.8483 - val_loss: 35.2434\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.6076 - val_loss: 35.2439\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.1348 - val_loss: 33.7251\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.1782 - val_loss: 34.1074\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.0283 - val_loss: 33.9505\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.6249 - val_loss: 33.7566\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.9765 - val_loss: 36.6988\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.8001 - val_loss: 36.1205\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.7791 - val_loss: 33.6442\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.1272 - val_loss: 27.8632\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.9829 - val_loss: 29.2344\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 3.9491 - val_loss: 28.2533\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.0181 - val_loss: 30.9890\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.1728 - val_loss: 28.9525\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.5474 - val_loss: 29.9701\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.9909 - val_loss: 30.7618\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.0474 - val_loss: 30.8606\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.5723 - val_loss: 31.0183\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.4923 - val_loss: 31.1644\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.5951 - val_loss: 30.0218\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.4418 - val_loss: 31.6938\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.4343 - val_loss: 32.2419\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.2687 - val_loss: 32.2811\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 2.5372 - val_loss: 30.0141\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.0117 - val_loss: 31.1619\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.1922 - val_loss: 32.5422\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.3911 - val_loss: 33.2093\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.3214 - val_loss: 31.8292\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.0074 - val_loss: 32.1728\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.0710 - val_loss: 31.8683\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.0342 - val_loss: 33.7118\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.0927 - val_loss: 31.9822\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.1406 - val_loss: 33.3113\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.0130 - val_loss: 31.1011\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 2.2111 - val_loss: 31.7023\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.5392 - val_loss: 28.8838\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.0239 - val_loss: 28.6739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.6153 - val_loss: 27.7735\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.5105 - val_loss: 32.4267\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.9935 - val_loss: 32.4180\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 6.7182 - val_loss: 31.1262\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 5.1835 - val_loss: 32.2841\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.6562 - val_loss: 29.6292\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.3398 - val_loss: 31.2028\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.1100 - val_loss: 30.1784\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.6146 - val_loss: 29.1615\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.7362 - val_loss: 32.2471\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 2.8883 - val_loss: 29.6627\n",
      "\n",
      "Mean squared error: 2.9\n",
      "\n",
      "dropout: 2.0e-01\n",
      "filter_num: 10\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 96us/sample - loss: 64.2131 - val_loss: 38.0662\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 64.1328 - val_loss: 37.9989\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 64.0483 - val_loss: 37.9085\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 63.9279 - val_loss: 37.7784\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 63.7282 - val_loss: 37.5814\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 63.4271 - val_loss: 37.2877\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 62.9740 - val_loss: 36.8122\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 62.1514 - val_loss: 36.0025\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 60.8881 - val_loss: 34.6475\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 58.4775 - val_loss: 32.5144\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 54.8976 - val_loss: 29.5701\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 50.2411 - val_loss: 26.0656\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 45.0018 - val_loss: 23.0748\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 39.8160 - val_loss: 21.5970\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 39.1984 - val_loss: 21.3627\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 37.8657 - val_loss: 20.7281\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 35.1526 - val_loss: 19.7705\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 34.5237 - val_loss: 19.1593\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 34.4461 - val_loss: 19.1186\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 34.4928 - val_loss: 19.5845\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 32.0075 - val_loss: 20.1100\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 30.4734 - val_loss: 20.5802\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 31.1986 - val_loss: 20.5289\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 30.3875 - val_loss: 20.4101\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 28.3342 - val_loss: 20.1744\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 31.6133 - val_loss: 19.6111\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 28.3548 - val_loss: 19.4253\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 29.1814 - val_loss: 19.3547\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 26.5840 - val_loss: 19.3590\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 27.9599 - val_loss: 19.2115\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 30.6869 - val_loss: 19.2383\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 28.9392 - val_loss: 19.2033\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 28.7003 - val_loss: 19.2752\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 28.8272 - val_loss: 19.2969\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 27.6445 - val_loss: 19.4826\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 26.1132 - val_loss: 19.6966\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 28.2658 - val_loss: 20.0476\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 27.3484 - val_loss: 19.9911\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 26.8502 - val_loss: 19.6951\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 24.9933 - val_loss: 19.7630\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 25.3783 - val_loss: 20.2321\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 24.8923 - val_loss: 21.2948\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 26.1390 - val_loss: 21.1583\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 26.1243 - val_loss: 20.7460\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 25.2585 - val_loss: 20.4822\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 24.9558 - val_loss: 20.3072\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 23.3869 - val_loss: 20.6776\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 24.5411 - val_loss: 22.1248\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 24.3901 - val_loss: 22.4213\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 24.4544 - val_loss: 22.6847\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 23.3220 - val_loss: 23.8951\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 24.8694 - val_loss: 23.9461\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 24.3846 - val_loss: 24.0225\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 23.9473 - val_loss: 23.6155\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 22.4655 - val_loss: 24.0296\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 22.5404 - val_loss: 25.3616\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 23.0008 - val_loss: 26.3869\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 22.2640 - val_loss: 26.7440\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 23.1205 - val_loss: 26.2843\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 23.6644 - val_loss: 27.5088\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 23.1068 - val_loss: 29.4625\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 21.0129 - val_loss: 31.5063\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 21.7421 - val_loss: 33.1648\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 9us/sample - loss: 21.1347 - val_loss: 33.8646\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 19.9716 - val_loss: 35.4675\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 19.7283 - val_loss: 37.1818\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 20.7539 - val_loss: 38.9500\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 22.8796 - val_loss: 41.9380\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 20.6304 - val_loss: 49.2603\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 19.6650 - val_loss: 53.1010\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 19.4840 - val_loss: 52.6002\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 17.7711 - val_loss: 56.1182\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 17.9979 - val_loss: 62.8039\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 19.5396 - val_loss: 68.2249\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 17.1021 - val_loss: 69.1202\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 16.8889 - val_loss: 69.0521\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 17.4833 - val_loss: 72.5146\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 16.7557 - val_loss: 80.7341\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 19.0021 - val_loss: 99.1121\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 16.9995 - val_loss: 101.5896\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 16.4505 - val_loss: 107.5075\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 17.0986 - val_loss: 116.4136\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 15.3428 - val_loss: 129.8734\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 15.3747 - val_loss: 136.1125\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 14.4748 - val_loss: 144.9372\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 14.9295 - val_loss: 150.3596\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 16.0312 - val_loss: 152.9475\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 15.3810 - val_loss: 145.1913\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 14.4459 - val_loss: 150.7823\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 12.8411 - val_loss: 165.0532\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 13.6611 - val_loss: 180.4238\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 12.9252 - val_loss: 200.0032\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 15.4488 - val_loss: 192.7129\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 12.4229 - val_loss: 191.5636\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 13.4577 - val_loss: 196.9012\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 11.5980 - val_loss: 210.0246\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 11.7455 - val_loss: 226.1085\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 11.7605 - val_loss: 236.1756\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 10.6437 - val_loss: 243.9916\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 10.5390 - val_loss: 258.9174\n",
      "\n",
      "Mean squared error: 1.1e+01\n",
      "\n",
      "dropout: 3.4e-01\n",
      "filter_num: 147\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 104us/sample - loss: 61.2987 - val_loss: 30.2652\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 49.3282 - val_loss: 23.1047\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 44.5547 - val_loss: 22.1436\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 39.7833 - val_loss: 20.7562\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 38.6376 - val_loss: 19.7118\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 34.4071 - val_loss: 21.1601\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 33.0026 - val_loss: 19.0580\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 30.5660 - val_loss: 18.8148\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 28.9460 - val_loss: 20.6435\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 27.7934 - val_loss: 19.3913\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 25.9657 - val_loss: 20.4608\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 24.8325 - val_loss: 21.7690\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 23.9833 - val_loss: 22.9881\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 22.4067 - val_loss: 23.9120\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 21.9983 - val_loss: 25.4217\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 21.0540 - val_loss: 28.0759\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 17.0055 - val_loss: 27.5345\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 16.2225 - val_loss: 33.5706\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 15.3346 - val_loss: 32.5850\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 14.9857 - val_loss: 43.6896\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 16.5110 - val_loss: 38.3576\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 13.2591 - val_loss: 42.4306\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 10.8638 - val_loss: 56.5517\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 11.7035 - val_loss: 47.9734\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 10.8576 - val_loss: 50.5097\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 8.6871 - val_loss: 61.8704\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 8.4602 - val_loss: 56.5319\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 7.8675 - val_loss: 59.1190\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 6.6599 - val_loss: 58.5953\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 6.6894 - val_loss: 56.6076\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 6.4570 - val_loss: 58.8419\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 6.6891 - val_loss: 66.7197\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 6.6549 - val_loss: 62.8500\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 5.6803 - val_loss: 65.3306\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 5.3199 - val_loss: 65.0674\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 6.3279 - val_loss: 71.1327\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 6.4518 - val_loss: 72.1406\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 16us/sample - loss: 6.4106 - val_loss: 72.8361\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 5.1231 - val_loss: 63.2388\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 5.2970 - val_loss: 70.3580\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 5.1819 - val_loss: 63.7707\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 4.5004 - val_loss: 65.7919\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.6666 - val_loss: 67.1920\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 4.3812 - val_loss: 65.3406\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 3.8941 - val_loss: 64.5209\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 3.9590 - val_loss: 67.2169\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 4.0298 - val_loss: 66.7374\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 4.4429 - val_loss: 67.3063\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 4.1042 - val_loss: 67.5765\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 3.7385 - val_loss: 64.8686\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 4.0984 - val_loss: 67.7879\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.7076 - val_loss: 72.2675\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 4.1931 - val_loss: 70.2791\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.0586 - val_loss: 77.4293\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.3970 - val_loss: 68.4432\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 3.9129 - val_loss: 70.0871\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 3.6755 - val_loss: 74.1507\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 3.9521 - val_loss: 71.5212\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 3.5266 - val_loss: 76.2253\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 4.1571 - val_loss: 68.5557\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 3.4667 - val_loss: 71.7634\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 3.8817 - val_loss: 68.3073\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 3.3470 - val_loss: 71.8173\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.1552 - val_loss: 74.0181\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 3.3636 - val_loss: 68.0529\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 3.2481 - val_loss: 66.6130\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 3.3042 - val_loss: 62.6729\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 3.3930 - val_loss: 66.8653\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 2.9772 - val_loss: 71.4958\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 2.9089 - val_loss: 64.5649\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 2.9787 - val_loss: 66.1568\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 2.7491 - val_loss: 66.7217\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 2.6831 - val_loss: 66.7853\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 2.9116 - val_loss: 72.7531\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 3.3314 - val_loss: 65.5540\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 5.9774 - val_loss: 50.0315\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 6.9976 - val_loss: 69.1860\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 6.6658 - val_loss: 45.6670\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 6.6717 - val_loss: 64.6694\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 4.8861 - val_loss: 60.7873\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 4.0285 - val_loss: 56.5091\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 3.6402 - val_loss: 63.1471\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 3.4099 - val_loss: 54.5171\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 2.9410 - val_loss: 56.0336\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 3.7117 - val_loss: 53.2906\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 3.9806 - val_loss: 58.2885\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 3.3537 - val_loss: 55.9153\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 3.4322 - val_loss: 58.0361\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 3.7329 - val_loss: 56.3826\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.8775 - val_loss: 56.0003\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 4.4899 - val_loss: 50.9114\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 4.0274 - val_loss: 58.7623\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 3.4886 - val_loss: 53.6576\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 4.2229 - val_loss: 58.9919\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 4.4357 - val_loss: 56.8080\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 5.0722 - val_loss: 61.2400\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 5.0841 - val_loss: 64.4485\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 3.7593 - val_loss: 57.5974\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 2.8410 - val_loss: 58.7042\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 2.7189 - val_loss: 53.1913\n",
      "\n",
      "Mean squared error: 2.7\n",
      "\n",
      "dropout: 2.0e-01\n",
      "filter_num: 300\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 114us/sample - loss: 55.3796 - val_loss: 24.2629\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 46.0742 - val_loss: 21.7646\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 42.9474 - val_loss: 21.8154\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 38.8715 - val_loss: 24.1121\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 38.5833 - val_loss: 21.6892\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 32.6374 - val_loss: 19.5479\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 32.2191 - val_loss: 19.8494\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 27.8233 - val_loss: 22.4668\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 25.6134 - val_loss: 19.9936\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 26.5439 - val_loss: 20.1759\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 22.7933 - val_loss: 27.2060\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 21.5771 - val_loss: 22.8102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 19.0961 - val_loss: 27.7348\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 16.1909 - val_loss: 26.4592\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 14.4350 - val_loss: 28.5815\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 12.1316 - val_loss: 26.9312\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 10.4072 - val_loss: 29.4358\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 9.4209 - val_loss: 24.5847\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 8.1521 - val_loss: 30.3613\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 7.0833 - val_loss: 24.5611\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 6.7836 - val_loss: 29.6669\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 5.8030 - val_loss: 26.2135\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 5.3194 - val_loss: 27.1876\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 4.4696 - val_loss: 25.9174\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 4.3338 - val_loss: 27.6031\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.4272 - val_loss: 23.0165\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.6413 - val_loss: 27.6503\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.8678 - val_loss: 22.8129\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.8180 - val_loss: 32.2068\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 6.1068 - val_loss: 22.8317\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.1367 - val_loss: 27.1479\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 3.9213 - val_loss: 24.6851\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.9047 - val_loss: 26.3189\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.5887 - val_loss: 24.5066\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.4958 - val_loss: 24.8100\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.2616 - val_loss: 25.6868\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.3378 - val_loss: 26.0839\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.9047 - val_loss: 27.0807\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.7267 - val_loss: 24.7666\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.0060 - val_loss: 24.9136\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.7997 - val_loss: 26.4490\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.5460 - val_loss: 26.4298\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.6814 - val_loss: 26.5128\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.7195 - val_loss: 27.9466\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.4812 - val_loss: 26.3429\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.2695 - val_loss: 26.7388\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.4051 - val_loss: 24.5312\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.5614 - val_loss: 25.8974\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 2.2787 - val_loss: 25.9576\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.0752 - val_loss: 27.1828\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.3381 - val_loss: 28.1498\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.2953 - val_loss: 25.8113\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.2419 - val_loss: 24.9495\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.4451 - val_loss: 24.6950\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.6403 - val_loss: 25.1710\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.3912 - val_loss: 24.2729\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.2998 - val_loss: 26.7302\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.1535 - val_loss: 26.1088\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.9663 - val_loss: 25.7629\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.9828 - val_loss: 24.7580\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.6933 - val_loss: 25.3378\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.8227 - val_loss: 24.3166\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.8617 - val_loss: 23.9189\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.8116 - val_loss: 27.2904\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.3104 - val_loss: 24.2650\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 3.6494 - val_loss: 28.9167\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.5844 - val_loss: 24.2607\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.5379 - val_loss: 25.8302\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.3326 - val_loss: 26.3804\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.6229 - val_loss: 27.7753\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.2546 - val_loss: 26.6548\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.0366 - val_loss: 25.9175\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.5677 - val_loss: 26.8158\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.8025 - val_loss: 27.3058\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.4836 - val_loss: 25.4397\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 1.5901 - val_loss: 27.4535\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.5864 - val_loss: 25.5573\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.6299 - val_loss: 26.3496\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.2284 - val_loss: 26.8991\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.6423 - val_loss: 25.9890\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.4742 - val_loss: 27.1964\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.5683 - val_loss: 26.2074\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 1.1253 - val_loss: 27.0089\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.2270 - val_loss: 25.5275\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.5999 - val_loss: 26.1736\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.4134 - val_loss: 25.9537\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.3086 - val_loss: 25.4407\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.1567 - val_loss: 26.3827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.6671 - val_loss: 25.5949\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.5376 - val_loss: 28.6712\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.5577 - val_loss: 24.0444\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.2269 - val_loss: 27.1817\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 1.7943 - val_loss: 26.0015\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.5025 - val_loss: 28.7985\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.4882 - val_loss: 26.2380\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.2023 - val_loss: 26.4062\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.2298 - val_loss: 25.3063\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.3955 - val_loss: 26.8487\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.2379 - val_loss: 25.0227\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.2678 - val_loss: 26.0141\n",
      "\n",
      "Mean squared error: 1.3\n",
      "\n",
      "dropout: 2.0e-01\n",
      "filter_num: 230\n",
      "num_dense_layers: 8\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 1s 268us/sample - loss: 62.5023 - val_loss: 24.0827\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 47.4272 - val_loss: 26.8807\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 43.7476 - val_loss: 20.3040\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 38.3517 - val_loss: 19.9016\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 57us/sample - loss: 35.4151 - val_loss: 19.2042\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 31.7399 - val_loss: 20.6230\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 29.8765 - val_loss: 21.0699\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 27.6979 - val_loss: 19.4340\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 23.6514 - val_loss: 20.5768\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 20.1362 - val_loss: 21.9395\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 19.3412 - val_loss: 24.3124\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 16.2173 - val_loss: 24.8129\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 15.0502 - val_loss: 22.7701\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 15.2367 - val_loss: 25.1477\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 57us/sample - loss: 14.0879 - val_loss: 24.7485\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 12.1955 - val_loss: 23.1041\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 11.2554 - val_loss: 23.4859\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 9.3720 - val_loss: 24.5646\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 9.6168 - val_loss: 22.2428\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 9.5467 - val_loss: 21.1278\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 58us/sample - loss: 9.5759 - val_loss: 23.5579\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 9.4722 - val_loss: 25.7468\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 11.4176 - val_loss: 28.1798\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 16.6496 - val_loss: 25.9644\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 14.3848 - val_loss: 25.0921\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 57us/sample - loss: 15.4396 - val_loss: 21.3616\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 12.9272 - val_loss: 23.0270\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 10.7745 - val_loss: 23.7782\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 11.9770 - val_loss: 23.0651\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 11.2863 - val_loss: 29.0058\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 11.2998 - val_loss: 24.2273\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 12.3789 - val_loss: 23.3698\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 13.2394 - val_loss: 22.5729\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 10.3316 - val_loss: 21.4849\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 10.3894 - val_loss: 24.8953\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 16.4652 - val_loss: 25.9775\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 20.7781 - val_loss: 24.6943\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 14.7464 - val_loss: 24.0505\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 16.1069 - val_loss: 22.3612\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 9.5934 - val_loss: 21.9186\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 7.4277 - val_loss: 21.9572\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 7.8002 - val_loss: 21.9342\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 6.7530 - val_loss: 21.2927\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 7.0532 - val_loss: 22.0567\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 6.5783 - val_loss: 21.7148\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 57us/sample - loss: 5.1271 - val_loss: 23.1309\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 56us/sample - loss: 5.4928 - val_loss: 21.6163\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 5.8965 - val_loss: 21.6070\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 5.5562 - val_loss: 21.7491\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 6.0530 - val_loss: 21.9294\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 57us/sample - loss: 6.1475 - val_loss: 21.4771\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 5.2954 - val_loss: 22.7608\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 7.7729 - val_loss: 22.2579\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 8.0734 - val_loss: 22.6563\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 57us/sample - loss: 5.9370 - val_loss: 22.1440\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 6.0143 - val_loss: 23.0377\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 4.9950 - val_loss: 22.7645\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 4.7650 - val_loss: 25.5381\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 7.8859 - val_loss: 23.4775\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 6.7605 - val_loss: 23.6136\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 6.4414 - val_loss: 22.4115\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 5.1288 - val_loss: 24.0560\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 56us/sample - loss: 5.5505 - val_loss: 23.0827\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 4.8898 - val_loss: 22.1997\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 4.9658 - val_loss: 21.5082\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 56us/sample - loss: 4.5581 - val_loss: 22.3697\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 4.8057 - val_loss: 23.2388\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 4.5453 - val_loss: 22.5725\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 4.8807 - val_loss: 22.3070\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 13.7151 - val_loss: 22.2844\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 9.2676 - val_loss: 22.0619\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 58us/sample - loss: 7.4464 - val_loss: 23.5829\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 7.2642 - val_loss: 22.5544\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 8.1426 - val_loss: 22.2072\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 7.0290 - val_loss: 22.7400\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 6.0646 - val_loss: 22.7764\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 8.3383 - val_loss: 22.1591\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 5.2699 - val_loss: 21.4793\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 5.3007 - val_loss: 21.2255\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 6.4426 - val_loss: 21.6551\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 7.2691 - val_loss: 22.8915\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 6.6945 - val_loss: 24.8431\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 6.2791 - val_loss: 21.8178\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 6.1114 - val_loss: 25.3775\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 7.5719 - val_loss: 22.2457\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 6.7684 - val_loss: 24.7931\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 5.8491 - val_loss: 22.3093\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 4.8495 - val_loss: 23.3041\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 5.6148 - val_loss: 22.9192\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 5.1512 - val_loss: 24.2127\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 4.4631 - val_loss: 25.2649\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 5.6567 - val_loss: 24.0639\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 4.1856 - val_loss: 23.4898\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 4.0432 - val_loss: 22.4624\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 4.1703 - val_loss: 22.2044\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 4.4362 - val_loss: 22.3151\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 4.8733 - val_loss: 22.3677\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 5.2612 - val_loss: 23.0740\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 4.7069 - val_loss: 22.3854\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 3.9990 - val_loss: 22.0355\n",
      "\n",
      "Mean squared error: 4.0\n",
      "\n",
      "dropout: 2.9e-01\n",
      "filter_num: 300\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 115us/sample - loss: 59.9902 - val_loss: 24.0342\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 45.3861 - val_loss: 23.6408\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 41.8672 - val_loss: 21.4032\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 38.9491 - val_loss: 21.4314\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 37.9973 - val_loss: 22.5990\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 32.6591 - val_loss: 19.2721\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 29.8209 - val_loss: 22.9240\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 29.4040 - val_loss: 20.3868\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 26.8236 - val_loss: 20.1967\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 24.8307 - val_loss: 23.7212\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 22.2741 - val_loss: 20.9450\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 20.8076 - val_loss: 24.8667\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 19.0128 - val_loss: 22.8362\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 16.3188 - val_loss: 24.3743\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 14.6357 - val_loss: 24.3428\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 12.8259 - val_loss: 25.6250\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 11.0758 - val_loss: 27.5750\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 9.7645 - val_loss: 27.7734\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 8.3988 - val_loss: 26.5720\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 7.3996 - val_loss: 27.1602\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.8014 - val_loss: 23.2972\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 6.4752 - val_loss: 24.0322\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.6984 - val_loss: 23.8940\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.8210 - val_loss: 21.5106\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.7239 - val_loss: 24.8188\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.3074 - val_loss: 23.3335\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.1224 - val_loss: 25.4982\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.2623 - val_loss: 26.2005\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.9879 - val_loss: 21.5445\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.3259 - val_loss: 27.0343\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.3086 - val_loss: 25.1021\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 5.8438 - val_loss: 28.6150\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 5.1917 - val_loss: 24.9309\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 5.8289 - val_loss: 27.9756\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 4.8282 - val_loss: 24.3193\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.9455 - val_loss: 29.4676\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.5489 - val_loss: 23.1452\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.7824 - val_loss: 25.9416\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.2805 - val_loss: 25.4996\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.5004 - val_loss: 26.7080\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.4727 - val_loss: 25.0110\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.8990 - val_loss: 24.5460\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.3881 - val_loss: 23.8792\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.0520 - val_loss: 25.1710\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.1636 - val_loss: 25.1915\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.2212 - val_loss: 26.3649\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.7043 - val_loss: 24.9858\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.0995 - val_loss: 25.6653\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.9547 - val_loss: 25.8390\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.2021 - val_loss: 24.9809\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.8652 - val_loss: 24.8486\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 3.1912 - val_loss: 23.6767\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.4915 - val_loss: 23.8471\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.6645 - val_loss: 26.6169\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 3.5963 - val_loss: 23.9495\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 3.2465 - val_loss: 24.9397\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.8484 - val_loss: 24.6101\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.6730 - val_loss: 25.9439\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.3348 - val_loss: 25.4741\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.5825 - val_loss: 25.2665\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.2563 - val_loss: 24.9765\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.9289 - val_loss: 24.8229\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.5585 - val_loss: 24.9761\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.3149 - val_loss: 26.1052\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.2539 - val_loss: 25.0605\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.4537 - val_loss: 26.6330\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.4576 - val_loss: 24.5741\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.1603 - val_loss: 25.9919\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.0248 - val_loss: 24.5628\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.1406 - val_loss: 24.3730\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.8479 - val_loss: 24.5060\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 2.1535 - val_loss: 24.3215\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.1039 - val_loss: 25.0159\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 1.7589 - val_loss: 23.9303\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.7233 - val_loss: 25.0710\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.5184 - val_loss: 25.8020\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.6424 - val_loss: 23.8485\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.9634 - val_loss: 27.7389\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.0853 - val_loss: 24.4860\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.5731 - val_loss: 27.7336\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.3946 - val_loss: 24.3955\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.6030 - val_loss: 27.5067\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.1330 - val_loss: 23.7597\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.4513 - val_loss: 25.4059\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.8573 - val_loss: 23.6419\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.8724 - val_loss: 26.6087\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.3955 - val_loss: 25.6597\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.1752 - val_loss: 26.9073\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.1839 - val_loss: 24.7310\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 3.3598 - val_loss: 25.6495\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 3.3586 - val_loss: 26.8885\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.7336 - val_loss: 24.4035\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.3215 - val_loss: 26.0431\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.9424 - val_loss: 23.3828\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.8081 - val_loss: 25.6024\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.9902 - val_loss: 25.6547\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.3609 - val_loss: 26.6635\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.3586 - val_loss: 24.4647\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.8693 - val_loss: 24.1445\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.8099 - val_loss: 25.6499\n",
      "\n",
      "Mean squared error: 1.8\n",
      "\n",
      "dropout: 2.5e-01\n",
      "filter_num: 238\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 115us/sample - loss: 58.3963 - val_loss: 23.2196\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 44.9360 - val_loss: 23.9034\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 39.8847 - val_loss: 20.3743\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 38.7588 - val_loss: 19.4564\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 35.0136 - val_loss: 22.4827\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 31.7096 - val_loss: 18.5922\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 29.5726 - val_loss: 19.3793\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 27.8628 - val_loss: 22.6971\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 26.2094 - val_loss: 22.0290\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 23.7674 - val_loss: 27.1417\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 23.2180 - val_loss: 29.4554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 21.1722 - val_loss: 26.3128\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 19.3193 - val_loss: 26.1009\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 17.0874 - val_loss: 27.8336\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 15.2407 - val_loss: 27.5165\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 14.0300 - val_loss: 30.5917\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 11.3820 - val_loss: 32.2364\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 10.1476 - val_loss: 31.3321\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 9.4535 - val_loss: 28.8748\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 7.5901 - val_loss: 34.5582\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 7.4287 - val_loss: 32.8561\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 6.5406 - val_loss: 37.0281\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 8.6032 - val_loss: 29.0147\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 6.9058 - val_loss: 31.8792\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 6.4481 - val_loss: 29.0329\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 5.8395 - val_loss: 32.7916\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 5.3418 - val_loss: 27.6012\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.4355 - val_loss: 31.9732\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.6227 - val_loss: 27.5317\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.3479 - val_loss: 33.3133\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.9776 - val_loss: 28.5139\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.9485 - val_loss: 33.9452\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.7759 - val_loss: 26.2209\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.6444 - val_loss: 28.0433\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.3716 - val_loss: 25.8306\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.2344 - val_loss: 30.8414\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.3678 - val_loss: 31.1110\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.7260 - val_loss: 30.2438\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.7434 - val_loss: 30.8893\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - ETA: 0s - loss: 5.827 - 0s 19us/sample - loss: 5.0809 - val_loss: 26.6258\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 4.0394 - val_loss: 31.1392\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.3458 - val_loss: 27.1779\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.1536 - val_loss: 29.3385\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.7128 - val_loss: 29.1296\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.7645 - val_loss: 27.7890\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.7946 - val_loss: 30.0716\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.4933 - val_loss: 28.7021\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.8354 - val_loss: 29.0042\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.4507 - val_loss: 31.9092\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.2563 - val_loss: 24.5999\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.5607 - val_loss: 32.7555\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.2312 - val_loss: 26.9748\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.7768 - val_loss: 33.6123\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.9032 - val_loss: 25.6945\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.7412 - val_loss: 34.2097\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.7574 - val_loss: 27.7507\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 3.3467 - val_loss: 31.4627\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.9088 - val_loss: 27.2266\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.5659 - val_loss: 30.2506\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.0105 - val_loss: 29.0687\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.1986 - val_loss: 28.2281\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.0673 - val_loss: 29.7019\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.9516 - val_loss: 28.2372\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.7798 - val_loss: 29.4676\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.1143 - val_loss: 30.5105\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.4476 - val_loss: 32.6739\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.4242 - val_loss: 33.9202\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.5268 - val_loss: 26.5369\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.9371 - val_loss: 29.0218\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.2538 - val_loss: 27.3604\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.3346 - val_loss: 30.5336\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.0529 - val_loss: 28.8324\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.9129 - val_loss: 32.5786\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.7750 - val_loss: 28.5083\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.2663 - val_loss: 33.7372\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.2355 - val_loss: 29.3254\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.7833 - val_loss: 31.3227\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.9978 - val_loss: 28.7986\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.7088 - val_loss: 32.3719\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.4300 - val_loss: 29.2795\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.8213 - val_loss: 28.5145\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.3074 - val_loss: 28.7599\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.1914 - val_loss: 28.2259\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.0225 - val_loss: 32.1422\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.6280 - val_loss: 29.3468\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.7956 - val_loss: 31.5807\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.3597 - val_loss: 30.4803\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.5256 - val_loss: 29.3692\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.7350 - val_loss: 31.0853\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.4327 - val_loss: 31.0604\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.2928 - val_loss: 32.1641\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.4001 - val_loss: 28.8555\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.3683 - val_loss: 30.3132\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.2746 - val_loss: 29.5718\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.3995 - val_loss: 29.6974\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.4028 - val_loss: 29.4876\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.5669 - val_loss: 29.0291\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.3267 - val_loss: 29.5441\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.3381 - val_loss: 27.6286\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.3616 - val_loss: 28.1281\n",
      "\n",
      "Mean squared error: 1.4\n",
      "\n",
      "dropout: 2.4e-01\n",
      "filter_num: 300\n",
      "num_dense_layers: 5\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 1s 216us/sample - loss: 56.4386 - val_loss: 29.5585\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 57us/sample - loss: 49.1204 - val_loss: 28.3524\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 46.4486 - val_loss: 21.6520\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 41.2125 - val_loss: 21.2542\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 40.4482 - val_loss: 20.8623\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 34.4649 - val_loss: 21.1932\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 57us/sample - loss: 31.5074 - val_loss: 19.7023\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 27.0676 - val_loss: 31.5628\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 59us/sample - loss: 28.8491 - val_loss: 21.8082\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 25.0766 - val_loss: 24.2478\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 20.5490 - val_loss: 23.7075\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 19.5984 - val_loss: 23.1695\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 15.7534 - val_loss: 41.8167\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 17.0299 - val_loss: 23.7416\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 61us/sample - loss: 16.3924 - val_loss: 36.8839\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 13.9335 - val_loss: 24.2016\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 59us/sample - loss: 12.1842 - val_loss: 28.7644\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 57us/sample - loss: 12.1618 - val_loss: 22.5253\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 58us/sample - loss: 12.3326 - val_loss: 26.6546\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 58us/sample - loss: 9.6645 - val_loss: 32.4166\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 9.7226 - val_loss: 26.1141\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 8.2557 - val_loss: 23.3369\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 9.3523 - val_loss: 22.4565\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 10.0562 - val_loss: 25.0343\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 7.3230 - val_loss: 25.3102\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 6.9163 - val_loss: 25.0960\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 6.2186 - val_loss: 28.2475\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 56us/sample - loss: 6.9556 - val_loss: 23.9502\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 5.6948 - val_loss: 37.8283\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 9.9306 - val_loss: 24.6921\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 9.5638 - val_loss: 23.5078\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 6.8914 - val_loss: 24.0776\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 5.8673 - val_loss: 26.5738\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 6.6384 - val_loss: 23.7897\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 6.6952 - val_loss: 30.8241\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 6.2651 - val_loss: 23.1917\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 6.2222 - val_loss: 31.3054\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 5.2853 - val_loss: 23.6586\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 5.6808 - val_loss: 25.4040\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 56us/sample - loss: 5.0417 - val_loss: 24.0913\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 6.3469 - val_loss: 23.7534\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 6.1872 - val_loss: 30.7352\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 8.1990 - val_loss: 24.0516\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 9.2674 - val_loss: 29.5158\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 6.6924 - val_loss: 23.6256\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 6.7002 - val_loss: 28.0521\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 6.2208 - val_loss: 28.7260\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 57us/sample - loss: 6.3774 - val_loss: 25.8809\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 58us/sample - loss: 6.6569 - val_loss: 27.0051\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 58us/sample - loss: 5.2968 - val_loss: 24.7149\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 59us/sample - loss: 5.3550 - val_loss: 27.0978\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 58us/sample - loss: 7.0427 - val_loss: 34.6080\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 59us/sample - loss: 12.4933 - val_loss: 25.5710\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 58us/sample - loss: 8.5552 - val_loss: 34.6866\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 57us/sample - loss: 7.7648 - val_loss: 24.6831\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 59us/sample - loss: 6.5858 - val_loss: 30.5781\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 58us/sample - loss: 5.6044 - val_loss: 24.7518\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 5.4615 - val_loss: 29.7786\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 56us/sample - loss: 4.7380 - val_loss: 24.3347\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 5.3899 - val_loss: 26.7193\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 54us/sample - loss: 5.8583 - val_loss: 24.1429\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 56us/sample - loss: 4.9782 - val_loss: 25.7777\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 3.8784 - val_loss: 26.1658\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 57us/sample - loss: 5.5167 - val_loss: 22.7074\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 5.4940 - val_loss: 27.9597\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 4.2677 - val_loss: 25.8807\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 4.3781 - val_loss: 27.5261\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 5.5102 - val_loss: 27.1897\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 56us/sample - loss: 3.4301 - val_loss: 26.5956\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 4.8952 - val_loss: 22.9253\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 5.3200 - val_loss: 22.5009\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 8.2385 - val_loss: 24.8584\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 5.6371 - val_loss: 24.1812\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 5.9445 - val_loss: 30.9281\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 8.2305 - val_loss: 23.0374\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 7.3363 - val_loss: 42.3005\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 11.6468 - val_loss: 28.4449\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 10.0804 - val_loss: 38.6094\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 9.8609 - val_loss: 25.0593\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 10.9474 - val_loss: 32.4887\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 57us/sample - loss: 7.0953 - val_loss: 26.6523\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 5.5780 - val_loss: 27.7657\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 5.8587 - val_loss: 25.4151\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 5.9384 - val_loss: 28.7397\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 6.5156 - val_loss: 25.1942\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 5.9713 - val_loss: 31.7184\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 5.6587 - val_loss: 25.7183\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 5.7511 - val_loss: 26.6752\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 56us/sample - loss: 4.1562 - val_loss: 27.9195\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 4.8720 - val_loss: 27.5781\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 6.6027 - val_loss: 24.7098\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 6.3916 - val_loss: 28.3387\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 4.8622 - val_loss: 29.1129\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 4.0731 - val_loss: 28.4460\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 4.2638 - val_loss: 26.4186\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 5.4951 - val_loss: 27.7533\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 4.6443 - val_loss: 27.3279\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 3.4387 - val_loss: 30.9242\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 5.0519 - val_loss: 27.5495\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 4.1853 - val_loss: 34.1543\n",
      "\n",
      "Mean squared error: 4.2\n",
      "\n",
      "dropout: 2.0e-01\n",
      "filter_num: 97\n",
      "num_dense_layers: 11\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 1s 307us/sample - loss: 64.0774 - val_loss: 37.5281\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 60.3233 - val_loss: 26.8915\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 46.8638 - val_loss: 24.8751\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 44.6696 - val_loss: 23.2345\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 39.5094 - val_loss: 20.3821\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 37.7385 - val_loss: 21.9515\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 36.9803 - val_loss: 19.3128\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 32.6892 - val_loss: 21.3164\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 30.0932 - val_loss: 19.6497\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 30.1816 - val_loss: 21.6026\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 29.1828 - val_loss: 21.2063\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 26.4160 - val_loss: 21.3967\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 24.3514 - val_loss: 24.2701\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 35.7935 - val_loss: 27.8298\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 31.2909 - val_loss: 21.8409\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 26.7674 - val_loss: 22.6686\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 21.8641 - val_loss: 22.3046\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 20.8195 - val_loss: 22.5849\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 18.9425 - val_loss: 23.2266\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 17.4123 - val_loss: 24.5519\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 16.5817 - val_loss: 24.4333\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 17.6331 - val_loss: 25.1332\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 18.2079 - val_loss: 22.2722\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 16.1361 - val_loss: 22.4442\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 13.8326 - val_loss: 21.5746\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 13.0662 - val_loss: 21.7966\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 19.0014 - val_loss: 24.9033\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 17.9788 - val_loss: 22.1040\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 19.4492 - val_loss: 23.7616\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 16.2813 - val_loss: 21.7732\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 14.4282 - val_loss: 22.3025\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 12.4683 - val_loss: 24.2348\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 14.1255 - val_loss: 24.1368\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 12.7625 - val_loss: 22.8641\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 35us/sample - loss: 12.4522 - val_loss: 22.4909\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 10.9277 - val_loss: 21.2167\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 11.4559 - val_loss: 21.5359\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 12.0176 - val_loss: 20.8821\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 11.4468 - val_loss: 20.0848\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 10.8894 - val_loss: 20.4236\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 13.4086 - val_loss: 22.4638\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 11.8154 - val_loss: 19.7824\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 10.5603 - val_loss: 21.6100\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 11.0440 - val_loss: 21.0794\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 9.4687 - val_loss: 20.9029\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 10.0063 - val_loss: 21.4825\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 9.2511 - val_loss: 20.1129\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 9.2193 - val_loss: 21.3032\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 9.7298 - val_loss: 20.9907\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 9.0960 - val_loss: 20.9980\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 8.5890 - val_loss: 22.2645\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 9.6792 - val_loss: 21.0214\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 10.3218 - val_loss: 22.7764\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 12.9809 - val_loss: 21.4695\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 10.4880 - val_loss: 20.8373\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 10.0480 - val_loss: 20.6525\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 8.1551 - val_loss: 21.7283\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 8.5037 - val_loss: 23.4902\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 10.6560 - val_loss: 21.8936\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 13.2107 - val_loss: 22.3264\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 13.2972 - val_loss: 20.2953\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 8.2845 - val_loss: 20.7571\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 8.2423 - val_loss: 21.2616\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 7.6972 - val_loss: 21.3977\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 7.8895 - val_loss: 21.8777\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 8.0991 - val_loss: 20.5021\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 7.4766 - val_loss: 22.5343\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 7.3406 - val_loss: 21.3191\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 7.3178 - val_loss: 21.8159\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 10.2398 - val_loss: 19.7426\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 9.6749 - val_loss: 22.3247\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 9.4810 - val_loss: 20.7778\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 10.4590 - val_loss: 22.3387\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 9.0335 - val_loss: 19.4880\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 8.3054 - val_loss: 22.2639\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 7.9608 - val_loss: 21.0133\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 6.7558 - val_loss: 20.9769\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 6.7885 - val_loss: 21.8704\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 7.0113 - val_loss: 21.1126\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 12.0135 - val_loss: 23.9815\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 11.3862 - val_loss: 20.9962\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 7.7877 - val_loss: 21.7364\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 8.8090 - val_loss: 19.9724\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 7.4011 - val_loss: 21.0474\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 7.1746 - val_loss: 19.4391\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 7.7406 - val_loss: 21.3057\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 6.5765 - val_loss: 20.3716\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 6.8987 - val_loss: 21.3906\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 6.7933 - val_loss: 20.6468\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 8.3699 - val_loss: 20.6561\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 6.8715 - val_loss: 21.4393\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 5.6971 - val_loss: 19.9986\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 7.0943 - val_loss: 21.7160\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 7.7868 - val_loss: 21.1035\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 5.6489 - val_loss: 21.0962\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 5.5858 - val_loss: 21.3104\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 6.1362 - val_loss: 20.8410\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 7.1332 - val_loss: 23.3501\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 7.8062 - val_loss: 20.9971\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 8.9979 - val_loss: 23.3705\n",
      "\n",
      "Mean squared error: 9.0\n",
      "\n",
      "dropout: 2.0e-01\n",
      "filter_num: 239\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 167us/sample - loss: 57.5729 - val_loss: 22.8962\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 43.6706 - val_loss: 22.4755\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 39.5684 - val_loss: 20.4953\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 36.1501 - val_loss: 20.6730\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 32.7339 - val_loss: 19.1720\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 29.8546 - val_loss: 19.7912\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 26.9177 - val_loss: 20.7465\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 24.8699 - val_loss: 21.4069\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 19us/sample - loss: 22.6993 - val_loss: 22.5270\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 20.1949 - val_loss: 26.2830\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 18.0436 - val_loss: 28.5374\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 17.2454 - val_loss: 24.5908\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 13.9364 - val_loss: 30.7868\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 12.2561 - val_loss: 25.1936\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 10.2841 - val_loss: 24.9244\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 12.6580 - val_loss: 25.8540\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 12.9898 - val_loss: 29.2325\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 11.7042 - val_loss: 28.8650\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 9.5025 - val_loss: 31.6789\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 8.5851 - val_loss: 26.1459\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 7.1965 - val_loss: 24.0647\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 8.2329 - val_loss: 28.6716\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 7.6163 - val_loss: 26.5166\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 7.9635 - val_loss: 34.0864\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 6.3626 - val_loss: 26.5865\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 6.1415 - val_loss: 28.2596\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 5.2768 - val_loss: 25.9554\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.9503 - val_loss: 27.7147\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.6734 - val_loss: 28.1385\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 4.0611 - val_loss: 27.5052\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.8931 - val_loss: 26.7722\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.5542 - val_loss: 26.5770\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.5003 - val_loss: 26.7268\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.4427 - val_loss: 29.8332\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 4.2958 - val_loss: 23.9267\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 5.0202 - val_loss: 27.2111\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.5740 - val_loss: 24.2843\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.8901 - val_loss: 29.5014\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.8042 - val_loss: 25.1174\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.2269 - val_loss: 28.1942\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.5910 - val_loss: 22.8481\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.4447 - val_loss: 25.4119\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.2410 - val_loss: 24.2029\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.2882 - val_loss: 25.7998\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.5412 - val_loss: 25.5425\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.9541 - val_loss: 27.2792\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.8220 - val_loss: 26.8902\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.7416 - val_loss: 26.9354\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.4245 - val_loss: 27.1126\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.5278 - val_loss: 27.1566\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.4120 - val_loss: 25.3941\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.4941 - val_loss: 26.3294\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.1598 - val_loss: 25.1717\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.0128 - val_loss: 26.7223\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.2373 - val_loss: 24.9814\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.4120 - val_loss: 27.0141\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.2326 - val_loss: 23.9923\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.3216 - val_loss: 24.0390\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 4.4270 - val_loss: 24.0049\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.3400 - val_loss: 24.5532\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.2989 - val_loss: 23.3588\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.4840 - val_loss: 22.7696\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.1018 - val_loss: 23.5225\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.7198 - val_loss: 23.6849\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.7018 - val_loss: 23.8217\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.9651 - val_loss: 23.4959\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.0031 - val_loss: 23.8066\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.8080 - val_loss: 24.6491\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.9996 - val_loss: 23.7512\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.4809 - val_loss: 24.0285\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.5648 - val_loss: 23.4456\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.4680 - val_loss: 24.8979\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.7068 - val_loss: 23.9602\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.3439 - val_loss: 24.5731\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.0584 - val_loss: 22.7947\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.7993 - val_loss: 24.7196\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.1176 - val_loss: 23.3675\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.0221 - val_loss: 24.7524\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.4977 - val_loss: 23.5126\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.4407 - val_loss: 23.5191\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.3121 - val_loss: 23.3081\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.2423 - val_loss: 22.9812\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.1311 - val_loss: 23.7970\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.1065 - val_loss: 23.3101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.0773 - val_loss: 25.4485\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.1278 - val_loss: 23.9630\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.5924 - val_loss: 24.2276\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.6364 - val_loss: 23.1017\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.6333 - val_loss: 23.3479\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.2829 - val_loss: 22.3101\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.4125 - val_loss: 23.3733\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.2601 - val_loss: 23.2401\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.3485 - val_loss: 23.7902\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.1821 - val_loss: 23.5546\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.1582 - val_loss: 24.7304\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.1924 - val_loss: 23.4643\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.1687 - val_loss: 24.6147\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.0323 - val_loss: 24.3811\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.0185 - val_loss: 24.1138\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 0.9794 - val_loss: 24.2583\n",
      "\n",
      "Mean squared error: 0.98\n",
      "\n",
      "dropout: 2.0e-01\n",
      "filter_num: 259\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 110us/sample - loss: 58.0074 - val_loss: 23.3758\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 44.9085 - val_loss: 22.1289\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 40.8051 - val_loss: 20.2228\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 37.6201 - val_loss: 20.0659\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 34.9649 - val_loss: 18.9151\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 30.9542 - val_loss: 19.8106\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 28.8834 - val_loss: 18.6020\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 27.2069 - val_loss: 21.8213\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 24.0133 - val_loss: 20.3318\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 22.0095 - val_loss: 23.4626\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 20.3822 - val_loss: 23.0986\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 16.9870 - val_loss: 27.3807\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 14.8255 - val_loss: 28.2020\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 12.8333 - val_loss: 29.8926\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 10.9529 - val_loss: 27.8920\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 9.4828 - val_loss: 33.0169\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 8.4897 - val_loss: 29.6314\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 6.9677 - val_loss: 30.4408\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 6.3118 - val_loss: 31.9338\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 5.7052 - val_loss: 29.8106\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 5.3965 - val_loss: 31.1838\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 5.5666 - val_loss: 27.5999\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 4.9831 - val_loss: 26.5721\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 4.2709 - val_loss: 27.2576\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 3.9500 - val_loss: 26.8719\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 4.0530 - val_loss: 27.2414\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 4.9480 - val_loss: 25.5941\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 4.4776 - val_loss: 26.3234\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 3.9207 - val_loss: 25.2760\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 4.0214 - val_loss: 30.9555\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 6.3472 - val_loss: 23.2868\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 6.8188 - val_loss: 27.7894\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 6.3211 - val_loss: 21.9908\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 5.4495 - val_loss: 29.9246\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 4.4529 - val_loss: 23.4999\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 4.0928 - val_loss: 28.9735\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.8219 - val_loss: 23.5013\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 2.8585 - val_loss: 25.5698\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.8382 - val_loss: 23.1280\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.2356 - val_loss: 23.8877\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 2.4958 - val_loss: 23.2683\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 2.3553 - val_loss: 25.1174\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 2.2603 - val_loss: 26.0403\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 5.8116 - val_loss: 22.9545\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 7.5836 - val_loss: 23.4038\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 5.2148 - val_loss: 25.4449\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 3.7479 - val_loss: 26.8166\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 3.2672 - val_loss: 27.2564\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.6452 - val_loss: 24.4877\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.7910 - val_loss: 27.4726\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 2.3023 - val_loss: 25.5309\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.1322 - val_loss: 26.3639\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.8815 - val_loss: 25.3786\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.3414 - val_loss: 24.9416\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 1.9049 - val_loss: 25.5861\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.8526 - val_loss: 24.0413\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.5694 - val_loss: 26.2787\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.9553 - val_loss: 25.7583\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.8265 - val_loss: 25.9970\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.7709 - val_loss: 25.5423\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.6812 - val_loss: 24.0463\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.0594 - val_loss: 25.8087\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.0595 - val_loss: 24.2324\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.1572 - val_loss: 25.2743\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.0374 - val_loss: 26.2642\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.7160 - val_loss: 25.6235\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.6512 - val_loss: 24.1509\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.4580 - val_loss: 22.6278\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.6123 - val_loss: 23.6903\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.8199 - val_loss: 23.2518\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.6262 - val_loss: 24.7775\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.3731 - val_loss: 23.6585\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.7752 - val_loss: 24.8826\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.5962 - val_loss: 24.2024\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.2830 - val_loss: 25.4583\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.5573 - val_loss: 25.5414\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.4246 - val_loss: 26.4503\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.6091 - val_loss: 23.8191\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.2812 - val_loss: 23.8907\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 1.4085 - val_loss: 24.2645\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.6874 - val_loss: 24.8928\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.4483 - val_loss: 23.9445\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.3933 - val_loss: 24.8249\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.2616 - val_loss: 23.6629\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.3863 - val_loss: 24.4138\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.3195 - val_loss: 23.6474\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.4952 - val_loss: 24.3377\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.5387 - val_loss: 23.3199\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.5082 - val_loss: 24.0075\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.2431 - val_loss: 23.3973\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.2831 - val_loss: 24.7887\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.1776 - val_loss: 24.9804\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 0.9384 - val_loss: 24.0006\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.1793 - val_loss: 24.2278\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 0.9587 - val_loss: 23.0801\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.1058 - val_loss: 24.2966\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.2831 - val_loss: 23.3082\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 0.9516 - val_loss: 24.8655\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.0212 - val_loss: 24.2444\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.1399 - val_loss: 25.9885\n",
      "\n",
      "Mean squared error: 1.1\n",
      "\n",
      "dropout: 3.3e-01\n",
      "filter_num: 233\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 97us/sample - loss: 60.8535 - val_loss: 26.3188\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 45.1181 - val_loss: 26.3246\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 42.5356 - val_loss: 20.6753\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 37.7259 - val_loss: 19.8374\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 35.2425 - val_loss: 21.8325\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 33.6308 - val_loss: 19.2148\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 30.5568 - val_loss: 19.0735\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 29.7032 - val_loss: 22.6661\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 27.7942 - val_loss: 18.3601\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 27.0348 - val_loss: 19.7772\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 25.7351 - val_loss: 27.8173\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 24.3373 - val_loss: 20.3387\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 22.0678 - val_loss: 21.5654\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 20.4560 - val_loss: 24.7171\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 18.9672 - val_loss: 23.0625\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 17.6677 - val_loss: 24.2177\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 15.8711 - val_loss: 25.1869\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 15.6733 - val_loss: 28.5530\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 13.8854 - val_loss: 25.3090\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 11.9964 - val_loss: 29.1459\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 10.8838 - val_loss: 28.4161\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 9.9497 - val_loss: 29.9423\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 8.8791 - val_loss: 31.9053\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 7.9899 - val_loss: 29.2025\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 8.3465 - val_loss: 29.7281\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 8.3129 - val_loss: 28.4215\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 7.6477 - val_loss: 30.7285\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 7.0030 - val_loss: 28.3286\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 7.2181 - val_loss: 30.2953\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 6.1150 - val_loss: 28.7157\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 5.5496 - val_loss: 33.3169\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 6.1696 - val_loss: 30.8248\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.9903 - val_loss: 34.2212\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 4.6386 - val_loss: 29.5632\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 4.7955 - val_loss: 32.5930\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.4376 - val_loss: 31.7090\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.2842 - val_loss: 31.4747\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.0934 - val_loss: 32.2480\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.3250 - val_loss: 30.3969\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.9058 - val_loss: 33.7302\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.9590 - val_loss: 34.6280\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.0417 - val_loss: 35.1077\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.9154 - val_loss: 33.3768\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.2327 - val_loss: 35.3148\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.5369 - val_loss: 33.6428\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.3453 - val_loss: 37.9451\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.3059 - val_loss: 35.8931\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.9252 - val_loss: 33.0642\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.4898 - val_loss: 31.2767\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.3783 - val_loss: 31.6048\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.3340 - val_loss: 30.2869\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.9983 - val_loss: 32.0023\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.3707 - val_loss: 34.2296\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.7119 - val_loss: 34.3415\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.7761 - val_loss: 34.7644\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.1125 - val_loss: 30.5355\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.0751 - val_loss: 32.9858\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.0152 - val_loss: 33.2463\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.8032 - val_loss: 31.8596\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.6902 - val_loss: 32.6543\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.8361 - val_loss: 31.6544\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.9342 - val_loss: 31.4592\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.5461 - val_loss: 30.1923\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.7582 - val_loss: 31.0685\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.7444 - val_loss: 31.0332\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.7614 - val_loss: 31.3930\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.4690 - val_loss: 34.2575\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 5.3102 - val_loss: 33.7248\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.8763 - val_loss: 36.8279\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.3712 - val_loss: 37.3087\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 4.6882 - val_loss: 37.7999\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.8268 - val_loss: 42.9534\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.0308 - val_loss: 37.4852\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 5.4390 - val_loss: 40.7111\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 6.3421 - val_loss: 36.0666\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 5.3601 - val_loss: 37.6863\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 4.2144 - val_loss: 38.1599\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.3495 - val_loss: 35.5401\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.2490 - val_loss: 41.8296\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.1852 - val_loss: 37.9688\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.0897 - val_loss: 41.4243\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.6293 - val_loss: 39.7163\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.1457 - val_loss: 38.9202\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.0223 - val_loss: 37.1273\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.2086 - val_loss: 36.2206\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.3671 - val_loss: 35.2817\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.7190 - val_loss: 40.0862\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.1794 - val_loss: 41.1430\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 3.7433 - val_loss: 41.8231\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.8835 - val_loss: 40.6167\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.5900 - val_loss: 35.9183\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.4282 - val_loss: 41.4778\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.4547 - val_loss: 35.3432\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.7458 - val_loss: 40.3005\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.7488 - val_loss: 39.4999\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.0519 - val_loss: 39.3830\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.8123 - val_loss: 37.2034\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.6206 - val_loss: 37.7600\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.1218 - val_loss: 38.5601\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.8072 - val_loss: 39.4785\n",
      "\n",
      "Mean squared error: 1.8\n",
      "\n",
      "dropout: 2.0e-01\n",
      "filter_num: 10\n",
      "num_dense_layers: 9\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 1s 244us/sample - loss: 64.1898 - val_loss: 38.0580\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 64.1133 - val_loss: 37.9860\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 63.9940 - val_loss: 37.8828\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 63.7965 - val_loss: 37.7023\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 63.4199 - val_loss: 37.3271\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 62.3807 - val_loss: 36.4832\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 60.5648 - val_loss: 34.7159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 56.3918 - val_loss: 30.7670\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 50.6367 - val_loss: 24.8550\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 46.5108 - val_loss: 23.3282\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 46.9270 - val_loss: 25.8634\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 45.8855 - val_loss: 26.4172\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 46.1984 - val_loss: 25.2605\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 44.5885 - val_loss: 23.6995\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 42.6647 - val_loss: 23.9673\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 40.8266 - val_loss: 23.1222\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 40.9179 - val_loss: 22.4772\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 41.5876 - val_loss: 22.4981\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 38.1338 - val_loss: 24.1008\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 40.0951 - val_loss: 24.8459\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 38.6555 - val_loss: 24.8196\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 39.4486 - val_loss: 25.0013\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 35.5317 - val_loss: 24.0173\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 38.0103 - val_loss: 22.9635\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 39.8150 - val_loss: 23.3044\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 38.0713 - val_loss: 24.6789\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 38.8603 - val_loss: 25.0987\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 36.4413 - val_loss: 24.3322\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 30.9255 - val_loss: 22.0118\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 36.3452 - val_loss: 20.6716\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 40.5152 - val_loss: 23.7549\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 37.3199 - val_loss: 25.8158\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 38.0549 - val_loss: 25.2008\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 37.1259 - val_loss: 23.5823\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 34.3243 - val_loss: 22.6856\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 38.6423 - val_loss: 23.1993\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 37.2836 - val_loss: 24.2031\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 33.2688 - val_loss: 24.1527\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 33.7728 - val_loss: 24.2512\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 36.8193 - val_loss: 22.9619\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 33.2142 - val_loss: 24.0220\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 32.5254 - val_loss: 24.0126\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 32.9282 - val_loss: 24.2730\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 32.5527 - val_loss: 24.3675\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 34.3716 - val_loss: 24.1067\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 30.6447 - val_loss: 23.1985\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 34.6464 - val_loss: 22.5709\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 34.0398 - val_loss: 23.4957\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 33.2318 - val_loss: 24.4990\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 30.7620 - val_loss: 24.3482\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 31.3419 - val_loss: 24.3163\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 30.9573 - val_loss: 25.0128\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 28.8170 - val_loss: 24.2819\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 31.7570 - val_loss: 23.5688\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 30.5761 - val_loss: 23.0845\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 28.4338 - val_loss: 23.3269\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 34.7568 - val_loss: 23.8970\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 28.9605 - val_loss: 24.3198\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 28.3692 - val_loss: 24.4008\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 28.2448 - val_loss: 24.2833\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 29.7201 - val_loss: 24.0802\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 28.9969 - val_loss: 24.4682\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 29.6817 - val_loss: 25.0445\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 25.3598 - val_loss: 24.8953\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 27.2347 - val_loss: 24.7036\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 28.0399 - val_loss: 24.7399\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 26.8586 - val_loss: 25.0233\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 24.7747 - val_loss: 25.1959\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 24.8360 - val_loss: 25.5496\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 24.8459 - val_loss: 26.2007\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 23.0403 - val_loss: 26.8223\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 23.6865 - val_loss: 27.5032\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 26.6883 - val_loss: 28.2104\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 25.2545 - val_loss: 29.0328\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 24.2777 - val_loss: 29.9323\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 22.0229 - val_loss: 31.5866\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 24.7082 - val_loss: 31.9717\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 21.3987 - val_loss: 31.8764\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 21.7573 - val_loss: 33.2365\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 22.2242 - val_loss: 33.7074\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 22.8925 - val_loss: 33.3101\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 20.8181 - val_loss: 34.4042\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 14us/sample - loss: 21.4095 - val_loss: 36.4438\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 24.8909 - val_loss: 36.2862\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 18.8605 - val_loss: 38.1721\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 21.8704 - val_loss: 37.1577\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 23.9720 - val_loss: 36.6056\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 18.2041 - val_loss: 38.8141\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 17.9583 - val_loss: 43.3688\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 19.7545 - val_loss: 43.8819\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 19.5944 - val_loss: 44.2799\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 17.2815 - val_loss: 46.6430\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 19.7102 - val_loss: 49.0081\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 20.5105 - val_loss: 48.5676\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 15.6808 - val_loss: 49.7177\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 17.7451 - val_loss: 49.3353\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 17.8539 - val_loss: 48.1894\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 17.4636 - val_loss: 48.3960\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 19.4294 - val_loss: 47.8771\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 19.2211 - val_loss: 43.0783\n",
      "\n",
      "Mean squared error: 1.9e+01\n",
      "\n",
      "dropout: 2.0e-01\n",
      "filter_num: 185\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 107us/sample - loss: 59.8760 - val_loss: 25.9409\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 46.0900 - val_loss: 27.1322\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 42.3787 - val_loss: 21.0551\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 37.8362 - val_loss: 20.4866\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 34.6489 - val_loss: 21.7850\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 32.4644 - val_loss: 19.9149\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 30.9135 - val_loss: 19.3906\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 27.9188 - val_loss: 23.1030\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 26.6204 - val_loss: 21.4794\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 24.9191 - val_loss: 20.5875\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 24.2644 - val_loss: 20.9266\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 22.6104 - val_loss: 29.4806\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 20.9707 - val_loss: 25.0595\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 19.1522 - val_loss: 27.5706\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 18.0446 - val_loss: 26.7768\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 15.3817 - val_loss: 28.6359\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 14.0606 - val_loss: 30.5626\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 12.8245 - val_loss: 32.5371\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 11.0390 - val_loss: 36.2429\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 9.6462 - val_loss: 33.8516\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 9.0593 - val_loss: 41.2405\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 10.8683 - val_loss: 30.7954\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 9.5676 - val_loss: 37.9623\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 8.8607 - val_loss: 37.9298\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 7.6427 - val_loss: 40.9905\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 7.6195 - val_loss: 39.4088\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 6.6811 - val_loss: 40.6055\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 6.6761 - val_loss: 41.4294\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 5.2811 - val_loss: 35.5464\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.6734 - val_loss: 39.2964\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 4.5132 - val_loss: 33.1489\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.0711 - val_loss: 39.4380\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.0229 - val_loss: 39.3085\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.3079 - val_loss: 40.3637\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 3.5415 - val_loss: 38.7538\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 3.7783 - val_loss: 40.2934\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 3.8806 - val_loss: 42.0323\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.5819 - val_loss: 40.0648\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 3.2727 - val_loss: 39.3848\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.0243 - val_loss: 38.5262\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 3.1000 - val_loss: 36.3261\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 3.2224 - val_loss: 38.7348\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.9896 - val_loss: 38.3627\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.9314 - val_loss: 48.4565\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.8866 - val_loss: 39.9634\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 7.3175 - val_loss: 42.3355\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.4284 - val_loss: 37.1084\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 3.1676 - val_loss: 39.3226\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.9493 - val_loss: 35.2645\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.8951 - val_loss: 37.9231\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.3576 - val_loss: 40.4546\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.5363 - val_loss: 40.5565\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.4340 - val_loss: 42.2655\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.1149 - val_loss: 40.5119\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.0868 - val_loss: 41.7527\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 1.9671 - val_loss: 39.6520\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.9281 - val_loss: 40.2411\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.0993 - val_loss: 39.1578\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.8564 - val_loss: 42.1143\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.9077 - val_loss: 42.6366\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 1.7946 - val_loss: 44.7520\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 1.9868 - val_loss: 42.7092\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.8381 - val_loss: 40.5259\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.6890 - val_loss: 43.8375\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.0150 - val_loss: 46.7698\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.4174 - val_loss: 50.6947\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.5184 - val_loss: 51.4543\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.1528 - val_loss: 46.8985\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.4535 - val_loss: 49.8009\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.9519 - val_loss: 44.8046\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.4092 - val_loss: 51.1451\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.2760 - val_loss: 45.5903\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.8095 - val_loss: 49.5644\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.5844 - val_loss: 48.8148\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.8738 - val_loss: 49.2880\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.7962 - val_loss: 43.7345\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.3272 - val_loss: 47.8579\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.0755 - val_loss: 42.1482\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.0819 - val_loss: 46.5366\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.6779 - val_loss: 43.3373\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.7157 - val_loss: 48.1154\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.0297 - val_loss: 41.5082\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.5845 - val_loss: 44.6404\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.3640 - val_loss: 44.6821\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.2692 - val_loss: 45.3891\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 1.9297 - val_loss: 43.9273\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 1.6922 - val_loss: 43.0588\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 1.5491 - val_loss: 43.1785\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.7031 - val_loss: 42.7658\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.3908 - val_loss: 41.0194\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 1.5032 - val_loss: 45.3234\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 1.5211 - val_loss: 42.6837\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.3577 - val_loss: 45.6974\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.7222 - val_loss: 41.4653\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.4474 - val_loss: 42.1012\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.2617 - val_loss: 40.3665\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.2120 - val_loss: 42.2412\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.3046 - val_loss: 43.5045\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.0564 - val_loss: 42.5600\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.2725 - val_loss: 46.2654\n",
      "\n",
      "Mean squared error: 1.3\n",
      "\n",
      "dropout: 2.9e-01\n",
      "filter_num: 167\n",
      "num_dense_layers: 6\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 1s 213us/sample - loss: 63.6713 - val_loss: 35.2084\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 52.8119 - val_loss: 23.1353\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 43.9795 - val_loss: 26.0319\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 43.7658 - val_loss: 20.9676\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 37.8329 - val_loss: 20.6695\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 37.3825 - val_loss: 19.4020\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 31.7882 - val_loss: 18.2720\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 29.6710 - val_loss: 19.1578\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 27.9269 - val_loss: 20.0041\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 26.0452 - val_loss: 21.8771\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 23.7897 - val_loss: 26.0358\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 24.2873 - val_loss: 23.9061\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 22.7217 - val_loss: 25.5495\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 20.4376 - val_loss: 23.9221\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 19.6595 - val_loss: 32.0584\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 19.5112 - val_loss: 24.9050\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 15.2585 - val_loss: 34.5914\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 19.2255 - val_loss: 24.8235\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 19.2561 - val_loss: 26.1505\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 16.3788 - val_loss: 23.4709\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 14.3362 - val_loss: 27.0957\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 14.8650 - val_loss: 25.9733\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 16.8548 - val_loss: 23.8941\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 13.3274 - val_loss: 29.3671\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 11.3892 - val_loss: 22.7058\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 11.2494 - val_loss: 24.6112\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 10.1782 - val_loss: 27.8664\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 11.4894 - val_loss: 24.7956\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 9.3403 - val_loss: 26.8461\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 8.3603 - val_loss: 25.8368\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 34us/sample - loss: 11.9127 - val_loss: 26.6537\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 11.3837 - val_loss: 24.1120\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 10.1139 - val_loss: 27.6414\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 9.0360 - val_loss: 26.7564\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 7.9808 - val_loss: 29.6585\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 9.9318 - val_loss: 29.4222\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 9.8065 - val_loss: 29.1301\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 8.9619 - val_loss: 26.3907\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 13.2779 - val_loss: 23.2496\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 10.4589 - val_loss: 25.3516\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 9.3167 - val_loss: 22.9698\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 9.2589 - val_loss: 27.0572\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 9.8474 - val_loss: 23.2433\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 14.1933 - val_loss: 22.3083\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 9.6296 - val_loss: 22.9995\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 9.2260 - val_loss: 23.8670\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 9.8657 - val_loss: 22.7912\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 12.8645 - val_loss: 21.1548\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 10.8243 - val_loss: 22.4896\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 10.0803 - val_loss: 23.3863\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 10.9592 - val_loss: 25.8954\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 8.6476 - val_loss: 25.5167\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 9.0048 - val_loss: 27.3831\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 9.1794 - val_loss: 26.3215\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 7.9013 - val_loss: 27.3510\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 8.5277 - val_loss: 24.5241\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 6.5608 - val_loss: 22.6738\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 7.2500 - val_loss: 28.4597\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 9.8187 - val_loss: 23.6693\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 11.0818 - val_loss: 24.2047\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 9.7132 - val_loss: 22.6095\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 6.1539 - val_loss: 21.3977\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 6.9049 - val_loss: 24.1583\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 6.0299 - val_loss: 23.8960\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 6.1860 - val_loss: 24.1081\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 6.6101 - val_loss: 22.4903\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 8.8446 - val_loss: 21.4026\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 7.5140 - val_loss: 22.6974\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 6.3574 - val_loss: 22.8313\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 6.1146 - val_loss: 24.1277\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 7.5250 - val_loss: 22.9990\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 5.9083 - val_loss: 23.4309\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 6.2674 - val_loss: 25.2142\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 5.5422 - val_loss: 30.2537\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 11.4749 - val_loss: 27.0376\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 8.8755 - val_loss: 24.4183\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 10.6119 - val_loss: 21.8688\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 13.2212 - val_loss: 21.4398\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 13.4635 - val_loss: 31.1247\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 11.8508 - val_loss: 23.2061\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 10.7656 - val_loss: 26.3019\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 7.5330 - val_loss: 24.5188\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 6.6313 - val_loss: 24.3714\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 6.4508 - val_loss: 26.3015\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 5.8754 - val_loss: 27.3500\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 5.9994 - val_loss: 25.6343\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 6.7674 - val_loss: 31.4327\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 6.2898 - val_loss: 23.6944\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 9.1727 - val_loss: 25.2234\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 7.1338 - val_loss: 26.4603\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 6.4282 - val_loss: 24.0514\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 5.7671 - val_loss: 26.2758\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 5.6728 - val_loss: 24.5481\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 6.4345 - val_loss: 24.4678\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 5.4975 - val_loss: 25.5926\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 5.9762 - val_loss: 24.2557\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 6.3907 - val_loss: 24.4857\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 6.1734 - val_loss: 22.2877\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 7.9530 - val_loss: 26.5563\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 8.3927 - val_loss: 23.6460\n",
      "\n",
      "Mean squared error: 8.4\n",
      "\n",
      "dropout: 3.3e-01\n",
      "filter_num: 65\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 96us/sample - loss: 63.7072 - val_loss: 36.6261\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 61.0627 - val_loss: 33.0263\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 54.8232 - val_loss: 26.1378\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 44.7155 - val_loss: 21.8422\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 13us/sample - loss: 41.6369 - val_loss: 23.6754\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 37.6073 - val_loss: 19.9851\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 35.8793 - val_loss: 18.9678\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 33.7388 - val_loss: 18.4883\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 31.4053 - val_loss: 19.0541\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 29.9180 - val_loss: 18.6724\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 30.9483 - val_loss: 18.4639\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 29.0102 - val_loss: 19.9856\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 28.9330 - val_loss: 19.6134\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 26.5709 - val_loss: 18.6865\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 26.7162 - val_loss: 19.1468\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 26.5496 - val_loss: 21.0892\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 25.1432 - val_loss: 21.1019\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 24.1310 - val_loss: 20.4218\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 24.0027 - val_loss: 21.9995\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 23.0366 - val_loss: 23.7650\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 22.0707 - val_loss: 24.1123\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 21.0275 - val_loss: 24.3325\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 19.6350 - val_loss: 28.3229\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 18.7737 - val_loss: 26.0437\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 18.3298 - val_loss: 28.2566\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 16.6562 - val_loss: 33.1099\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 16.5023 - val_loss: 39.6901\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 15.8326 - val_loss: 40.9956\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 12.9935 - val_loss: 52.7980\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 13.3126 - val_loss: 51.4453\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 12.9243 - val_loss: 50.8320\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 12.2538 - val_loss: 59.1974\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 11.8826 - val_loss: 58.8016\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 10.2532 - val_loss: 71.5336\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 9.8704 - val_loss: 75.0618\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 9.1716 - val_loss: 63.6988\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 9.2538 - val_loss: 67.5527\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 8.8912 - val_loss: 68.0991\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 8.9480 - val_loss: 68.8988\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 8.0993 - val_loss: 78.0530\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 7.3800 - val_loss: 85.8792\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 6.8676 - val_loss: 88.8052\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 7.0167 - val_loss: 94.3336\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 6.6005 - val_loss: 91.8105\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 5.7473 - val_loss: 92.8128\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 5.6015 - val_loss: 92.8728\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 5.8761 - val_loss: 91.5945\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 5.5003 - val_loss: 104.9971\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 5.7219 - val_loss: 99.9238\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 5.3708 - val_loss: 101.5701\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 5.2776 - val_loss: 100.6368\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 5.2581 - val_loss: 97.0117\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 6.5980 - val_loss: 87.7511\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 6.1781 - val_loss: 91.6607\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 6.2301 - val_loss: 79.0792\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 6.5428 - val_loss: 79.7221\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 5.8616 - val_loss: 80.6073\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 5.6904 - val_loss: 84.0881\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 5.6870 - val_loss: 88.5637\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 4.7101 - val_loss: 90.7706\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 5.5351 - val_loss: 98.1345\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 5.4951 - val_loss: 90.9056\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 5.4335 - val_loss: 86.5864\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 4.1314 - val_loss: 89.4746\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 4.8387 - val_loss: 81.9957\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 5.5153 - val_loss: 87.6107\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 4.8159 - val_loss: 89.0905\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 4.9259 - val_loss: 89.8146\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 4.1158 - val_loss: 105.8973\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 4.8411 - val_loss: 114.4026\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 4.6037 - val_loss: 107.7102\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 4.1890 - val_loss: 106.1809\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 5.2387 - val_loss: 90.6699\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 5.5579 - val_loss: 93.8562\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 4.7191 - val_loss: 92.0885\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 4.3553 - val_loss: 102.0375\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 4.9763 - val_loss: 118.9637\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 4.3965 - val_loss: 114.3834\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 4.5167 - val_loss: 122.5835\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 12us/sample - loss: 3.7993 - val_loss: 126.0343\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 3.9827 - val_loss: 118.1921\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 4.0029 - val_loss: 128.6692\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 4.6350 - val_loss: 110.9656\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 4.6907 - val_loss: 92.7501\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 5.3622 - val_loss: 106.9655\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 5.4509 - val_loss: 108.7127\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 4.2481 - val_loss: 107.8367\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 5.1681 - val_loss: 128.8452\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 4.1624 - val_loss: 120.3426\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 4.3797 - val_loss: 113.2853\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 4.0968 - val_loss: 121.2066\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 3.8615 - val_loss: 122.5497\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 3.9000 - val_loss: 112.9901\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 3.9098 - val_loss: 116.8761\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 3.6837 - val_loss: 115.4143\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 4.1858 - val_loss: 110.6780\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 3.5781 - val_loss: 116.1995\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 3.1394 - val_loss: 118.4521\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 3.1409 - val_loss: 115.5623\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 2.7651 - val_loss: 122.3887\n",
      "\n",
      "Mean squared error: 2.8\n",
      "\n",
      "dropout: 2.0e-01\n",
      "filter_num: 300\n",
      "num_dense_layers: 20\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 2s 639us/sample - loss: 62.4150 - val_loss: 22.8832\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 172us/sample - loss: 58.4560 - val_loss: 35.8188\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 171us/sample - loss: 60.2576 - val_loss: 33.4733\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 168us/sample - loss: 52.5031 - val_loss: 29.0119\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 169us/sample - loss: 54.1141 - val_loss: 32.6119\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 171us/sample - loss: 55.0416 - val_loss: 25.9476\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 172us/sample - loss: 42.9135 - val_loss: 26.0086\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 169us/sample - loss: 50.0469 - val_loss: 28.1916\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 172us/sample - loss: 46.2924 - val_loss: 19.9001\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 168us/sample - loss: 32.9931 - val_loss: 21.2016\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 173us/sample - loss: 31.7920 - val_loss: 20.2314\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 172us/sample - loss: 27.9259 - val_loss: 25.9666\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 169us/sample - loss: 37.3968 - val_loss: 21.5449\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 169us/sample - loss: 27.3781 - val_loss: 20.4154\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 168us/sample - loss: 22.3241 - val_loss: 22.8946\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 169us/sample - loss: 26.0248 - val_loss: 60.3396\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 169us/sample - loss: 47.9738 - val_loss: 29.2775\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 169us/sample - loss: 51.2795 - val_loss: 27.7719\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 166us/sample - loss: 41.7846 - val_loss: 37.3712\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 170us/sample - loss: 45.4698 - val_loss: 25.3927\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 168us/sample - loss: 42.2470 - val_loss: 21.6112\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 171us/sample - loss: 36.3068 - val_loss: 22.3386\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 168us/sample - loss: 40.3287 - val_loss: 22.0926\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 170us/sample - loss: 26.7538 - val_loss: 19.6273\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 169us/sample - loss: 18.7824 - val_loss: 23.4697\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 168us/sample - loss: 27.1821 - val_loss: 35.8720\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 167us/sample - loss: 21.8493 - val_loss: 21.6786\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 167us/sample - loss: 26.1711 - val_loss: 23.2602\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 170us/sample - loss: 36.5574 - val_loss: 21.7733\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 170us/sample - loss: 31.9556 - val_loss: 23.1988\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 170us/sample - loss: 43.7177 - val_loss: 29.0045\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 166us/sample - loss: 51.3191 - val_loss: 27.0700\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 170us/sample - loss: 43.3875 - val_loss: 22.5351\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 178us/sample - loss: 30.6141 - val_loss: 23.5162\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 183us/sample - loss: 45.3707 - val_loss: 27.6305\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 178us/sample - loss: 50.6375 - val_loss: 26.6710\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 167us/sample - loss: 46.6891 - val_loss: 21.1054\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 169us/sample - loss: 31.2213 - val_loss: 21.9893\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 167us/sample - loss: 41.4830 - val_loss: 24.2293\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 169us/sample - loss: 36.0307 - val_loss: 26.9702\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 167us/sample - loss: 28.3416 - val_loss: 23.5165\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 170us/sample - loss: 37.2415 - val_loss: 20.8307\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 167us/sample - loss: 31.8572 - val_loss: 22.3209\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 167us/sample - loss: 33.2737 - val_loss: 20.2253\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 166us/sample - loss: 23.9889 - val_loss: 21.4233\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 169us/sample - loss: 31.7778 - val_loss: 20.8797\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 166us/sample - loss: 26.8764 - val_loss: 20.7071\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 171us/sample - loss: 19.5472 - val_loss: 21.0014\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 166us/sample - loss: 16.9808 - val_loss: 21.0898\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 170us/sample - loss: 16.8795 - val_loss: 21.6855\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 168us/sample - loss: 18.5591 - val_loss: 21.3206\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 168us/sample - loss: 14.6063 - val_loss: 20.6901\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 167us/sample - loss: 16.2197 - val_loss: 21.3569\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 167us/sample - loss: 21.5066 - val_loss: 20.8601\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 167us/sample - loss: 20.6341 - val_loss: 21.5394\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 166us/sample - loss: 21.8522 - val_loss: 21.8303\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 168us/sample - loss: 27.0794 - val_loss: 19.0383\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 167us/sample - loss: 20.6163 - val_loss: 21.8361\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 166us/sample - loss: 18.2583 - val_loss: 22.8096\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 167us/sample - loss: 19.2205 - val_loss: 20.4860\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 168us/sample - loss: 14.8432 - val_loss: 20.1834\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 165us/sample - loss: 16.7378 - val_loss: 20.7052\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 169us/sample - loss: 14.4360 - val_loss: 21.5703\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 169us/sample - loss: 23.7361 - val_loss: 22.0789\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 165us/sample - loss: 28.5690 - val_loss: 18.4878\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 168us/sample - loss: 22.6354 - val_loss: 24.6333\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 167us/sample - loss: 23.7287 - val_loss: 20.1226\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 168us/sample - loss: 16.6097 - val_loss: 22.7520\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 162us/sample - loss: 14.5218 - val_loss: 19.3733\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 165us/sample - loss: 15.4370 - val_loss: 28.0255\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 173us/sample - loss: 14.4494 - val_loss: 20.4196\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 178us/sample - loss: 17.9847 - val_loss: 20.1118\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 175us/sample - loss: 11.1954 - val_loss: 23.6786\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 171us/sample - loss: 10.7825 - val_loss: 18.4207\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 171us/sample - loss: 13.5832 - val_loss: 31.8785\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 169us/sample - loss: 28.0437 - val_loss: 19.4213\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 167us/sample - loss: 34.3846 - val_loss: 18.4980\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 165us/sample - loss: 33.8604 - val_loss: 18.4418\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 171us/sample - loss: 26.8643 - val_loss: 20.5710\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 166us/sample - loss: 20.6354 - val_loss: 25.9766\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 162us/sample - loss: 16.0680 - val_loss: 27.3462\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 166us/sample - loss: 15.4452 - val_loss: 21.2383\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 167us/sample - loss: 12.3968 - val_loss: 29.2219\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 165us/sample - loss: 12.8821 - val_loss: 18.9399\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 166us/sample - loss: 12.0766 - val_loss: 24.2382\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 167us/sample - loss: 12.5459 - val_loss: 20.2327\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 168us/sample - loss: 10.9350 - val_loss: 23.7232\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 167us/sample - loss: 8.8845 - val_loss: 20.9014\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 167us/sample - loss: 9.4302 - val_loss: 20.5470\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 167us/sample - loss: 8.5028 - val_loss: 28.6567\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 169us/sample - loss: 10.0400 - val_loss: 21.8961\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 169us/sample - loss: 9.0133 - val_loss: 23.6635\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 166us/sample - loss: 7.3812 - val_loss: 23.5858\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 169us/sample - loss: 7.9149 - val_loss: 21.7151\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 166us/sample - loss: 7.3115 - val_loss: 24.4100\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 167us/sample - loss: 8.4684 - val_loss: 21.9297\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 166us/sample - loss: 7.9232 - val_loss: 25.9989\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 166us/sample - loss: 7.7432 - val_loss: 23.3214\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 166us/sample - loss: 8.6607 - val_loss: 20.2796\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 167us/sample - loss: 8.7811 - val_loss: 22.5927\n",
      "\n",
      "Mean squared error: 8.8\n",
      "\n",
      "dropout: 2.0e-01\n",
      "filter_num: 118\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 192us/sample - loss: 63.2149 - val_loss: 34.4344\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 56.4585 - val_loss: 25.2709\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 44.0732 - val_loss: 23.1035\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 39.9583 - val_loss: 20.5549\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 36.5152 - val_loss: 19.5028\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 34.3450 - val_loss: 18.9080\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 31.8619 - val_loss: 19.9210\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 30.8774 - val_loss: 20.4595\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 28.8446 - val_loss: 18.3773\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 27.9866 - val_loss: 19.2430\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 25.9090 - val_loss: 21.4571\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 25.4334 - val_loss: 21.6838\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 24.2928 - val_loss: 21.5368\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 23.2925 - val_loss: 25.5552\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 23.2409 - val_loss: 25.9285\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 19.9929 - val_loss: 24.0781\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 18.9321 - val_loss: 34.4096\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 20.9219 - val_loss: 28.7655\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 16.6448 - val_loss: 27.3281\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 15.1898 - val_loss: 39.0942\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 13.4902 - val_loss: 31.8843\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 12.6863 - val_loss: 38.9682\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 10.7428 - val_loss: 48.1290\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 9.3252 - val_loss: 46.8087\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 8.6781 - val_loss: 52.4356\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 7.4702 - val_loss: 52.5051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 7.5423 - val_loss: 52.2345\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 6.2181 - val_loss: 60.1927\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 6.0194 - val_loss: 53.3538\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 5.7849 - val_loss: 57.8369\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 5.1524 - val_loss: 55.9810\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 5.2200 - val_loss: 58.8550\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.5748 - val_loss: 56.0677\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.4358 - val_loss: 60.9239\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.1476 - val_loss: 62.8934\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.3437 - val_loss: 66.4533\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.9422 - val_loss: 60.9232\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.9593 - val_loss: 60.4643\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.7377 - val_loss: 52.3195\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.5697 - val_loss: 56.9484\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.0427 - val_loss: 49.7018\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 5.3456 - val_loss: 54.8634\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.8702 - val_loss: 45.8672\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 4.8937 - val_loss: 47.7595\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 4.3996 - val_loss: 45.9085\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 4.0233 - val_loss: 53.8958\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.5603 - val_loss: 49.5083\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 4.8342 - val_loss: 53.2421\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 4.2726 - val_loss: 56.2517\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 5.3793 - val_loss: 46.6319\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.1806 - val_loss: 48.1342\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.6996 - val_loss: 44.3761\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 3.2859 - val_loss: 47.0968\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.0125 - val_loss: 50.8603\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 2.8379 - val_loss: 50.1728\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 3.5493 - val_loss: 49.2986\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 3.0139 - val_loss: 49.7093\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 3.0378 - val_loss: 50.7688\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 2.8676 - val_loss: 50.3038\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.5562 - val_loss: 48.2029\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.6354 - val_loss: 49.5104\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.1444 - val_loss: 49.1891\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 2.8933 - val_loss: 51.2925\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 2.4738 - val_loss: 51.6923\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 2.1809 - val_loss: 49.8436\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.0582 - val_loss: 51.6748\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 2.2381 - val_loss: 42.5430\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.3009 - val_loss: 44.9400\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.4388 - val_loss: 48.7695\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.1105 - val_loss: 52.4094\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.9847 - val_loss: 54.2939\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.8871 - val_loss: 50.0862\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.4488 - val_loss: 45.7104\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.1971 - val_loss: 45.2540\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.8171 - val_loss: 47.5247\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.8610 - val_loss: 47.2321\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.7589 - val_loss: 51.9010\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.8047 - val_loss: 50.1073\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.5733 - val_loss: 49.5132\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 1.6456 - val_loss: 45.3244\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.6382 - val_loss: 53.3496\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.9663 - val_loss: 48.9290\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.7077 - val_loss: 55.7685\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.0349 - val_loss: 52.8199\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.7857 - val_loss: 54.7163\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.1297 - val_loss: 49.6072\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.5595 - val_loss: 51.4111\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.6981 - val_loss: 53.6545\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.0518 - val_loss: 49.5608\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.8382 - val_loss: 51.8912\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.8391 - val_loss: 50.1475\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.5729 - val_loss: 47.5354\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.5995 - val_loss: 46.7540\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.6360 - val_loss: 46.7428\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.5778 - val_loss: 52.3232\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.5687 - val_loss: 52.6353\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.6667 - val_loss: 59.6339\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.3169 - val_loss: 50.7466\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.8184 - val_loss: 53.5713\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.6100 - val_loss: 51.2918\n",
      "\n",
      "Mean squared error: 1.6\n",
      "\n",
      "dropout: 4.1e-01\n",
      "filter_num: 300\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 117us/sample - loss: 54.1777 - val_loss: 23.2167\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 43.5586 - val_loss: 21.5655\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 39.9856 - val_loss: 20.4132\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 36.8805 - val_loss: 19.7284\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 34.1684 - val_loss: 21.1929\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 29.9119 - val_loss: 19.1880\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 27.9736 - val_loss: 20.8992\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 25.3407 - val_loss: 21.4840\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 23.3377 - val_loss: 22.5820\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 21.4739 - val_loss: 25.1154\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 18.8499 - val_loss: 24.4749\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 16.9466 - val_loss: 27.9300\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - ETA: 0s - loss: 15.35 - 0s 25us/sample - loss: 14.2387 - val_loss: 31.0348\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 13.4139 - val_loss: 27.2308\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 12.3279 - val_loss: 29.4902\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 12.3939 - val_loss: 25.0646\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 11.2812 - val_loss: 26.3772\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 9.6676 - val_loss: 24.9380\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 9.6556 - val_loss: 25.3697\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 8.6784 - val_loss: 27.5501\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 9.3229 - val_loss: 27.2440\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 8.7765 - val_loss: 28.4919\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 8.3658 - val_loss: 24.7907\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 6.2573 - val_loss: 26.3834\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.3973 - val_loss: 25.4610\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.8637 - val_loss: 26.0796\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 6.0126 - val_loss: 27.0569\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.4437 - val_loss: 26.7961\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.5110 - val_loss: 24.6351\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.2222 - val_loss: 26.4763\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.4505 - val_loss: 26.9626\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 5.7667 - val_loss: 25.7502\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 6.5530 - val_loss: 26.4652\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.5410 - val_loss: 26.0767\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.7973 - val_loss: 26.0195\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.5319 - val_loss: 28.0488\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 4.5418 - val_loss: 26.0896\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.5316 - val_loss: 28.8698\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 5.0240 - val_loss: 27.2783\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.4865 - val_loss: 27.7955\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 7.3995 - val_loss: 27.8268\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.4351 - val_loss: 28.9537\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.8870 - val_loss: 27.6535\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.5169 - val_loss: 27.3816\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.1051 - val_loss: 26.1352\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.0050 - val_loss: 25.3333\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.8044 - val_loss: 24.5008\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.9575 - val_loss: 24.0415\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.1407 - val_loss: 25.7046\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.8956 - val_loss: 25.6307\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.6889 - val_loss: 26.5173\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.2641 - val_loss: 26.0580\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.1411 - val_loss: 26.1781\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.3491 - val_loss: 26.4408\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.4786 - val_loss: 26.3409\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.1360 - val_loss: 25.2008\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.9025 - val_loss: 25.5635\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.7358 - val_loss: 26.5137\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 2.8162 - val_loss: 26.4987\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.2934 - val_loss: 26.1468\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.6921 - val_loss: 27.1788\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.7508 - val_loss: 27.6127\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.6461 - val_loss: 26.9709\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.6926 - val_loss: 26.9126\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.9141 - val_loss: 27.8704\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.6431 - val_loss: 27.3639\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.8654 - val_loss: 28.3495\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 3.2121 - val_loss: 24.9717\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.1252 - val_loss: 26.4878\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.4775 - val_loss: 26.4979\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.6419 - val_loss: 27.0958\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.8857 - val_loss: 28.2825\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.4434 - val_loss: 28.4298\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.3447 - val_loss: 25.8356\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.3080 - val_loss: 25.3298\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.7019 - val_loss: 27.0960\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.6729 - val_loss: 27.5240\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.7592 - val_loss: 28.6124\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.5515 - val_loss: 25.5216\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.6535 - val_loss: 26.2136\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 3.2801 - val_loss: 26.5354\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.6634 - val_loss: 27.4638\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.5204 - val_loss: 29.4991\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.1589 - val_loss: 26.6480\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.1334 - val_loss: 29.2059\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.2711 - val_loss: 27.7240\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.8798 - val_loss: 28.6419\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.0430 - val_loss: 27.7112\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.1895 - val_loss: 27.5399\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.9442 - val_loss: 28.2381\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.4405 - val_loss: 28.5306\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.7694 - val_loss: 27.1972\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.9122 - val_loss: 28.8348\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.7637 - val_loss: 30.6194\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.2010 - val_loss: 29.0422\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 3.9222 - val_loss: 27.0248\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.6373 - val_loss: 29.5194\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.5038 - val_loss: 27.5873\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.3559 - val_loss: 32.3287\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.4884 - val_loss: 29.5121\n",
      "\n",
      "Mean squared error: 3.5\n",
      "\n",
      "dropout: 4.3e-01\n",
      "filter_num: 199\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 110us/sample - loss: 60.8376 - val_loss: 28.0829\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 46.9411 - val_loss: 25.0315\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 44.5078 - val_loss: 20.6351\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 39.3755 - val_loss: 19.8804\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 36.6178 - val_loss: 20.8206\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 34.7947 - val_loss: 19.5865\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 31.5835 - val_loss: 18.3956\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 30.0796 - val_loss: 20.1573\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 27.9320 - val_loss: 20.7071\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 25.8504 - val_loss: 21.2045\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 24.8695 - val_loss: 21.0526\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 23.1347 - val_loss: 23.9126\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 22.5706 - val_loss: 24.4008\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 20.1672 - val_loss: 25.6423\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 19.4466 - val_loss: 27.4016\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 17.7038 - val_loss: 27.5361\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 15.3297 - val_loss: 31.6583\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 13.4848 - val_loss: 31.8715\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 12.9379 - val_loss: 34.3245\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 10.9252 - val_loss: 37.5006\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 11.1505 - val_loss: 36.4967\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 9.7891 - val_loss: 36.0132\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 8.6427 - val_loss: 37.5441\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 8.0536 - val_loss: 34.1730\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 7.8828 - val_loss: 35.1018\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 7.0527 - val_loss: 32.1547\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 6.4425 - val_loss: 30.9136\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 6.1436 - val_loss: 30.2244\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 6.4942 - val_loss: 33.4270\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 6.0294 - val_loss: 32.7150\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 6.2269 - val_loss: 33.9886\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 5.4706 - val_loss: 32.5140\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 5.0703 - val_loss: 32.6446\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 5.5540 - val_loss: 34.4175\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 5.0256 - val_loss: 34.6521\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.7645 - val_loss: 34.6772\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 5.7805 - val_loss: 31.1099\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.9592 - val_loss: 36.3791\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.8582 - val_loss: 33.3972\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 4.6861 - val_loss: 35.2092\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.2791 - val_loss: 32.5956\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.1774 - val_loss: 34.0302\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.7461 - val_loss: 31.7015\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.5452 - val_loss: 31.8683\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.5510 - val_loss: 29.0655\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.2172 - val_loss: 32.1405\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.8432 - val_loss: 31.2487\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.3360 - val_loss: 33.8240\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.3725 - val_loss: 31.2310\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 18us/sample - loss: 4.1017 - val_loss: 33.7334\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 3.7098 - val_loss: 30.1577\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.3790 - val_loss: 36.0504\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 5.5112 - val_loss: 29.6244\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 5.4421 - val_loss: 32.4380\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.3136 - val_loss: 32.1507\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 3.8461 - val_loss: 31.9707\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 4.3600 - val_loss: 36.8801\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.6056 - val_loss: 36.6430\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 4.8191 - val_loss: 35.2929\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.0281 - val_loss: 32.0155\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 3.7162 - val_loss: 32.8669\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.5773 - val_loss: 32.0391\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 3.3889 - val_loss: 31.1607\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 3.3363 - val_loss: 28.9531\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.9545 - val_loss: 30.9953\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 6.2814 - val_loss: 32.6047\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 5.1086 - val_loss: 31.1835\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 5.0724 - val_loss: 39.8871\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 6.1950 - val_loss: 33.0241\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 4.6296 - val_loss: 35.3961\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 4.0452 - val_loss: 38.0872\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.9800 - val_loss: 36.0502\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.5023 - val_loss: 38.0318\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.0099 - val_loss: 35.9297\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 3.4027 - val_loss: 32.8146\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.3320 - val_loss: 35.8654\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.2898 - val_loss: 34.1029\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.7657 - val_loss: 33.5543\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.0731 - val_loss: 34.8041\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.5952 - val_loss: 35.5489\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.0066 - val_loss: 40.7039\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.9966 - val_loss: 39.7529\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.8102 - val_loss: 37.2116\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.8825 - val_loss: 37.1338\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.6048 - val_loss: 37.5076\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.2993 - val_loss: 39.5186\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.9545 - val_loss: 36.6185\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.6927 - val_loss: 38.3608\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.1029 - val_loss: 36.5948\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.6054 - val_loss: 35.8806\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.0346 - val_loss: 35.4935\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.9642 - val_loss: 37.0969\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.4829 - val_loss: 37.1422\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.9159 - val_loss: 36.7136\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.3609 - val_loss: 37.2229\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.7967 - val_loss: 37.7792\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.3520 - val_loss: 35.5116\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.6132 - val_loss: 35.0704\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.6948 - val_loss: 32.8869\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.2899 - val_loss: 34.8217\n",
      "\n",
      "Mean squared error: 2.3\n",
      "\n",
      "dropout: 4.1e-01\n",
      "filter_num: 105\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 99us/sample - loss: 62.6806 - val_loss: 34.2247\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 55.4987 - val_loss: 25.3565\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 44.4455 - val_loss: 22.2365\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 41.2737 - val_loss: 20.0307\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 38.0016 - val_loss: 19.1915\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 35.6571 - val_loss: 18.9184\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 33.7169 - val_loss: 19.0252\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 32.8187 - val_loss: 18.4116\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 30.6457 - val_loss: 19.3618\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 29.9204 - val_loss: 19.0118\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 29.1871 - val_loss: 18.8299\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 27.7016 - val_loss: 22.1243\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 26.3019 - val_loss: 19.9699\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 25.3658 - val_loss: 19.6000\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 24.3352 - val_loss: 21.2436\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 24.1600 - val_loss: 25.4586\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 23.9376 - val_loss: 22.9647\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 21.1102 - val_loss: 21.9195\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 20.6287 - val_loss: 25.9003\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 20.1260 - val_loss: 25.9285\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 17.7571 - val_loss: 27.4990\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 16.9247 - val_loss: 27.4437\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 15.7482 - val_loss: 28.2378\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 14us/sample - loss: 14.7898 - val_loss: 27.9418\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 12.8973 - val_loss: 32.1059\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 12.9388 - val_loss: 31.3597\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 11.4333 - val_loss: 35.4163\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 10.4384 - val_loss: 35.0222\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 9.3777 - val_loss: 37.9573\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 7.9599 - val_loss: 36.4006\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 7.7088 - val_loss: 36.3364\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 7.3999 - val_loss: 36.5661\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 7.5698 - val_loss: 39.0490\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 6.6408 - val_loss: 39.8500\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 7.1301 - val_loss: 42.0559\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 7.2840 - val_loss: 44.5597\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 6.9995 - val_loss: 46.0812\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 7.0197 - val_loss: 47.9175\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 6.2609 - val_loss: 42.1780\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 6.5179 - val_loss: 43.4688\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 6.0461 - val_loss: 42.6447\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 5.9202 - val_loss: 37.8188\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 6.2707 - val_loss: 37.4996\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 6.6834 - val_loss: 35.6442\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 6.2148 - val_loss: 39.6198\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 6.3699 - val_loss: 41.6803\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 5.1112 - val_loss: 44.2653\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 6.5489 - val_loss: 48.7514\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 7.3893 - val_loss: 54.0062\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 7.6379 - val_loss: 44.6593\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 6.7215 - val_loss: 49.2020\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 6.0952 - val_loss: 40.9262\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 5.8625 - val_loss: 40.7368\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 5.2753 - val_loss: 43.4974\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 5.0275 - val_loss: 45.5146\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 5.1055 - val_loss: 47.0794\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 6.6686 - val_loss: 46.5621\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 7.5516 - val_loss: 51.1070\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 6.6682 - val_loss: 47.0891\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 6.1046 - val_loss: 53.2145\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 6.5708 - val_loss: 50.1273\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 6.6660 - val_loss: 51.2354\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 5.0571 - val_loss: 53.6415\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.8086 - val_loss: 51.3773\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.1151 - val_loss: 52.5550\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.1254 - val_loss: 54.0330\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.9075 - val_loss: 53.0865\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.9578 - val_loss: 51.3539\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.8413 - val_loss: 52.0211\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.3862 - val_loss: 47.8282\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.1647 - val_loss: 51.7946\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.0509 - val_loss: 54.2274\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.9708 - val_loss: 55.1755\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 5.0875 - val_loss: 52.8521\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 6.4416 - val_loss: 50.9324\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.8835 - val_loss: 56.7966\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.6488 - val_loss: 52.9463\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.9081 - val_loss: 53.0445\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 3.7818 - val_loss: 58.2096\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 3.7497 - val_loss: 53.1602\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.5628 - val_loss: 57.8160\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.1963 - val_loss: 54.7449\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 3.6496 - val_loss: 55.4510\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.9938 - val_loss: 61.9641\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 3.2762 - val_loss: 54.2324\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 3.3731 - val_loss: 57.2974\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 3.5922 - val_loss: 56.4144\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 3.0053 - val_loss: 56.9729\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 3.6718 - val_loss: 55.0475\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 3.5419 - val_loss: 56.3911\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 3.0532 - val_loss: 56.3643\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.0852 - val_loss: 53.5404\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.7483 - val_loss: 50.3398\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.9415 - val_loss: 53.9981\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.0896 - val_loss: 51.1464\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 3.7878 - val_loss: 56.4661\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 3.4936 - val_loss: 57.5339\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.9270 - val_loss: 59.5327\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.8495 - val_loss: 64.2034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.5840 - val_loss: 61.6807\n",
      "\n",
      "Mean squared error: 2.6\n",
      "\n",
      "dropout: 2.0e-01\n",
      "filter_num: 221\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 111us/sample - loss: 58.9422 - val_loss: 24.1994\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 44.7586 - val_loss: 23.0042\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 39.4299 - val_loss: 20.6109\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 37.4524 - val_loss: 20.4444\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 35.0701 - val_loss: 21.2877\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 31.5954 - val_loss: 19.0908\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 28.7264 - val_loss: 22.3126\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 26.2059 - val_loss: 21.5642\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 23.7930 - val_loss: 22.8992\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 22.0337 - val_loss: 23.1474\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 20.8244 - val_loss: 27.0205\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 20.5507 - val_loss: 23.8472\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 18.1057 - val_loss: 23.8684\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 14.4847 - val_loss: 28.9749\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 13.0718 - val_loss: 23.8856\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 11.3761 - val_loss: 29.5760\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 10.7775 - val_loss: 25.1920\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 8.7342 - val_loss: 30.7254\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 8.9253 - val_loss: 25.5919\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 7.8746 - val_loss: 29.8759\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 6.7002 - val_loss: 26.2508\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 6.2935 - val_loss: 30.2337\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 5.4902 - val_loss: 25.6731\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 5.4604 - val_loss: 29.2791\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 5.6269 - val_loss: 24.5923\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.9862 - val_loss: 30.3501\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 5.2288 - val_loss: 26.6048\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.8021 - val_loss: 27.2725\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.8528 - val_loss: 26.4384\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.9173 - val_loss: 25.3101\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.3627 - val_loss: 25.6060\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.3782 - val_loss: 27.1350\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.0321 - val_loss: 27.2686\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.0558 - val_loss: 27.8678\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.4025 - val_loss: 26.3423\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.0491 - val_loss: 25.5656\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.1569 - val_loss: 24.9316\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.1955 - val_loss: 25.9876\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.1714 - val_loss: 27.3626\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.6553 - val_loss: 24.5112\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.9066 - val_loss: 27.6754\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.1961 - val_loss: 24.8594\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.7484 - val_loss: 28.0821\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.9910 - val_loss: 24.7790\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.6157 - val_loss: 28.7719\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.6551 - val_loss: 26.3471\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.3707 - val_loss: 27.8696\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.0493 - val_loss: 24.6302\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.2613 - val_loss: 25.5764\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.8297 - val_loss: 24.6795\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.9279 - val_loss: 26.3755\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.1605 - val_loss: 26.3412\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.8566 - val_loss: 27.0856\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.0920 - val_loss: 26.7902\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.6603 - val_loss: 26.1696\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.9790 - val_loss: 25.1371\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.1090 - val_loss: 26.0478\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.9506 - val_loss: 25.1093\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.8258 - val_loss: 26.1639\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.9832 - val_loss: 25.0749\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.7308 - val_loss: 25.8336\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.9257 - val_loss: 26.1626\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.5714 - val_loss: 26.0812\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.6459 - val_loss: 27.4500\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.6685 - val_loss: 24.5234\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.6656 - val_loss: 25.7424\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.3865 - val_loss: 26.1937\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.3587 - val_loss: 25.1617\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.5845 - val_loss: 23.4289\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.9879 - val_loss: 26.7434\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.9121 - val_loss: 24.1097\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.9328 - val_loss: 27.4632\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.7156 - val_loss: 26.0792\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.6223 - val_loss: 27.8350\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.4874 - val_loss: 26.4176\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.4308 - val_loss: 26.7298\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.7853 - val_loss: 27.4112\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 5.6873 - val_loss: 23.9715\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 5.0363 - val_loss: 27.5296\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.6062 - val_loss: 25.2906\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.8100 - val_loss: 28.5125\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.0600 - val_loss: 25.0560\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.1731 - val_loss: 28.1988\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.5120 - val_loss: 25.6332\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.5273 - val_loss: 27.0674\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.3059 - val_loss: 25.3506\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.5845 - val_loss: 26.8225\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.7133 - val_loss: 24.4519\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.4666 - val_loss: 27.4223\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.7035 - val_loss: 24.6112\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.7817 - val_loss: 27.4463\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.5991 - val_loss: 25.4816\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.6411 - val_loss: 25.7912\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.4363 - val_loss: 24.9854\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.2990 - val_loss: 26.3237\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.4899 - val_loss: 26.6697\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.1147 - val_loss: 26.4004\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.0267 - val_loss: 26.2185\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.2293 - val_loss: 25.4663\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.1185 - val_loss: 27.0001\n",
      "\n",
      "Mean squared error: 1.1\n",
      "\n",
      "dropout: 2.3e-01\n",
      "filter_num: 272\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 108us/sample - loss: 58.4559 - val_loss: 23.1744\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 44.7094 - val_loss: 23.8112\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 40.9577 - val_loss: 20.4832\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 38.2877 - val_loss: 19.7359\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 34.3069 - val_loss: 20.2329\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 31.9378 - val_loss: 18.5385\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 29.7250 - val_loss: 19.1165\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 26.8269 - val_loss: 20.7953\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 25.7196 - val_loss: 22.6196\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 23.1058 - val_loss: 21.9747\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 21.5504 - val_loss: 27.2326\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 19.3994 - val_loss: 25.1907\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 17.4861 - val_loss: 25.3938\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 15.4458 - val_loss: 26.6109\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 12.6855 - val_loss: 27.7264\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 11.3441 - val_loss: 26.9838\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 10.5668 - val_loss: 29.5490\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 10.1254 - val_loss: 28.7186\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 8.8349 - val_loss: 32.4038\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 8.9394 - val_loss: 24.3564\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 7.6294 - val_loss: 28.5395\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 7.5380 - val_loss: 23.6479\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.0229 - val_loss: 29.0980\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 5.9480 - val_loss: 25.3007\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 6.1847 - val_loss: 31.1937\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 5.3815 - val_loss: 24.3839\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 5.0985 - val_loss: 27.6271\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 5.1849 - val_loss: 23.1246\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 4.5986 - val_loss: 27.7250\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 4.5653 - val_loss: 25.0734\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 4.2080 - val_loss: 28.3635\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 4.3011 - val_loss: 26.5255\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 3.5769 - val_loss: 26.3675\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.8613 - val_loss: 25.2306\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 3.4501 - val_loss: 27.7032\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.1251 - val_loss: 26.2365\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 3.1014 - val_loss: 27.3600\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.9778 - val_loss: 24.2967\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.8102 - val_loss: 23.9214\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.1444 - val_loss: 26.6309\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.7240 - val_loss: 25.7385\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 3.1875 - val_loss: 28.7316\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 3.1787 - val_loss: 23.9984\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.8481 - val_loss: 27.3144\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.5460 - val_loss: 25.0325\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.4193 - val_loss: 28.7171\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.6988 - val_loss: 25.6288\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.8937 - val_loss: 24.8564\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.8700 - val_loss: 28.5647\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.9587 - val_loss: 26.5116\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.8765 - val_loss: 30.1636\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.6504 - val_loss: 25.9621\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.6037 - val_loss: 29.3660\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.6086 - val_loss: 25.2701\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 3.5017 - val_loss: 30.8775\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.9922 - val_loss: 25.7508\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.1966 - val_loss: 30.5603\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.5237 - val_loss: 24.8840\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.5693 - val_loss: 28.6017\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.1856 - val_loss: 25.7040\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.2839 - val_loss: 29.4377\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.3113 - val_loss: 25.4026\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.3996 - val_loss: 28.8068\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.1049 - val_loss: 27.0084\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.8451 - val_loss: 29.0826\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.7386 - val_loss: 25.9748\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.9109 - val_loss: 27.6101\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.8028 - val_loss: 26.2909\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.6015 - val_loss: 26.4589\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.6820 - val_loss: 24.9054\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.7092 - val_loss: 26.6836\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.7155 - val_loss: 26.2992\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.8862 - val_loss: 27.0767\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.6674 - val_loss: 26.6195\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.5518 - val_loss: 28.4387\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.0571 - val_loss: 27.4226\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.2843 - val_loss: 27.0782\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 3.8419 - val_loss: 24.0673\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.0262 - val_loss: 27.9462\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.8526 - val_loss: 26.9103\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.4117 - val_loss: 28.1415\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.5164 - val_loss: 28.6968\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.6746 - val_loss: 28.0445\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.3263 - val_loss: 28.0916\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.9846 - val_loss: 27.2154\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.7384 - val_loss: 30.1672\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 1.6310 - val_loss: 26.5266\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.3964 - val_loss: 28.3332\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.3577 - val_loss: 26.6165\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.2556 - val_loss: 26.0340\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.3028 - val_loss: 25.9935\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.2549 - val_loss: 27.0126\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.4108 - val_loss: 28.0832\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.4286 - val_loss: 26.2251\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.2882 - val_loss: 26.4192\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.3492 - val_loss: 27.2110\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.3993 - val_loss: 28.1929\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.1246 - val_loss: 26.7989\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.3628 - val_loss: 29.1412\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.7433 - val_loss: 24.7376\n",
      "\n",
      "Mean squared error: 1.7\n",
      "\n",
      "dropout: 3.3e-01\n",
      "filter_num: 272\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 113us/sample - loss: 57.8206 - val_loss: 22.8545\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 44.8735 - val_loss: 21.4632\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 40.7038 - val_loss: 20.1975\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 38.0876 - val_loss: 19.4917\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 34.3602 - val_loss: 18.4476\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 31.9546 - val_loss: 19.3261\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 28.3263 - val_loss: 18.4912\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 25.6039 - val_loss: 22.8257\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 25.2041 - val_loss: 21.8151\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 23.1707 - val_loss: 23.2745\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 20.9372 - val_loss: 24.6491\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 17.9705 - val_loss: 25.0186\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 16.1203 - val_loss: 27.3478\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 15.5677 - val_loss: 23.9431\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 14.8602 - val_loss: 26.3776\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 12.1841 - val_loss: 23.6713\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 12.4003 - val_loss: 32.2012\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 12.0758 - val_loss: 24.9680\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 10.4443 - val_loss: 26.1529\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 9.8836 - val_loss: 26.6123\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 7.4246 - val_loss: 25.9000\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 21us/sample - loss: 7.1404 - val_loss: 28.2829\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.7421 - val_loss: 26.9495\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 6.1527 - val_loss: 27.3582\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 5.5684 - val_loss: 26.3831\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 5.1529 - val_loss: 25.7725\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 5.0973 - val_loss: 25.7385\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 5.0162 - val_loss: 25.0377\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 4.6663 - val_loss: 25.5902\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 4.9130 - val_loss: 23.6640\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 5.3846 - val_loss: 28.3220\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 5.4811 - val_loss: 25.3001\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 4.3533 - val_loss: 29.4800\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 4.6107 - val_loss: 23.3043\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 4.5885 - val_loss: 26.9598\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 4.9646 - val_loss: 22.9700\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 3.9122 - val_loss: 29.2425\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 5.2498 - val_loss: 22.9341\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 4.6514 - val_loss: 27.5829\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 4.8244 - val_loss: 25.7571\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.7458 - val_loss: 27.4914\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.3989 - val_loss: 25.4000\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 3.4448 - val_loss: 27.0730\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.2093 - val_loss: 25.7264\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.9474 - val_loss: 26.9272\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.9259 - val_loss: 24.9453\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 3.2384 - val_loss: 27.4274\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.1115 - val_loss: 25.2444\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 3.8671 - val_loss: 26.5857\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 4.0391 - val_loss: 24.8427\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.4501 - val_loss: 28.4764\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 3.1227 - val_loss: 26.3190\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.9044 - val_loss: 28.2318\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 3.0238 - val_loss: 24.1296\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 3.0340 - val_loss: 27.3236\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.0246 - val_loss: 25.1430\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.1932 - val_loss: 28.8706\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.7175 - val_loss: 26.7975\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.7322 - val_loss: 31.3888\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 4.0170 - val_loss: 26.4065\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 8.4626 - val_loss: 23.5345\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 6.9011 - val_loss: 28.0394\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 5.4326 - val_loss: 28.0888\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 4.8836 - val_loss: 28.7835\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 4.3178 - val_loss: 25.8500\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.7870 - val_loss: 28.3901\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 4.0104 - val_loss: 26.3860\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.3071 - val_loss: 29.7892\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.0926 - val_loss: 26.1561\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.9009 - val_loss: 29.0832\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.5890 - val_loss: 27.0586\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.6049 - val_loss: 27.9025\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.6736 - val_loss: 25.6193\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 3.3786 - val_loss: 26.1851\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.6839 - val_loss: 27.5667\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.3342 - val_loss: 28.4409\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.5674 - val_loss: 29.8961\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.5373 - val_loss: 25.0541\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.7789 - val_loss: 29.3281\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.6146 - val_loss: 25.0608\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 4.4958 - val_loss: 24.6295\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 3.1232 - val_loss: 29.1310\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.5871 - val_loss: 24.7804\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.7479 - val_loss: 29.9701\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.6971 - val_loss: 27.6165\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.6536 - val_loss: 26.9047\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.2356 - val_loss: 29.2039\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.1518 - val_loss: 24.9281\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 6.7701 - val_loss: 23.5103\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 4.4986 - val_loss: 33.6012\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 4.3789 - val_loss: 26.9051\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 3.1733 - val_loss: 29.5948\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 3.2141 - val_loss: 25.0062\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.8865 - val_loss: 26.4557\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.2114 - val_loss: 27.0585\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.9187 - val_loss: 28.2072\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.0802 - val_loss: 28.0710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 1.6019 - val_loss: 26.9728\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.5956 - val_loss: 29.2896\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.6668 - val_loss: 26.4537\n",
      "\n",
      "Mean squared error: 1.7\n",
      "\n",
      "dropout: 2.2e-01\n",
      "filter_num: 231\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 110us/sample - loss: 59.9704 - val_loss: 25.0651\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 44.7956 - val_loss: 23.3123\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 41.1674 - val_loss: 20.9529\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 38.8450 - val_loss: 19.7502\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 34.2315 - val_loss: 20.3195\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 31.4703 - val_loss: 18.5599\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 29.2297 - val_loss: 21.0886\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 26.3103 - val_loss: 19.8637\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 25.3522 - val_loss: 21.9437\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 22.2517 - val_loss: 24.7654\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 20.2883 - val_loss: 26.0873\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 18.6896 - val_loss: 26.2267\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 16.4253 - val_loss: 27.6291\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 14.5800 - val_loss: 28.3266\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 12.7032 - val_loss: 30.8863\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 10.7898 - val_loss: 28.0265\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 10.5060 - val_loss: 36.9552\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 9.4930 - val_loss: 28.4541\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 9.3305 - val_loss: 40.4421\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 9.3942 - val_loss: 26.9044\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 8.5320 - val_loss: 36.7547\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 8.7492 - val_loss: 26.9505\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 8.4860 - val_loss: 30.4192\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 6.3819 - val_loss: 33.7559\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 5.5691 - val_loss: 31.8865\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 5.0371 - val_loss: 35.7799\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 4.6453 - val_loss: 29.6632\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 4.5985 - val_loss: 34.5510\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.0073 - val_loss: 32.0658\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 4.0177 - val_loss: 31.8743\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 4.0850 - val_loss: 31.0205\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.8225 - val_loss: 33.4011\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 3.6583 - val_loss: 35.5189\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.6869 - val_loss: 32.4494\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 4.0491 - val_loss: 32.1326\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.1678 - val_loss: 29.4356\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 4.7135 - val_loss: 35.7552\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 5.4956 - val_loss: 27.9765\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 4.7587 - val_loss: 33.4261\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 3.7192 - val_loss: 29.0540\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.6654 - val_loss: 37.7700\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 4.0685 - val_loss: 30.8128\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 3.2444 - val_loss: 37.2933\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 3.4334 - val_loss: 33.9813\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.8078 - val_loss: 34.5514\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.4496 - val_loss: 30.8460\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.3065 - val_loss: 31.7282\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.2096 - val_loss: 32.0710\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 3.0245 - val_loss: 33.0268\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 3.0034 - val_loss: 32.2427\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.4428 - val_loss: 32.5363\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.3480 - val_loss: 32.8204\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.1056 - val_loss: 31.8295\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.2372 - val_loss: 31.4819\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.1099 - val_loss: 34.8766\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.4256 - val_loss: 36.1395\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.5069 - val_loss: 35.2322\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.0531 - val_loss: 32.0078\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.8979 - val_loss: 34.2415\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.7460 - val_loss: 32.8124\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.0510 - val_loss: 32.3502\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.0463 - val_loss: 31.7964\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.3085 - val_loss: 32.6463\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.9324 - val_loss: 30.7450\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.9547 - val_loss: 36.7517\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.7864 - val_loss: 30.5055\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.0524 - val_loss: 35.9417\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.3038 - val_loss: 28.7304\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.1848 - val_loss: 32.7017\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.8020 - val_loss: 28.8489\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.0057 - val_loss: 34.2611\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.7859 - val_loss: 31.1733\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.6877 - val_loss: 32.8008\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.5379 - val_loss: 31.4431\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.9039 - val_loss: 30.0036\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.3177 - val_loss: 31.6150\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.0064 - val_loss: 31.1774\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.7330 - val_loss: 28.5393\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.4409 - val_loss: 30.7740\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.6753 - val_loss: 28.7233\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.9115 - val_loss: 32.6183\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.8177 - val_loss: 29.2213\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.6990 - val_loss: 32.1504\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.5099 - val_loss: 28.7566\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.4213 - val_loss: 31.7761\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.2578 - val_loss: 28.6330\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.2264 - val_loss: 32.6877\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.6345 - val_loss: 31.0810\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.4997 - val_loss: 32.3870\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.6350 - val_loss: 29.3298\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.5385 - val_loss: 32.2203\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.4306 - val_loss: 31.0474\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.5074 - val_loss: 32.0109\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.3806 - val_loss: 30.2081\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.3227 - val_loss: 32.4026\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.2572 - val_loss: 30.2346\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.2529 - val_loss: 30.4861\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.1918 - val_loss: 33.2753\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.9821 - val_loss: 27.7912\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.1782 - val_loss: 33.0826\n",
      "\n",
      "Mean squared error: 2.2\n",
      "\n",
      "dropout: 2.0e-01\n",
      "filter_num: 155\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 102us/sample - loss: 62.2712 - val_loss: 31.5041\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 51.3679 - val_loss: 21.5073\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 43.1609 - val_loss: 23.3010\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 39.1174 - val_loss: 19.4702\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 36.6680 - val_loss: 18.9229\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 33.8304 - val_loss: 19.6631\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 31.5661 - val_loss: 18.0164\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 30.3786 - val_loss: 19.8062\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 28.6531 - val_loss: 20.1561\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 27.2931 - val_loss: 19.1977\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 26.0971 - val_loss: 20.5503\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 23.6547 - val_loss: 20.3769\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 22.3611 - val_loss: 21.9815\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 21.9757 - val_loss: 22.4751\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 19.5073 - val_loss: 27.0436\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 18.5595 - val_loss: 26.8000\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 16.1355 - val_loss: 27.5790\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 14.5240 - val_loss: 30.8472\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 13.0293 - val_loss: 29.4772\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 11.0679 - val_loss: 32.8479\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 9.9937 - val_loss: 30.3140\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 8.8336 - val_loss: 33.9713\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 8.4638 - val_loss: 33.0218\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 8.6631 - val_loss: 39.1633\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 7.0547 - val_loss: 36.2828\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 6.4045 - val_loss: 39.0616\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 5.9960 - val_loss: 33.7315\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 5.3873 - val_loss: 39.8982\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 5.1712 - val_loss: 34.6943\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 5.1135 - val_loss: 40.0793\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.6348 - val_loss: 34.8124\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.7441 - val_loss: 40.9367\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.9898 - val_loss: 40.6553\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 5.0782 - val_loss: 44.1886\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 5.3653 - val_loss: 45.1507\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 5.0853 - val_loss: 44.7620\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.5022 - val_loss: 42.3254\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.7153 - val_loss: 41.1964\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.2895 - val_loss: 45.6720\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.1820 - val_loss: 44.5720\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.9920 - val_loss: 46.1090\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.2805 - val_loss: 40.5773\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.1006 - val_loss: 40.8007\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 3.3558 - val_loss: 35.9315\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.3736 - val_loss: 39.7674\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.8860 - val_loss: 40.4284\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.7184 - val_loss: 39.4175\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.5175 - val_loss: 40.3944\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.6156 - val_loss: 40.5379\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.5438 - val_loss: 40.2430\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 2.4484 - val_loss: 40.3353\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.2620 - val_loss: 39.7517\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.2528 - val_loss: 43.1126\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.4671 - val_loss: 40.9643\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.5793 - val_loss: 41.2147\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 2.7604 - val_loss: 43.7255\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.3216 - val_loss: 40.6277\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.4667 - val_loss: 45.8644\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.4860 - val_loss: 40.4885\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.0501 - val_loss: 47.1067\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.4492 - val_loss: 40.9736\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.3703 - val_loss: 48.2172\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.8017 - val_loss: 37.6876\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.7857 - val_loss: 45.5752\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.2605 - val_loss: 40.0956\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.0330 - val_loss: 46.9825\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 1.9591 - val_loss: 41.9679\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.0544 - val_loss: 47.5460\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 1.9586 - val_loss: 41.2458\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 1.8985 - val_loss: 42.9699\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 1.9761 - val_loss: 40.7522\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 1.8997 - val_loss: 42.7833\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 1.9646 - val_loss: 40.9671\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 1.7792 - val_loss: 42.8344\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 1.7882 - val_loss: 42.6144\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.8261 - val_loss: 45.2143\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 1.8684 - val_loss: 42.9052\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 1.5144 - val_loss: 41.6961\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 1.7944 - val_loss: 38.8980\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 1.8185 - val_loss: 42.5450\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.1225 - val_loss: 37.5558\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 1.9222 - val_loss: 43.5514\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 2.4835 - val_loss: 37.3422\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 2.1858 - val_loss: 42.9859\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 1.8718 - val_loss: 38.8964\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 1.7915 - val_loss: 46.4341\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 2.8174 - val_loss: 39.8985\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.5852 - val_loss: 46.7992\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.7415 - val_loss: 39.3245\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.4524 - val_loss: 44.4777\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 2.4085 - val_loss: 39.1291\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 2.0259 - val_loss: 45.1718\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.2349 - val_loss: 45.0217\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 1.6600 - val_loss: 46.0605\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 1.6054 - val_loss: 43.8262\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 1.3847 - val_loss: 45.0883\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 1.4351 - val_loss: 42.5882\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 1.3677 - val_loss: 42.5259\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 1.2984 - val_loss: 43.0995\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 1.1124 - val_loss: 42.6950\n",
      "\n",
      "Mean squared error: 1.1\n",
      "\n",
      "dropout: 2.0e-01\n",
      "filter_num: 269\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 112us/sample - loss: 57.1628 - val_loss: 23.0179\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 44.8784 - val_loss: 21.7676\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 41.0629 - val_loss: 20.5653\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 36.6926 - val_loss: 23.1955\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 34.8258 - val_loss: 19.6106\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 31.0768 - val_loss: 18.5118\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 28.8983 - val_loss: 20.5242\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 26.5530 - val_loss: 21.6011\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 24.1014 - val_loss: 22.1176\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 22.9615 - val_loss: 25.1507\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 21.1886 - val_loss: 24.7095\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 19.3846 - val_loss: 25.7826\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 16.3647 - val_loss: 35.4533\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 16.3891 - val_loss: 31.7527\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 15.2156 - val_loss: 38.8203\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 12.9170 - val_loss: 36.7249\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 11.0256 - val_loss: 35.7154\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 9.0583 - val_loss: 37.7769\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 8.1020 - val_loss: 34.0801\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 24us/sample - loss: 7.7115 - val_loss: 39.3887\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 7.1412 - val_loss: 35.0358\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 7.0239 - val_loss: 34.6433\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 5.8721 - val_loss: 39.1954\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 5.9234 - val_loss: 35.1898\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 4.9696 - val_loss: 38.4781\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 4.6561 - val_loss: 37.8862\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 4.5358 - val_loss: 36.8211\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 4.5023 - val_loss: 42.7579\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 5.5662 - val_loss: 37.4020\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 4.7133 - val_loss: 43.0339\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 4.5839 - val_loss: 38.5643\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 4.1427 - val_loss: 39.3456\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 4.4419 - val_loss: 41.2234\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 4.3883 - val_loss: 39.6621\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 4.1300 - val_loss: 45.6321\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 3.6786 - val_loss: 39.3822\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 3.3299 - val_loss: 43.4188\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.0293 - val_loss: 37.6344\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.7631 - val_loss: 42.2295\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.7959 - val_loss: 39.9559\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.7624 - val_loss: 46.3159\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.7344 - val_loss: 45.4344\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.8284 - val_loss: 53.7346\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 3.2962 - val_loss: 48.9506\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.6510 - val_loss: 46.2233\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.9273 - val_loss: 44.8175\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.6446 - val_loss: 41.6047\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.5636 - val_loss: 44.2842\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.0176 - val_loss: 41.6524\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 2.0249 - val_loss: 45.3908\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.1614 - val_loss: 46.3507\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.4913 - val_loss: 42.6040\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.0340 - val_loss: 42.4841\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 2.0550 - val_loss: 41.8038\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.8293 - val_loss: 43.8948\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.8865 - val_loss: 44.4299\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.8960 - val_loss: 46.1898\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.7806 - val_loss: 43.2159\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.5415 - val_loss: 42.7630\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.8841 - val_loss: 48.2644\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.1879 - val_loss: 41.5368\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.0163 - val_loss: 47.9576\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.9694 - val_loss: 44.5808\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.7708 - val_loss: 48.7617\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.7115 - val_loss: 46.3918\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 3.1054 - val_loss: 41.7186\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.3200 - val_loss: 48.4215\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.7712 - val_loss: 44.6335\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.8867 - val_loss: 52.2318\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.6608 - val_loss: 48.3432\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.4670 - val_loss: 53.7989\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.0085 - val_loss: 45.9431\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.6516 - val_loss: 49.8117\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.9006 - val_loss: 43.1821\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.7119 - val_loss: 53.6848\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.6054 - val_loss: 46.5153\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.6322 - val_loss: 51.1058\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.2480 - val_loss: 50.4364\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.4642 - val_loss: 46.7161\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 1.1746 - val_loss: 50.0318\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 1.1661 - val_loss: 47.7457\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.8556 - val_loss: 49.8350\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.9085 - val_loss: 47.1931\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.2796 - val_loss: 51.3736\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.3436 - val_loss: 44.6655\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 1.2325 - val_loss: 47.3461\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.1721 - val_loss: 48.0862\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 1.5423 - val_loss: 47.2884\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.7581 - val_loss: 54.9365\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 2.0307 - val_loss: 46.3912\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 2.1085 - val_loss: 55.9831\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.0186 - val_loss: 43.9964\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.9588 - val_loss: 56.4978\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.9523 - val_loss: 35.6815\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 3.2822 - val_loss: 48.2835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.9158 - val_loss: 35.5790\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.0273 - val_loss: 38.1895\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.4485 - val_loss: 35.6508\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.4043 - val_loss: 38.3710\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.8983 - val_loss: 40.6784\n",
      "\n",
      "Mean squared error: 1.9\n",
      "\n",
      "dropout: 2.0e-01\n",
      "filter_num: 161\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 100us/sample - loss: 62.9288 - val_loss: 32.8808\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 53.6280 - val_loss: 22.9389\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 43.9844 - val_loss: 25.6582\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 40.7718 - val_loss: 21.1023\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 37.0636 - val_loss: 21.2827\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 33.7963 - val_loss: 20.5369\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 31.4142 - val_loss: 19.4204\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 31.2810 - val_loss: 19.5596\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 28.7744 - val_loss: 21.3358\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 27.2218 - val_loss: 20.6066\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 25.9184 - val_loss: 20.6298\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 23.8417 - val_loss: 22.7901\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 22.6861 - val_loss: 23.9012\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 20.7147 - val_loss: 25.0378\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 18.7528 - val_loss: 26.9055\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 17.2703 - val_loss: 27.1444\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 15.8037 - val_loss: 31.1688\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 13.9340 - val_loss: 31.9595\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 12.0260 - val_loss: 29.1826\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 10.3379 - val_loss: 33.4931\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 9.8900 - val_loss: 28.3059\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 8.6450 - val_loss: 38.5998\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 8.1176 - val_loss: 30.7191\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 6.8353 - val_loss: 40.7573\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 7.2073 - val_loss: 28.9141\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 6.7109 - val_loss: 32.6111\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 6.3313 - val_loss: 31.7546\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 6.7822 - val_loss: 35.3284\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 6.2999 - val_loss: 32.2025\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 5.5996 - val_loss: 36.2452\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 5.4294 - val_loss: 30.6509\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.9328 - val_loss: 32.2792\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 5.2849 - val_loss: 28.5349\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.5890 - val_loss: 30.7519\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.2943 - val_loss: 29.9283\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.8475 - val_loss: 28.8848\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.8289 - val_loss: 28.0001\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.6993 - val_loss: 31.0119\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.3707 - val_loss: 26.7678\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.0555 - val_loss: 27.2966\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.9196 - val_loss: 27.0737\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.8721 - val_loss: 29.3730\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.4707 - val_loss: 28.9682\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.7464 - val_loss: 28.6728\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.7226 - val_loss: 28.4451\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.8763 - val_loss: 31.4435\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.7822 - val_loss: 27.4951\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.5980 - val_loss: 31.2953\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.0575 - val_loss: 29.2079\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.9604 - val_loss: 28.9675\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.7244 - val_loss: 30.0596\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.7528 - val_loss: 27.7729\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.6909 - val_loss: 30.0705\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.4895 - val_loss: 29.1423\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.5852 - val_loss: 30.3390\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.4058 - val_loss: 29.8880\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.6182 - val_loss: 30.1947\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 2.3183 - val_loss: 29.2129\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.3668 - val_loss: 29.5585\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.4981 - val_loss: 30.5214\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.3551 - val_loss: 29.9734\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.6059 - val_loss: 30.0821\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.4424 - val_loss: 28.9023\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.6507 - val_loss: 33.3487\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.5008 - val_loss: 29.9578\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.0771 - val_loss: 27.4470\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.0467 - val_loss: 29.3464\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.8816 - val_loss: 28.2849\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.8690 - val_loss: 32.4511\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.6947 - val_loss: 29.3691\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.8052 - val_loss: 31.2192\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.7728 - val_loss: 30.4653\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 2.3607 - val_loss: 32.1317\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.2601 - val_loss: 28.3888\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.3739 - val_loss: 30.8392\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 1.7880 - val_loss: 29.5808\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.0130 - val_loss: 32.1882\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 1.9365 - val_loss: 28.8044\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.4135 - val_loss: 31.5018\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.2473 - val_loss: 30.1181\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 1.9490 - val_loss: 30.3790\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 1.6562 - val_loss: 30.2060\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 1.5694 - val_loss: 30.2658\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 1.8195 - val_loss: 29.0402\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 1.6475 - val_loss: 31.2990\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.0969 - val_loss: 29.2788\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.2377 - val_loss: 32.4731\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.1092 - val_loss: 29.9146\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 1.8570 - val_loss: 32.5791\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 1.8030 - val_loss: 30.5087\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 1.8738 - val_loss: 29.7444\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 1.6236 - val_loss: 29.1216\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 1.5491 - val_loss: 29.2634\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 1.5233 - val_loss: 30.5958\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 1.6655 - val_loss: 28.3374\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.3523 - val_loss: 29.7596\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.1374 - val_loss: 27.8818\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.5003 - val_loss: 32.0725\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.7091 - val_loss: 27.5283\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.5475 - val_loss: 30.1743\n",
      "\n",
      "Mean squared error: 2.5\n",
      "\n",
      "dropout: 2.0e-01\n",
      "filter_num: 228\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 107us/sample - loss: 59.2194 - val_loss: 25.1947\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 43.9510 - val_loss: 27.5750\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 41.0610 - val_loss: 21.0393\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 38.7203 - val_loss: 20.0592\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 34.5746 - val_loss: 22.5900\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 32.7318 - val_loss: 19.0815\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 30.0077 - val_loss: 19.1415\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 27.1115 - val_loss: 24.7056\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 26.0674 - val_loss: 19.2125\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 25.3646 - val_loss: 21.1630\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 22.2627 - val_loss: 24.8017\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 19.9586 - val_loss: 23.3799\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 18.3797 - val_loss: 29.2560\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 16.5635 - val_loss: 26.3902\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 15.8227 - val_loss: 28.1478\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 13.1898 - val_loss: 27.7737\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 12.8118 - val_loss: 26.1331\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 11.8881 - val_loss: 25.3185\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 9.9544 - val_loss: 24.9861\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 8.6306 - val_loss: 23.7919\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 7.8618 - val_loss: 27.4357\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 7.4553 - val_loss: 25.1594\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 6.4163 - val_loss: 25.5399\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 6.6176 - val_loss: 25.6071\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 6.0931 - val_loss: 27.9174\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 5.6356 - val_loss: 25.3879\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 5.2293 - val_loss: 24.2770\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 5.1393 - val_loss: 27.2240\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.6396 - val_loss: 27.2898\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 4.4950 - val_loss: 27.5578\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.1765 - val_loss: 25.0802\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.8835 - val_loss: 25.0856\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.7367 - val_loss: 24.7336\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.7185 - val_loss: 27.6533\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.6212 - val_loss: 25.3898\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.5370 - val_loss: 28.0341\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.4392 - val_loss: 24.3212\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.5324 - val_loss: 29.5688\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.7365 - val_loss: 24.9979\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.6304 - val_loss: 26.6458\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.2444 - val_loss: 27.5563\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.8301 - val_loss: 26.7733\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.6758 - val_loss: 29.4393\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.2679 - val_loss: 23.9744\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.3126 - val_loss: 25.2964\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.3172 - val_loss: 25.8322\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.2774 - val_loss: 26.8562\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.1737 - val_loss: 29.3437\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.0851 - val_loss: 27.2938\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.8049 - val_loss: 27.7885\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.7982 - val_loss: 26.0997\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.2975 - val_loss: 27.5070\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.5054 - val_loss: 26.0021\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.8504 - val_loss: 28.3486\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.0646 - val_loss: 25.8030\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.0049 - val_loss: 27.1972\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.0158 - val_loss: 26.2543\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.9995 - val_loss: 30.0970\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.7442 - val_loss: 25.6224\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 6.6786 - val_loss: 27.2721\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.3804 - val_loss: 24.7750\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.8026 - val_loss: 27.8899\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.8004 - val_loss: 27.9626\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.5694 - val_loss: 28.4288\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.0307 - val_loss: 27.1701\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.0880 - val_loss: 26.7926\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.8314 - val_loss: 26.1957\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.8540 - val_loss: 29.9880\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 4.8296 - val_loss: 24.9678\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.8783 - val_loss: 27.9118\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.4190 - val_loss: 30.0596\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.3106 - val_loss: 29.4357\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.3326 - val_loss: 29.6409\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.8265 - val_loss: 27.2873\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.8831 - val_loss: 27.9353\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.7883 - val_loss: 27.3745\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.3151 - val_loss: 27.4682\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.4178 - val_loss: 26.5607\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.5317 - val_loss: 25.8604\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.6625 - val_loss: 27.0563\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.4874 - val_loss: 27.2459\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.3776 - val_loss: 26.8481\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.3774 - val_loss: 26.4979\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.5286 - val_loss: 27.8523\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.9430 - val_loss: 32.0962\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.3665 - val_loss: 26.3986\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.3582 - val_loss: 26.4044\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.7437 - val_loss: 25.8126\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.1491 - val_loss: 28.7299\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.5454 - val_loss: 26.6125\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.2951 - val_loss: 28.2596\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.6237 - val_loss: 27.3183\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.7318 - val_loss: 27.6730\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.5415 - val_loss: 26.7877\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.5437 - val_loss: 27.0854\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.5357 - val_loss: 27.1174\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.5421 - val_loss: 27.2098\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.4905 - val_loss: 26.1302\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.4527 - val_loss: 26.4563\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.2742 - val_loss: 26.2049\n",
      "\n",
      "Mean squared error: 1.3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kat\\anaconda3\\envs\\tensor\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropout: 2.0e-01\n",
      "filter_num: 300\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 127us/sample - loss: 58.1858 - val_loss: 22.1068\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 43.4015 - val_loss: 20.8871\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 39.8456 - val_loss: 19.9809\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 36.0608 - val_loss: 21.3567\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 32.9173 - val_loss: 20.6598\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 29.2364 - val_loss: 18.6376\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 26.6581 - val_loss: 21.6779\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 23.9463 - val_loss: 22.4498\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 22.2953 - val_loss: 22.8958\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 20.5878 - val_loss: 23.4662\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 18.9735 - val_loss: 23.2578\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 16.9653 - val_loss: 28.3473\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 14.7350 - val_loss: 22.8584\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 13.3612 - val_loss: 26.5934\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 11.9660 - val_loss: 28.7262\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 11.3902 - val_loss: 25.6776\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 10.3162 - val_loss: 28.4702\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 8.4846 - val_loss: 27.0861\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 7.2548 - val_loss: 28.1113\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 6.5310 - val_loss: 25.4348\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.8505 - val_loss: 27.3793\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.5902 - val_loss: 24.2633\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.6374 - val_loss: 25.7761\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.2814 - val_loss: 24.1923\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 4.4193 - val_loss: 28.7580\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.3936 - val_loss: 22.8902\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.9621 - val_loss: 28.1099\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.6404 - val_loss: 23.4588\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.8285 - val_loss: 27.7383\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.9977 - val_loss: 22.5019\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.0693 - val_loss: 24.3211\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.3866 - val_loss: 22.3956\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.3049 - val_loss: 26.4176\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.1171 - val_loss: 23.3665\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.3863 - val_loss: 23.4438\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 4.1348 - val_loss: 24.8591\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.5295 - val_loss: 23.8390\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.4267 - val_loss: 23.9889\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.3739 - val_loss: 22.9040\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.5701 - val_loss: 23.8500\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.3650 - val_loss: 24.0042\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.3282 - val_loss: 23.5784\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.0324 - val_loss: 24.5221\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.3674 - val_loss: 23.4326\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.9534 - val_loss: 23.8192\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.1783 - val_loss: 22.2504\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.4034 - val_loss: 23.2525\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.8305 - val_loss: 22.1797\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.8460 - val_loss: 24.0452\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.9345 - val_loss: 23.0525\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 1.6713 - val_loss: 22.9474\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.6953 - val_loss: 22.6022\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.6590 - val_loss: 23.0745\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.7496 - val_loss: 24.0101\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.2220 - val_loss: 22.2796\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.7856 - val_loss: 23.2866\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.8874 - val_loss: 22.3621\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.9722 - val_loss: 24.6931\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 1.5249 - val_loss: 22.0498\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.6673 - val_loss: 22.9656\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 1.6359 - val_loss: 21.5340\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.8021 - val_loss: 24.1523\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.8101 - val_loss: 23.2304\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.6605 - val_loss: 25.8982\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.7445 - val_loss: 22.6542\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 1.5257 - val_loss: 23.2837\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.2513 - val_loss: 22.2507\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.2396 - val_loss: 23.7287\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.4019 - val_loss: 22.0962\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.3474 - val_loss: 22.6355\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.4436 - val_loss: 23.1718\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.5384 - val_loss: 23.0383\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.5550 - val_loss: 23.7426\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.4335 - val_loss: 22.6582\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.2529 - val_loss: 23.3637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.1929 - val_loss: 21.3522\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.2561 - val_loss: 22.8830\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.1999 - val_loss: 22.3337\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.4271 - val_loss: 22.3989\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.2884 - val_loss: 23.1052\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.2030 - val_loss: 22.9870\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.3167 - val_loss: 24.3672\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.2959 - val_loss: 22.9808\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.6451 - val_loss: 23.0952\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.0252 - val_loss: 23.7096\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.1339 - val_loss: 23.2290\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.0830 - val_loss: 23.2362\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.0011 - val_loss: 23.0914\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 0.9819 - val_loss: 23.7858\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 0.8463 - val_loss: 22.7432\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 0.8793 - val_loss: 23.6597\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 0.9530 - val_loss: 22.9262\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.0271 - val_loss: 23.8079\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.0085 - val_loss: 22.0405\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 0.8724 - val_loss: 22.9678\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.0375 - val_loss: 22.9921\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 0.9193 - val_loss: 23.0422\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 0.7822 - val_loss: 23.4639\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 0.9167 - val_loss: 23.4035\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 0.8406 - val_loss: 22.7676\n",
      "\n",
      "Mean squared error: 0.84\n",
      "\n",
      "dropout: 3.8e-01\n",
      "filter_num: 246\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 108us/sample - loss: 59.1551 - val_loss: 24.1714\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 45.6309 - val_loss: 22.9605\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 42.2536 - val_loss: 22.0267\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 39.3813 - val_loss: 20.9221\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 35.3487 - val_loss: 20.5003\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 31.6465 - val_loss: 19.1919\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 30.7681 - val_loss: 19.5447\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 26.7196 - val_loss: 20.0330\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 24.9131 - val_loss: 20.5004\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 23.5518 - val_loss: 21.4743\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 23.5159 - val_loss: 21.4892\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 21.0334 - val_loss: 25.4543\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 19.4435 - val_loss: 22.6886\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 17.9388 - val_loss: 26.0283\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 16.2031 - val_loss: 27.5472\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 14.3598 - val_loss: 30.0443\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 13.2114 - val_loss: 30.1147\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 11.8383 - val_loss: 30.3226\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 10.8609 - val_loss: 33.7738\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 9.1734 - val_loss: 31.2571\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 8.6286 - val_loss: 36.3739\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 7.9225 - val_loss: 31.6993\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 8.2965 - val_loss: 41.3840\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 7.5240 - val_loss: 30.2300\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 8.4242 - val_loss: 36.5570\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 7.7705 - val_loss: 30.0780\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 6.8320 - val_loss: 34.9094\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 7.6254 - val_loss: 29.2770\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 6.2466 - val_loss: 33.5936\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 6.5791 - val_loss: 31.3356\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 6.8057 - val_loss: 31.0333\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 9.0538 - val_loss: 31.4815\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 5.1021 - val_loss: 30.3034\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 5.5140 - val_loss: 33.1981\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 5.1576 - val_loss: 36.8188\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 8.2903 - val_loss: 34.5640\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 8.0498 - val_loss: 31.3047\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 5.8279 - val_loss: 35.5479\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 5.1336 - val_loss: 31.5578\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.3836 - val_loss: 33.5262\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 4.3542 - val_loss: 36.1911\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 4.6839 - val_loss: 34.4013\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 4.0177 - val_loss: 35.6744\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.8674 - val_loss: 36.4216\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 4.0874 - val_loss: 33.7169\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 4.9929 - val_loss: 34.0878\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 4.6005 - val_loss: 32.4704\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 4.6239 - val_loss: 32.9298\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 4.5845 - val_loss: 33.8465\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 21us/sample - loss: 3.7211 - val_loss: 34.8220\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 3.3894 - val_loss: 35.0310\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.3195 - val_loss: 36.7297\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 3.4136 - val_loss: 34.3508\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.4501 - val_loss: 35.0172\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 3.8511 - val_loss: 34.2075\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 3.2464 - val_loss: 34.9445\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 3.3042 - val_loss: 36.9674\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 4.3721 - val_loss: 35.3343\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 3.4109 - val_loss: 36.4674\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 3.2638 - val_loss: 34.6981\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.9256 - val_loss: 36.9741\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.0700 - val_loss: 35.7374\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.7906 - val_loss: 37.0134\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.2714 - val_loss: 37.0240\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.7839 - val_loss: 34.8607\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.8794 - val_loss: 34.4105\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.7377 - val_loss: 33.7812\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.5411 - val_loss: 34.3693\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.6065 - val_loss: 37.3009\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.6925 - val_loss: 35.8214\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.9156 - val_loss: 35.3135\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.9928 - val_loss: 33.0281\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.7994 - val_loss: 32.3860\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.6901 - val_loss: 34.9503\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.3955 - val_loss: 33.7506\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.6280 - val_loss: 36.8231\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.5420 - val_loss: 32.6432\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.5074 - val_loss: 33.4998\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.3881 - val_loss: 32.5751\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.3676 - val_loss: 33.2744\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.4666 - val_loss: 33.9634\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 3.8621 - val_loss: 34.8249\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.9683 - val_loss: 34.1997\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.0740 - val_loss: 34.0950\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.5721 - val_loss: 33.6237\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 3.2376 - val_loss: 34.6959\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 3.6023 - val_loss: 35.7340\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.9425 - val_loss: 35.4820\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 3.3562 - val_loss: 35.8896\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 4.1428 - val_loss: 33.0201\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.7564 - val_loss: 41.0083\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 3.8575 - val_loss: 33.6544\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 3.3589 - val_loss: 38.3655\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.8764 - val_loss: 33.3047\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.8761 - val_loss: 35.4506\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.3363 - val_loss: 36.3761\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.2222 - val_loss: 34.5218\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.2762 - val_loss: 36.3452\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.7434 - val_loss: 34.3194\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.3822 - val_loss: 36.2300\n",
      "\n",
      "Mean squared error: 2.4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kat\\anaconda3\\envs\\tensor\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropout: 2.0e-01\n",
      "filter_num: 300\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 112us/sample - loss: 55.8143 - val_loss: 23.9484\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 43.9315 - val_loss: 21.5737\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 40.2187 - val_loss: 20.6000\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 36.5522 - val_loss: 20.3434\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 32.6661 - val_loss: 18.8431\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 29.6165 - val_loss: 20.3978\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 26.3181 - val_loss: 20.0678\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 24.7400 - val_loss: 26.0062\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 22.8091 - val_loss: 22.3994\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 19.6050 - val_loss: 25.7785\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 17.4574 - val_loss: 23.6683\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 15.7459 - val_loss: 27.1649\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 13.5227 - val_loss: 26.2533\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 10.8997 - val_loss: 23.7930\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 9.8219 - val_loss: 29.4847\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 9.9953 - val_loss: 22.4273\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 8.9450 - val_loss: 31.0656\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 7.8651 - val_loss: 24.8800\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 7.4760 - val_loss: 27.9282\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 7.2079 - val_loss: 29.6925\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 5.9052 - val_loss: 24.5968\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.3296 - val_loss: 22.1141\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 6.5147 - val_loss: 24.5566\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 6.2573 - val_loss: 21.5904\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 5.7908 - val_loss: 27.1654\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.7040 - val_loss: 23.4205\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.9038 - val_loss: 28.4575\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.1704 - val_loss: 23.0369\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.1565 - val_loss: 27.3064\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.6761 - val_loss: 22.7228\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.7215 - val_loss: 27.4097\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.9917 - val_loss: 23.4036\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.4002 - val_loss: 26.2584\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.4568 - val_loss: 22.1220\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 3.0881 - val_loss: 25.6882\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 3.0259 - val_loss: 23.6525\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.7905 - val_loss: 24.1977\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.7444 - val_loss: 23.4221\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 2.9679 - val_loss: 22.2386\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.6020 - val_loss: 26.5796\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.9973 - val_loss: 22.2534\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.1629 - val_loss: 27.4365\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.9131 - val_loss: 22.6319\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.4968 - val_loss: 27.8741\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.8752 - val_loss: 23.2406\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.7960 - val_loss: 24.9016\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.2220 - val_loss: 24.0111\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.9632 - val_loss: 25.9543\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.0916 - val_loss: 23.0029\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.1821 - val_loss: 26.2421\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.1478 - val_loss: 23.6561\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.4452 - val_loss: 25.6675\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.1126 - val_loss: 23.2652\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.9787 - val_loss: 24.5950\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.0911 - val_loss: 22.2799\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.7934 - val_loss: 24.0066\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.7614 - val_loss: 24.3244\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.6668 - val_loss: 24.9527\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.4718 - val_loss: 25.1340\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.5771 - val_loss: 23.9478\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.7820 - val_loss: 25.1730\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.6492 - val_loss: 24.9503\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 1.7104 - val_loss: 24.8510\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.5179 - val_loss: 23.8220\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.4506 - val_loss: 25.3634\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.2712 - val_loss: 23.6994\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.5837 - val_loss: 27.3100\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.8692 - val_loss: 24.0708\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.9855 - val_loss: 26.6429\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.8939 - val_loss: 23.5597\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.0140 - val_loss: 25.3082\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.9548 - val_loss: 24.4204\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.6978 - val_loss: 26.4968\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.6887 - val_loss: 25.2471\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.3243 - val_loss: 25.6565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.6477 - val_loss: 26.8974\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.9993 - val_loss: 23.4018\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.7592 - val_loss: 24.9813\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.8245 - val_loss: 24.0859\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.3307 - val_loss: 22.8348\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.0369 - val_loss: 21.3985\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.2693 - val_loss: 22.0729\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.0833 - val_loss: 23.4337\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.5143 - val_loss: 23.1270\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.4120 - val_loss: 24.0491\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.4197 - val_loss: 25.0585\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.9474 - val_loss: 22.6330\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.6827 - val_loss: 22.4761\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.6444 - val_loss: 24.3182\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.5597 - val_loss: 23.9228\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.1878 - val_loss: 23.1276\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.8264 - val_loss: 23.8613\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.0995 - val_loss: 23.9577\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.8340 - val_loss: 26.9929\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.8756 - val_loss: 24.6875\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.7193 - val_loss: 25.1873\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.2779 - val_loss: 24.0335\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.2491 - val_loss: 24.3076\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.3044 - val_loss: 23.3211\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.0521 - val_loss: 23.2392\n",
      "\n",
      "Mean squared error: 1.1\n",
      "\n",
      "dropout: 2.8e-01\n",
      "filter_num: 263\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 115us/sample - loss: 55.0082 - val_loss: 23.2074\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 45.2074 - val_loss: 21.2179\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 40.8613 - val_loss: 20.6236\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 37.7481 - val_loss: 19.8683\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 34.0679 - val_loss: 19.3524\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 31.4613 - val_loss: 18.4372\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 28.2840 - val_loss: 22.7415\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 27.3802 - val_loss: 23.9312\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 24.6693 - val_loss: 22.5911\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 23.8569 - val_loss: 24.1283\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 21.8783 - val_loss: 25.0022\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 20.2447 - val_loss: 23.2631\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 17.6237 - val_loss: 26.2914\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 16.7225 - val_loss: 23.8185\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 14.8818 - val_loss: 29.3317\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 12.9200 - val_loss: 26.3512\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 11.3353 - val_loss: 30.3319\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 9.4581 - val_loss: 28.7861\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 9.1012 - val_loss: 28.0902\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 7.5124 - val_loss: 34.8950\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 7.8808 - val_loss: 30.2926\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 6.3796 - val_loss: 32.7517\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 7.0757 - val_loss: 26.0469\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 7.5041 - val_loss: 27.6506\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 7.6217 - val_loss: 24.3680\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 7.1632 - val_loss: 30.1445\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 6.7970 - val_loss: 27.2065\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 6.4858 - val_loss: 30.0240\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 5.6325 - val_loss: 31.2698\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 5.4704 - val_loss: 33.9219\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 4.7546 - val_loss: 31.9809\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 5.3063 - val_loss: 28.5096\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 5.1426 - val_loss: 28.9176\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 4.8909 - val_loss: 26.6510\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 4.9138 - val_loss: 27.4774\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 4.6305 - val_loss: 31.5898\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 5.0367 - val_loss: 27.0653\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 4.9048 - val_loss: 30.7374\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 4.2816 - val_loss: 27.9234\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 4.5582 - val_loss: 26.4555\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 5.2151 - val_loss: 29.4851\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 5.3982 - val_loss: 24.3441\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 5.3931 - val_loss: 30.0078\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 5.5534 - val_loss: 25.4874\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 5.1054 - val_loss: 29.0792\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 4.4761 - val_loss: 27.4370\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.8662 - val_loss: 27.2626\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 3.4267 - val_loss: 27.9727\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.2065 - val_loss: 27.3312\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.7752 - val_loss: 26.3258\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 3.1053 - val_loss: 26.9421\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.1566 - val_loss: 27.7250\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.8071 - val_loss: 27.7049\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.3357 - val_loss: 27.8079\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.7655 - val_loss: 26.6524\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.4805 - val_loss: 27.9646\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.7126 - val_loss: 24.6206\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 3.4808 - val_loss: 26.7843\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.5722 - val_loss: 28.8733\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 3.3526 - val_loss: 28.3269\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.8724 - val_loss: 28.2394\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.1758 - val_loss: 25.9927\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 4.5615 - val_loss: 25.3486\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 4.6897 - val_loss: 25.5679\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.7370 - val_loss: 26.2371\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.5764 - val_loss: 27.1328\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.0137 - val_loss: 26.5274\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.5354 - val_loss: 28.9630\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.1517 - val_loss: 28.1150\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.9749 - val_loss: 27.1654\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.7914 - val_loss: 25.7859\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.8704 - val_loss: 27.6596\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.9270 - val_loss: 27.4594\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.4618 - val_loss: 25.9881\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.2920 - val_loss: 26.4964\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.2048 - val_loss: 25.1024\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.1635 - val_loss: 27.9545\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.0571 - val_loss: 26.3020\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 4.5244 - val_loss: 25.8567\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 4.0472 - val_loss: 25.5523\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.4925 - val_loss: 26.2814\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 3.3772 - val_loss: 26.4489\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.7507 - val_loss: 24.4799\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.7233 - val_loss: 25.5365\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.9998 - val_loss: 24.7433\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.2488 - val_loss: 25.6150\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.7497 - val_loss: 24.6865\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.4794 - val_loss: 26.8524\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.2985 - val_loss: 26.3587\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.9051 - val_loss: 26.6470\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.4026 - val_loss: 26.3298\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.9403 - val_loss: 26.5845\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.7793 - val_loss: 26.2847\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.3650 - val_loss: 26.5707\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.1048 - val_loss: 26.0781\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.9058 - val_loss: 27.7552\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.7700 - val_loss: 27.0136\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.5478 - val_loss: 28.6395\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.6045 - val_loss: 26.1082\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.7676 - val_loss: 27.1525\n",
      "\n",
      "Mean squared error: 1.8\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kat\\anaconda3\\envs\\tensor\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropout: 2.0e-01\n",
      "filter_num: 300\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 119us/sample - loss: 55.0512 - val_loss: 25.6418\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 44.2319 - val_loss: 21.9227\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 40.2584 - val_loss: 20.7191\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 36.7207 - val_loss: 20.1077\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 32.1614 - val_loss: 18.8433\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 28.8491 - val_loss: 19.7931\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 26.9610 - val_loss: 19.0778\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 24.4861 - val_loss: 24.8006\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 22.8392 - val_loss: 20.5905\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 20.6828 - val_loss: 24.5121\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 17.4298 - val_loss: 26.4267\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 15.5426 - val_loss: 26.7304\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 12.7849 - val_loss: 30.1947\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 11.4407 - val_loss: 24.7599\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 9.4403 - val_loss: 27.1243\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 8.4087 - val_loss: 22.9795\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 8.2146 - val_loss: 24.8003\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 6.5384 - val_loss: 19.9727\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 6.8295 - val_loss: 19.7431\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 7.8990 - val_loss: 24.5068\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 7.3526 - val_loss: 20.9517\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 6.2635 - val_loss: 29.3495\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 7.5616 - val_loss: 21.4843\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 9.6055 - val_loss: 22.7607\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 8.8288 - val_loss: 20.7934\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 7.0215 - val_loss: 23.9137\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.8563 - val_loss: 24.2872\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 4.7765 - val_loss: 24.8952\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.4419 - val_loss: 24.2639\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.3030 - val_loss: 22.3534\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.3825 - val_loss: 23.6887\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.1976 - val_loss: 20.8716\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.8337 - val_loss: 24.3717\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.7224 - val_loss: 22.4108\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.4553 - val_loss: 24.3090\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.6011 - val_loss: 21.9709\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.8036 - val_loss: 23.4426\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 2.8600 - val_loss: 23.9402\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.6827 - val_loss: 23.8311\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.5637 - val_loss: 24.5613\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 2.5750 - val_loss: 23.4734\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.4448 - val_loss: 23.6696\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.2180 - val_loss: 23.0533\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.2124 - val_loss: 24.4241\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.0114 - val_loss: 23.7810\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.1087 - val_loss: 24.0962\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.1108 - val_loss: 23.1073\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.9391 - val_loss: 23.6037\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.6504 - val_loss: 23.5138\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.8611 - val_loss: 24.1305\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.8905 - val_loss: 23.1882\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.3364 - val_loss: 22.9177\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.1020 - val_loss: 25.3929\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.0047 - val_loss: 23.2636\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.1499 - val_loss: 25.0889\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 2.0478 - val_loss: 22.7463\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.1476 - val_loss: 25.7176\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.7690 - val_loss: 23.0785\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.8768 - val_loss: 24.8887\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.8955 - val_loss: 22.6534\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 1.9246 - val_loss: 24.5392\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.9379 - val_loss: 23.9245\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.0091 - val_loss: 24.5642\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.8203 - val_loss: 22.8578\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.8005 - val_loss: 25.0155\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.5768 - val_loss: 23.6296\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.7836 - val_loss: 25.6161\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.6638 - val_loss: 23.1597\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.7851 - val_loss: 25.3455\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.5110 - val_loss: 23.7510\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.0426 - val_loss: 25.8195\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.2797 - val_loss: 22.5636\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.0161 - val_loss: 25.8287\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.2869 - val_loss: 22.3990\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.2205 - val_loss: 25.3641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 2.2770 - val_loss: 22.7242\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.5538 - val_loss: 24.9321\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.4782 - val_loss: 22.6989\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.4380 - val_loss: 22.9150\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.5698 - val_loss: 22.9295\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.1396 - val_loss: 22.6118\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.2077 - val_loss: 23.4989\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.0746 - val_loss: 23.7840\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.2658 - val_loss: 25.1050\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.6398 - val_loss: 22.3275\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.5269 - val_loss: 22.1586\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 2.1056 - val_loss: 22.3807\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.3788 - val_loss: 23.9381\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.4163 - val_loss: 23.3022\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.1995 - val_loss: 24.3192\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.2399 - val_loss: 22.5664\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.3058 - val_loss: 23.9007\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.2155 - val_loss: 23.5617\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.3117 - val_loss: 22.7941\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.0520 - val_loss: 23.4166\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.2143 - val_loss: 24.2069\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.0256 - val_loss: 23.6119\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 3.0725 - val_loss: 24.1375\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 2.1882 - val_loss: 22.1064\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.1513 - val_loss: 23.6096\n",
      "\n",
      "Mean squared error: 1.2\n",
      "\n",
      "dropout: 2.0e-01\n",
      "filter_num: 100\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 94us/sample - loss: 62.3525 - val_loss: 33.1340\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 54.6722 - val_loss: 24.0762\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 43.3931 - val_loss: 24.0732\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 40.7878 - val_loss: 20.4117\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 37.4326 - val_loss: 19.4779\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 35.1963 - val_loss: 18.9378\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 32.9638 - val_loss: 18.7136\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 31.9948 - val_loss: 18.7174\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 30.0452 - val_loss: 19.0579\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 28.3122 - val_loss: 19.4321\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 27.3309 - val_loss: 19.9340\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 25.4585 - val_loss: 20.7257\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 24.6901 - val_loss: 20.8623\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 22.5864 - val_loss: 22.2734\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 21.7063 - val_loss: 25.2873\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 20.3248 - val_loss: 24.6528\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 19.1419 - val_loss: 25.1188\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 17.0125 - val_loss: 31.4282\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 16.0164 - val_loss: 29.9712\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 15.0860 - val_loss: 34.5168\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 12.7347 - val_loss: 35.7780\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 11.4948 - val_loss: 38.1756\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 10.5444 - val_loss: 42.8391\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 9.0144 - val_loss: 38.7808\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 8.9617 - val_loss: 38.8479\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 8.5451 - val_loss: 40.7343\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 8.1606 - val_loss: 41.0656\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 6.9359 - val_loss: 50.6198\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 6.5363 - val_loss: 57.1880\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 6.5246 - val_loss: 52.8433\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 6.2680 - val_loss: 55.2238\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 5.6453 - val_loss: 56.3660\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 5.8231 - val_loss: 45.1795\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 7.0615 - val_loss: 56.0603\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 5.5335 - val_loss: 53.3747\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.8028 - val_loss: 56.8549\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.6074 - val_loss: 55.9262\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.6307 - val_loss: 51.3408\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 5.3209 - val_loss: 49.4326\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 5.8875 - val_loss: 50.9710\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 6.2230 - val_loss: 50.6304\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 5.2796 - val_loss: 55.3668\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.6250 - val_loss: 47.3021\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.9606 - val_loss: 47.4618\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.5412 - val_loss: 47.0079\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 3.9507 - val_loss: 46.5894\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 3.9734 - val_loss: 46.2806\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.9884 - val_loss: 48.2670\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 5.7998 - val_loss: 46.7805\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.7150 - val_loss: 41.1042\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.7019 - val_loss: 51.8972\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.7632 - val_loss: 47.9219\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.6873 - val_loss: 48.7293\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 7.7065 - val_loss: 36.4488\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 6.2445 - val_loss: 48.8707\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 6.4154 - val_loss: 35.8676\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.9221 - val_loss: 42.9370\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 5.2053 - val_loss: 46.1926\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.1788 - val_loss: 47.6728\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 3.5419 - val_loss: 54.7008\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 3.4295 - val_loss: 55.2654\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 3.0465 - val_loss: 54.7421\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.7300 - val_loss: 54.6033\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.6523 - val_loss: 54.9085\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.5831 - val_loss: 52.8054\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.5462 - val_loss: 51.9395\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.5302 - val_loss: 49.2946\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.9119 - val_loss: 51.8382\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.9473 - val_loss: 51.5635\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.9491 - val_loss: 50.4450\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.6959 - val_loss: 54.4434\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.6692 - val_loss: 51.2872\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 3.1164 - val_loss: 52.4280\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.3573 - val_loss: 56.2982\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.2572 - val_loss: 54.7411\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.4563 - val_loss: 53.8556\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.2639 - val_loss: 52.1969\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.3151 - val_loss: 49.4122\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.4464 - val_loss: 50.6081\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.5378 - val_loss: 50.1297\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.4217 - val_loss: 48.7540\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.5859 - val_loss: 47.4772\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 2.5399 - val_loss: 50.5560\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.3492 - val_loss: 52.1498\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.1766 - val_loss: 55.6375\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.2467 - val_loss: 53.9582\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.0665 - val_loss: 54.8536\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.1289 - val_loss: 58.3310\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.1482 - val_loss: 55.1694\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.0553 - val_loss: 54.4614\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.0445 - val_loss: 57.8266\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.0089 - val_loss: 51.6822\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.1990 - val_loss: 56.2622\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.5277 - val_loss: 52.4599\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.4409 - val_loss: 56.3493\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.1459 - val_loss: 56.5848\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.1466 - val_loss: 58.7165\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.1883 - val_loss: 56.6861\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 1.9095 - val_loss: 54.9362\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 1.8891 - val_loss: 53.6566\n",
      "\n",
      "Mean squared error: 1.9\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kat\\anaconda3\\envs\\tensor\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropout: 2.0e-01\n",
      "filter_num: 300\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 117us/sample - loss: 58.1773 - val_loss: 22.8887\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 44.1232 - val_loss: 21.4261\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 40.9330 - val_loss: 20.1248\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 36.9772 - val_loss: 21.1766\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 33.3079 - val_loss: 19.0621\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 29.6931 - val_loss: 19.2299\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 27.2079 - val_loss: 21.4766\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 24.8026 - val_loss: 21.5415\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 22.1552 - val_loss: 24.5026\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 19.4197 - val_loss: 24.2328\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 17.2135 - val_loss: 26.8157\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 14.7216 - val_loss: 24.6665\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 12.8440 - val_loss: 29.4205\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 10.9398 - val_loss: 28.8462\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 8.9762 - val_loss: 29.5525\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 8.4363 - val_loss: 25.4257\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 8.3272 - val_loss: 28.6835\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 7.5101 - val_loss: 25.4512\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 6.8907 - val_loss: 25.6569\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.8541 - val_loss: 30.2448\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.5764 - val_loss: 25.1439\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.9182 - val_loss: 26.7066\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.4315 - val_loss: 27.7694\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.2846 - val_loss: 24.7012\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.5323 - val_loss: 27.5247\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.6613 - val_loss: 24.4290\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.0429 - val_loss: 27.5504\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 4.2294 - val_loss: 24.6800\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 5.5338 - val_loss: 26.8859\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.5890 - val_loss: 27.3412\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 6.1181 - val_loss: 27.2976\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 6.3658 - val_loss: 26.0412\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.6632 - val_loss: 26.5610\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.7186 - val_loss: 25.1217\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.1350 - val_loss: 23.8544\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.7957 - val_loss: 25.8312\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 3.5679 - val_loss: 22.8886\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 3.5962 - val_loss: 26.9379\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.5157 - val_loss: 23.9955\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 3.1349 - val_loss: 26.1679\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 2.9730 - val_loss: 23.4676\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 3.0745 - val_loss: 26.2504\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 2.8948 - val_loss: 23.9332\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 2.6652 - val_loss: 26.1262\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 2.6026 - val_loss: 25.4906\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 2.7208 - val_loss: 23.4168\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 2.8181 - val_loss: 23.1995\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.4823 - val_loss: 23.2056\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 2.2926 - val_loss: 24.6924\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 2.2378 - val_loss: 23.8660\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 2.0756 - val_loss: 23.9376\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 2.0352 - val_loss: 24.3503\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 1.7894 - val_loss: 24.5296\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 1.8149 - val_loss: 25.5981\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 1.9642 - val_loss: 23.6529\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.9775 - val_loss: 24.9350\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.1513 - val_loss: 25.0743\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.0643 - val_loss: 25.7912\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.3373 - val_loss: 23.9608\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.0707 - val_loss: 25.7267\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.8303 - val_loss: 23.8082\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.8907 - val_loss: 27.1524\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.9469 - val_loss: 24.3827\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.7214 - val_loss: 24.4722\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.2232 - val_loss: 24.5287\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.9870 - val_loss: 26.9751\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.0021 - val_loss: 26.3390\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.8802 - val_loss: 25.7958\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.7073 - val_loss: 23.8219\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.3299 - val_loss: 25.7848\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.8918 - val_loss: 22.7583\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.9639 - val_loss: 25.9623\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.9996 - val_loss: 24.5083\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.7600 - val_loss: 24.6079\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.8374 - val_loss: 23.2056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.9197 - val_loss: 24.9771\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 1.5592 - val_loss: 25.4221\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.5469 - val_loss: 25.9567\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.3779 - val_loss: 24.8892\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.3343 - val_loss: 23.7360\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.3435 - val_loss: 25.8406\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.6728 - val_loss: 25.8113\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.7147 - val_loss: 26.2297\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.7643 - val_loss: 24.9602\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.3371 - val_loss: 25.5339\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.1913 - val_loss: 25.7581\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.3722 - val_loss: 24.2117\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.1461 - val_loss: 24.4312\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.4677 - val_loss: 23.5690\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.1995 - val_loss: 24.4730\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.2160 - val_loss: 24.0565\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 1.1875 - val_loss: 24.0293\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.0572 - val_loss: 24.3864\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.0246 - val_loss: 23.5919\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.0424 - val_loss: 23.7557\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.2168 - val_loss: 24.3276\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.0859 - val_loss: 23.5486\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.2121 - val_loss: 25.0024\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.2311 - val_loss: 24.3662\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.8088 - val_loss: 27.2117\n",
      "\n",
      "Mean squared error: 1.8\n",
      "\n",
      "dropout: 2.0e-01\n",
      "filter_num: 214\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 109us/sample - loss: 58.5735 - val_loss: 24.0143\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 43.6664 - val_loss: 23.6582\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 40.6034 - val_loss: 20.5171\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 37.3864 - val_loss: 20.7334\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 34.2800 - val_loss: 19.0252\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 32.0476 - val_loss: 18.5986\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 29.1198 - val_loss: 19.7701\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 26.3345 - val_loss: 20.6757\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 24.8319 - val_loss: 22.4467\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 22.2261 - val_loss: 22.6199\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 20.4272 - val_loss: 22.6963\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 18.5808 - val_loss: 27.2987\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 15.6036 - val_loss: 23.8756\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 14.2685 - val_loss: 31.3491\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 12.5300 - val_loss: 24.5360\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 11.3548 - val_loss: 31.9925\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 9.2575 - val_loss: 27.9064\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 8.0772 - val_loss: 30.5382\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 7.5615 - val_loss: 27.5958\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 7.0489 - val_loss: 26.2499\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 7.5447 - val_loss: 32.2310\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 6.5538 - val_loss: 23.2751\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 12.1060 - val_loss: 25.2318\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 8.7645 - val_loss: 23.8504\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 7.0271 - val_loss: 23.3023\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 6.2755 - val_loss: 26.8573\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 5.3563 - val_loss: 23.8738\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 5.4161 - val_loss: 28.2752\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 5.2095 - val_loss: 24.3036\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 4.5108 - val_loss: 25.6182\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.5985 - val_loss: 24.3763\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.9067 - val_loss: 26.1364\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.8409 - val_loss: 25.6140\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.6347 - val_loss: 24.8753\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.3841 - val_loss: 25.0883\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.1591 - val_loss: 25.0629\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.1824 - val_loss: 23.7721\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.1169 - val_loss: 24.2685\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.7253 - val_loss: 24.6128\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.2323 - val_loss: 25.1012\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.1962 - val_loss: 24.1812\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.0713 - val_loss: 25.9343\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.4067 - val_loss: 24.2085\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.5777 - val_loss: 24.5316\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.6881 - val_loss: 24.2121\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.9754 - val_loss: 24.9685\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.6087 - val_loss: 24.3679\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.3941 - val_loss: 26.5641\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.2756 - val_loss: 25.1473\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.3865 - val_loss: 25.1173\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.3197 - val_loss: 23.4503\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.3129 - val_loss: 24.2772\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.2028 - val_loss: 25.5175\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.1233 - val_loss: 26.4631\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.2357 - val_loss: 26.3443\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.4497 - val_loss: 24.2304\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.6845 - val_loss: 22.9361\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.0009 - val_loss: 23.6706\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.7795 - val_loss: 24.7808\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.3034 - val_loss: 24.0307\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.2632 - val_loss: 24.9958\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.2875 - val_loss: 24.8550\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.9398 - val_loss: 25.6464\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.0026 - val_loss: 25.5329\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.1338 - val_loss: 22.9817\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.5307 - val_loss: 23.2261\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.1804 - val_loss: 23.1120\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.2372 - val_loss: 25.3964\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.8069 - val_loss: 24.8285\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.9019 - val_loss: 22.9196\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.8262 - val_loss: 24.8148\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.5217 - val_loss: 24.5235\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.3117 - val_loss: 26.1147\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.8558 - val_loss: 25.3043\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.6594 - val_loss: 26.2967\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.0200 - val_loss: 23.2367\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.9476 - val_loss: 22.9463\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.2383 - val_loss: 21.7633\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.1843 - val_loss: 22.8796\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.2764 - val_loss: 27.9952\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 8.9256 - val_loss: 25.1537\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 12.8348 - val_loss: 23.0641\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 6.4760 - val_loss: 27.6994\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.7375 - val_loss: 24.9687\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 5.7781 - val_loss: 29.3364\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 5.3790 - val_loss: 24.6538\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 4.1364 - val_loss: 25.4312\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.5562 - val_loss: 24.2030\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.6196 - val_loss: 27.6491\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.5824 - val_loss: 25.4492\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.4588 - val_loss: 25.5421\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.0466 - val_loss: 26.4514\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.2727 - val_loss: 23.4209\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.6044 - val_loss: 24.6766\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.0317 - val_loss: 23.6826\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.6086 - val_loss: 22.9477\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.0623 - val_loss: 24.0945\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.3986 - val_loss: 24.3227\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.5295 - val_loss: 24.8747\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.4339 - val_loss: 23.1701\n",
      "\n",
      "Mean squared error: 1.4\n",
      "\n",
      "dropout: 2.4e-01\n",
      "filter_num: 300\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 115us/sample - loss: 58.1661 - val_loss: 23.3068\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 46.2286 - val_loss: 22.3905\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 40.9167 - val_loss: 20.5749\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 37.9871 - val_loss: 20.7987\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 35.1781 - val_loss: 19.1203\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 32.1032 - val_loss: 18.7061\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 29.3817 - val_loss: 19.5235\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 26.4218 - val_loss: 20.0869\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 24.5778 - val_loss: 25.6304\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 25.0415 - val_loss: 22.7824\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 20.4953 - val_loss: 25.8687\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 18.9602 - val_loss: 24.5483\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 15.7348 - val_loss: 23.5004\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 13.5212 - val_loss: 22.4571\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 12.9837 - val_loss: 24.9165\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 11.0653 - val_loss: 23.7379\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 10.2687 - val_loss: 27.5869\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 8.9219 - val_loss: 25.6044\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 7.3787 - val_loss: 25.4169\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 7.2883 - val_loss: 26.3425\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.4485 - val_loss: 20.6715\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.5868 - val_loss: 30.7687\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 6.4101 - val_loss: 21.8560\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.2711 - val_loss: 25.5244\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.2980 - val_loss: 21.7058\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.9039 - val_loss: 25.7004\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.3931 - val_loss: 24.1777\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.7521 - val_loss: 26.9529\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.4458 - val_loss: 22.6345\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.0678 - val_loss: 23.6719\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.0882 - val_loss: 22.5656\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.9537 - val_loss: 22.6135\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.9178 - val_loss: 22.8432\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.6568 - val_loss: 23.9280\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.7036 - val_loss: 27.4546\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.8658 - val_loss: 23.6023\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.9316 - val_loss: 24.9314\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.7888 - val_loss: 21.3744\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.7132 - val_loss: 24.4870\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.8389 - val_loss: 21.0650\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.5852 - val_loss: 26.0469\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.9887 - val_loss: 21.4709\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.2779 - val_loss: 27.3601\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.2300 - val_loss: 20.5534\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.8415 - val_loss: 24.1653\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.7944 - val_loss: 21.5999\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.4599 - val_loss: 24.4753\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.5116 - val_loss: 21.8135\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.3019 - val_loss: 21.8677\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 2.2411 - val_loss: 22.6390\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.1233 - val_loss: 22.4286\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 2.1352 - val_loss: 19.7851\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 4.1097 - val_loss: 21.3443\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 5.7651 - val_loss: 21.2436\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 5.2810 - val_loss: 24.5566\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.8192 - val_loss: 20.3499\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 5.5145 - val_loss: 29.7863\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 12.3146 - val_loss: 22.2901\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 12.4554 - val_loss: 20.4791\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 6.8365 - val_loss: 26.3278\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 3.5750 - val_loss: 19.7400\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 3.6788 - val_loss: 21.9162\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 3.0536 - val_loss: 21.7898\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 2.2942 - val_loss: 22.3627\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 2.0410 - val_loss: 23.9031\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 1.7583 - val_loss: 22.5924\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 1.9048 - val_loss: 23.0647\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 1.7380 - val_loss: 21.8100\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.6773 - val_loss: 22.1329\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.0678 - val_loss: 22.9038\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.2482 - val_loss: 22.5453\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 2.0929 - val_loss: 24.3998\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.1758 - val_loss: 22.3824\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.0787 - val_loss: 22.3437\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.9198 - val_loss: 23.3022\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.8342 - val_loss: 21.6586\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.1842 - val_loss: 22.1454\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.2771 - val_loss: 20.4617\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.7289 - val_loss: 22.0832\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.9740 - val_loss: 21.9039\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 1.5147 - val_loss: 23.2019\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.5362 - val_loss: 23.7917\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.5350 - val_loss: 23.1554\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.3900 - val_loss: 23.1853\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.4713 - val_loss: 22.4370\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.5093 - val_loss: 23.9477\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.6373 - val_loss: 22.3810\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.7207 - val_loss: 23.5020\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.3263 - val_loss: 22.5748\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.1733 - val_loss: 22.5857\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.3093 - val_loss: 21.8964\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.2255 - val_loss: 22.4053\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.5349 - val_loss: 22.7573\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.2156 - val_loss: 22.5104\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.3296 - val_loss: 23.0403\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.2760 - val_loss: 22.9856\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.2748 - val_loss: 23.5356\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.3120 - val_loss: 22.8916\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.2719 - val_loss: 23.9780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.3835 - val_loss: 21.9395\n",
      "\n",
      "Mean squared error: 1.4\n",
      "\n",
      "dropout: 2.5e-01\n",
      "filter_num: 80\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 101us/sample - loss: 63.4727 - val_loss: 35.7689\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 59.2701 - val_loss: 30.1754\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 50.6169 - val_loss: 22.1630\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 40.6644 - val_loss: 23.0658\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 38.2239 - val_loss: 20.0163\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 35.0294 - val_loss: 19.1312\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 33.6882 - val_loss: 18.9390\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 32.3697 - val_loss: 20.2952\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 31.2513 - val_loss: 19.1751\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 30.1938 - val_loss: 18.8744\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 28.6002 - val_loss: 20.1074\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 27.1572 - val_loss: 20.0691\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 25.9836 - val_loss: 20.1703\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 24.7180 - val_loss: 21.3792\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 24.0421 - val_loss: 22.3367\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 23.4357 - val_loss: 22.2035\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 22.9027 - val_loss: 21.9834\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 22.3817 - val_loss: 26.7656\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 20.6872 - val_loss: 32.6550\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 19.6678 - val_loss: 27.5037\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 18.5496 - val_loss: 30.6536\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 18.0000 - val_loss: 38.4736\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 16.7797 - val_loss: 37.5316\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 14.9779 - val_loss: 43.6885\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 13.5102 - val_loss: 53.6171\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 11.8613 - val_loss: 59.0757\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 10.5829 - val_loss: 70.4847\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 9.8515 - val_loss: 77.8737\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 9.1598 - val_loss: 88.6946\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 8.4458 - val_loss: 106.3666\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 7.3197 - val_loss: 112.5546\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 6.5404 - val_loss: 120.8431\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 6.2374 - val_loss: 110.5190\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 6.7220 - val_loss: 120.1987\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 6.1786 - val_loss: 122.2084\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 5.3988 - val_loss: 125.2840\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 5.9125 - val_loss: 120.1445\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 5.5494 - val_loss: 103.5649\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 6.1604 - val_loss: 105.6270\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 5.5478 - val_loss: 112.3661\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 6.4990 - val_loss: 118.3235\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 6.6761 - val_loss: 127.1063\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 5.0555 - val_loss: 121.3909\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 5.1025 - val_loss: 114.8586\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 4.6766 - val_loss: 117.6867\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 4.6146 - val_loss: 124.3483\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 4.9434 - val_loss: 135.3481\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 4.8696 - val_loss: 144.5997\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 4.3611 - val_loss: 157.9204\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 6.6284 - val_loss: 137.5809\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 4.5621 - val_loss: 130.7862\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 3.9754 - val_loss: 127.2308\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 3.8147 - val_loss: 123.4287\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 3.8341 - val_loss: 120.6988\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 3.6591 - val_loss: 124.1532\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 3.8467 - val_loss: 121.6830\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 3.5906 - val_loss: 126.9565\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 3.7949 - val_loss: 133.9488\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 3.1943 - val_loss: 134.9464\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 3.0831 - val_loss: 128.1940\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 3.7261 - val_loss: 121.2193\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 3.2213 - val_loss: 124.4348\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 3.0532 - val_loss: 126.4303\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 3.0872 - val_loss: 130.6860\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 3.0589 - val_loss: 130.5953\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 2.9119 - val_loss: 133.8450\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 2.6154 - val_loss: 128.7034\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 2.9154 - val_loss: 127.1639\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 2.5691 - val_loss: 125.4039\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 3.1077 - val_loss: 124.0209\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 2.7393 - val_loss: 125.0714\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 2.9445 - val_loss: 123.3643\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 3.1997 - val_loss: 130.8240\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 13us/sample - loss: 2.9679 - val_loss: 131.9445\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 2.6159 - val_loss: 139.2030\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 2.8818 - val_loss: 143.6991\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 3.0836 - val_loss: 129.4737\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 3.0487 - val_loss: 133.9310\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 2.5250 - val_loss: 135.4249\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 2.6626 - val_loss: 143.2401\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 2.5734 - val_loss: 143.4028\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 2.5500 - val_loss: 133.9684\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 2.4208 - val_loss: 138.0077\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 2.2696 - val_loss: 125.4677\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 2.8810 - val_loss: 128.5186\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 2.9986 - val_loss: 111.6471\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 5.0001 - val_loss: 88.3655\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 4.6568 - val_loss: 89.6418\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 5.2257 - val_loss: 82.7947\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 5.5512 - val_loss: 107.8501\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 5.0014 - val_loss: 105.8851\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 4.6819 - val_loss: 123.8456\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 2.8087 - val_loss: 120.6298\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 3.3010 - val_loss: 120.2710\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 3.2898 - val_loss: 124.4255\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 2.7897 - val_loss: 129.3100\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 3.2700 - val_loss: 130.3590\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 3.4923 - val_loss: 117.7830\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 3.8035 - val_loss: 125.4265\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 3.4344 - val_loss: 111.5114\n",
      "\n",
      "Mean squared error: 3.4\n",
      "\n",
      "Best solution:\n",
      "[0.20000000000000004, 300, 1]\n",
      "\n",
      "Score:\n",
      "45.14787027912755\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_mean_squared_error = 9999999999999999\n",
    "default_parameters =[0.6, 200, 5]\n",
    "#dropout, filter_num, num_dense_layers\n",
    "print_and_plot(default_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7a87a1",
   "metadata": {},
   "source": [
    "# Initial conditions try 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b6e37e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load and split data\n",
    "x_train_pre, x_test_pre, y_train, y_test = train_test_split(X, Y, test_size=0.15)\n",
    "scaler = StandardScaler().fit(x_train_pre) \n",
    "x_train = scaler.transform(x_train_pre) \n",
    "scaler = StandardScaler().fit(x_test_pre) \n",
    "x_test = scaler.transform(x_test_pre) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1ee582a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropout: 7.0e-01\n",
      "filter_num: 150\n",
      "num_dense_layers: 9\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 1s 304us/sample - loss: 55.8703 - val_loss: 59.5458\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 51.2360 - val_loss: 59.4567\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 42us/sample - loss: 49.5233 - val_loss: 59.2325\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 42us/sample - loss: 51.5397 - val_loss: 58.9469\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 45.1877 - val_loss: 58.6382\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 42us/sample - loss: 47.6917 - val_loss: 58.4266\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 42us/sample - loss: 46.6270 - val_loss: 58.2098\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 42us/sample - loss: 45.0342 - val_loss: 58.0100\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 42us/sample - loss: 45.9817 - val_loss: 57.7942\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 44.6076 - val_loss: 57.6279\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 45.1469 - val_loss: 57.4242\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 44.6657 - val_loss: 57.2257\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 43.8276 - val_loss: 57.0295\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 42.7363 - val_loss: 56.7510\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 45.1352 - val_loss: 56.5336\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 40.9420 - val_loss: 56.3223\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 39.2387 - val_loss: 56.0216\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 37.1753 - val_loss: 55.7326\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 43us/sample - loss: 40.3957 - val_loss: 55.7786\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 41.9922 - val_loss: 55.6798\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 38.6425 - val_loss: 55.2710\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 34.2446 - val_loss: 54.7100\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 35.6986 - val_loss: 54.5253\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 43us/sample - loss: 36.5803 - val_loss: 54.3745\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 42us/sample - loss: 32.2194 - val_loss: 54.0952\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 33.2060 - val_loss: 53.9547\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 32.1347 - val_loss: 53.7654\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 42us/sample - loss: 30.7825 - val_loss: 53.3461\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 35.4350 - val_loss: 53.3173\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 30.1493 - val_loss: 53.6267\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 42us/sample - loss: 35.7846 - val_loss: 53.2063\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 28.1166 - val_loss: 52.4006\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 29.3359 - val_loss: 51.9764\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 42us/sample - loss: 31.3322 - val_loss: 51.8907\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 29.4040 - val_loss: 51.6755\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 28.0799 - val_loss: 51.6479\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 30.1475 - val_loss: 51.2095\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 26.8006 - val_loss: 50.7492\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 42us/sample - loss: 25.8977 - val_loss: 50.3715\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 31.2910 - val_loss: 49.9756\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 28.5910 - val_loss: 49.7987\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 26.1714 - val_loss: 50.0527\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 27.5277 - val_loss: 49.9272\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 42us/sample - loss: 29.7474 - val_loss: 49.6912\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 25.4903 - val_loss: 49.4907\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 25.7168 - val_loss: 49.1320\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 42us/sample - loss: 26.5112 - val_loss: 49.2468\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 23.9927 - val_loss: 48.8876\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 24.3423 - val_loss: 48.3177\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 42us/sample - loss: 41.7218 - val_loss: 48.7216\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 42us/sample - loss: 29.4008 - val_loss: 49.2485\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 23.4098 - val_loss: 48.8718\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 42us/sample - loss: 25.5295 - val_loss: 48.2486\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 42us/sample - loss: 27.2319 - val_loss: 48.2456\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 25.2431 - val_loss: 47.8936\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 42us/sample - loss: 26.1553 - val_loss: 48.1194\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 42us/sample - loss: 25.8434 - val_loss: 48.0644\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 42us/sample - loss: 23.8012 - val_loss: 47.8628\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 42us/sample - loss: 32.0212 - val_loss: 47.4232\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 24.8725 - val_loss: 47.8065\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 25.7160 - val_loss: 48.2823\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 42us/sample - loss: 23.9020 - val_loss: 48.1144\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 43us/sample - loss: 28.4041 - val_loss: 48.0231\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 42us/sample - loss: 23.2762 - val_loss: 47.7125\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 31.8714 - val_loss: 47.9027\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 24.9996 - val_loss: 47.7984\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 23.6513 - val_loss: 47.7176\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 27.8694 - val_loss: 48.0352\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 28.6459 - val_loss: 49.0007\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 28.8039 - val_loss: 48.8865\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 30.7520 - val_loss: 48.1052\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 22.5936 - val_loss: 47.3773\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 22.7639 - val_loss: 47.1358\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 45us/sample - loss: 31.9679 - val_loss: 47.8231\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 40us/sample - loss: 26.8416 - val_loss: 48.1709\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 25.6921 - val_loss: 48.3167\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 26.0936 - val_loss: 47.9355\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 25.5151 - val_loss: 48.0427\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 25.6543 - val_loss: 48.6218\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 27.5396 - val_loss: 48.6927\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 26.1767 - val_loss: 48.6250\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 24.3847 - val_loss: 48.0583\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 24.5951 - val_loss: 47.7466\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 23.4713 - val_loss: 47.8952\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 23.3480 - val_loss: 48.2275\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 23.7559 - val_loss: 48.0916\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 22.3015 - val_loss: 47.7990\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 21.8987 - val_loss: 47.2520\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 42us/sample - loss: 26.1473 - val_loss: 47.6802\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 23.5533 - val_loss: 48.2605\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 23.3745 - val_loss: 48.3272\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 21.0727 - val_loss: 48.0019\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 22.2180 - val_loss: 47.4209\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 21.9737 - val_loss: 47.1034\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 37.4521 - val_loss: 48.3520\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 23.8232 - val_loss: 49.0465\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 30.3668 - val_loss: 48.9767\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 23.4772 - val_loss: 48.0414\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 23.5379 - val_loss: 47.3594\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 31.1596 - val_loss: 47.7047\n",
      "\n",
      "Mean squared error: 3.1e+01\n",
      "\n",
      "dropout: 3.9e-01\n",
      "filter_num: 277\n",
      "num_dense_layers: 16\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 1s 531us/sample - loss: 61.6650 - val_loss: 48.0947\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 127us/sample - loss: 56.3023 - val_loss: 58.4542\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 117us/sample - loss: 57.4029 - val_loss: 55.8968\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 119us/sample - loss: 47.2941 - val_loss: 52.5695\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 118us/sample - loss: 43.6572 - val_loss: 51.0989\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 114us/sample - loss: 42.9394 - val_loss: 50.0212\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 120us/sample - loss: 41.6307 - val_loss: 52.2599\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 114us/sample - loss: 38.9186 - val_loss: 48.2468\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 119us/sample - loss: 35.8510 - val_loss: 48.4027\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 117us/sample - loss: 34.4733 - val_loss: 52.0731\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 121us/sample - loss: 34.7400 - val_loss: 44.5665\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 118us/sample - loss: 35.0813 - val_loss: 50.9421\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 121us/sample - loss: 28.1685 - val_loss: 46.8136\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 119us/sample - loss: 28.6028 - val_loss: 48.2257\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 117us/sample - loss: 28.2157 - val_loss: 51.8406\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 117us/sample - loss: 30.5593 - val_loss: 39.6899\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 118us/sample - loss: 29.2775 - val_loss: 50.6538\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 116us/sample - loss: 26.7844 - val_loss: 40.9279\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 117us/sample - loss: 40.3665 - val_loss: 50.5755\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 117us/sample - loss: 26.9431 - val_loss: 38.7964\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 124us/sample - loss: 29.7831 - val_loss: 49.3410\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 118us/sample - loss: 26.9918 - val_loss: 43.9254\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 117us/sample - loss: 22.1203 - val_loss: 47.4490\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 119us/sample - loss: 21.7047 - val_loss: 41.6685\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 121us/sample - loss: 23.9119 - val_loss: 48.5348\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 118us/sample - loss: 23.8661 - val_loss: 41.9655\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 117us/sample - loss: 19.6399 - val_loss: 43.6972\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 115us/sample - loss: 20.8110 - val_loss: 48.1129\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 114us/sample - loss: 27.8197 - val_loss: 43.3205\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 118us/sample - loss: 21.1356 - val_loss: 48.7341\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 118us/sample - loss: 27.7176 - val_loss: 41.3723\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 117us/sample - loss: 18.9193 - val_loss: 44.3531\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 116us/sample - loss: 20.0682 - val_loss: 44.9775\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 120us/sample - loss: 16.7933 - val_loss: 42.5914\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 120us/sample - loss: 23.2506 - val_loss: 48.5959\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 116us/sample - loss: 23.6585 - val_loss: 45.3011\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 120us/sample - loss: 19.1193 - val_loss: 40.9538\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 114us/sample - loss: 20.3594 - val_loss: 46.4550\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 121us/sample - loss: 19.6301 - val_loss: 41.7197\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 117us/sample - loss: 18.0167 - val_loss: 40.7326\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 114us/sample - loss: 28.4608 - val_loss: 51.2105\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 121us/sample - loss: 38.3453 - val_loss: 40.9365\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 117us/sample - loss: 29.8626 - val_loss: 47.1830\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 118us/sample - loss: 26.0371 - val_loss: 37.8327\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 118us/sample - loss: 24.5423 - val_loss: 45.6012\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 118us/sample - loss: 22.9938 - val_loss: 41.1336\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 123us/sample - loss: 19.9670 - val_loss: 41.6927\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 117us/sample - loss: 29.9513 - val_loss: 48.0650\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 121us/sample - loss: 22.1092 - val_loss: 36.9585\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 113us/sample - loss: 27.9448 - val_loss: 47.4420\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 116us/sample - loss: 21.2376 - val_loss: 40.0274\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 121us/sample - loss: 19.5716 - val_loss: 44.7359\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 126us/sample - loss: 20.0511 - val_loss: 37.5284\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 130us/sample - loss: 31.2294 - val_loss: 48.7496\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 128us/sample - loss: 27.9038 - val_loss: 37.5868\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 125us/sample - loss: 27.4375 - val_loss: 50.0311\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 117us/sample - loss: 40.4099 - val_loss: 46.7250\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 117us/sample - loss: 23.5084 - val_loss: 41.9243\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 120us/sample - loss: 24.9984 - val_loss: 45.1809\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 110us/sample - loss: 41.3972 - val_loss: 45.8989\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 115us/sample - loss: 27.2119 - val_loss: 40.6375\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 116us/sample - loss: 22.5839 - val_loss: 44.9358\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 122us/sample - loss: 32.8229 - val_loss: 44.8972\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 117us/sample - loss: 25.4423 - val_loss: 37.5355\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 116us/sample - loss: 24.4232 - val_loss: 44.7395\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 118us/sample - loss: 24.6027 - val_loss: 41.2679\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 116us/sample - loss: 21.5288 - val_loss: 43.0995\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 117us/sample - loss: 31.7865 - val_loss: 44.6304\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 119us/sample - loss: 18.9631 - val_loss: 38.4868\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 119us/sample - loss: 40.9769 - val_loss: 49.1815\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 114us/sample - loss: 30.7667 - val_loss: 37.5690\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 116us/sample - loss: 31.7593 - val_loss: 50.6947\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 121us/sample - loss: 34.2032 - val_loss: 42.7527\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 112us/sample - loss: 39.5657 - val_loss: 50.4349\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 116us/sample - loss: 49.8023 - val_loss: 53.0570\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 117us/sample - loss: 53.4151 - val_loss: 51.6906\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 120us/sample - loss: 48.8176 - val_loss: 43.7471\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 118us/sample - loss: 33.5247 - val_loss: 42.2696\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 116us/sample - loss: 35.3001 - val_loss: 46.6719\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 120us/sample - loss: 27.6744 - val_loss: 42.0239\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 117us/sample - loss: 43.5957 - val_loss: 45.7860\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 117us/sample - loss: 31.8875 - val_loss: 42.8242\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 117us/sample - loss: 25.1827 - val_loss: 42.1206\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 123us/sample - loss: 20.6155 - val_loss: 43.2228\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 122us/sample - loss: 19.2763 - val_loss: 42.9523\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 116us/sample - loss: 21.4387 - val_loss: 45.2998\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 121us/sample - loss: 19.4320 - val_loss: 43.1885\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 116us/sample - loss: 22.2925 - val_loss: 44.0359\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 117us/sample - loss: 22.6245 - val_loss: 41.3209\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 117us/sample - loss: 19.1790 - val_loss: 44.9611\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 113us/sample - loss: 17.5304 - val_loss: 41.6659\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 116us/sample - loss: 19.2368 - val_loss: 45.1636\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 116us/sample - loss: 20.3814 - val_loss: 40.0335\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 121us/sample - loss: 27.3451 - val_loss: 46.5082\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 117us/sample - loss: 21.7874 - val_loss: 40.5835\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 116us/sample - loss: 26.0320 - val_loss: 46.3430\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 119us/sample - loss: 23.6448 - val_loss: 41.4209\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 117us/sample - loss: 19.1586 - val_loss: 42.5559\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 117us/sample - loss: 20.0349 - val_loss: 44.2543\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 115us/sample - loss: 23.3528 - val_loss: 40.8197\n",
      "\n",
      "Mean squared error: 2.3e+01\n",
      "\n",
      "dropout: 2.9e-01\n",
      "filter_num: 131\n",
      "num_dense_layers: 15\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 1s 418us/sample - loss: 63.8877 - val_loss: 54.0561\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 58us/sample - loss: 49.4282 - val_loss: 54.4463\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 56us/sample - loss: 50.3497 - val_loss: 49.5632\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 42.7396 - val_loss: 46.7005\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 41.6577 - val_loss: 46.3352\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 61us/sample - loss: 36.9466 - val_loss: 41.1681\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 36.8802 - val_loss: 45.8835\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 60us/sample - loss: 33.3282 - val_loss: 43.4118\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 56us/sample - loss: 32.2975 - val_loss: 45.4754\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 33.3104 - val_loss: 42.9445\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 30.3976 - val_loss: 41.7452\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 59us/sample - loss: 30.2123 - val_loss: 45.0199\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 56us/sample - loss: 24.7937 - val_loss: 42.0134\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 24.4081 - val_loss: 43.1214\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 57us/sample - loss: 26.3799 - val_loss: 46.3975\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 56us/sample - loss: 25.5227 - val_loss: 40.2744\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 56us/sample - loss: 25.9219 - val_loss: 45.5847\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 21.0132 - val_loss: 43.2513\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 27.0155 - val_loss: 48.1301\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 30.6195 - val_loss: 40.3282\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 56us/sample - loss: 24.7381 - val_loss: 43.6921\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 24.4824 - val_loss: 43.2338\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 30.0906 - val_loss: 41.9432\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 21.0857 - val_loss: 41.7039\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 18.4934 - val_loss: 38.3864\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 17.9287 - val_loss: 45.0042\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 19.5863 - val_loss: 37.4971\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 23.0387 - val_loss: 44.1845\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 18.0264 - val_loss: 37.5832\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 56us/sample - loss: 24.8589 - val_loss: 43.6112\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 19.8407 - val_loss: 37.4316\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 18.2781 - val_loss: 43.4841\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 15.3956 - val_loss: 39.8574\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 14.6938 - val_loss: 41.0263\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 56us/sample - loss: 18.6494 - val_loss: 44.5997\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 20.3169 - val_loss: 37.9358\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 21.0206 - val_loss: 46.9432\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 57us/sample - loss: 27.2039 - val_loss: 43.2775\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 19.4366 - val_loss: 38.7214\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 19.2734 - val_loss: 43.9786\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 15.9928 - val_loss: 39.4110\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 60us/sample - loss: 17.2033 - val_loss: 42.0142\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 16.5803 - val_loss: 41.1120\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 58us/sample - loss: 18.5383 - val_loss: 41.6376\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 13.5727 - val_loss: 39.4500\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 18.5051 - val_loss: 45.1817\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 59us/sample - loss: 19.4274 - val_loss: 38.0523\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 16.5453 - val_loss: 41.0733\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 58us/sample - loss: 18.5824 - val_loss: 42.6171\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 56us/sample - loss: 23.5550 - val_loss: 43.5671\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 19.6485 - val_loss: 40.3881\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 19.0521 - val_loss: 42.9128\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 56us/sample - loss: 23.1382 - val_loss: 41.2284\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 15.8186 - val_loss: 37.6065\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 16.7740 - val_loss: 41.7336\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 13.4766 - val_loss: 41.9271\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 17.6935 - val_loss: 42.0266\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 14.8560 - val_loss: 41.7797\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 20.2528 - val_loss: 46.0871\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 60us/sample - loss: 22.6283 - val_loss: 35.8732\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 15.9836 - val_loss: 43.4680\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 15.8432 - val_loss: 37.3077\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 33.4084 - val_loss: 50.4407\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 60us/sample - loss: 41.0636 - val_loss: 48.8392\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 27.2748 - val_loss: 36.2657\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 21.0070 - val_loss: 44.3245\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 22.5819 - val_loss: 40.6863\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 57us/sample - loss: 18.3019 - val_loss: 43.1686\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 19.9855 - val_loss: 40.3538\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 17.1295 - val_loss: 41.5418\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 59us/sample - loss: 15.9278 - val_loss: 41.3498\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 58us/sample - loss: 16.8636 - val_loss: 41.4606\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 14.2943 - val_loss: 41.4478\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 14.8757 - val_loss: 41.1880\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 59us/sample - loss: 15.1337 - val_loss: 41.8771\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 58us/sample - loss: 13.1295 - val_loss: 43.4408\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 59us/sample - loss: 15.1099 - val_loss: 41.3204\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 58us/sample - loss: 13.7079 - val_loss: 43.4526\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 65us/sample - loss: 12.0160 - val_loss: 39.9092\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 60us/sample - loss: 11.3060 - val_loss: 44.2024\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 61us/sample - loss: 14.0039 - val_loss: 40.3862\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 59us/sample - loss: 15.3297 - val_loss: 44.4560\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 59us/sample - loss: 13.2699 - val_loss: 39.9873\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 11.7022 - val_loss: 41.6342\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 11.7889 - val_loss: 41.1478\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 58us/sample - loss: 16.3161 - val_loss: 44.6577\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 14.9835 - val_loss: 39.9524\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 14.0875 - val_loss: 43.1156\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 60us/sample - loss: 12.9825 - val_loss: 40.9904\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 57us/sample - loss: 11.0122 - val_loss: 42.3183\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 14.2539 - val_loss: 44.1960\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 12.2587 - val_loss: 41.4705\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 11.2548 - val_loss: 40.0747\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 12.7371 - val_loss: 41.7534\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 14.3618 - val_loss: 41.9873\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 57us/sample - loss: 13.9750 - val_loss: 40.1328\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 14.0639 - val_loss: 43.9497\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 23.6201 - val_loss: 44.9322\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 18.2659 - val_loss: 41.3241\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 33.9665 - val_loss: 45.9970\n",
      "\n",
      "Mean squared error: 3.4e+01\n",
      "\n",
      "dropout: 2.1e-01\n",
      "filter_num: 255\n",
      "num_dense_layers: 13\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 1s 406us/sample - loss: 61.2223 - val_loss: 41.3046\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 92us/sample - loss: 52.7933 - val_loss: 57.4697\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 90us/sample - loss: 59.9960 - val_loss: 53.0089\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 95us/sample - loss: 48.2006 - val_loss: 43.9817\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 87us/sample - loss: 44.6619 - val_loss: 39.4136\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 90us/sample - loss: 38.8577 - val_loss: 35.5410\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 88us/sample - loss: 35.8727 - val_loss: 32.6853\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 90us/sample - loss: 37.3574 - val_loss: 39.5870\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 89us/sample - loss: 33.2186 - val_loss: 34.6101\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 88us/sample - loss: 26.4028 - val_loss: 34.9585\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 88us/sample - loss: 22.0988 - val_loss: 36.1905\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 93us/sample - loss: 21.0503 - val_loss: 37.9228\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 89us/sample - loss: 18.9058 - val_loss: 39.0885\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 88us/sample - loss: 18.8009 - val_loss: 38.7896\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 90us/sample - loss: 16.0726 - val_loss: 40.6901\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 87us/sample - loss: 17.5960 - val_loss: 41.7908\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 90us/sample - loss: 18.5911 - val_loss: 43.0220\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 86us/sample - loss: 13.6651 - val_loss: 40.5824\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 89us/sample - loss: 17.9966 - val_loss: 44.0031\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 89us/sample - loss: 21.8519 - val_loss: 44.0506\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 90us/sample - loss: 20.0134 - val_loss: 42.2257\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 87us/sample - loss: 19.7680 - val_loss: 44.2011\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 89us/sample - loss: 30.6940 - val_loss: 41.4626\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 88us/sample - loss: 16.1176 - val_loss: 37.4512\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 91us/sample - loss: 14.2566 - val_loss: 38.1214\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 89us/sample - loss: 13.0703 - val_loss: 40.0890\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 88us/sample - loss: 12.8102 - val_loss: 42.4738\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 90us/sample - loss: 18.6710 - val_loss: 61.9283\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 87us/sample - loss: 25.4970 - val_loss: 41.2582\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 88us/sample - loss: 21.5500 - val_loss: 41.4803\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 89us/sample - loss: 16.5193 - val_loss: 41.3809\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 86us/sample - loss: 12.2229 - val_loss: 40.1273\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 94us/sample - loss: 12.7499 - val_loss: 37.1077\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 93us/sample - loss: 8.5894 - val_loss: 36.2762\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 101us/sample - loss: 8.4037 - val_loss: 36.3871\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 96us/sample - loss: 8.7329 - val_loss: 36.7302\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 101us/sample - loss: 10.5000 - val_loss: 37.1184\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 99us/sample - loss: 11.3277 - val_loss: 37.9407\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 93us/sample - loss: 32.8665 - val_loss: 44.6276\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 87us/sample - loss: 24.1271 - val_loss: 34.2370\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 89us/sample - loss: 14.2830 - val_loss: 38.0292\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 92us/sample - loss: 11.6911 - val_loss: 38.0709\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 86us/sample - loss: 11.5569 - val_loss: 35.6389\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 87us/sample - loss: 8.9853 - val_loss: 37.6064\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 90us/sample - loss: 8.9664 - val_loss: 41.6707\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 89us/sample - loss: 14.6019 - val_loss: 39.6916\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 90us/sample - loss: 13.0519 - val_loss: 34.6569\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 90us/sample - loss: 14.5533 - val_loss: 35.6229\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 91us/sample - loss: 11.1084 - val_loss: 36.5538\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 88us/sample - loss: 9.5073 - val_loss: 38.0867\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 87us/sample - loss: 13.0350 - val_loss: 36.2518\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 90us/sample - loss: 8.4976 - val_loss: 36.7089\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 87us/sample - loss: 10.1246 - val_loss: 38.3314\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 90us/sample - loss: 7.1946 - val_loss: 37.3343\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 94us/sample - loss: 10.8751 - val_loss: 40.5428\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 92us/sample - loss: 10.2472 - val_loss: 39.7194\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 91us/sample - loss: 9.0084 - val_loss: 38.6628\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 94us/sample - loss: 8.9335 - val_loss: 39.5280\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 93us/sample - loss: 9.4466 - val_loss: 38.2321\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 90us/sample - loss: 7.1779 - val_loss: 40.6471\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 91us/sample - loss: 14.3951 - val_loss: 41.5607\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 92us/sample - loss: 14.4344 - val_loss: 39.5221\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 91us/sample - loss: 21.0576 - val_loss: 43.3930\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 91us/sample - loss: 23.0496 - val_loss: 36.9349\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 87us/sample - loss: 9.3469 - val_loss: 38.7227\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 92us/sample - loss: 8.9177 - val_loss: 41.8579\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 90us/sample - loss: 7.8679 - val_loss: 38.0965\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 94us/sample - loss: 8.0460 - val_loss: 43.5589\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 91us/sample - loss: 8.2651 - val_loss: 41.3758\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 92us/sample - loss: 7.4123 - val_loss: 36.5115\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 90us/sample - loss: 7.7005 - val_loss: 36.3891\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 87us/sample - loss: 7.2526 - val_loss: 39.3616\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 86us/sample - loss: 8.2771 - val_loss: 37.9145\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 92us/sample - loss: 9.9497 - val_loss: 40.0127\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 93us/sample - loss: 10.4981 - val_loss: 41.0662\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 88us/sample - loss: 17.7109 - val_loss: 36.0283\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 90us/sample - loss: 11.2712 - val_loss: 37.4548\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 90us/sample - loss: 15.6281 - val_loss: 36.3680\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 88us/sample - loss: 13.0735 - val_loss: 40.2564\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 92us/sample - loss: 38.9504 - val_loss: 48.3335\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 87us/sample - loss: 46.7223 - val_loss: 43.3476\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 89us/sample - loss: 35.8070 - val_loss: 34.7403\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 93us/sample - loss: 13.8266 - val_loss: 43.3748\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 94us/sample - loss: 46.9105 - val_loss: 49.5367\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 94us/sample - loss: 48.2891 - val_loss: 47.9498\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 89us/sample - loss: 47.4852 - val_loss: 44.0455\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 92us/sample - loss: 37.0976 - val_loss: 39.1385\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 89us/sample - loss: 19.2042 - val_loss: 41.5589\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 90us/sample - loss: 17.9235 - val_loss: 41.1355\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 91us/sample - loss: 14.0334 - val_loss: 47.0019\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 96us/sample - loss: 14.6182 - val_loss: 33.9144\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 90us/sample - loss: 15.6393 - val_loss: 38.9409\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 89us/sample - loss: 8.7754 - val_loss: 35.3101\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 92us/sample - loss: 10.7296 - val_loss: 37.9058\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 87us/sample - loss: 10.0438 - val_loss: 38.1811\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 93us/sample - loss: 7.8870 - val_loss: 42.8869\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 90us/sample - loss: 6.0079 - val_loss: 37.1386\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 86us/sample - loss: 9.0465 - val_loss: 40.5665\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 88us/sample - loss: 16.3309 - val_loss: 39.4968\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 90us/sample - loss: 25.3074 - val_loss: 35.2335\n",
      "\n",
      "Mean squared error: 2.5e+01\n",
      "\n",
      "dropout: 3.8e-01\n",
      "filter_num: 230\n",
      "num_dense_layers: 11\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 1s 340us/sample - loss: 62.0875 - val_loss: 48.3422\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 48.9148 - val_loss: 48.2465\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 65us/sample - loss: 45.4383 - val_loss: 49.5406\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 43.3879 - val_loss: 49.9705\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 64us/sample - loss: 42.9929 - val_loss: 47.2602\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 38.6702 - val_loss: 42.6488\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 67us/sample - loss: 36.0758 - val_loss: 41.3838\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 32.9933 - val_loss: 44.3849\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 65us/sample - loss: 32.7185 - val_loss: 40.4449\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 28.2269 - val_loss: 45.0024\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 24.3858 - val_loss: 38.5579\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 26.2846 - val_loss: 46.4737\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 23.0601 - val_loss: 43.4577\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 67us/sample - loss: 24.2923 - val_loss: 45.2199\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 65us/sample - loss: 21.7166 - val_loss: 43.2666\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 67us/sample - loss: 18.8662 - val_loss: 43.1448\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 61us/sample - loss: 22.3351 - val_loss: 39.4040\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 19.9733 - val_loss: 44.5383\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 15.7681 - val_loss: 42.0393\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 65us/sample - loss: 21.9831 - val_loss: 46.1722\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 67us/sample - loss: 19.2971 - val_loss: 41.5625\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 65us/sample - loss: 18.3869 - val_loss: 47.7290\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 65us/sample - loss: 19.8421 - val_loss: 43.6511\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 15.7963 - val_loss: 47.2831\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 65us/sample - loss: 19.0530 - val_loss: 44.2470\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 65us/sample - loss: 20.6206 - val_loss: 49.2040\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 18.6688 - val_loss: 44.5596\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 17.3762 - val_loss: 46.3122\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 14.9600 - val_loss: 42.8510\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 19.1725 - val_loss: 45.9757\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 65us/sample - loss: 18.0534 - val_loss: 43.0613\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 15.9153 - val_loss: 43.9278\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 65us/sample - loss: 15.1445 - val_loss: 44.0044\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 62us/sample - loss: 15.0618 - val_loss: 40.8407\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 14.7429 - val_loss: 43.3886\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 14.5507 - val_loss: 43.4954\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 67us/sample - loss: 12.2222 - val_loss: 43.3657\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 65us/sample - loss: 13.0483 - val_loss: 40.6170\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 65us/sample - loss: 15.2059 - val_loss: 41.3237\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 65us/sample - loss: 14.4760 - val_loss: 43.5772\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 12.3812 - val_loss: 40.9877\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 65us/sample - loss: 16.7257 - val_loss: 44.6953\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 15.8309 - val_loss: 43.4335\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 64us/sample - loss: 16.7995 - val_loss: 44.3404\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 64us/sample - loss: 19.0673 - val_loss: 42.0353\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 15.5855 - val_loss: 39.9271\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 67us/sample - loss: 14.9684 - val_loss: 44.1881\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 14.8100 - val_loss: 37.9448\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 65us/sample - loss: 14.3841 - val_loss: 42.3547\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 67us/sample - loss: 15.6031 - val_loss: 44.2090\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 16.6272 - val_loss: 37.6034\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 65us/sample - loss: 21.2742 - val_loss: 47.2163\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 65us/sample - loss: 19.4430 - val_loss: 39.2014\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 16.7869 - val_loss: 47.3336\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 65us/sample - loss: 17.9166 - val_loss: 40.5418\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 65us/sample - loss: 19.3278 - val_loss: 45.8123\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 67us/sample - loss: 18.4258 - val_loss: 38.3539\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 64us/sample - loss: 19.6914 - val_loss: 48.6295\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 65us/sample - loss: 28.9315 - val_loss: 42.8065\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 22.3253 - val_loss: 42.9324\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 13.8980 - val_loss: 40.1900\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 65us/sample - loss: 19.5278 - val_loss: 43.4203\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 20.7363 - val_loss: 44.0131\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 65us/sample - loss: 24.0478 - val_loss: 41.4969\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 65us/sample - loss: 18.8825 - val_loss: 41.8370\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 65us/sample - loss: 16.3062 - val_loss: 40.9943\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 13.5759 - val_loss: 40.9039\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 65us/sample - loss: 15.7438 - val_loss: 41.0148\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 14.4223 - val_loss: 41.3921\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 76us/sample - loss: 12.2122 - val_loss: 40.2593\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 72us/sample - loss: 12.8004 - val_loss: 40.8735\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 71us/sample - loss: 11.9178 - val_loss: 44.5457\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 72us/sample - loss: 27.3008 - val_loss: 48.5671\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 70us/sample - loss: 20.2657 - val_loss: 41.0569\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 22.3267 - val_loss: 45.9972\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 64us/sample - loss: 19.5545 - val_loss: 40.4691\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 74us/sample - loss: 19.8317 - val_loss: 45.8311\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 64us/sample - loss: 20.9545 - val_loss: 41.1074\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 18.4078 - val_loss: 43.3489\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 67us/sample - loss: 16.0347 - val_loss: 40.5225\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 65us/sample - loss: 17.4259 - val_loss: 43.4223\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 65us/sample - loss: 15.6144 - val_loss: 41.4409\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 67us/sample - loss: 11.3078 - val_loss: 41.1288\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 62us/sample - loss: 14.6198 - val_loss: 43.4250\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 10.8347 - val_loss: 42.7404\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 13.7068 - val_loss: 42.3088\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 67us/sample - loss: 11.6431 - val_loss: 42.5321\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 65us/sample - loss: 11.9784 - val_loss: 40.2995\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 35.4365 - val_loss: 48.7961\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 38.2804 - val_loss: 48.1748\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 65us/sample - loss: 23.3104 - val_loss: 36.9313\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 61us/sample - loss: 19.4749 - val_loss: 44.1444\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 18.7618 - val_loss: 42.5233\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 65us/sample - loss: 22.2325 - val_loss: 46.2433\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 18.1989 - val_loss: 40.6105\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 15.2454 - val_loss: 43.1014\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 15.0001 - val_loss: 42.1349\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 65us/sample - loss: 13.4676 - val_loss: 40.8615\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 65us/sample - loss: 14.9233 - val_loss: 42.1774\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 14.1349 - val_loss: 41.2636\n",
      "\n",
      "Mean squared error: 1.4e+01\n",
      "\n",
      "dropout: 3.9e-01\n",
      "filter_num: 28\n",
      "num_dense_layers: 20\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 1s 494us/sample - loss: 65.4804 - val_loss: 59.9323\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 65.1102 - val_loss: 59.7189\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 63.3397 - val_loss: 58.9751\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 58.4146 - val_loss: 57.0801\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 68.8082 - val_loss: 57.8917\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 57.1961 - val_loss: 58.0172\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 56.8626 - val_loss: 57.7524\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 55.6941 - val_loss: 57.4396\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 55.5964 - val_loss: 57.2594\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 54.3255 - val_loss: 57.1853\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 48.7281 - val_loss: 56.7533\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 52.5657 - val_loss: 56.6588\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 54.6627 - val_loss: 56.9242\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 51.8445 - val_loss: 56.5902\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 50.8128 - val_loss: 55.8310\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 49.4698 - val_loss: 55.2858\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 50.2617 - val_loss: 55.3441\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 38us/sample - loss: 47.9721 - val_loss: 55.1088\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 48.0518 - val_loss: 54.7556\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 54.1597 - val_loss: 55.4571\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 50.8178 - val_loss: 55.2993\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 49.2164 - val_loss: 54.5217\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 47.1876 - val_loss: 53.4576\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 45.0366 - val_loss: 52.5223\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 46.0502 - val_loss: 52.7433\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 57.8066 - val_loss: 53.4031\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 48.6057 - val_loss: 53.7597\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 48.0167 - val_loss: 53.3715\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 47.3273 - val_loss: 52.4319\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 48.4714 - val_loss: 51.6720\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 42.5140 - val_loss: 51.4035\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 42.8093 - val_loss: 51.2028\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 43.4124 - val_loss: 51.2885\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 41.2358 - val_loss: 51.0682\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 44.7191 - val_loss: 50.2188\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 45.3148 - val_loss: 50.3359\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 47.3665 - val_loss: 51.0780\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 45.9428 - val_loss: 51.6540\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 44.5406 - val_loss: 52.5651\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 46.6975 - val_loss: 52.3656\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 46.0173 - val_loss: 51.2613\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 45.2204 - val_loss: 49.3644\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 39.8000 - val_loss: 48.2907\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 41.2847 - val_loss: 49.0138\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 42.4538 - val_loss: 49.4819\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 39.1215 - val_loss: 48.9396\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 42.9483 - val_loss: 48.6224\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 43.7828 - val_loss: 48.9488\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 48.5425 - val_loss: 49.8271\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 41.2898 - val_loss: 49.8833\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 41.9995 - val_loss: 49.0897\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 42.5738 - val_loss: 48.3051\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 37.3151 - val_loss: 47.4786\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 42.5450 - val_loss: 47.9627\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 37.7392 - val_loss: 48.2255\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 38.6366 - val_loss: 47.5539\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 38.3478 - val_loss: 47.0440\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 37.9813 - val_loss: 46.9765\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 43.4522 - val_loss: 47.5745\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 33.3801 - val_loss: 47.9473\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 42.5748 - val_loss: 47.9936\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 35.9546 - val_loss: 48.1116\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 41.0399 - val_loss: 47.8447\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 38.2484 - val_loss: 47.2178\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 32.4742 - val_loss: 46.8023\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 41.6334 - val_loss: 47.1709\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 37.7320 - val_loss: 46.8090\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 54.3081 - val_loss: 47.5368\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 41.0875 - val_loss: 49.8980\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 47.8566 - val_loss: 50.4235\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 46.7063 - val_loss: 50.0758\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 46.2720 - val_loss: 49.2232\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 44.4814 - val_loss: 47.6365\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 41.1286 - val_loss: 46.3120\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 38.8452 - val_loss: 45.5958\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 40.8757 - val_loss: 45.9881\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 34.2479 - val_loss: 46.2732\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 35.4664 - val_loss: 46.1931\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 35.0084 - val_loss: 45.8570\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 35.2742 - val_loss: 45.6458\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 36.5100 - val_loss: 45.5083\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 33.5981 - val_loss: 45.7149\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 33.1525 - val_loss: 46.9531\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 38.9119 - val_loss: 47.1581\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 42.8509 - val_loss: 46.9610\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 37.2593 - val_loss: 46.2098\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 34.4057 - val_loss: 45.4049\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 37.5844 - val_loss: 45.0357\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 37.2093 - val_loss: 45.6066\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 35.3653 - val_loss: 46.0615\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 32.0671 - val_loss: 46.4667\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 35.8235 - val_loss: 46.8091\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 36us/sample - loss: 37.3086 - val_loss: 46.5543\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 40.4438 - val_loss: 46.0497\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 59.6277 - val_loss: 47.0943\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 40.3893 - val_loss: 47.4092\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 35.0926 - val_loss: 47.2653\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 35.7955 - val_loss: 46.6872\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 32.0946 - val_loss: 46.0289\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 38.3184 - val_loss: 45.7851\n",
      "\n",
      "Mean squared error: 3.8e+01\n",
      "\n",
      "dropout: 3.4e-01\n",
      "filter_num: 264\n",
      "num_dense_layers: 15\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 1s 457us/sample - loss: 60.0425 - val_loss: 50.5724\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 108us/sample - loss: 50.1938 - val_loss: 51.4382\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 103us/sample - loss: 46.0883 - val_loss: 53.8735\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 105us/sample - loss: 46.9806 - val_loss: 44.8686\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 101us/sample - loss: 42.7126 - val_loss: 47.2848\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 105us/sample - loss: 38.7397 - val_loss: 49.8114\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 103us/sample - loss: 41.6582 - val_loss: 42.2463\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 101us/sample - loss: 37.2530 - val_loss: 50.3367\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 105us/sample - loss: 35.7959 - val_loss: 43.6462\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 99us/sample - loss: 33.2514 - val_loss: 44.1992\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 101us/sample - loss: 29.4088 - val_loss: 48.3501\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 101us/sample - loss: 26.7292 - val_loss: 48.4450\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 99us/sample - loss: 32.1862 - val_loss: 35.3353\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 110us/sample - loss: 35.2586 - val_loss: 48.8475\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 108us/sample - loss: 26.2031 - val_loss: 44.2447\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 114us/sample - loss: 27.5687 - val_loss: 41.8346\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 110us/sample - loss: 26.6305 - val_loss: 48.3618\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 106us/sample - loss: 24.7456 - val_loss: 37.2008\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 105us/sample - loss: 19.2262 - val_loss: 46.2336\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 102us/sample - loss: 28.3505 - val_loss: 45.3605\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 98us/sample - loss: 30.5590 - val_loss: 38.5263\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 97us/sample - loss: 21.8199 - val_loss: 46.0178\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 101us/sample - loss: 25.0952 - val_loss: 40.0739\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 104us/sample - loss: 16.9651 - val_loss: 37.1413\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 100us/sample - loss: 21.3867 - val_loss: 48.0722\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 100us/sample - loss: 22.9917 - val_loss: 37.7857\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 100us/sample - loss: 22.1505 - val_loss: 46.1228\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 100us/sample - loss: 26.0467 - val_loss: 37.4760\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 99us/sample - loss: 20.2018 - val_loss: 40.2185\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 99us/sample - loss: 17.0125 - val_loss: 44.3553\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 103us/sample - loss: 17.9685 - val_loss: 41.2469\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 101us/sample - loss: 17.4879 - val_loss: 38.5183\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 96us/sample - loss: 17.4742 - val_loss: 38.7308\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 99us/sample - loss: 22.8527 - val_loss: 41.1010\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 98us/sample - loss: 18.7010 - val_loss: 39.4913\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 105us/sample - loss: 17.6770 - val_loss: 44.4196\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 97us/sample - loss: 21.6109 - val_loss: 41.2951\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 99us/sample - loss: 14.3821 - val_loss: 38.2798\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 104us/sample - loss: 15.3027 - val_loss: 43.2329\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 100us/sample - loss: 17.2085 - val_loss: 37.2434\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 100us/sample - loss: 18.7114 - val_loss: 42.5562\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 102us/sample - loss: 22.4149 - val_loss: 44.2107\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 98us/sample - loss: 24.9042 - val_loss: 35.1681\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 98us/sample - loss: 29.6123 - val_loss: 50.1751\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 98us/sample - loss: 30.7837 - val_loss: 37.2578\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 100us/sample - loss: 32.9013 - val_loss: 48.3133\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 99us/sample - loss: 28.9980 - val_loss: 34.2971\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 100us/sample - loss: 26.0050 - val_loss: 45.0004\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 100us/sample - loss: 26.9323 - val_loss: 41.2318\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 103us/sample - loss: 22.1555 - val_loss: 36.9211\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 100us/sample - loss: 19.5674 - val_loss: 36.7127\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 100us/sample - loss: 18.0870 - val_loss: 36.5518\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 102us/sample - loss: 18.8554 - val_loss: 43.6747\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 102us/sample - loss: 18.1199 - val_loss: 37.3540\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 105us/sample - loss: 34.5315 - val_loss: 42.7697\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 99us/sample - loss: 18.8397 - val_loss: 38.3408\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 105us/sample - loss: 25.9953 - val_loss: 46.2176\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 100us/sample - loss: 24.8853 - val_loss: 44.2971\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 99us/sample - loss: 35.4069 - val_loss: 48.1049\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 100us/sample - loss: 43.4293 - val_loss: 40.9773\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 105us/sample - loss: 27.4784 - val_loss: 48.6400\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 97us/sample - loss: 28.3689 - val_loss: 40.0251\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 101us/sample - loss: 26.5163 - val_loss: 42.8134\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 102us/sample - loss: 22.6920 - val_loss: 41.6577\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 97us/sample - loss: 23.8261 - val_loss: 42.6369\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 105us/sample - loss: 26.9651 - val_loss: 42.6174\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 99us/sample - loss: 24.3960 - val_loss: 38.0314\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 103us/sample - loss: 22.9047 - val_loss: 40.8480\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 100us/sample - loss: 21.9079 - val_loss: 38.4039\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 100us/sample - loss: 32.3807 - val_loss: 43.4530\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 99us/sample - loss: 22.9300 - val_loss: 37.7167\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 99us/sample - loss: 25.5161 - val_loss: 44.6827\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 99us/sample - loss: 20.0069 - val_loss: 38.4236\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 96us/sample - loss: 17.4196 - val_loss: 41.8076\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 96us/sample - loss: 18.3995 - val_loss: 41.4937\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 104us/sample - loss: 15.8955 - val_loss: 39.3148\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 106us/sample - loss: 22.7765 - val_loss: 45.6916\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 110us/sample - loss: 23.7503 - val_loss: 37.8279\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 114us/sample - loss: 17.4357 - val_loss: 41.7181\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 110us/sample - loss: 18.0216 - val_loss: 39.3242\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 101us/sample - loss: 21.3974 - val_loss: 41.1648\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 99us/sample - loss: 22.2305 - val_loss: 44.5897\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 101us/sample - loss: 26.3565 - val_loss: 40.3220\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 106us/sample - loss: 16.5828 - val_loss: 41.1497\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 100us/sample - loss: 19.1520 - val_loss: 41.1702\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 96us/sample - loss: 25.9472 - val_loss: 42.2923\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 99us/sample - loss: 20.3267 - val_loss: 41.5402\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 99us/sample - loss: 29.7098 - val_loss: 45.5816\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 99us/sample - loss: 22.2896 - val_loss: 42.4575\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 101us/sample - loss: 25.9291 - val_loss: 40.3980\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 99us/sample - loss: 17.2576 - val_loss: 39.3997\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 95us/sample - loss: 17.0895 - val_loss: 39.5652\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 99us/sample - loss: 18.1940 - val_loss: 41.3025\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 105us/sample - loss: 21.5690 - val_loss: 42.6379\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 101us/sample - loss: 17.2043 - val_loss: 43.1556\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 99us/sample - loss: 18.8853 - val_loss: 41.9750\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 100us/sample - loss: 30.6364 - val_loss: 48.2745\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 97us/sample - loss: 37.1166 - val_loss: 47.8204\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 100us/sample - loss: 23.9417 - val_loss: 40.8615\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 100us/sample - loss: 19.0557 - val_loss: 42.5900\n",
      "\n",
      "Mean squared error: 1.9e+01\n",
      "\n",
      "dropout: 5.1e-01\n",
      "filter_num: 89\n",
      "num_dense_layers: 8\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 1s 241us/sample - loss: 64.2198 - val_loss: 58.6151\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 54.5693 - val_loss: 49.2404\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 50.2756 - val_loss: 53.3722\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 49.1202 - val_loss: 55.1738\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 47.1386 - val_loss: 51.7611\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 45.7564 - val_loss: 49.1211\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 42.7673 - val_loss: 51.6651\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 44.4960 - val_loss: 52.4812\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 40.0897 - val_loss: 51.0355\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 38.8148 - val_loss: 48.6444\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 38.4322 - val_loss: 50.8976\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 36.6752 - val_loss: 52.0429\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 38.7221 - val_loss: 51.4630\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 35.4633 - val_loss: 49.5827\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 34.5163 - val_loss: 50.3247\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 38.2898 - val_loss: 50.1824\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 31.1258 - val_loss: 49.4279\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 33.1917 - val_loss: 51.0461\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 33.3481 - val_loss: 49.4959\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 32.2161 - val_loss: 50.5018\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 34.0331 - val_loss: 49.3444\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 27.7048 - val_loss: 48.7288\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 24.9865 - val_loss: 49.4911\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 28.4637 - val_loss: 49.6573\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 24.3349 - val_loss: 48.9248\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 24.7469 - val_loss: 49.0815\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 24.2393 - val_loss: 48.0555\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 22.1906 - val_loss: 49.0595\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 23.9752 - val_loss: 48.0518\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 22.1290 - val_loss: 47.3758\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 22.6640 - val_loss: 47.9036\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 24.3525 - val_loss: 48.4676\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 25.6938 - val_loss: 47.4565\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 20.6593 - val_loss: 45.4537\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 23.7236 - val_loss: 46.8299\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 19.9543 - val_loss: 44.1571\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 25.0080 - val_loss: 46.3950\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 22.7694 - val_loss: 44.7863\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 19.6012 - val_loss: 44.1761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 15.8307 - val_loss: 44.5264\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 17.0928 - val_loss: 44.3863\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 19.5103 - val_loss: 45.4412\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 15.6381 - val_loss: 43.6905\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 37.1653 - val_loss: 46.5858\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 21.6723 - val_loss: 45.7502\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 21.6586 - val_loss: 43.7434\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 21.3164 - val_loss: 44.4216\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 18.7432 - val_loss: 44.5916\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 18.7432 - val_loss: 44.9459\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 19.7022 - val_loss: 45.9539\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 17.0157 - val_loss: 44.6755\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 17.7574 - val_loss: 45.3968\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 16.2802 - val_loss: 46.8227\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 17.5689 - val_loss: 44.4723\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 20.4439 - val_loss: 44.6942\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 22.3311 - val_loss: 47.4940\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 21.9308 - val_loss: 46.4962\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 17.7674 - val_loss: 44.4574\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 17.6149 - val_loss: 45.4636\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 24.6175 - val_loss: 46.9725\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 17.6533 - val_loss: 46.4804\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 21.1527 - val_loss: 46.3206\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 17.6984 - val_loss: 43.4279\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 68.1422 - val_loss: 47.6094\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 27.6892 - val_loss: 48.0186\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 22.8377 - val_loss: 43.5131\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 21.6683 - val_loss: 42.5653\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 26.2486 - val_loss: 45.6624\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 20.5783 - val_loss: 46.1628\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 19.8666 - val_loss: 44.6683\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 18.9401 - val_loss: 43.8359\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 19.9471 - val_loss: 44.9905\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 25.0275 - val_loss: 46.4581\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 20.4905 - val_loss: 44.7307\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 22.4766 - val_loss: 45.4387\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 16.6298 - val_loss: 44.9953\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 19.9774 - val_loss: 45.1473\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 15.7261 - val_loss: 45.2233\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 16.5251 - val_loss: 44.4541\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 18.6525 - val_loss: 45.1781\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 13.5595 - val_loss: 46.8836\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 22.2029 - val_loss: 48.5306\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 25.3240 - val_loss: 46.8700\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 20.4817 - val_loss: 43.8651\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 23.8261 - val_loss: 43.9973\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 20.7202 - val_loss: 45.7394\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 18.2343 - val_loss: 46.4966\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 19.4157 - val_loss: 45.2470\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 15.8069 - val_loss: 44.2770\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 17.7658 - val_loss: 45.4122\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 19.1556 - val_loss: 45.9796\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 18.2380 - val_loss: 45.0282\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 19.6712 - val_loss: 44.3465\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 16.9845 - val_loss: 44.3829\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 19.4446 - val_loss: 45.8291\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 17.6074 - val_loss: 45.5858\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 15.9977 - val_loss: 44.4637\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 27.6231 - val_loss: 46.4185\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 17.1186 - val_loss: 46.7650\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 20.5869 - val_loss: 44.8488\n",
      "\n",
      "Mean squared error: 2.1e+01\n",
      "\n",
      "dropout: 3.5e-01\n",
      "filter_num: 284\n",
      "num_dense_layers: 2\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 137us/sample - loss: 59.0625 - val_loss: 39.9814\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 45.2884 - val_loss: 39.9346\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 42.6479 - val_loss: 36.6821\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 37.6101 - val_loss: 34.9769\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 35.5035 - val_loss: 34.7734\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 32.7789 - val_loss: 34.6623\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 29.2804 - val_loss: 36.1293\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 27.6632 - val_loss: 38.6063\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 25.5261 - val_loss: 38.3354\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 23.5024 - val_loss: 42.5802\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 18.9557 - val_loss: 40.4138\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 18.6409 - val_loss: 51.2096\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 16.4985 - val_loss: 41.2968\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 31us/sample - loss: 15.4843 - val_loss: 55.8918\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 13.8354 - val_loss: 42.1888\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 11.7112 - val_loss: 48.7732\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 11.4479 - val_loss: 39.0543\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 10.4335 - val_loss: 43.1962\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 10.2476 - val_loss: 41.5032\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 8.6230 - val_loss: 45.6500\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 8.0028 - val_loss: 43.5135\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 7.4639 - val_loss: 43.9987\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 7.9289 - val_loss: 39.7286\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 7.1385 - val_loss: 39.3031\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 7.6971 - val_loss: 41.2116\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 8.2349 - val_loss: 39.2511\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 9.4412 - val_loss: 43.0382\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 7.3365 - val_loss: 42.7497\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 6.2429 - val_loss: 49.5770\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 7.0882 - val_loss: 43.1069\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 7.5707 - val_loss: 47.4621\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 6.5510 - val_loss: 42.6435\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 7.8618 - val_loss: 42.4791\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 5.5670 - val_loss: 44.7342\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 5.4785 - val_loss: 43.2662\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 5.0487 - val_loss: 47.7170\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 5.7075 - val_loss: 43.5060\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 5.0811 - val_loss: 46.4811\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 5.5872 - val_loss: 42.0302\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 7.9256 - val_loss: 41.5159\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 6.4715 - val_loss: 42.1384\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 5.7698 - val_loss: 42.7901\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 4.7912 - val_loss: 48.2698\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 5.5804 - val_loss: 42.7324\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 5.5234 - val_loss: 48.9982\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 4.9068 - val_loss: 43.6665\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 4.7516 - val_loss: 45.9212\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 3.8701 - val_loss: 43.8550\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 4.4662 - val_loss: 43.8544\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 4.9433 - val_loss: 40.4746\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 4.4114 - val_loss: 43.3395\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 4.1845 - val_loss: 44.3758\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 3.8129 - val_loss: 43.5663\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 4.0854 - val_loss: 44.0421\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 4.3282 - val_loss: 44.0240\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 3.3417 - val_loss: 42.2182\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 2.9923 - val_loss: 42.8036\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 3.5059 - val_loss: 42.2284\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 3.7922 - val_loss: 44.2021\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 3.2776 - val_loss: 44.0322\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 3.9608 - val_loss: 43.3958\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 3.6002 - val_loss: 43.8731\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 3.7277 - val_loss: 45.9108\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 3.6265 - val_loss: 45.5033\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 2.8084 - val_loss: 43.3974\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 3.5544 - val_loss: 46.3502\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 2.8030 - val_loss: 46.5592\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 7.4679 - val_loss: 43.4697\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 5.6218 - val_loss: 41.3279\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 4.5516 - val_loss: 43.3768\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 4.7414 - val_loss: 45.9604\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 5.1861 - val_loss: 51.0769\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 4.0080 - val_loss: 48.9394\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 4.4804 - val_loss: 44.9342\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 3.9984 - val_loss: 44.6389\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 3.2196 - val_loss: 44.9146\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 3.5159 - val_loss: 50.0540\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 2.9562 - val_loss: 48.6015\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 4.0735 - val_loss: 47.8925\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 3.4785 - val_loss: 47.3844\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 2.9209 - val_loss: 45.3358\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 2.9421 - val_loss: 46.7989\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 3.2639 - val_loss: 45.8733\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 3.3468 - val_loss: 50.7600\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 3.7536 - val_loss: 44.6042\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 5.0846 - val_loss: 48.7632\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 5.9204 - val_loss: 43.8386\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 4.6292 - val_loss: 51.4236\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 3.2918 - val_loss: 47.4237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 3.0553 - val_loss: 52.2568\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 2.9096 - val_loss: 49.6197\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 3.0192 - val_loss: 50.2364\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 3.1044 - val_loss: 49.7492\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 2.5844 - val_loss: 47.1670\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 4.0387 - val_loss: 48.5981\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 2.8322 - val_loss: 46.0586\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 2.8626 - val_loss: 49.9179\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 2.6320 - val_loss: 49.1014\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 2.7037 - val_loss: 49.4407\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 3.0224 - val_loss: 48.1580\n",
      "\n",
      "Mean squared error: 3.0\n",
      "\n",
      "dropout: 6.0e-01\n",
      "filter_num: 276\n",
      "num_dense_layers: 9\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 1s 309us/sample - loss: 53.0181 - val_loss: 58.4008\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 48.4747 - val_loss: 58.1689\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 44.5458 - val_loss: 57.2958\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 44.0464 - val_loss: 57.7463\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 42.8221 - val_loss: 56.7426\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 41.8547 - val_loss: 56.0909\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 74us/sample - loss: 40.2554 - val_loss: 56.4188\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 76us/sample - loss: 39.1400 - val_loss: 55.8590\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 77us/sample - loss: 34.9584 - val_loss: 55.5416\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 74us/sample - loss: 37.7219 - val_loss: 56.6711\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 74us/sample - loss: 36.6718 - val_loss: 56.6049\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 73us/sample - loss: 35.0501 - val_loss: 55.6880\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 73us/sample - loss: 31.2213 - val_loss: 55.7364\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 71us/sample - loss: 31.7656 - val_loss: 55.2942\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 70us/sample - loss: 30.7362 - val_loss: 55.5489\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 31.8156 - val_loss: 56.2805\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 70us/sample - loss: 28.8255 - val_loss: 53.7868\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 27.9518 - val_loss: 54.3162\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 29.0657 - val_loss: 53.8363\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 28.4677 - val_loss: 54.1351\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 70us/sample - loss: 24.0495 - val_loss: 53.7893\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 26.5575 - val_loss: 53.2946\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 24.8962 - val_loss: 53.2842\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 63us/sample - loss: 23.1166 - val_loss: 52.1664\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 77us/sample - loss: 24.3770 - val_loss: 52.9345\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 71us/sample - loss: 23.0645 - val_loss: 51.3808\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 21.6454 - val_loss: 51.5775\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 70us/sample - loss: 24.0829 - val_loss: 50.2854\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 20.8261 - val_loss: 52.2334\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 26.5849 - val_loss: 50.7954\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 24.1930 - val_loss: 49.6823\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 23.2862 - val_loss: 52.0214\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 23.7724 - val_loss: 49.6294\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 22.6405 - val_loss: 50.7475\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 64us/sample - loss: 21.2044 - val_loss: 50.6086\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 75us/sample - loss: 20.5430 - val_loss: 47.6443\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 22.8470 - val_loss: 51.2022\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 18.1227 - val_loss: 48.2960\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 18.8017 - val_loss: 49.6266\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 18.8769 - val_loss: 49.8891\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 64us/sample - loss: 28.5872 - val_loss: 49.6741\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 72us/sample - loss: 19.1678 - val_loss: 48.7085\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 72us/sample - loss: 20.7799 - val_loss: 50.8562\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 23.1091 - val_loss: 50.3910\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 70us/sample - loss: 19.0042 - val_loss: 44.1371\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 21.6056 - val_loss: 52.7163\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 27.2936 - val_loss: 51.0493\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 23.3174 - val_loss: 45.3380\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 70us/sample - loss: 20.5151 - val_loss: 49.5546\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 67us/sample - loss: 18.3900 - val_loss: 47.9793\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 24.2407 - val_loss: 48.9520\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 16.0966 - val_loss: 47.9619\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 73us/sample - loss: 20.0743 - val_loss: 48.6759\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 21.1990 - val_loss: 48.0022\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 18.6584 - val_loss: 49.6118\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 20.6658 - val_loss: 47.5931\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 18.9555 - val_loss: 48.7406\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 17.4703 - val_loss: 48.2687\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 15.3879 - val_loss: 46.2842\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 21.5836 - val_loss: 49.4348\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 17.9335 - val_loss: 47.1006\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 20.2999 - val_loss: 48.4781\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 72us/sample - loss: 16.1622 - val_loss: 47.9142\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 69us/sample - loss: 17.9645 - val_loss: 46.7898\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 14.0737 - val_loss: 47.4461\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 70us/sample - loss: 19.4264 - val_loss: 49.0493\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 21.1676 - val_loss: 48.0229\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 70us/sample - loss: 17.0309 - val_loss: 44.9783\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 41.0478 - val_loss: 49.9875\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 26.4050 - val_loss: 49.8099\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 20.5461 - val_loss: 44.6165\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 18.9831 - val_loss: 49.2875\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 21.7212 - val_loss: 50.1775\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 71us/sample - loss: 18.1739 - val_loss: 45.5080\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 29.5566 - val_loss: 47.8624\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 15.9223 - val_loss: 48.8380\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 20.3320 - val_loss: 47.0068\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 17.3843 - val_loss: 47.0777\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 17.3379 - val_loss: 48.4854\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 18.6602 - val_loss: 46.6362\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 72us/sample - loss: 21.3948 - val_loss: 46.0655\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 17.2179 - val_loss: 48.1258\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 63us/sample - loss: 17.0101 - val_loss: 49.6005\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 74us/sample - loss: 17.6392 - val_loss: 44.4517\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 24.4971 - val_loss: 49.7548\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 20.3344 - val_loss: 48.9189\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 20.9353 - val_loss: 46.0810\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 62us/sample - loss: 13.0868 - val_loss: 48.2796\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 76us/sample - loss: 17.1647 - val_loss: 47.0002\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 71us/sample - loss: 15.9677 - val_loss: 47.0827\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 63us/sample - loss: 17.4031 - val_loss: 47.9127\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 73us/sample - loss: 18.6259 - val_loss: 47.0142\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 15.5361 - val_loss: 46.9826\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 62us/sample - loss: 16.3157 - val_loss: 48.0150\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 15.1953 - val_loss: 46.9591\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 31.0705 - val_loss: 48.2180\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 72us/sample - loss: 30.0207 - val_loss: 49.8929\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 75us/sample - loss: 21.6631 - val_loss: 46.4589\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 83us/sample - loss: 54.3877 - val_loss: 48.9782\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 76us/sample - loss: 23.2845 - val_loss: 48.1791\n",
      "\n",
      "Mean squared error: 2.3e+01\n",
      "\n",
      "dropout: 2.2e-01\n",
      "filter_num: 237\n",
      "num_dense_layers: 17\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 1s 500us/sample - loss: 61.1025 - val_loss: 45.6539\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 98us/sample - loss: 48.2631 - val_loss: 47.7883\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 97us/sample - loss: 45.2437 - val_loss: 45.1579\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 98us/sample - loss: 42.1924 - val_loss: 38.5980\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 100us/sample - loss: 41.9617 - val_loss: 37.6748\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 98us/sample - loss: 37.0194 - val_loss: 42.8275\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 97us/sample - loss: 30.4128 - val_loss: 43.9944\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 93us/sample - loss: 34.5741 - val_loss: 36.4325\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 96us/sample - loss: 35.1882 - val_loss: 41.0530\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 101us/sample - loss: 31.3262 - val_loss: 51.1635\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 97us/sample - loss: 38.5465 - val_loss: 38.7423\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 95us/sample - loss: 33.1665 - val_loss: 47.7101\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 97us/sample - loss: 28.9280 - val_loss: 40.6260\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 98us/sample - loss: 21.7281 - val_loss: 42.5674\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 95us/sample - loss: 18.7084 - val_loss: 42.1339\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 99us/sample - loss: 18.2756 - val_loss: 42.7735\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 102us/sample - loss: 19.2936 - val_loss: 40.0442\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 94us/sample - loss: 20.9357 - val_loss: 39.6996\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 95us/sample - loss: 16.9136 - val_loss: 40.9290\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 99us/sample - loss: 22.5024 - val_loss: 46.2379\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 99us/sample - loss: 19.0281 - val_loss: 41.5618\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 103us/sample - loss: 16.7295 - val_loss: 40.3800\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 97us/sample - loss: 22.8576 - val_loss: 41.5711\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 100us/sample - loss: 19.7669 - val_loss: 38.8387\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 94us/sample - loss: 16.5250 - val_loss: 42.6287\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 102us/sample - loss: 15.6741 - val_loss: 43.2396\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 98us/sample - loss: 14.1864 - val_loss: 42.5460\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 94us/sample - loss: 19.0384 - val_loss: 39.4369\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 96us/sample - loss: 17.0976 - val_loss: 40.7007\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 97us/sample - loss: 15.9095 - val_loss: 41.7161\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 100us/sample - loss: 12.6830 - val_loss: 40.3710\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 93us/sample - loss: 12.4391 - val_loss: 41.2690\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 97us/sample - loss: 13.3847 - val_loss: 44.7145\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 102us/sample - loss: 41.5492 - val_loss: 51.3480\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 101us/sample - loss: 43.9502 - val_loss: 37.9475\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 104us/sample - loss: 28.5931 - val_loss: 45.2641\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 100us/sample - loss: 24.7203 - val_loss: 46.0762\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 106us/sample - loss: 24.9423 - val_loss: 43.6839\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 107us/sample - loss: 25.2512 - val_loss: 45.3547\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 108us/sample - loss: 22.0375 - val_loss: 42.3840\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 94us/sample - loss: 20.1397 - val_loss: 52.0520\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 102us/sample - loss: 17.8156 - val_loss: 42.3232\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 98us/sample - loss: 14.2061 - val_loss: 42.3983\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 96us/sample - loss: 15.9023 - val_loss: 43.6339\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 93us/sample - loss: 12.7836 - val_loss: 39.9416\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 97us/sample - loss: 12.3323 - val_loss: 40.0391\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 97us/sample - loss: 12.1497 - val_loss: 39.4628\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 97us/sample - loss: 18.5516 - val_loss: 42.0550\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 101us/sample - loss: 14.7828 - val_loss: 37.8191\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 98us/sample - loss: 31.4351 - val_loss: 43.6759\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 100us/sample - loss: 24.4843 - val_loss: 38.7963\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 94us/sample - loss: 16.7271 - val_loss: 41.5276\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 96us/sample - loss: 13.9814 - val_loss: 41.2531\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 99us/sample - loss: 13.0848 - val_loss: 42.6713\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 97us/sample - loss: 19.7661 - val_loss: 40.0171\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 102us/sample - loss: 27.6006 - val_loss: 42.5727\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 94us/sample - loss: 27.5743 - val_loss: 36.0846\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 101us/sample - loss: 21.1221 - val_loss: 40.7397\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 97us/sample - loss: 19.6006 - val_loss: 41.5335\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 94us/sample - loss: 27.8199 - val_loss: 45.2486\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 100us/sample - loss: 27.6744 - val_loss: 39.3654\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 98us/sample - loss: 18.9623 - val_loss: 39.3381\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 95us/sample - loss: 24.8821 - val_loss: 42.7030\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 91us/sample - loss: 27.8743 - val_loss: 41.2847\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 104us/sample - loss: 21.1320 - val_loss: 43.4194\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 98us/sample - loss: 27.6544 - val_loss: 40.6819\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 101us/sample - loss: 16.8630 - val_loss: 42.3659\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 98us/sample - loss: 12.6578 - val_loss: 41.7558\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 97us/sample - loss: 10.3543 - val_loss: 40.5747\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 101us/sample - loss: 12.2371 - val_loss: 38.6812\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 97us/sample - loss: 11.7883 - val_loss: 38.3822\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 101us/sample - loss: 9.4154 - val_loss: 39.3480\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 98us/sample - loss: 13.6068 - val_loss: 41.6116\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 97us/sample - loss: 17.3894 - val_loss: 39.1105\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 94us/sample - loss: 10.0247 - val_loss: 40.3584\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 98us/sample - loss: 12.6883 - val_loss: 42.3517\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 100us/sample - loss: 12.7537 - val_loss: 39.9701\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 97us/sample - loss: 12.2734 - val_loss: 38.4240\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 95us/sample - loss: 15.8062 - val_loss: 36.7094\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 98us/sample - loss: 12.0558 - val_loss: 38.6336\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 99us/sample - loss: 11.6004 - val_loss: 40.7263\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 97us/sample - loss: 12.0723 - val_loss: 38.7658\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 98us/sample - loss: 12.8147 - val_loss: 39.5056\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 100us/sample - loss: 15.6949 - val_loss: 38.0401\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 98us/sample - loss: 11.7335 - val_loss: 39.8631\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 101us/sample - loss: 12.8146 - val_loss: 40.0403\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 100us/sample - loss: 13.8947 - val_loss: 39.7663\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 100us/sample - loss: 12.5636 - val_loss: 51.8978\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 94us/sample - loss: 23.7976 - val_loss: 44.7863\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 96us/sample - loss: 34.1013 - val_loss: 38.0201\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 97us/sample - loss: 20.2497 - val_loss: 44.8092\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 97us/sample - loss: 20.5993 - val_loss: 42.3528\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 97us/sample - loss: 15.1351 - val_loss: 50.4136\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 93us/sample - loss: 28.5135 - val_loss: 42.2151\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 101us/sample - loss: 30.7665 - val_loss: 37.1890\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 97us/sample - loss: 21.6332 - val_loss: 38.6712\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 97us/sample - loss: 43.3855 - val_loss: 49.4911\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 95us/sample - loss: 51.2371 - val_loss: 49.5588\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 93us/sample - loss: 51.3761 - val_loss: 47.3056\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 105us/sample - loss: 47.5485 - val_loss: 42.1223\n",
      "\n",
      "Mean squared error: 4.8e+01\n",
      "\n",
      "dropout: 2.4e-01\n",
      "filter_num: 300\n",
      "num_dense_layers: 3\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 168us/sample - loss: 57.6508 - val_loss: 40.4730\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 46.6413 - val_loss: 39.5608\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 42.4559 - val_loss: 36.0588\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 37.7760 - val_loss: 34.7774\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 34.5349 - val_loss: 34.0725\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 30.5515 - val_loss: 34.6515\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 26.0388 - val_loss: 38.0030\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 22.3913 - val_loss: 42.0981\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 19.7038 - val_loss: 46.5735\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 17.1022 - val_loss: 39.9362\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 14.5633 - val_loss: 36.9369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 12.3366 - val_loss: 37.5325\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 11.7013 - val_loss: 38.7821\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 10.6045 - val_loss: 41.8078\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 10.9770 - val_loss: 42.5147\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 9.7765 - val_loss: 40.5143\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 8.7997 - val_loss: 41.3719\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 8.6856 - val_loss: 38.7160\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 42us/sample - loss: 8.2338 - val_loss: 37.6736\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 7.5339 - val_loss: 38.6912\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 7.5570 - val_loss: 37.3221\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 7.3345 - val_loss: 38.1337\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 42us/sample - loss: 7.5623 - val_loss: 43.4751\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 6.4788 - val_loss: 40.6452\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 6.8293 - val_loss: 43.5206\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 5.8031 - val_loss: 49.8950\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 8.9012 - val_loss: 42.6689\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 9.1733 - val_loss: 50.0717\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 10.6902 - val_loss: 40.3120\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 8.6687 - val_loss: 46.5077\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 7.0535 - val_loss: 39.7743\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 8.2040 - val_loss: 43.4875\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 5.2468 - val_loss: 42.2954\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 6.0501 - val_loss: 42.8223\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 5.4635 - val_loss: 40.1800\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 5.1809 - val_loss: 39.4735\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 5.2540 - val_loss: 41.4700\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 4.1155 - val_loss: 40.8842\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 42us/sample - loss: 3.9840 - val_loss: 42.5749\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 4.0410 - val_loss: 41.8037\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 5.2806 - val_loss: 44.3305\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 5.2027 - val_loss: 40.9934\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 5.7240 - val_loss: 42.1539\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 4.4445 - val_loss: 40.6426\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 4.4529 - val_loss: 45.0478\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 4.2676 - val_loss: 42.3114\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 4.0655 - val_loss: 49.2969\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 5.1738 - val_loss: 42.1583\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 5.1943 - val_loss: 47.7300\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 5.1418 - val_loss: 42.6105\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 6.8953 - val_loss: 47.4835\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 42us/sample - loss: 8.7017 - val_loss: 41.3229\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 6.9666 - val_loss: 47.4025\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 7.1251 - val_loss: 43.7938\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 4.3167 - val_loss: 46.3604\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 4.5756 - val_loss: 42.5942\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 4.3767 - val_loss: 41.2343\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 3.8705 - val_loss: 40.0984\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 4.3178 - val_loss: 40.3001\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 3.3946 - val_loss: 42.5104\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 3.1640 - val_loss: 42.2421\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 3.4732 - val_loss: 42.9117\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 3.1232 - val_loss: 44.0826\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 42us/sample - loss: 3.0232 - val_loss: 48.1584\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 2.7691 - val_loss: 45.9308\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 3.1664 - val_loss: 45.1569\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 2.5849 - val_loss: 43.9083\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 3.9757 - val_loss: 40.8988\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 3.8082 - val_loss: 40.5260\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 11.3487 - val_loss: 41.0892\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 9.6234 - val_loss: 44.4220\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 6.8627 - val_loss: 46.7133\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 6.0995 - val_loss: 41.4681\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 42us/sample - loss: 11.3743 - val_loss: 39.2280\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 8.7937 - val_loss: 42.4995\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 5.8025 - val_loss: 49.8311\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 5.7749 - val_loss: 45.2013\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 4.3856 - val_loss: 47.0162\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 3.8536 - val_loss: 44.9507\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 3.2516 - val_loss: 44.9579\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 3.3265 - val_loss: 41.6323\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 3.3135 - val_loss: 43.4165\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 3.0988 - val_loss: 42.6297\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 2.7230 - val_loss: 43.7613\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 3.5498 - val_loss: 45.0582\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 4.6420 - val_loss: 42.3943\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 4.0187 - val_loss: 43.3500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 4.4692 - val_loss: 41.9023\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 3.1924 - val_loss: 41.5247\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 42us/sample - loss: 3.9349 - val_loss: 44.5203\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 3.0414 - val_loss: 43.8162\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 4.0594 - val_loss: 43.4373\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 4.4344 - val_loss: 45.1501\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 3.9460 - val_loss: 41.9854\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 3.6575 - val_loss: 43.1658\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 2.9744 - val_loss: 42.5626\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 3.0306 - val_loss: 43.4004\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 42us/sample - loss: 2.5995 - val_loss: 41.5273\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 2.7763 - val_loss: 43.4672\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 3.4589 - val_loss: 41.4640\n",
      "\n",
      "Mean squared error: 3.5\n",
      "\n",
      "dropout: 2.7e-01\n",
      "filter_num: 10\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 96us/sample - loss: 65.5032 - val_loss: 59.9577\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 65.3888 - val_loss: 59.8141\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 65.1777 - val_loss: 59.5619\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 64.8251 - val_loss: 59.1013\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 64.2485 - val_loss: 58.2633\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 62.9949 - val_loss: 56.7563\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 60.8602 - val_loss: 54.2373\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 57.5227 - val_loss: 50.1326\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 53.0374 - val_loss: 44.4910\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 46.8616 - val_loss: 38.5219\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 39.8344 - val_loss: 34.2043\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 38.9054 - val_loss: 32.9679\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 36.0368 - val_loss: 33.0219\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 35.4990 - val_loss: 33.3463\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 33.0882 - val_loss: 33.6578\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 36.1236 - val_loss: 33.7757\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 35.2568 - val_loss: 34.0604\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 33.3269 - val_loss: 33.8792\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 32.2195 - val_loss: 33.8235\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 33.7015 - val_loss: 33.9998\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 31.1300 - val_loss: 34.1470\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 31.3899 - val_loss: 34.0722\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 31.4082 - val_loss: 34.2451\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 31.5060 - val_loss: 34.4699\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 31.3040 - val_loss: 34.6793\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 28.5513 - val_loss: 34.9234\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 28.7129 - val_loss: 35.1623\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 29.0733 - val_loss: 35.5328\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 27.9916 - val_loss: 35.9263\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 28.7354 - val_loss: 35.6394\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 28.3873 - val_loss: 35.5352\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 28.9007 - val_loss: 35.5165\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 31.3052 - val_loss: 35.6976\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 28.3838 - val_loss: 36.1687\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 27.6674 - val_loss: 36.5082\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 26.9793 - val_loss: 36.8693\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 23.9731 - val_loss: 37.6017\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 23.4041 - val_loss: 38.2075\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 27.3885 - val_loss: 38.6438\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 25.4414 - val_loss: 39.4700\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 24.5494 - val_loss: 40.7255\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 25.5210 - val_loss: 41.8171\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 24.7983 - val_loss: 42.9606\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 27.2696 - val_loss: 45.3791\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 24.1943 - val_loss: 45.3915\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 25.7333 - val_loss: 44.4333\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 23.5046 - val_loss: 44.8560\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 23.2310 - val_loss: 47.9298\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 24.6245 - val_loss: 51.0051\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 24.5235 - val_loss: 53.1797\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 21.7230 - val_loss: 54.3399\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 24.7983 - val_loss: 54.8323\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 24.2495 - val_loss: 56.8139\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 21.3779 - val_loss: 59.5928\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 20.1565 - val_loss: 61.9126\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 20.4430 - val_loss: 65.8101\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 19.2633 - val_loss: 73.7375\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 21.3126 - val_loss: 79.4701\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 19.7006 - val_loss: 83.4509\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 18.3589 - val_loss: 84.8327\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 19.6621 - val_loss: 86.1398\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 10us/sample - loss: 19.9451 - val_loss: 89.0086\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 19.7139 - val_loss: 94.3721\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 19.3947 - val_loss: 99.8219\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 18.3609 - val_loss: 104.8641\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 19.2538 - val_loss: 110.3402\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 15.1833 - val_loss: 117.0235\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 14.7732 - val_loss: 125.1238\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 15.9477 - val_loss: 132.5256\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 15.7982 - val_loss: 140.3761\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 17.3039 - val_loss: 150.5376\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 15.1243 - val_loss: 156.1458\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 14.9734 - val_loss: 161.9753\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 16.5208 - val_loss: 170.0863\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 13.9739 - val_loss: 184.1123\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 14.9731 - val_loss: 199.4671\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 13.7846 - val_loss: 200.9000\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 15.5251 - val_loss: 209.9060\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 11.7437 - val_loss: 224.7374\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 13.2818 - val_loss: 245.8438\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 14.1099 - val_loss: 245.7420\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 12.7886 - val_loss: 262.4082\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 12.3135 - val_loss: 306.4991\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 16.8993 - val_loss: 310.1541\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 12.2575 - val_loss: 305.1380\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 10.6252 - val_loss: 313.5551\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 11.7363 - val_loss: 325.8789\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 10.9861 - val_loss: 336.0791\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 10.4650 - val_loss: 340.1761\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 10.0744 - val_loss: 353.7794\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 9.8382 - val_loss: 361.5898\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 11.1234 - val_loss: 364.3866\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 13.2267 - val_loss: 352.2637\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 9.7977 - val_loss: 332.7065\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 10.0398 - val_loss: 338.3102\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 9.6959 - val_loss: 352.3440\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 10.1499 - val_loss: 353.8357\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 9.0811 - val_loss: 331.4590\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 11.2877 - val_loss: 331.5120\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 10.1329 - val_loss: 345.3461\n",
      "\n",
      "Mean squared error: 1e+01\n",
      "\n",
      "dropout: 2.9e-01\n",
      "filter_num: 300\n",
      "num_dense_layers: 5\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 1s 210us/sample - loss: 58.1346 - val_loss: 41.5404\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 60us/sample - loss: 49.8395 - val_loss: 49.5767\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 56us/sample - loss: 47.1030 - val_loss: 37.8854\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 41.9170 - val_loss: 38.8889\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 37.2875 - val_loss: 34.9705\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 33.5933 - val_loss: 35.2788\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 57us/sample - loss: 29.6967 - val_loss: 35.6115\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 56us/sample - loss: 27.7407 - val_loss: 38.8216\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 26.9002 - val_loss: 38.9147\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 60us/sample - loss: 21.7059 - val_loss: 39.0144\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 20.5816 - val_loss: 44.1546\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 56us/sample - loss: 17.5697 - val_loss: 41.9879\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 56us/sample - loss: 16.1313 - val_loss: 49.6731\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 56us/sample - loss: 15.2589 - val_loss: 47.5177\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 61us/sample - loss: 15.6255 - val_loss: 44.9029\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 14.5637 - val_loss: 53.6296\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 20.3793 - val_loss: 43.2198\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 12.9813 - val_loss: 44.5311\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 11.8489 - val_loss: 47.0790\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 11.7109 - val_loss: 47.5917\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 11.0042 - val_loss: 45.9219\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 9.9696 - val_loss: 56.6359\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 60us/sample - loss: 13.1342 - val_loss: 44.9766\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 56us/sample - loss: 12.6566 - val_loss: 57.8181\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 10.3334 - val_loss: 55.9590\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 11.6669 - val_loss: 47.4159\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 56us/sample - loss: 17.4783 - val_loss: 45.1819\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 56us/sample - loss: 12.3551 - val_loss: 42.6760\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 56us/sample - loss: 9.7509 - val_loss: 49.0592\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 8.9693 - val_loss: 46.0355\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 9.4585 - val_loss: 49.0612\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 7.5170 - val_loss: 49.4616\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 59us/sample - loss: 7.3515 - val_loss: 49.2819\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 7.1142 - val_loss: 51.4266\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 56us/sample - loss: 7.8098 - val_loss: 45.2440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 12.4468 - val_loss: 48.8405\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 9.2291 - val_loss: 43.0970\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 10.6415 - val_loss: 49.4247\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 8.6952 - val_loss: 46.7960\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 58us/sample - loss: 6.6874 - val_loss: 48.8078\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 6.1157 - val_loss: 47.9196\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 6.7593 - val_loss: 43.9684\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 6.0210 - val_loss: 48.9777\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 7.8444 - val_loss: 40.1773\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 6.2284 - val_loss: 44.7007\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 57us/sample - loss: 6.9363 - val_loss: 41.8200\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 7.6335 - val_loss: 51.2750\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 6.8656 - val_loss: 41.4475\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 6.0117 - val_loss: 48.0366\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 5.6643 - val_loss: 43.2088\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 7.0935 - val_loss: 46.9240\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 5.7069 - val_loss: 41.4861\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 56us/sample - loss: 6.5928 - val_loss: 41.3138\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 6.2694 - val_loss: 43.1550\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 4.8635 - val_loss: 44.7736\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 5.9072 - val_loss: 46.9934\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 56us/sample - loss: 5.6018 - val_loss: 42.4343\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 5.7368 - val_loss: 44.4753\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 4.9464 - val_loss: 42.4924\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 4.3353 - val_loss: 44.7310\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 58us/sample - loss: 4.6344 - val_loss: 42.6506\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 5.6977 - val_loss: 44.7303\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 5.6425 - val_loss: 40.6219\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 5.7025 - val_loss: 45.2665\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 59us/sample - loss: 4.7257 - val_loss: 42.1292\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 56us/sample - loss: 4.8304 - val_loss: 44.5919\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 5.7289 - val_loss: 42.5530\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 9.2012 - val_loss: 44.6173\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 6.1351 - val_loss: 49.1351\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 58us/sample - loss: 6.6138 - val_loss: 42.9855\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 56us/sample - loss: 5.2908 - val_loss: 48.5561\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 5.0761 - val_loss: 42.5600\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 5.5678 - val_loss: 46.4123\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 5.1731 - val_loss: 43.3838\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 57us/sample - loss: 5.4639 - val_loss: 42.9971\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 5.6710 - val_loss: 45.0283\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 5.8336 - val_loss: 43.5476\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 5.3995 - val_loss: 47.9904\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 59us/sample - loss: 3.6080 - val_loss: 43.2391\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 4.7358 - val_loss: 42.4731\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 57us/sample - loss: 4.3624 - val_loss: 40.8333\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 9.9176 - val_loss: 42.4779\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 56us/sample - loss: 7.4395 - val_loss: 41.1162\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 8.7234 - val_loss: 58.4136\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 56us/sample - loss: 7.1490 - val_loss: 45.8751\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 59us/sample - loss: 6.7533 - val_loss: 73.0671\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 59us/sample - loss: 10.4394 - val_loss: 52.0388\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 60us/sample - loss: 8.0654 - val_loss: 51.4825\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 59us/sample - loss: 11.3654 - val_loss: 38.7015\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 61us/sample - loss: 6.9871 - val_loss: 40.6463\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 58us/sample - loss: 6.2916 - val_loss: 43.5069\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 59us/sample - loss: 5.7725 - val_loss: 44.9231\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 59us/sample - loss: 4.8082 - val_loss: 44.2389\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 5.0123 - val_loss: 46.4103\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 57us/sample - loss: 5.4935 - val_loss: 46.7387\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 56us/sample - loss: 5.2230 - val_loss: 45.2953\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 5.1900 - val_loss: 43.8791\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 4.7538 - val_loss: 42.4651\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 4.6203 - val_loss: 43.3661\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 56us/sample - loss: 3.8608 - val_loss: 43.6034\n",
      "\n",
      "Mean squared error: 3.9\n",
      "\n",
      "dropout: 2.9e-01\n",
      "filter_num: 300\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 109us/sample - loss: 57.7924 - val_loss: 39.5910\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 46.3875 - val_loss: 38.5233\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 43.0339 - val_loss: 38.2476\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 39.2907 - val_loss: 35.8297\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 35.8698 - val_loss: 34.2072\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 32.4416 - val_loss: 34.4996\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 29.0242 - val_loss: 37.4557\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 27.1679 - val_loss: 36.3996\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 25.1550 - val_loss: 39.2834\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 26us/sample - loss: 23.2319 - val_loss: 38.7384\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 20.0405 - val_loss: 41.0012\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 18.7297 - val_loss: 42.4002\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 16.4047 - val_loss: 44.1972\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 14.1488 - val_loss: 44.9229\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 11.8736 - val_loss: 49.4314\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 11.0956 - val_loss: 48.4659\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 9.5770 - val_loss: 54.7706\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 9.0602 - val_loss: 48.9042\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 8.5041 - val_loss: 52.2248\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 7.6438 - val_loss: 55.4408\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 8.4416 - val_loss: 46.1245\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 8.2074 - val_loss: 51.6645\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 6.6925 - val_loss: 49.3075\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.6854 - val_loss: 51.5048\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.9003 - val_loss: 58.4765\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 8.0437 - val_loss: 47.7745\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 8.6481 - val_loss: 60.9895\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 9.5798 - val_loss: 47.9741\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 9.7033 - val_loss: 54.5798\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 7.6191 - val_loss: 57.4638\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 6.8062 - val_loss: 55.6965\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 6.4564 - val_loss: 60.7959\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.0917 - val_loss: 57.8734\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.6511 - val_loss: 59.5430\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.3804 - val_loss: 58.3629\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.8993 - val_loss: 56.5463\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.2758 - val_loss: 61.3756\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.0606 - val_loss: 59.7739\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.7515 - val_loss: 61.1750\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.6584 - val_loss: 61.3874\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.7338 - val_loss: 66.1435\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.4346 - val_loss: 63.6104\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.4468 - val_loss: 59.7758\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.3495 - val_loss: 63.5717\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.2553 - val_loss: 58.1688\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.3140 - val_loss: 62.8450\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.5292 - val_loss: 59.8794\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.2034 - val_loss: 67.0290\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.0321 - val_loss: 66.1064\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.4589 - val_loss: 65.6775\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.7952 - val_loss: 63.0849\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.8150 - val_loss: 60.8206\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.2202 - val_loss: 59.8811\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.7809 - val_loss: 59.5380\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.6126 - val_loss: 63.9654\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.7738 - val_loss: 58.2570\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.8372 - val_loss: 61.7909\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.2557 - val_loss: 59.7755\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.6420 - val_loss: 61.0907\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.4769 - val_loss: 60.4333\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.9544 - val_loss: 55.9895\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.6892 - val_loss: 54.7767\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.8029 - val_loss: 54.0706\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.5965 - val_loss: 55.3013\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.6031 - val_loss: 53.0656\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.4904 - val_loss: 59.0751\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.9947 - val_loss: 54.4722\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.6987 - val_loss: 63.0854\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.9461 - val_loss: 54.2315\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.3006 - val_loss: 57.5873\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.2531 - val_loss: 56.2114\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.1003 - val_loss: 57.1306\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.5023 - val_loss: 58.9520\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 2.0702 - val_loss: 58.7941\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.3451 - val_loss: 59.2529\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.5250 - val_loss: 63.8106\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.4615 - val_loss: 60.5720\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.9432 - val_loss: 61.3104\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 1.9429 - val_loss: 61.0402\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.2512 - val_loss: 57.7316\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.4038 - val_loss: 63.7578\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.5530 - val_loss: 59.5829\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.1832 - val_loss: 63.2698\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.3273 - val_loss: 56.6840\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.1234 - val_loss: 55.6396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 2.0982 - val_loss: 55.1754\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.0500 - val_loss: 54.8188\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.1725 - val_loss: 57.9476\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.9201 - val_loss: 57.1207\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.1869 - val_loss: 58.6029\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.6128 - val_loss: 53.4078\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.4095 - val_loss: 59.4075\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.5569 - val_loss: 57.2992\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.0770 - val_loss: 63.4885\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.8979 - val_loss: 58.4606\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.8679 - val_loss: 64.2072\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.7406 - val_loss: 58.1045\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.5055 - val_loss: 58.3049\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.8468 - val_loss: 56.9984\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.6744 - val_loss: 58.2403\n",
      "\n",
      "Mean squared error: 1.7\n",
      "\n",
      "dropout: 2.0e-01\n",
      "filter_num: 300\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 113us/sample - loss: 56.3837 - val_loss: 40.1040\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 44.8863 - val_loss: 38.3369\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 40.9005 - val_loss: 35.8785\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 36.8283 - val_loss: 34.8968\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 33.2672 - val_loss: 34.0462\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 30.7957 - val_loss: 34.4927\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 27.6791 - val_loss: 38.7548\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 24.5104 - val_loss: 36.9028\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 22.2192 - val_loss: 41.1416\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 18.8553 - val_loss: 41.7131\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 17.0451 - val_loss: 43.0024\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 14.1550 - val_loss: 43.0632\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 12.5539 - val_loss: 45.4932\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 11.4374 - val_loss: 40.5420\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 11.5847 - val_loss: 49.0003\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 11.2861 - val_loss: 38.4179\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 8.9177 - val_loss: 45.2905\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 7.9559 - val_loss: 39.5181\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 7.6353 - val_loss: 49.9457\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 7.4037 - val_loss: 38.9934\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 7.7042 - val_loss: 44.3312\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 6.6611 - val_loss: 38.4236\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.2995 - val_loss: 43.2688\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.9984 - val_loss: 40.9215\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.8020 - val_loss: 43.8710\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 6.0857 - val_loss: 40.9045\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.4596 - val_loss: 42.4960\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.5871 - val_loss: 43.2411\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.8228 - val_loss: 42.1238\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.4309 - val_loss: 44.6855\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.4040 - val_loss: 42.2607\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.0651 - val_loss: 45.8280\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.8301 - val_loss: 44.2082\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.6023 - val_loss: 47.3415\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.7633 - val_loss: 44.4413\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.7271 - val_loss: 44.8530\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.6086 - val_loss: 43.6197\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.5965 - val_loss: 45.8864\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.5120 - val_loss: 45.3395\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.3895 - val_loss: 45.6339\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.4626 - val_loss: 49.2194\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.1298 - val_loss: 46.8833\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.9022 - val_loss: 46.8753\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 2.1333 - val_loss: 44.4295\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.2642 - val_loss: 43.4858\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.0695 - val_loss: 45.1502\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.9955 - val_loss: 45.8583\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.7709 - val_loss: 43.6612\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 1.7175 - val_loss: 43.6958\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.5592 - val_loss: 45.0901\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 1.6844 - val_loss: 46.0147\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.5221 - val_loss: 45.3995\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.4616 - val_loss: 46.2451\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.2941 - val_loss: 46.7348\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.3631 - val_loss: 45.0983\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 1.6616 - val_loss: 46.0423\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 1.5251 - val_loss: 46.2900\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 1.5587 - val_loss: 46.1558\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 1.5869 - val_loss: 45.2380\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 28us/sample - loss: 1.6887 - val_loss: 44.9222\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 1.4047 - val_loss: 43.3105\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 1.3392 - val_loss: 47.1912\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 1.9770 - val_loss: 44.5653\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 1.9877 - val_loss: 51.0620\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 2.0989 - val_loss: 44.0415\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 1.7904 - val_loss: 49.2440\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 2.1058 - val_loss: 44.1345\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 1.5842 - val_loss: 46.4684\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 1.2539 - val_loss: 43.9509\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 1.2976 - val_loss: 46.3002\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 1.2774 - val_loss: 45.6435\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 1.4998 - val_loss: 48.7970\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 1.4957 - val_loss: 45.5506\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 1.3607 - val_loss: 45.2801\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.3377 - val_loss: 46.8045\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.3797 - val_loss: 45.7840\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 1.3449 - val_loss: 49.3753\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.5622 - val_loss: 42.9134\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.6455 - val_loss: 45.6323\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.3770 - val_loss: 43.9715\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.4273 - val_loss: 46.9285\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.1291 - val_loss: 44.1732\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.3899 - val_loss: 50.2248\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.7250 - val_loss: 42.5019\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.1690 - val_loss: 51.8837\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.6503 - val_loss: 41.5462\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.5507 - val_loss: 48.9860\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.2212 - val_loss: 44.5301\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.2707 - val_loss: 53.6856\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 2.2233 - val_loss: 47.2754\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.4503 - val_loss: 48.1127\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.6721 - val_loss: 44.6351\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 1.5396 - val_loss: 46.4349\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 1.4998 - val_loss: 46.1520\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.1690 - val_loss: 45.8423\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.3764 - val_loss: 45.9954\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.4537 - val_loss: 47.4887\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.4435 - val_loss: 46.3535\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.4112 - val_loss: 47.5846\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.0627 - val_loss: 46.3807\n",
      "\n",
      "Mean squared error: 1.1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kat\\anaconda3\\envs\\tensor\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropout: 2.0e-01\n",
      "filter_num: 300\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 114us/sample - loss: 60.3249 - val_loss: 41.3156\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 47.0264 - val_loss: 37.6217\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 41.8376 - val_loss: 37.3495\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 38.7461 - val_loss: 34.9162\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 34.9170 - val_loss: 34.6861\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 30.9392 - val_loss: 34.4872\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 27.8954 - val_loss: 35.4496\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 25.4179 - val_loss: 37.9430\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 23.3073 - val_loss: 37.3125\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 21.5817 - val_loss: 42.4587\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 20.3555 - val_loss: 42.6270\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 18.2153 - val_loss: 41.4268\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 16.4601 - val_loss: 48.9925\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 13.6310 - val_loss: 44.7683\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 12.6514 - val_loss: 55.4551\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 10.8749 - val_loss: 48.0148\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 9.3592 - val_loss: 52.0805\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 8.0827 - val_loss: 43.7496\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 7.7049 - val_loss: 46.9683\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 7.1626 - val_loss: 43.6009\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 7.2511 - val_loss: 49.3297\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.7803 - val_loss: 47.2348\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.0169 - val_loss: 48.1175\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.1277 - val_loss: 47.1299\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.0140 - val_loss: 46.4072\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.5175 - val_loss: 50.9151\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.1406 - val_loss: 44.9936\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 4.0256 - val_loss: 50.3984\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.9558 - val_loss: 44.4126\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.0349 - val_loss: 51.7032\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.4844 - val_loss: 47.0402\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.6829 - val_loss: 47.7531\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.2214 - val_loss: 44.1581\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.9176 - val_loss: 51.4369\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 7.8982 - val_loss: 47.1566\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 6.6059 - val_loss: 54.3851\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.4953 - val_loss: 50.1541\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.6631 - val_loss: 58.7246\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.2206 - val_loss: 52.9757\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.9553 - val_loss: 53.7987\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.6369 - val_loss: 48.4436\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.5471 - val_loss: 50.4023\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.4812 - val_loss: 50.7749\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.4316 - val_loss: 52.4088\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.7703 - val_loss: 52.3548\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.3791 - val_loss: 52.5160\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.5662 - val_loss: 52.1352\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 2.4706 - val_loss: 52.8489\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.1835 - val_loss: 51.2833\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.1027 - val_loss: 51.6915\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.2958 - val_loss: 50.7445\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.4264 - val_loss: 50.8059\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.0959 - val_loss: 50.5639\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.0978 - val_loss: 48.5787\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.8649 - val_loss: 48.9418\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.8903 - val_loss: 50.3492\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.8199 - val_loss: 51.8918\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.8283 - val_loss: 47.8297\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.6230 - val_loss: 49.5309\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.4768 - val_loss: 50.3056\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.4887 - val_loss: 49.6541\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.5262 - val_loss: 49.5827\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.8433 - val_loss: 47.4201\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.7305 - val_loss: 50.8060\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.4943 - val_loss: 51.1111\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.7289 - val_loss: 47.0191\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.4635 - val_loss: 46.9199\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.3721 - val_loss: 47.5682\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.2272 - val_loss: 52.0818\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.2336 - val_loss: 54.6351\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.4281 - val_loss: 49.2506\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.5016 - val_loss: 49.2090\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.2802 - val_loss: 51.0881\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.4170 - val_loss: 50.4238\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.3867 - val_loss: 50.1972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.3034 - val_loss: 52.2755\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.8360 - val_loss: 51.8557\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.6018 - val_loss: 53.9121\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.4778 - val_loss: 52.6444\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.6232 - val_loss: 54.9559\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 1.3888 - val_loss: 50.8773\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.2775 - val_loss: 53.8777\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.5152 - val_loss: 48.4032\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.0716 - val_loss: 51.7293\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 1.4710 - val_loss: 48.4620\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.8297 - val_loss: 51.6065\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.8866 - val_loss: 47.8037\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.6698 - val_loss: 50.4697\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.4781 - val_loss: 48.8552\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.8300 - val_loss: 51.8312\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 1.6214 - val_loss: 50.0925\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 1.2857 - val_loss: 53.8608\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 1.1038 - val_loss: 48.9733\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 1.4020 - val_loss: 51.1459\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 1.5207 - val_loss: 47.0480\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 1.6270 - val_loss: 51.7128\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 2.5728 - val_loss: 47.2149\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 2.0714 - val_loss: 52.6362\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 2.1155 - val_loss: 50.8610\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 1.1961 - val_loss: 52.6670\n",
      "\n",
      "Mean squared error: 1.2\n",
      "\n",
      "dropout: 7.1e-01\n",
      "filter_num: 300\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 120us/sample - loss: 56.5165 - val_loss: 39.9727\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 47.0006 - val_loss: 40.6185\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 43.8594 - val_loss: 42.7962\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 41.1344 - val_loss: 36.9467\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 37.9563 - val_loss: 35.1045\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 35.4219 - val_loss: 36.2632\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 34.1025 - val_loss: 35.9560\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 33.4338 - val_loss: 33.8735\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 31.0908 - val_loss: 34.4085\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 28.4427 - val_loss: 34.4894\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 29.3179 - val_loss: 34.6065\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 26.0589 - val_loss: 35.0517\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 26.5473 - val_loss: 35.8616\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 23.3673 - val_loss: 37.3389\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 22.2876 - val_loss: 39.4998\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 21.4597 - val_loss: 41.2175\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 20.2086 - val_loss: 42.6799\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 19.7431 - val_loss: 44.0030\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 17.7035 - val_loss: 46.4438\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 16.6116 - val_loss: 48.1496\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 14.8077 - val_loss: 48.8469\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 15.7675 - val_loss: 52.2113\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 13.6134 - val_loss: 53.6990\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 13.1424 - val_loss: 60.2747\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 13.2708 - val_loss: 60.8419\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 12.8351 - val_loss: 61.7906\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 11.4586 - val_loss: 66.0048\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 10.9043 - val_loss: 66.0926\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 13.4021 - val_loss: 64.9332\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 11.0264 - val_loss: 68.3196\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 9.6798 - val_loss: 70.9126\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 10.6684 - val_loss: 67.0620\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 10.8724 - val_loss: 65.4473\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 10.8345 - val_loss: 66.7668\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 11.7337 - val_loss: 71.2588\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 9.9212 - val_loss: 78.4454\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 12.5018 - val_loss: 75.6802\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 9.8764 - val_loss: 78.4959\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 8.6886 - val_loss: 73.5639\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 9.8291 - val_loss: 71.6739\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 9.8432 - val_loss: 78.8400\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 8.9570 - val_loss: 71.7271\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 10.1273 - val_loss: 73.3846\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 8.7018 - val_loss: 76.0555\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 9.1228 - val_loss: 77.3891\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 8.2767 - val_loss: 81.8056\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 8.2863 - val_loss: 94.3405\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 8.4371 - val_loss: 94.8739\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 8.3927 - val_loss: 95.7945\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 27us/sample - loss: 8.1992 - val_loss: 91.0150\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 7.7733 - val_loss: 92.3576\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 8.3617 - val_loss: 95.6334\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 7.5049 - val_loss: 97.8523\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 7.1616 - val_loss: 100.1827\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 7.3735 - val_loss: 84.2201\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 9.2023 - val_loss: 96.6374\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 8.6935 - val_loss: 93.8801\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 7.5681 - val_loss: 88.1583\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 8.2910 - val_loss: 104.3267\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 7.5119 - val_loss: 110.0161\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.9660 - val_loss: 91.5957\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 8.1626 - val_loss: 88.9752\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 7.0122 - val_loss: 100.0193\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 7.8909 - val_loss: 97.1432\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 6.9750 - val_loss: 106.8573\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.5914 - val_loss: 114.0420\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 6.3560 - val_loss: 99.4222\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 7.6896 - val_loss: 107.1032\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 7.7031 - val_loss: 100.6565\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 6.3218 - val_loss: 91.5245\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.5602 - val_loss: 97.2090\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 6.5130 - val_loss: 99.8797\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 6.4631 - val_loss: 103.8557\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 7.0022 - val_loss: 100.7522\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 6.9143 - val_loss: 101.6736\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 7.7251 - val_loss: 98.6454\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 6.8527 - val_loss: 95.8457\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 6.3227 - val_loss: 99.5920\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 6.9169 - val_loss: 102.6681\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 5.9920 - val_loss: 98.8675\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 5.8750 - val_loss: 104.8507\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 5.7488 - val_loss: 112.3384\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 4.9868 - val_loss: 107.8053\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 5.6952 - val_loss: 115.2035\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 5.7506 - val_loss: 103.2602\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 5.1106 - val_loss: 106.8785\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 5.1950 - val_loss: 116.2540\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 5.2672 - val_loss: 108.8299\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 5.0127 - val_loss: 105.1918\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 5.0228 - val_loss: 107.4441\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 5.6481 - val_loss: 105.9104\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 4.9333 - val_loss: 110.4148\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 5.9305 - val_loss: 112.6774\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.5071 - val_loss: 125.3685\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 5.7819 - val_loss: 109.2158\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 7.1798 - val_loss: 104.3300\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 5.7530 - val_loss: 121.4830\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - ETA: 0s - loss: 7.430 - 0s 23us/sample - loss: 6.4366 - val_loss: 111.5333\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 6.3125 - val_loss: 103.1661\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.4773 - val_loss: 116.2603\n",
      "\n",
      "Mean squared error: 5.5\n",
      "\n",
      "dropout: 8.0e-01\n",
      "filter_num: 10\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 94us/sample - loss: 65.3596 - val_loss: 59.8450\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 65.0685 - val_loss: 59.5587\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 6us/sample - loss: 64.5180 - val_loss: 59.0942\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 63.7538 - val_loss: 58.3583\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 62.7062 - val_loss: 57.2924\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 61.4027 - val_loss: 55.7418\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 58.8163 - val_loss: 53.6265\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 56.3281 - val_loss: 50.9239\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 55.1846 - val_loss: 48.2308\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 55.5637 - val_loss: 46.4723\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 52.1585 - val_loss: 45.9423\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 50.6775 - val_loss: 45.8777\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 53.7380 - val_loss: 46.3532\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 51.6723 - val_loss: 46.7035\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 50.1601 - val_loss: 46.8656\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 51.0450 - val_loss: 47.1043\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 49.0031 - val_loss: 46.9571\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 48.5555 - val_loss: 46.3956\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 50.1127 - val_loss: 45.6901\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 49.1031 - val_loss: 45.1285\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 46.5562 - val_loss: 44.2676\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 48.7755 - val_loss: 43.6042\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 45.1542 - val_loss: 42.7043\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 9us/sample - loss: 40.8867 - val_loss: 41.7225\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 46.9278 - val_loss: 41.4340\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 47.0430 - val_loss: 42.0837\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 48.2284 - val_loss: 43.1775\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 41.6356 - val_loss: 43.5839\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 44.1442 - val_loss: 43.8518\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 47.6437 - val_loss: 43.9222\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 50.8838 - val_loss: 43.9655\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 47.9234 - val_loss: 43.9091\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 48.1606 - val_loss: 43.8281\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 49.5256 - val_loss: 43.4157\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 46.5822 - val_loss: 43.0505\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 42.2755 - val_loss: 42.8583\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 42.7134 - val_loss: 42.8616\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 45.4008 - val_loss: 42.8933\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 43.7159 - val_loss: 42.8927\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 50.9423 - val_loss: 43.0439\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 49.3754 - val_loss: 43.6384\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 48.0150 - val_loss: 43.9257\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 44.3246 - val_loss: 43.8649\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 44.3610 - val_loss: 43.5934\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 42.5713 - val_loss: 43.2521\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 43.3578 - val_loss: 43.2809\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 47.0504 - val_loss: 43.1087\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 44.2924 - val_loss: 42.8493\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 46.5461 - val_loss: 42.2599\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 42.3070 - val_loss: 41.8663\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 45.2066 - val_loss: 42.1718\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 44.1476 - val_loss: 42.9111\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 43.9847 - val_loss: 43.2881\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 44.9355 - val_loss: 43.6184\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 45.5116 - val_loss: 43.6814\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 39.2951 - val_loss: 43.3629\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 47.0605 - val_loss: 42.6654\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 38.8477 - val_loss: 42.3729\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 42.3094 - val_loss: 42.4214\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 42.6634 - val_loss: 42.0546\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 46.5063 - val_loss: 42.1581\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 41.1138 - val_loss: 42.3815\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 42.0778 - val_loss: 42.4520\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 40.1828 - val_loss: 42.5573\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 38.1006 - val_loss: 43.1273\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 42.9177 - val_loss: 43.5812\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 42.6603 - val_loss: 43.7087\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 44.7738 - val_loss: 43.6142\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 41.5441 - val_loss: 43.2106\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 34.8588 - val_loss: 42.8379\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 39.0223 - val_loss: 42.5000\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 40.2396 - val_loss: 42.3325\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 35.5152 - val_loss: 42.1112\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 39.4047 - val_loss: 42.4282\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 42.4880 - val_loss: 42.7817\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 40.8200 - val_loss: 43.0375\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 40.0081 - val_loss: 43.0527\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 37.0056 - val_loss: 42.9316\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 35.8532 - val_loss: 42.7039\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 38.0428 - val_loss: 42.6707\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 35.6959 - val_loss: 42.9048\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 39.2493 - val_loss: 43.0663\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 42.2072 - val_loss: 43.2493\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 36.9838 - val_loss: 43.3631\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 34.1989 - val_loss: 43.7004\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 32.6586 - val_loss: 44.0175\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 34.4117 - val_loss: 44.0883\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 36.0314 - val_loss: 44.0875\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 38.5718 - val_loss: 44.2790\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 36.0912 - val_loss: 44.7830\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 37.9775 - val_loss: 44.9788\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 40.0808 - val_loss: 45.0381\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 37.6295 - val_loss: 45.1777\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 38.7197 - val_loss: 45.1669\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 39.5941 - val_loss: 45.1169\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 42.3040 - val_loss: 44.9674\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 39.3252 - val_loss: 44.9752\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 36.1621 - val_loss: 44.8377\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 10us/sample - loss: 37.4811 - val_loss: 44.6400\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 31.6748 - val_loss: 44.6120\n",
      "\n",
      "Mean squared error: 3.2e+01\n",
      "\n",
      "dropout: 2.0e-01\n",
      "filter_num: 183\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 102us/sample - loss: 62.6116 - val_loss: 49.4940\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 47.5345 - val_loss: 41.4321\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 45.7308 - val_loss: 37.1396\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 40.8606 - val_loss: 37.8342\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 37.5131 - val_loss: 34.1713\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 34.8485 - val_loss: 34.6078\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 32.0459 - val_loss: 33.5509\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 31.0683 - val_loss: 33.4760\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 28.5590 - val_loss: 36.4949\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 26.3255 - val_loss: 34.4009\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 25.7379 - val_loss: 35.1776\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 23.3261 - val_loss: 41.3389\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 23.4069 - val_loss: 37.5987\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 21.0326 - val_loss: 39.4474\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 18.8910 - val_loss: 42.1121\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 16.8870 - val_loss: 42.5147\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 14.6838 - val_loss: 45.0442\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 13.1084 - val_loss: 49.8672\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 14.1080 - val_loss: 44.4874\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 13.0872 - val_loss: 43.7077\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 10.6675 - val_loss: 49.1955\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 9.2923 - val_loss: 45.5447\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 8.9886 - val_loss: 53.0980\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 8.4731 - val_loss: 51.7470\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 8.4700 - val_loss: 54.4875\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 7.6897 - val_loss: 48.4264\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 7.5321 - val_loss: 52.7591\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 6.6265 - val_loss: 48.7769\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 6.9188 - val_loss: 58.1501\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 6.2447 - val_loss: 54.6448\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 6.5222 - val_loss: 52.3273\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 5.1745 - val_loss: 56.8909\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 4.7432 - val_loss: 53.3679\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 4.6524 - val_loss: 58.5832\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 4.1935 - val_loss: 54.2425\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 4.0129 - val_loss: 52.6061\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 4.8617 - val_loss: 51.3907\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.7011 - val_loss: 51.0217\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 4.2839 - val_loss: 55.6144\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 7.3758 - val_loss: 55.8733\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 9.3448 - val_loss: 52.9619\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 7.3346 - val_loss: 59.9430\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 7.8935 - val_loss: 54.3174\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 5.7967 - val_loss: 63.4583\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 5.4744 - val_loss: 55.2911\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 5.4856 - val_loss: 59.5079\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.8819 - val_loss: 57.9953\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.7143 - val_loss: 63.0771\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 4.5866 - val_loss: 62.5213\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 3.6992 - val_loss: 67.2185\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 4.0736 - val_loss: 70.3292\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 4.6555 - val_loss: 63.0556\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 4.7487 - val_loss: 68.9778\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 3.0582 - val_loss: 62.6728\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.6304 - val_loss: 70.1548\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.8798 - val_loss: 65.4974\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.7422 - val_loss: 64.5595\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.5115 - val_loss: 62.8630\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.8406 - val_loss: 62.3416\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.6593 - val_loss: 64.2408\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.2832 - val_loss: 63.5034\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.2129 - val_loss: 65.8656\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.1029 - val_loss: 68.0751\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.0770 - val_loss: 65.7794\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.2583 - val_loss: 67.1133\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.1707 - val_loss: 65.4616\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.3698 - val_loss: 64.5459\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.2651 - val_loss: 59.6039\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 4.5391 - val_loss: 51.4983\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 4.3034 - val_loss: 59.6096\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 3.7642 - val_loss: 59.0229\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 3.5824 - val_loss: 64.4186\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.9550 - val_loss: 62.1689\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.9261 - val_loss: 64.0024\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.2154 - val_loss: 62.6062\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.8917 - val_loss: 63.4509\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.9160 - val_loss: 63.3114\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.9969 - val_loss: 65.1323\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.7732 - val_loss: 66.2011\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.8756 - val_loss: 62.4657\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.8214 - val_loss: 65.3417\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.4000 - val_loss: 66.5152\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.4568 - val_loss: 66.8477\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.3883 - val_loss: 67.0138\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.4869 - val_loss: 64.7568\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.6238 - val_loss: 64.0336\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.6585 - val_loss: 62.1919\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 1.6856 - val_loss: 63.3688\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.5113 - val_loss: 62.4101\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.6225 - val_loss: 65.5426\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.4266 - val_loss: 64.1985\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.4212 - val_loss: 64.5294\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 1.3537 - val_loss: 64.0233\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.4107 - val_loss: 63.6706\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.3382 - val_loss: 70.1058\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 3.5307 - val_loss: 70.5247\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 5.4300 - val_loss: 67.5359\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.8452 - val_loss: 68.9576\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.5487 - val_loss: 63.9833\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.7220 - val_loss: 67.9244\n",
      "\n",
      "Mean squared error: 1.7\n",
      "\n",
      "dropout: 2.0e-01\n",
      "filter_num: 44\n",
      "num_dense_layers: 5\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 170us/sample - loss: 65.4372 - val_loss: 59.7120\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 64.8732 - val_loss: 58.6309\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 62.8087 - val_loss: 55.0142\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 56.3557 - val_loss: 44.3255\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 45.7201 - val_loss: 35.3471\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 43.5861 - val_loss: 35.6565\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 40.3590 - val_loss: 37.0048\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 36.9981 - val_loss: 33.4277\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 35.5013 - val_loss: 33.3063\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 34.5126 - val_loss: 33.8537\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 32.5754 - val_loss: 33.1378\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 32.1727 - val_loss: 32.9155\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 32.1506 - val_loss: 33.2719\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 30.8379 - val_loss: 33.8274\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 29.5861 - val_loss: 34.0132\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 29.5959 - val_loss: 34.8759\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 27.9352 - val_loss: 35.2117\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 28.5538 - val_loss: 36.0369\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 26.1789 - val_loss: 36.8748\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 27.8393 - val_loss: 37.7120\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 26.0652 - val_loss: 37.6931\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 23.9277 - val_loss: 39.0056\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 25.0697 - val_loss: 39.5373\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 23.8847 - val_loss: 41.1670\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 22.4529 - val_loss: 40.8353\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 20.9554 - val_loss: 43.7638\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 22.0349 - val_loss: 52.0799\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 23.3411 - val_loss: 46.6077\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 20.9427 - val_loss: 54.0268\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 19.7179 - val_loss: 54.9546\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 16.7892 - val_loss: 50.8800\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 17.9669 - val_loss: 62.6592\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 16.2601 - val_loss: 75.2341\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 14.3762 - val_loss: 72.8861\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 14.5302 - val_loss: 72.4948\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 12.8243 - val_loss: 88.7506\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 12.6974 - val_loss: 97.6307\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 10.7952 - val_loss: 103.9517\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 17.8351 - val_loss: 70.0947\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 14.1625 - val_loss: 82.2309\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 15.5053 - val_loss: 78.3405\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 13.4032 - val_loss: 82.9028\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 11.9372 - val_loss: 97.5112\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 11.6693 - val_loss: 100.4095\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 9.9122 - val_loss: 109.4422\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 10.3317 - val_loss: 98.0411\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 17us/sample - loss: 13.9108 - val_loss: 71.3264\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 13.8057 - val_loss: 100.5417\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 14.3845 - val_loss: 72.6063\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 12.5321 - val_loss: 89.8954\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 11.4376 - val_loss: 111.7107\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 9.3065 - val_loss: 95.1809\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 9.3412 - val_loss: 106.4992\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 8.3666 - val_loss: 107.9722\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 9.1229 - val_loss: 108.0638\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 7.5813 - val_loss: 123.0200\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 8.0225 - val_loss: 125.7703\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 7.6799 - val_loss: 135.0586\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 8.1456 - val_loss: 126.0612\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 6.5377 - val_loss: 119.0491\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 7.1152 - val_loss: 121.7656\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 6.4705 - val_loss: 130.6769\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 6.5272 - val_loss: 114.9125\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 6.1733 - val_loss: 135.8583\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 10.1090 - val_loss: 131.1691\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 9.6127 - val_loss: 106.9460\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 10.0139 - val_loss: 114.7152\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 8.2489 - val_loss: 130.9412\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 8.8321 - val_loss: 98.2086\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 9.4246 - val_loss: 104.7899\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 6.9630 - val_loss: 124.3018\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 6.9342 - val_loss: 104.6933\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 7.4418 - val_loss: 112.1610\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 7.0275 - val_loss: 109.1835\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 6.2422 - val_loss: 106.6528\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 7.2098 - val_loss: 114.9446\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 7.9042 - val_loss: 125.8523\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 7.1636 - val_loss: 123.1798\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 5.8182 - val_loss: 123.3171\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 6.1868 - val_loss: 127.0026\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 6.6955 - val_loss: 118.7767\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 6.1442 - val_loss: 133.5863\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 5.6864 - val_loss: 128.7447\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 7.2709 - val_loss: 113.0414\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 5.8076 - val_loss: 109.9964\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 5.6256 - val_loss: 128.2779\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 7.1922 - val_loss: 126.8504\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 5.5897 - val_loss: 118.9582\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 5.7658 - val_loss: 116.5937\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 5.9754 - val_loss: 105.5700\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 5.3748 - val_loss: 107.6819\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 5.4120 - val_loss: 119.5474\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 6.0669 - val_loss: 134.1604\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 5.2634 - val_loss: 126.4488\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 6.2874 - val_loss: 117.7819\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 5.3259 - val_loss: 127.3516\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 6.0570 - val_loss: 114.5417\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 5.3634 - val_loss: 131.5853\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 7.1133 - val_loss: 123.8186\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 5.6694 - val_loss: 128.4619\n",
      "\n",
      "Mean squared error: 5.7\n",
      "\n",
      "dropout: 2.0e-01\n",
      "filter_num: 300\n",
      "num_dense_layers: 7\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 1s 264us/sample - loss: 59.3327 - val_loss: 40.2921\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 45.6461 - val_loss: 38.7348\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 41.1195 - val_loss: 35.0788\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 37.8023 - val_loss: 33.6783\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 34.1913 - val_loss: 35.9570\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 29.7822 - val_loss: 34.2273\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 72us/sample - loss: 24.9342 - val_loss: 34.1361\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 21.9604 - val_loss: 35.4380\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 20.3649 - val_loss: 34.8883\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 17.1468 - val_loss: 38.1561\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 16.2038 - val_loss: 38.6531\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 14.9176 - val_loss: 38.0301\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 12.9190 - val_loss: 40.1339\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 10.3051 - val_loss: 40.4404\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 10.1138 - val_loss: 40.6074\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 9.4536 - val_loss: 39.8265\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 11.6312 - val_loss: 36.2192\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 67us/sample - loss: 9.8761 - val_loss: 36.7076\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 71us/sample - loss: 8.5419 - val_loss: 38.1736\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 9.0823 - val_loss: 37.2368\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 68us/sample - loss: 7.5272 - val_loss: 35.9220\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 8.1754 - val_loss: 35.3230\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 70us/sample - loss: 7.1649 - val_loss: 36.4447\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 7.3083 - val_loss: 37.4717\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 7.2155 - val_loss: 37.5682\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 7.0054 - val_loss: 37.2314\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 7.2212 - val_loss: 36.9719\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 8.5172 - val_loss: 39.0135\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 10.2889 - val_loss: 36.5157\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 6.6317 - val_loss: 37.1443\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 6.7817 - val_loss: 39.2345\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 6.9697 - val_loss: 39.0077\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 70us/sample - loss: 7.1346 - val_loss: 37.6924\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 7.3073 - val_loss: 37.8431\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 6.9399 - val_loss: 36.7094\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 5.7187 - val_loss: 36.9241\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 72us/sample - loss: 6.8544 - val_loss: 36.8764\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 73us/sample - loss: 6.6460 - val_loss: 36.9704\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 76us/sample - loss: 6.1676 - val_loss: 36.8673\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 74us/sample - loss: 8.0082 - val_loss: 35.4103\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 73us/sample - loss: 6.3844 - val_loss: 40.3843\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 72us/sample - loss: 6.8763 - val_loss: 37.4183\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 74us/sample - loss: 6.5660 - val_loss: 38.6292\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 72us/sample - loss: 8.3141 - val_loss: 38.9099\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 7.0289 - val_loss: 38.2771\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 67us/sample - loss: 8.5790 - val_loss: 40.8086\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 6.9049 - val_loss: 41.7172\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 6.1581 - val_loss: 38.7617\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 5.3449 - val_loss: 38.5656\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 72us/sample - loss: 6.6899 - val_loss: 38.8013\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 4.7419 - val_loss: 38.1103\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 5.5135 - val_loss: 39.1976\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 5.9826 - val_loss: 37.5783\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 6.9700 - val_loss: 37.2172\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 5.2605 - val_loss: 40.3658\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 6.4804 - val_loss: 37.7435\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 70us/sample - loss: 6.0961 - val_loss: 37.8755\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 63us/sample - loss: 4.6770 - val_loss: 39.7915\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 73us/sample - loss: 8.5841 - val_loss: 37.1230\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 7.6104 - val_loss: 37.8903\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 7.3715 - val_loss: 42.2421\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 13.2130 - val_loss: 36.5033\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 11.8660 - val_loss: 41.7435\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 26.1585 - val_loss: 36.9717\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 65us/sample - loss: 9.9038 - val_loss: 38.4349\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 73us/sample - loss: 8.2035 - val_loss: 41.2640\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 5.3436 - val_loss: 38.0038\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 5.4092 - val_loss: 39.8426\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 4.6518 - val_loss: 37.1957\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 3.9853 - val_loss: 41.1803\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 5.4591 - val_loss: 37.9623\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 70us/sample - loss: 4.3940 - val_loss: 41.5292\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 4.6510 - val_loss: 38.2431\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 70us/sample - loss: 5.0449 - val_loss: 40.4126\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 7.7893 - val_loss: 37.8740\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 4.4499 - val_loss: 38.8736\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 4.2674 - val_loss: 41.7565\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 4.6825 - val_loss: 39.2155\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 3.7484 - val_loss: 40.3747\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 3.6203 - val_loss: 39.9098\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 4.1024 - val_loss: 38.6717\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 4.2434 - val_loss: 38.0623\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 3.7823 - val_loss: 38.9440\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 65us/sample - loss: 3.6828 - val_loss: 38.6955\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 75us/sample - loss: 3.2068 - val_loss: 37.7657\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 3.5957 - val_loss: 37.6749\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 2.6848 - val_loss: 38.0895\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 3.8379 - val_loss: 39.0036\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 3.2612 - val_loss: 39.0212\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 3.0290 - val_loss: 38.9683\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 3.0707 - val_loss: 38.9743\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 3.2571 - val_loss: 38.0792\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 3.0911 - val_loss: 41.2283\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 4.1860 - val_loss: 39.0108\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 4.4013 - val_loss: 39.8517\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 6.8004 - val_loss: 48.0039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 14.9157 - val_loss: 42.5889\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 13.6508 - val_loss: 60.5656\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 73us/sample - loss: 16.5767 - val_loss: 41.8715\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 16.7075 - val_loss: 50.4413\n",
      "\n",
      "Mean squared error: 1.7e+01\n",
      "\n",
      "dropout: 2.9e-01\n",
      "filter_num: 157\n",
      "num_dense_layers: 4\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 156us/sample - loss: 64.2649 - val_loss: 54.3052\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 51.3263 - val_loss: 39.3460\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 44.9145 - val_loss: 41.2492\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 41.3028 - val_loss: 36.2314\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 37.4834 - val_loss: 36.6187\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 35.6183 - val_loss: 34.7366\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 32.4177 - val_loss: 33.5978\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 30.2549 - val_loss: 33.4837\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 28.7227 - val_loss: 33.9337\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 28.1006 - val_loss: 35.4031\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 25.0764 - val_loss: 34.3789\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 23.5767 - val_loss: 34.5405\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 20.0736 - val_loss: 35.9346\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 18.5843 - val_loss: 35.7747\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 16.2252 - val_loss: 35.8143\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 14.5251 - val_loss: 37.0522\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 13.6649 - val_loss: 45.1908\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 15.6477 - val_loss: 41.3223\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 20.0138 - val_loss: 38.7730\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 16.7370 - val_loss: 38.0897\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 13.8208 - val_loss: 37.8970\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 11.4414 - val_loss: 41.8368\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 10.8055 - val_loss: 38.8473\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 9.4755 - val_loss: 42.6907\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 8.9176 - val_loss: 38.7097\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 9.4281 - val_loss: 40.4994\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 8.0180 - val_loss: 38.6297\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 8.1077 - val_loss: 38.2490\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 7.1852 - val_loss: 39.3187\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 8.3358 - val_loss: 39.2020\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 8.0651 - val_loss: 39.7455\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 6.0379 - val_loss: 40.5644\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 6.2265 - val_loss: 40.8642\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 7.1079 - val_loss: 40.7130\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 6.2473 - val_loss: 40.0969\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 6.4099 - val_loss: 41.4833\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 6.6390 - val_loss: 42.0645\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 5.2604 - val_loss: 41.5746\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 5.2677 - val_loss: 40.2008\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 6.4590 - val_loss: 39.7575\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 6.3166 - val_loss: 41.7147\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 5.6388 - val_loss: 41.6264\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 5.2697 - val_loss: 42.7871\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 4.9884 - val_loss: 41.8370\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 5.9410 - val_loss: 44.4282\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 5.1365 - val_loss: 43.5856\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 6.4416 - val_loss: 45.8471\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 4.2088 - val_loss: 44.8308\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 4.5819 - val_loss: 42.3383\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.1265 - val_loss: 42.0530\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 4.9506 - val_loss: 48.3654\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 7.0671 - val_loss: 42.8340\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 8.2288 - val_loss: 60.2805\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 15.8135 - val_loss: 45.9582\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 20.7211 - val_loss: 42.7632\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 30.3031 - val_loss: 39.8974\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 9.9164 - val_loss: 37.3970\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 9.2145 - val_loss: 45.5870\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 8.5360 - val_loss: 40.6176\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 9.8776 - val_loss: 43.3558\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 6.6774 - val_loss: 48.4637\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.7942 - val_loss: 45.6210\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 5.6165 - val_loss: 48.7327\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 5.5475 - val_loss: 45.5372\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.3852 - val_loss: 44.0923\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.7512 - val_loss: 43.1422\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 5.1635 - val_loss: 44.0912\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.1542 - val_loss: 45.6892\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 4.1755 - val_loss: 46.1352\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.1597 - val_loss: 46.7786\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 27us/sample - loss: 4.2657 - val_loss: 47.4736\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.8652 - val_loss: 46.6873\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.3232 - val_loss: 47.4987\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.1486 - val_loss: 45.8866\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.8934 - val_loss: 47.0293\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.9108 - val_loss: 50.7178\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.7077 - val_loss: 46.8999\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.9417 - val_loss: 46.3858\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.8057 - val_loss: 45.9017\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.5920 - val_loss: 51.0935\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 6.2976 - val_loss: 52.6792\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 9.2533 - val_loss: 49.4185\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 6.4811 - val_loss: 50.7733\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.2093 - val_loss: 50.7296\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 7.4971 - val_loss: 50.1640\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.9046 - val_loss: 54.0699\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 5.1229 - val_loss: 55.9591\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 5.1151 - val_loss: 51.2289\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.5226 - val_loss: 59.1809\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.3199 - val_loss: 48.6410\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.3333 - val_loss: 53.7402\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.4764 - val_loss: 49.4646\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.1334 - val_loss: 49.1908\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.7949 - val_loss: 50.6099\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.5859 - val_loss: 45.1833\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.2459 - val_loss: 49.2675\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 5.3669 - val_loss: 44.6521\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.7375 - val_loss: 43.7674\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 4.0847 - val_loss: 47.7742\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 4.1789 - val_loss: 45.4219\n",
      "\n",
      "Mean squared error: 4.2\n",
      "\n",
      "dropout: 4.5e-01\n",
      "filter_num: 300\n",
      "num_dense_layers: 4\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 183us/sample - loss: 57.3718 - val_loss: 41.0241\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 48.1401 - val_loss: 48.1872\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 44.4745 - val_loss: 40.1342\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 40.9808 - val_loss: 41.4354\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 38.4412 - val_loss: 36.9043\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 34.5789 - val_loss: 37.0541\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 49us/sample - loss: 32.7790 - val_loss: 35.6617\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 30.3917 - val_loss: 38.4602\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 27.4128 - val_loss: 36.2542\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 25.5989 - val_loss: 38.4240\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 22.5630 - val_loss: 37.8285\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 22.2587 - val_loss: 38.2865\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 20.6496 - val_loss: 39.2197\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 19.9515 - val_loss: 41.9933\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 17.2281 - val_loss: 42.3934\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 17.8556 - val_loss: 39.0849\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 14.1607 - val_loss: 40.5759\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 12.6441 - val_loss: 41.7751\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 12.5771 - val_loss: 41.0645\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 11.5573 - val_loss: 41.6844\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 11.8473 - val_loss: 39.9172\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 11.3280 - val_loss: 37.9976\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 10.9128 - val_loss: 38.6021\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 9.4709 - val_loss: 38.8666\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 49us/sample - loss: 8.9635 - val_loss: 39.0177\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 10.4905 - val_loss: 40.7337\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 10.5323 - val_loss: 38.0771\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 10.8904 - val_loss: 41.9007\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 10.4226 - val_loss: 38.2843\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 9.6615 - val_loss: 39.8493\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 9.4681 - val_loss: 38.8427\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 10.1542 - val_loss: 41.6900\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 49us/sample - loss: 8.0588 - val_loss: 42.5710\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 10.1829 - val_loss: 43.2360\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 12.1636 - val_loss: 38.2550\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 49us/sample - loss: 9.9980 - val_loss: 39.8378\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 10.8648 - val_loss: 40.4045\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 10.7713 - val_loss: 40.3452\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 10.5301 - val_loss: 41.6420\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 9.9506 - val_loss: 43.4565\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 49us/sample - loss: 9.2899 - val_loss: 42.0129\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 49us/sample - loss: 8.4528 - val_loss: 42.5769\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 8.1066 - val_loss: 41.7721\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 9.5407 - val_loss: 41.5876\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 48us/sample - loss: 8.6146 - val_loss: 40.8363\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 8.4144 - val_loss: 39.9113\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 8.9766 - val_loss: 40.3479\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 8.1583 - val_loss: 40.3839\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 7.3236 - val_loss: 40.3782\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 8.1047 - val_loss: 41.4573\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 6.3554 - val_loss: 40.7255\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 7.6552 - val_loss: 40.3836\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 6.6902 - val_loss: 40.5380\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 43us/sample - loss: 7.0393 - val_loss: 41.0141\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 7.9065 - val_loss: 41.9530\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 6.9924 - val_loss: 43.6317\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 7.7697 - val_loss: 42.8939\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 7.9800 - val_loss: 42.1800\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 7.2414 - val_loss: 40.6610\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 8.0291 - val_loss: 39.8194\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 49us/sample - loss: 8.2337 - val_loss: 41.1799\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 7.7390 - val_loss: 44.5450\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 6.4814 - val_loss: 43.2362\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 6.2848 - val_loss: 41.4853\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 7.6534 - val_loss: 40.5000\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 44us/sample - loss: 7.1453 - val_loss: 41.4852\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 7.8555 - val_loss: 40.5006\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 6.5076 - val_loss: 41.9623\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 8.2248 - val_loss: 41.0735\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 8.1903 - val_loss: 39.0038\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 9.9356 - val_loss: 40.2710\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 12.7404 - val_loss: 38.7613\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 7.5975 - val_loss: 39.1078\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 54us/sample - loss: 6.4581 - val_loss: 39.5419\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 8.3981 - val_loss: 39.9888\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 10.9313 - val_loss: 37.8556\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 56us/sample - loss: 6.5647 - val_loss: 36.9025\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 49us/sample - loss: 5.4219 - val_loss: 38.8807\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 53us/sample - loss: 6.9948 - val_loss: 40.4214\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 5.5540 - val_loss: 40.6747\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 7.0011 - val_loss: 40.3039\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 5.8359 - val_loss: 39.2692\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 5.8605 - val_loss: 38.4455\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 4.7931 - val_loss: 38.3080\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 5.1950 - val_loss: 39.3540\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 49us/sample - loss: 5.1207 - val_loss: 39.4949\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 6.0078 - val_loss: 39.0838\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 6.4801 - val_loss: 38.7212\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 5.1382 - val_loss: 38.2288\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 49us/sample - loss: 6.0416 - val_loss: 38.0115\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 5.0017 - val_loss: 37.7848\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 4.7837 - val_loss: 39.4868\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 49us/sample - loss: 6.4914 - val_loss: 39.6752\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 5.8878 - val_loss: 39.1161\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 7.6953 - val_loss: 38.6096\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 5.7830 - val_loss: 38.5674\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 4.5325 - val_loss: 39.6054\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 49us/sample - loss: 4.5860 - val_loss: 40.5896\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 5.7936 - val_loss: 41.3210\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 4.2867 - val_loss: 40.6626\n",
      "\n",
      "Mean squared error: 4.3\n",
      "\n",
      "dropout: 4.6e-01\n",
      "filter_num: 300\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 113us/sample - loss: 57.3047 - val_loss: 39.5262\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 46.1155 - val_loss: 38.2965\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 43.4919 - val_loss: 38.4913\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 39.9089 - val_loss: 34.0401\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 36.9429 - val_loss: 34.3388\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 34.4352 - val_loss: 33.6751\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 30.4814 - val_loss: 33.1275\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 29.7051 - val_loss: 33.6146\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 27.8290 - val_loss: 34.6448\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 24.2649 - val_loss: 35.4537\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 21.6667 - val_loss: 35.7254\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 20.2075 - val_loss: 37.4214\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 18.3653 - val_loss: 40.9108\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 15.8150 - val_loss: 43.0925\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 13.0966 - val_loss: 44.1336\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 11.6284 - val_loss: 44.4058\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 10.8078 - val_loss: 49.6980\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 9.9739 - val_loss: 44.1522\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 25us/sample - loss: 11.2432 - val_loss: 58.7136\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 9.9931 - val_loss: 48.8933\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 8.1627 - val_loss: 61.9336\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 8.5832 - val_loss: 45.6254\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 8.9373 - val_loss: 55.2330\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 9.1500 - val_loss: 45.4596\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 8.1667 - val_loss: 52.3578\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 7.1985 - val_loss: 49.0824\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.2189 - val_loss: 54.2743\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 7.1094 - val_loss: 48.9804\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 6.9940 - val_loss: 51.6855\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 6.2577 - val_loss: 54.3145\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.3020 - val_loss: 55.1213\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 8.9716 - val_loss: 50.0725\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.5317 - val_loss: 50.3192\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 7.6658 - val_loss: 46.1868\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 7.3509 - val_loss: 44.0303\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 7.1113 - val_loss: 47.4243\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.4541 - val_loss: 45.7212\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.8518 - val_loss: 51.7804\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.0005 - val_loss: 46.1293\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.7905 - val_loss: 45.9048\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.2092 - val_loss: 45.7758\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 6.1143 - val_loss: 44.6996\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.8632 - val_loss: 53.0453\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.7076 - val_loss: 49.7498\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.6818 - val_loss: 52.4682\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.0966 - val_loss: 49.0986\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.6927 - val_loss: 51.1575\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.5306 - val_loss: 50.3334\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 4.4629 - val_loss: 49.5533\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.2903 - val_loss: 47.2519\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 4.1810 - val_loss: 50.4562\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.9840 - val_loss: 48.9202\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.3759 - val_loss: 52.2346\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.8819 - val_loss: 51.7978\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.1684 - val_loss: 51.9040\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.5083 - val_loss: 54.1234\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.3982 - val_loss: 51.2434\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 8.0357 - val_loss: 52.6144\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.3347 - val_loss: 50.1799\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.2140 - val_loss: 52.2818\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 3.9041 - val_loss: 51.9075\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.4676 - val_loss: 55.4771\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.7694 - val_loss: 54.9817\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.0777 - val_loss: 54.6832\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.2953 - val_loss: 52.2247\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.3454 - val_loss: 53.4937\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 3.6569 - val_loss: 50.4524\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.4599 - val_loss: 52.7492\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.2209 - val_loss: 55.8983\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.7616 - val_loss: 49.1943\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.6774 - val_loss: 52.5433\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.2815 - val_loss: 48.5306\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.0297 - val_loss: 51.6236\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.9017 - val_loss: 56.5329\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.6920 - val_loss: 54.6785\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.4642 - val_loss: 53.3456\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.0173 - val_loss: 53.7202\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.1666 - val_loss: 54.7957\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.9560 - val_loss: 55.0768\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.0969 - val_loss: 54.8938\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.9233 - val_loss: 52.1929\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.6331 - val_loss: 52.0725\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.6593 - val_loss: 49.1966\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.5844 - val_loss: 54.1194\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.5355 - val_loss: 53.7630\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.7424 - val_loss: 51.5325\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.2798 - val_loss: 52.6495\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.5517 - val_loss: 50.3101\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 2.5421 - val_loss: 53.9920\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.5258 - val_loss: 53.2654\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.7318 - val_loss: 53.6033\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.8950 - val_loss: 53.7140\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.4226 - val_loss: 56.4891\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.0790 - val_loss: 55.6295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.5670 - val_loss: 57.3806\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.2675 - val_loss: 58.8600\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.2733 - val_loss: 56.7230\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.5599 - val_loss: 59.2463\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.4197 - val_loss: 56.8899\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.5383 - val_loss: 57.2223\n",
      "\n",
      "Mean squared error: 3.5\n",
      "\n",
      "dropout: 2.2e-01\n",
      "filter_num: 270\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 111us/sample - loss: 59.3973 - val_loss: 40.7930\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 45.7031 - val_loss: 37.9403\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 41.7174 - val_loss: 38.0514\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 38.0766 - val_loss: 35.0057\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 35.1245 - val_loss: 34.4906\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 31.6284 - val_loss: 34.8259\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 29.7488 - val_loss: 35.7654\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 26.4117 - val_loss: 35.9487\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 24.8876 - val_loss: 38.4668\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 22.9108 - val_loss: 38.2179\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 20.0181 - val_loss: 43.0809\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 19.3142 - val_loss: 44.0512\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 15.7725 - val_loss: 44.1928\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 13.8221 - val_loss: 47.3226\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 12.2541 - val_loss: 42.4793\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 10.5463 - val_loss: 50.5838\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 9.2465 - val_loss: 43.1343\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 8.3795 - val_loss: 56.7245\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 9.6410 - val_loss: 40.9212\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 10.2648 - val_loss: 52.7784\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 10.5545 - val_loss: 42.0462\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 11.1583 - val_loss: 51.8543\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 8.6156 - val_loss: 46.3549\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 8.3587 - val_loss: 43.5099\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 6.3545 - val_loss: 49.0349\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 5.4713 - val_loss: 43.7387\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 5.0990 - val_loss: 51.3791\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 5.1668 - val_loss: 43.1794\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 5.1860 - val_loss: 43.6446\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 4.7877 - val_loss: 43.7729\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 4.7368 - val_loss: 43.6212\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 4.3314 - val_loss: 43.5154\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 4.1626 - val_loss: 48.0736\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 7.8115 - val_loss: 46.3194\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 6.9848 - val_loss: 43.5741\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 4.9653 - val_loss: 45.3729\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.1720 - val_loss: 45.2334\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.2613 - val_loss: 49.4633\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.0197 - val_loss: 49.5412\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.7065 - val_loss: 47.6987\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.9641 - val_loss: 47.4109\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.5374 - val_loss: 45.0709\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.3191 - val_loss: 44.8016\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 2.5335 - val_loss: 44.6811\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.1647 - val_loss: 43.9338\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 2.1002 - val_loss: 42.8052\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.4319 - val_loss: 42.0505\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.5402 - val_loss: 43.5414\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.5437 - val_loss: 45.7990\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.3233 - val_loss: 48.3241\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.2836 - val_loss: 45.9309\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 2.4273 - val_loss: 48.4355\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.0186 - val_loss: 46.1945\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 1.9569 - val_loss: 47.1816\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.8783 - val_loss: 46.2290\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 1.8791 - val_loss: 46.8613\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.6501 - val_loss: 47.1625\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.7654 - val_loss: 46.2985\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.7261 - val_loss: 47.4436\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.6963 - val_loss: 46.7017\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.8575 - val_loss: 47.1532\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.9082 - val_loss: 46.3746\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.9915 - val_loss: 44.8290\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.6971 - val_loss: 47.8037\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.7670 - val_loss: 46.3241\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.8450 - val_loss: 46.9434\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.8034 - val_loss: 43.2741\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.9857 - val_loss: 41.2854\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.0528 - val_loss: 40.6473\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.7597 - val_loss: 40.2903\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.5521 - val_loss: 40.2248\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.6855 - val_loss: 41.3254\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.4089 - val_loss: 43.5797\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.9862 - val_loss: 43.9165\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 3.1832 - val_loss: 44.3830\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.8399 - val_loss: 43.3774\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 1.9640 - val_loss: 45.7011\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.5636 - val_loss: 45.4286\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.5111 - val_loss: 43.8865\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 1.3871 - val_loss: 44.9879\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.5143 - val_loss: 44.9729\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.7413 - val_loss: 45.2388\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.0788 - val_loss: 44.4389\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.8601 - val_loss: 43.4880\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.5883 - val_loss: 43.3312\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.4308 - val_loss: 44.1262\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.3093 - val_loss: 44.3435\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.0570 - val_loss: 45.2768\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.8834 - val_loss: 43.3478\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.7063 - val_loss: 44.4226\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.9993 - val_loss: 43.5569\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.6110 - val_loss: 44.3248\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.3065 - val_loss: 44.2049\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.4368 - val_loss: 45.0816\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 0.9972 - val_loss: 44.7911\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.0266 - val_loss: 43.1017\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.1634 - val_loss: 42.9731\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.1920 - val_loss: 44.1257\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.6127 - val_loss: 43.3804\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.3158 - val_loss: 43.8678\n",
      "\n",
      "Mean squared error: 1.3\n",
      "\n",
      "dropout: 2.0e-01\n",
      "filter_num: 10\n",
      "num_dense_layers: 3\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 131us/sample - loss: 65.5058 - val_loss: 59.9652\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 65.4083 - val_loss: 59.8280\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 65.1907 - val_loss: 59.5559\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 64.7842 - val_loss: 59.0136\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 63.9218 - val_loss: 57.8456\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 62.2630 - val_loss: 55.3398\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 58.4375 - val_loss: 50.4720\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 51.9879 - val_loss: 42.6352\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 44.9874 - val_loss: 35.2309\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 41.3943 - val_loss: 33.1918\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 43.0956 - val_loss: 33.5514\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 41.1109 - val_loss: 35.4261\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 39.4613 - val_loss: 35.2399\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 37.2156 - val_loss: 34.8115\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 37.0161 - val_loss: 34.2002\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 38.4713 - val_loss: 33.7931\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 36.9818 - val_loss: 33.8854\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 37.0608 - val_loss: 34.2202\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 35.0969 - val_loss: 34.3145\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 34.6556 - val_loss: 34.2126\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 34.6116 - val_loss: 33.9254\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 33.3505 - val_loss: 33.9974\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 33.1028 - val_loss: 34.2683\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 31.6554 - val_loss: 34.5888\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 31.1849 - val_loss: 34.6746\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 32.4973 - val_loss: 35.0514\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 30.6877 - val_loss: 35.0406\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 30.3424 - val_loss: 35.1463\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 30.8503 - val_loss: 35.4919\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 29.9408 - val_loss: 35.7966\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 27.8804 - val_loss: 36.1217\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 27.2670 - val_loss: 36.8536\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 34.6377 - val_loss: 37.2088\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 29.8356 - val_loss: 37.4563\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 27.6674 - val_loss: 38.2932\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 27.8890 - val_loss: 38.6662\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 25.2910 - val_loss: 38.9396\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 27.5693 - val_loss: 39.2830\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 27.6388 - val_loss: 39.9364\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 27.8236 - val_loss: 40.5910\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 25.5301 - val_loss: 41.6818\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 27.6760 - val_loss: 42.5618\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 11us/sample - loss: 25.1556 - val_loss: 42.9924\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 27.3522 - val_loss: 43.1140\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 26.2520 - val_loss: 43.6669\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 22.9084 - val_loss: 44.6419\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 24.9866 - val_loss: 45.9973\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 24.1258 - val_loss: 46.8919\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 25.4986 - val_loss: 50.4064\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 22.9530 - val_loss: 51.6695\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 23.6159 - val_loss: 53.7068\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 21.9790 - val_loss: 56.0406\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 20.9758 - val_loss: 57.5058\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 21.0891 - val_loss: 59.5851\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 5us/sample - loss: 21.8685 - val_loss: 60.9750\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 20.4296 - val_loss: 63.2864\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 20.5443 - val_loss: 66.2321\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 19.7490 - val_loss: 69.7717\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 17.5436 - val_loss: 73.9681\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 18.6989 - val_loss: 77.5537\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 19.5972 - val_loss: 84.7241\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 20.4465 - val_loss: 88.9919\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 17.4929 - val_loss: 95.3672\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 19.4479 - val_loss: 105.0574\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 20.1027 - val_loss: 110.3701\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 18.9507 - val_loss: 110.5596\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 18.0460 - val_loss: 122.5863\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 16.7500 - val_loss: 143.0268\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 16.5362 - val_loss: 152.4608\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 15.5580 - val_loss: 148.1313\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 16.0465 - val_loss: 148.1624\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 13.7415 - val_loss: 171.6235\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 15.6471 - val_loss: 197.5294\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 16.2125 - val_loss: 209.5602\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 13.9890 - val_loss: 202.4942\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 14.6600 - val_loss: 196.7166\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 14.5993 - val_loss: 212.7120\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 13.0353 - val_loss: 246.5782\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 10.4542 - val_loss: 260.0191\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 12.1997 - val_loss: 264.4169\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 12.1443 - val_loss: 282.3498\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 13.7716 - val_loss: 322.1912\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 9.1775 - val_loss: 342.7645\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 10.0522 - val_loss: 351.6274\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 11.0963 - val_loss: 346.0205\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 10.9565 - val_loss: 371.1482\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 11.3065 - val_loss: 444.0215\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 13.3151 - val_loss: 429.2418\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 11.0452 - val_loss: 427.2825\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 9.9653 - val_loss: 408.9429\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 10.2049 - val_loss: 409.2125\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 10.8184 - val_loss: 438.6443\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 11.1090 - val_loss: 475.0639\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 11.0224 - val_loss: 443.5799\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 12.0211 - val_loss: 387.5971\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 9.9289 - val_loss: 440.5137\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 9.9318 - val_loss: 480.6658\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 10.5553 - val_loss: 472.8638\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 8.9941 - val_loss: 461.2415\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 10.0638 - val_loss: 427.4820\n",
      "\n",
      "Mean squared error: 1e+01\n",
      "\n",
      "dropout: 8.0e-01\n",
      "filter_num: 300\n",
      "num_dense_layers: 14\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 1s 459us/sample - loss: 15513.8136 - val_loss: 60.0669\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 122us/sample - loss: 737.5662 - val_loss: 60.0214\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 126us/sample - loss: 265.9256 - val_loss: 60.0054\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 128us/sample - loss: 204.9705 - val_loss: 60.0127\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 135us/sample - loss: 144.6270 - val_loss: 60.0277\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 130us/sample - loss: 109.6606 - val_loss: 60.0398\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 128us/sample - loss: 109.9332 - val_loss: 60.0461\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 122us/sample - loss: 95.4257 - val_loss: 60.0494\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 115us/sample - loss: 86.3345 - val_loss: 60.0510\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 122us/sample - loss: 93.2291 - val_loss: 60.0505\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 122us/sample - loss: 85.6692 - val_loss: 60.0485\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 123us/sample - loss: 76.2555 - val_loss: 60.0441\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 118us/sample - loss: 70.1800 - val_loss: 60.0380\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 124us/sample - loss: 77.4548 - val_loss: 60.0307\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 122us/sample - loss: 72.9187 - val_loss: 60.0184\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 123us/sample - loss: 75.6231 - val_loss: 59.9998\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 122us/sample - loss: 69.0119 - val_loss: 59.9736\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 121us/sample - loss: 71.4066 - val_loss: 59.9404\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 119us/sample - loss: 65.1598 - val_loss: 59.9025\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 123us/sample - loss: 73.7702 - val_loss: 59.8645\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 118us/sample - loss: 66.0169 - val_loss: 59.8205\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 119us/sample - loss: 70.9952 - val_loss: 59.7767\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 124us/sample - loss: 65.2532 - val_loss: 59.7326\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 121us/sample - loss: 65.0822 - val_loss: 59.6865\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 115us/sample - loss: 68.2722 - val_loss: 59.6394\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 120us/sample - loss: 65.5770 - val_loss: 59.5954\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 118us/sample - loss: 66.3110 - val_loss: 59.5515\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 120us/sample - loss: 62.7106 - val_loss: 59.5043\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 124us/sample - loss: 63.4195 - val_loss: 59.4477\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 121us/sample - loss: 69.3407 - val_loss: 59.3960\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 121us/sample - loss: 61.3163 - val_loss: 59.3449\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 122us/sample - loss: 61.0639 - val_loss: 59.2975\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 119us/sample - loss: 66.3936 - val_loss: 59.2488\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 117us/sample - loss: 64.7964 - val_loss: 59.2032\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 122us/sample - loss: 77.4793 - val_loss: 59.1567\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 125us/sample - loss: 63.8038 - val_loss: 59.1001\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 121us/sample - loss: 67.2294 - val_loss: 59.0389\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 121us/sample - loss: 62.8180 - val_loss: 58.9681\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 117us/sample - loss: 62.8584 - val_loss: 58.9035\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 121us/sample - loss: 65.6060 - val_loss: 58.8363\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 119us/sample - loss: 63.7050 - val_loss: 58.7692\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 121us/sample - loss: 60.7278 - val_loss: 58.7030\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 120us/sample - loss: 61.5610 - val_loss: 58.6328\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 123us/sample - loss: 58.5208 - val_loss: 58.5612\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 121us/sample - loss: 61.8625 - val_loss: 58.4957\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 121us/sample - loss: 59.5046 - val_loss: 58.4249\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 125us/sample - loss: 62.2531 - val_loss: 58.3529\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 123us/sample - loss: 61.6434 - val_loss: 58.2862\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 121us/sample - loss: 57.6737 - val_loss: 58.2187\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 120us/sample - loss: 61.6025 - val_loss: 58.1562\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 122us/sample - loss: 59.0315 - val_loss: 58.0930\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 116us/sample - loss: 60.5674 - val_loss: 58.0321\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 121us/sample - loss: 62.1521 - val_loss: 57.9738\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 117us/sample - loss: 59.8473 - val_loss: 57.9137\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 123us/sample - loss: 56.4285 - val_loss: 57.8481\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 134us/sample - loss: 57.9932 - val_loss: 57.7803\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 131us/sample - loss: 59.6091 - val_loss: 57.7124\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 134us/sample - loss: 56.9879 - val_loss: 57.6486\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 131us/sample - loss: 61.6648 - val_loss: 57.5858\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 119us/sample - loss: 59.2161 - val_loss: 57.5213\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 120us/sample - loss: 62.1024 - val_loss: 57.4588\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 120us/sample - loss: 55.7093 - val_loss: 57.3959\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 122us/sample - loss: 57.9075 - val_loss: 57.3327\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 126us/sample - loss: 59.1470 - val_loss: 57.2568\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 120us/sample - loss: 61.1463 - val_loss: 57.1765\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 118us/sample - loss: 61.0052 - val_loss: 57.0997\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 122us/sample - loss: 56.3541 - val_loss: 57.0271\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 119us/sample - loss: 59.0670 - val_loss: 56.9639\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 121us/sample - loss: 56.4499 - val_loss: 56.9046\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 117us/sample - loss: 55.3309 - val_loss: 56.8413\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 122us/sample - loss: 60.4511 - val_loss: 56.7759\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 120us/sample - loss: 55.2338 - val_loss: 56.7093\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 124us/sample - loss: 55.2131 - val_loss: 56.6376\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 122us/sample - loss: 55.6652 - val_loss: 56.5707\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 120us/sample - loss: 55.7978 - val_loss: 56.4960\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 121us/sample - loss: 56.7950 - val_loss: 56.4183\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 122us/sample - loss: 58.9712 - val_loss: 56.3530\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 121us/sample - loss: 54.3708 - val_loss: 56.3063\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 123us/sample - loss: 58.0232 - val_loss: 56.2432\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 119us/sample - loss: 54.4061 - val_loss: 56.1699\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 122us/sample - loss: 58.1579 - val_loss: 56.0869\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 122us/sample - loss: 57.1494 - val_loss: 56.0031\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 121us/sample - loss: 57.3064 - val_loss: 55.9251\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 121us/sample - loss: 56.3782 - val_loss: 55.8474\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 122us/sample - loss: 53.4866 - val_loss: 55.7661\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 118us/sample - loss: 53.0691 - val_loss: 55.6812\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 123us/sample - loss: 54.1955 - val_loss: 55.5850\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 124us/sample - loss: 54.7079 - val_loss: 55.4844\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 121us/sample - loss: 56.6486 - val_loss: 55.3929\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 123us/sample - loss: 52.1545 - val_loss: 55.3158\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 118us/sample - loss: 54.8809 - val_loss: 55.2422\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 120us/sample - loss: 54.0248 - val_loss: 55.1778\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 117us/sample - loss: 52.4582 - val_loss: 55.1126\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 121us/sample - loss: 54.4094 - val_loss: 55.0456\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 120us/sample - loss: 56.9719 - val_loss: 54.9727\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 118us/sample - loss: 53.7321 - val_loss: 54.8973\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 120us/sample - loss: 53.1572 - val_loss: 54.8236\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 119us/sample - loss: 50.4759 - val_loss: 54.7386\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 123us/sample - loss: 54.3235 - val_loss: 54.6641\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 123us/sample - loss: 52.8856 - val_loss: 54.5827\n",
      "\n",
      "Mean squared error: 5.3e+01\n",
      "\n",
      "dropout: 2.6e-01\n",
      "filter_num: 10\n",
      "num_dense_layers: 7\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 1s 203us/sample - loss: 65.5141 - val_loss: 59.9846\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 65.4473 - val_loss: 59.9116\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 65.3575 - val_loss: 59.8140\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 65.2241 - val_loss: 59.6676\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 64.9891 - val_loss: 59.4239\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 64.4122 - val_loss: 58.9708\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 63.6352 - val_loss: 58.0658\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 61.9824 - val_loss: 56.1103\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 58.3795 - val_loss: 52.1266\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 55.0461 - val_loss: 46.3205\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 51.9746 - val_loss: 42.9587\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 49.7084 - val_loss: 44.1488\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 51.5868 - val_loss: 44.6686\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 45.5063 - val_loss: 43.8246\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 49.6069 - val_loss: 43.7830\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 49.6602 - val_loss: 44.3792\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 48.0696 - val_loss: 44.1616\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 45.0088 - val_loss: 43.0843\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 43.9379 - val_loss: 41.9697\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 42.5296 - val_loss: 41.8686\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 42.3364 - val_loss: 43.6631\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 43.6806 - val_loss: 43.5868\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 42.8354 - val_loss: 42.1845\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 39.8239 - val_loss: 41.4604\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 41.8552 - val_loss: 42.0171\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 38.3766 - val_loss: 41.5533\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 41.6341 - val_loss: 42.0932\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 39.9957 - val_loss: 42.8046\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 36.9714 - val_loss: 40.9590\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 37.7667 - val_loss: 40.9927\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 37.2413 - val_loss: 41.4629\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 42.4500 - val_loss: 43.2227\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 40.3810 - val_loss: 43.3364\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 35.7021 - val_loss: 41.5404\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 39.2454 - val_loss: 39.7505\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 35.8602 - val_loss: 40.9806\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 41.0556 - val_loss: 42.8350\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 36.8958 - val_loss: 43.8479\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 33.8903 - val_loss: 43.9931\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 37.6540 - val_loss: 42.5789\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 35.3716 - val_loss: 41.9913\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 34.6913 - val_loss: 42.6203\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 35.3836 - val_loss: 42.7673\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 34.7150 - val_loss: 42.2006\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 34.2386 - val_loss: 41.7350\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 34.1419 - val_loss: 41.5132\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 30.6195 - val_loss: 40.0267\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 33.9125 - val_loss: 39.7722\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 34.2513 - val_loss: 39.7990\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 32.0880 - val_loss: 40.5667\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 34.5851 - val_loss: 40.9283\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 32.6252 - val_loss: 42.5757\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 33.5937 - val_loss: 43.5798\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 34.0880 - val_loss: 43.0380\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 29.2347 - val_loss: 41.9485\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 34.9110 - val_loss: 42.0044\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 31.7053 - val_loss: 42.9987\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 27.6786 - val_loss: 42.7405\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 30.7005 - val_loss: 42.2008\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 28.4080 - val_loss: 42.5037\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 26.6640 - val_loss: 43.7279\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 28.2293 - val_loss: 44.7735\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 35.2377 - val_loss: 44.4181\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 13us/sample - loss: 27.4464 - val_loss: 44.8333\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 25.1516 - val_loss: 45.4906\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 29.8919 - val_loss: 45.9566\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 25.5501 - val_loss: 45.8042\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 25.8779 - val_loss: 46.4682\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 28.0690 - val_loss: 47.9669\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 27.4249 - val_loss: 49.0047\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 25.9842 - val_loss: 49.6547\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 22.0262 - val_loss: 49.5873\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 24.4384 - val_loss: 50.3816\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 26.6966 - val_loss: 50.8116\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 25.5044 - val_loss: 51.5214\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 29.9523 - val_loss: 51.2977\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 24.4318 - val_loss: 50.0904\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 20.7247 - val_loss: 50.1567\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 23.1817 - val_loss: 50.4528\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 23.1981 - val_loss: 51.0913\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 27.7171 - val_loss: 51.3118\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 21.8943 - val_loss: 52.6399\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 24.4044 - val_loss: 54.4618\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 25.5274 - val_loss: 55.7824\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 24.1719 - val_loss: 54.2683\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 20.1188 - val_loss: 53.9063\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 25.9842 - val_loss: 54.3700\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 28.9035 - val_loss: 54.0878\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 22.1472 - val_loss: 54.4312\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 21.2016 - val_loss: 55.3698\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 19.8808 - val_loss: 56.0017\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 21.0157 - val_loss: 55.1925\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 19.9448 - val_loss: 56.4575\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 22.2160 - val_loss: 57.5017\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 18.1091 - val_loss: 58.0962\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 21.0331 - val_loss: 57.5124\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 24.9423 - val_loss: 54.3304\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 21.3842 - val_loss: 52.9361\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 21.7376 - val_loss: 53.3976\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 22.1152 - val_loss: 54.0851\n",
      "\n",
      "Mean squared error: 2.2e+01\n",
      "\n",
      "dropout: 2.0e-01\n",
      "filter_num: 145\n",
      "num_dense_layers: 4\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 162us/sample - loss: 63.4738 - val_loss: 50.6267\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 48.5252 - val_loss: 41.2362\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 43.7202 - val_loss: 39.7386\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 41.7438 - val_loss: 37.1401\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 38.2793 - val_loss: 35.2289\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 34.9676 - val_loss: 36.0389\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 31.3628 - val_loss: 35.6027\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 29.4335 - val_loss: 35.7184\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 29.1390 - val_loss: 37.3532\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 25.7844 - val_loss: 37.2252\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 23.5977 - val_loss: 46.0865\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 21.0711 - val_loss: 39.4861\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 22.2365 - val_loss: 43.8540\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 18.6559 - val_loss: 41.6207\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 15.9787 - val_loss: 43.4363\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 14.0778 - val_loss: 46.2249\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 11.9321 - val_loss: 46.2037\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 10.8583 - val_loss: 50.0153\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 9.6157 - val_loss: 49.4666\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 9.5875 - val_loss: 52.6688\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 9.0543 - val_loss: 63.2488\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 9.0710 - val_loss: 53.0802\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 8.9749 - val_loss: 60.2963\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 8.9033 - val_loss: 53.8030\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 9.8428 - val_loss: 45.2080\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 10.3616 - val_loss: 58.3891\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 9.2010 - val_loss: 47.5468\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 8.6050 - val_loss: 64.4385\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 7.8452 - val_loss: 49.8126\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 8.0657 - val_loss: 56.6768\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.3477 - val_loss: 51.7551\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.6906 - val_loss: 58.0016\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 5.6650 - val_loss: 55.1842\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 5.4606 - val_loss: 53.0734\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.1993 - val_loss: 54.3700\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.8602 - val_loss: 55.1006\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.8502 - val_loss: 59.5142\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.9455 - val_loss: 53.1601\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.9319 - val_loss: 50.3697\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.6155 - val_loss: 58.0138\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.8762 - val_loss: 48.4123\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.0224 - val_loss: 56.8519\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 5.3448 - val_loss: 50.9572\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 5.1494 - val_loss: 55.8208\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.4049 - val_loss: 59.4176\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 13.3409 - val_loss: 48.4855\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 8.9855 - val_loss: 55.6890\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 8.7612 - val_loss: 46.5045\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.8791 - val_loss: 54.5498\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.2951 - val_loss: 53.8795\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.7073 - val_loss: 63.1316\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.3993 - val_loss: 50.5338\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 11.8506 - val_loss: 44.0339\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 7.0962 - val_loss: 54.0184\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 5.8142 - val_loss: 50.3278\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.7750 - val_loss: 60.5393\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.8546 - val_loss: 53.7403\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.2319 - val_loss: 51.0917\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.3730 - val_loss: 45.3834\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.1472 - val_loss: 46.9671\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.3591 - val_loss: 49.2984\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 6.4367 - val_loss: 43.6845\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 7.0368 - val_loss: 49.8554\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.1464 - val_loss: 46.8303\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.0135 - val_loss: 49.7195\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.8511 - val_loss: 50.2790\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.8390 - val_loss: 48.0112\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.5208 - val_loss: 49.3812\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.9038 - val_loss: 49.8557\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.3179 - val_loss: 53.1857\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.7852 - val_loss: 48.5561\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 3.7115 - val_loss: 51.9147\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.2947 - val_loss: 48.5871\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.5085 - val_loss: 53.5186\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.7299 - val_loss: 50.2539\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.9871 - val_loss: 55.2379\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.3436 - val_loss: 54.3004\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 3.5391 - val_loss: 53.8752\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.9187 - val_loss: 54.8736\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.3194 - val_loss: 50.0502\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.1695 - val_loss: 52.9072\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.6554 - val_loss: 48.9075\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.6496 - val_loss: 50.1690\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 2.8240 - val_loss: 51.8374\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.0309 - val_loss: 50.8437\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.4329 - val_loss: 49.0109\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.7674 - val_loss: 50.3225\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.5352 - val_loss: 45.9802\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 7.3419 - val_loss: 51.7928\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 6.1949 - val_loss: 45.3172\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.9218 - val_loss: 50.9723\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.0231 - val_loss: 44.0311\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.3711 - val_loss: 46.6557\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 7.4760 - val_loss: 45.6186\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.0577 - val_loss: 48.6029\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 4.5431 - val_loss: 52.1964\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.8559 - val_loss: 50.8403\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.3915 - val_loss: 52.4969\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.6684 - val_loss: 51.7096\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 3.6640 - val_loss: 49.0640\n",
      "\n",
      "Mean squared error: 3.7\n",
      "\n",
      "dropout: 2.8e-01\n",
      "filter_num: 189\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 101us/sample - loss: 61.8380 - val_loss: 47.5502\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 48.0962 - val_loss: 38.8608\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 42.8378 - val_loss: 36.8955\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 41.0206 - val_loss: 37.4267\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 36.8656 - val_loss: 34.3269\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 33.9943 - val_loss: 33.9071\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 32.0669 - val_loss: 33.7639\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 29.4203 - val_loss: 34.0829\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 28.5312 - val_loss: 36.4771\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 26.9919 - val_loss: 37.2513\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 25.2719 - val_loss: 38.2983\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 19us/sample - loss: 23.1770 - val_loss: 39.0009\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 21.2322 - val_loss: 42.1552\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 20.5609 - val_loss: 44.1355\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 18.8802 - val_loss: 45.3892\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 18.0805 - val_loss: 45.2129\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 15.1048 - val_loss: 54.0105\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 13.9233 - val_loss: 46.3368\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 13.3506 - val_loss: 51.6342\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 11.6804 - val_loss: 54.6592\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 10.5304 - val_loss: 57.9631\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 9.4099 - val_loss: 63.1244\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 7.7362 - val_loss: 56.5905\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 7.4822 - val_loss: 61.8852\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 7.6128 - val_loss: 58.1201\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 7.2020 - val_loss: 65.5309\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 7.0687 - val_loss: 61.5264\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 6.8390 - val_loss: 66.1743\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 6.2378 - val_loss: 65.8539\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 6.8386 - val_loss: 64.9637\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 6.2348 - val_loss: 61.9444\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 6.1865 - val_loss: 62.7236\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 6.5460 - val_loss: 62.7497\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 5.1949 - val_loss: 67.2430\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.8273 - val_loss: 63.4442\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 4.5671 - val_loss: 64.8855\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 4.2355 - val_loss: 63.7172\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 4.0040 - val_loss: 65.9656\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 3.9968 - val_loss: 67.4785\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 3.7366 - val_loss: 65.1966\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 3.9113 - val_loss: 65.7890\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 4.2618 - val_loss: 64.0079\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 4.1250 - val_loss: 66.8272\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.2475 - val_loss: 65.3920\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 3.7843 - val_loss: 64.2318\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 3.0765 - val_loss: 63.6374\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 3.3534 - val_loss: 65.4992\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 3.5279 - val_loss: 64.7844\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.9349 - val_loss: 67.9971\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 5.1494 - val_loss: 62.6353\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 3.6880 - val_loss: 63.8094\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 3.2631 - val_loss: 63.3115\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 3.6979 - val_loss: 63.0125\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.4694 - val_loss: 68.2286\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 3.3754 - val_loss: 69.3551\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.0011 - val_loss: 65.4061\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 5.1936 - val_loss: 66.8492\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 4.5605 - val_loss: 65.4808\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 3.2713 - val_loss: 67.3457\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 3.0598 - val_loss: 67.4786\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.9238 - val_loss: 69.9341\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.7216 - val_loss: 71.3583\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.4070 - val_loss: 68.7194\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.0915 - val_loss: 69.0399\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.8762 - val_loss: 67.0869\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 3.6707 - val_loss: 63.6806\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.9175 - val_loss: 65.3712\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.8414 - val_loss: 68.8714\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.6000 - val_loss: 67.9292\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.2251 - val_loss: 72.0717\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.3526 - val_loss: 67.7298\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.3800 - val_loss: 71.6407\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.0689 - val_loss: 70.7365\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.9815 - val_loss: 65.7099\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.4891 - val_loss: 65.3705\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.4526 - val_loss: 63.0082\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.4536 - val_loss: 68.6061\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.2966 - val_loss: 65.6462\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.3344 - val_loss: 64.3072\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.6048 - val_loss: 65.1508\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.6033 - val_loss: 61.2035\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.9313 - val_loss: 63.5455\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.5788 - val_loss: 62.6332\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.3355 - val_loss: 66.1193\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.4362 - val_loss: 62.2256\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.4709 - val_loss: 68.1895\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.3882 - val_loss: 62.9231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.4780 - val_loss: 63.1234\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.3521 - val_loss: 60.7583\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.4363 - val_loss: 62.5205\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.6580 - val_loss: 64.6820\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.9966 - val_loss: 65.5590\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.7040 - val_loss: 69.1658\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 1.7538 - val_loss: 71.1487\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.5091 - val_loss: 74.5345\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.7505 - val_loss: 69.0704\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.5717 - val_loss: 73.6059\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.8039 - val_loss: 71.6757\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.7995 - val_loss: 74.2939\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.7485 - val_loss: 70.5607\n",
      "\n",
      "Mean squared error: 1.7\n",
      "\n",
      "dropout: 2.0e-01\n",
      "filter_num: 249\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 101us/sample - loss: 58.8482 - val_loss: 40.4914\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 45.4183 - val_loss: 37.2453\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 41.1236 - val_loss: 36.5620\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 38.0626 - val_loss: 34.1894\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 34.4753 - val_loss: 33.3634\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 31.9875 - val_loss: 33.4837\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 27.9656 - val_loss: 35.7488\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 25.5357 - val_loss: 35.3017\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 22.2464 - val_loss: 38.6553\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 20.0337 - val_loss: 37.2579\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 18.1005 - val_loss: 38.6200\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 14.8190 - val_loss: 45.2104\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 13.2794 - val_loss: 42.0372\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 11.4120 - val_loss: 43.8682\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 9.9075 - val_loss: 45.8094\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 8.6674 - val_loss: 40.7105\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 8.2427 - val_loss: 46.7251\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 7.0343 - val_loss: 39.2297\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 7.1548 - val_loss: 47.6316\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 9.2051 - val_loss: 38.6963\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 8.0536 - val_loss: 41.7416\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 7.0907 - val_loss: 36.6530\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 7.7347 - val_loss: 39.6129\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 6.0987 - val_loss: 38.1494\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 5.7546 - val_loss: 40.1167\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 5.8759 - val_loss: 40.3851\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 5.8608 - val_loss: 41.5506\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 5.0928 - val_loss: 41.4807\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 4.6662 - val_loss: 40.4928\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.9991 - val_loss: 40.7669\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 4.2642 - val_loss: 41.2610\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.7285 - val_loss: 41.6530\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.5157 - val_loss: 41.8379\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.2780 - val_loss: 43.2878\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 3.6867 - val_loss: 45.8166\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 3.6124 - val_loss: 47.6309\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.0733 - val_loss: 44.6668\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.8773 - val_loss: 44.0082\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.7349 - val_loss: 42.4448\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.7189 - val_loss: 46.1048\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.7138 - val_loss: 42.6322\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 3.4947 - val_loss: 42.2323\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.2362 - val_loss: 41.5860\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 3.0015 - val_loss: 43.9702\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.8276 - val_loss: 43.8285\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.6917 - val_loss: 42.8494\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.0208 - val_loss: 40.7591\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.7282 - val_loss: 41.5861\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.8566 - val_loss: 43.6223\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 3.5004 - val_loss: 44.2163\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.9691 - val_loss: 45.2893\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 3.3473 - val_loss: 42.8710\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 3.0906 - val_loss: 40.8857\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.6040 - val_loss: 45.2300\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.4998 - val_loss: 42.7447\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.9983 - val_loss: 44.8240\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.7595 - val_loss: 42.5555\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.7709 - val_loss: 43.2901\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.5978 - val_loss: 42.6248\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.5631 - val_loss: 43.1437\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.2467 - val_loss: 42.7861\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.4616 - val_loss: 43.4603\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.7908 - val_loss: 43.7529\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.9111 - val_loss: 45.2169\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.7393 - val_loss: 44.5394\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.4091 - val_loss: 45.5368\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.3604 - val_loss: 45.3655\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.4063 - val_loss: 46.3105\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.0460 - val_loss: 44.5476\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.2921 - val_loss: 46.6032\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.5283 - val_loss: 45.3608\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.7113 - val_loss: 48.2755\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.5657 - val_loss: 44.2253\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.0635 - val_loss: 46.5188\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.8234 - val_loss: 45.9467\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.1810 - val_loss: 48.0788\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.8849 - val_loss: 45.4256\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.8977 - val_loss: 45.3058\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 1.8991 - val_loss: 44.4994\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.6126 - val_loss: 46.1507\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.6904 - val_loss: 45.4633\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.4755 - val_loss: 48.3386\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.5224 - val_loss: 45.5362\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.5363 - val_loss: 47.1107\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.4918 - val_loss: 43.6635\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.6130 - val_loss: 45.4077\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.4118 - val_loss: 44.8509\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.4536 - val_loss: 48.9074\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.3054 - val_loss: 44.4226\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.3724 - val_loss: 48.0758\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.3002 - val_loss: 45.6318\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.1119 - val_loss: 47.3737\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.3918 - val_loss: 46.3027\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.6980 - val_loss: 46.0312\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.1396 - val_loss: 47.3097\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.4167 - val_loss: 45.0417\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.3017 - val_loss: 43.6000\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.1990 - val_loss: 43.9096\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.2250 - val_loss: 47.9382\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.4317 - val_loss: 48.9117\n",
      "\n",
      "Mean squared error: 1.4\n",
      "\n",
      "dropout: 2.4e-01\n",
      "filter_num: 187\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 104us/sample - loss: 61.8962 - val_loss: 47.4980\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 46.7002 - val_loss: 39.4809\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 42.3814 - val_loss: 37.2130\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 40.0678 - val_loss: 35.2203\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 36.3536 - val_loss: 33.7389\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 33.2823 - val_loss: 33.0846\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 31.7645 - val_loss: 32.7407\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 29.3069 - val_loss: 34.3755\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 27.2781 - val_loss: 32.8519\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 27.1402 - val_loss: 33.4827\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 24.4607 - val_loss: 37.8512\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 23.4671 - val_loss: 35.2525\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 21.4090 - val_loss: 36.5553\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 19.2537 - val_loss: 38.3926\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 17.5507 - val_loss: 39.5430\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 15.9488 - val_loss: 42.2007\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 14.0327 - val_loss: 40.4431\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 12.9803 - val_loss: 45.4970\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 11.9186 - val_loss: 41.7619\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 10.9982 - val_loss: 45.4281\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 9.8615 - val_loss: 47.7285\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 8.5785 - val_loss: 54.4097\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 8.3721 - val_loss: 48.6872\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 8.7714 - val_loss: 54.5090\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 7.7945 - val_loss: 51.4222\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 7.1304 - val_loss: 53.2252\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 6.4027 - val_loss: 51.2170\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 5.2032 - val_loss: 53.6601\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 5.2650 - val_loss: 51.4437\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 4.6165 - val_loss: 52.8071\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.5890 - val_loss: 53.6847\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 4.1682 - val_loss: 58.0778\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 4.1093 - val_loss: 58.1514\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 4.2321 - val_loss: 54.5890\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 4.1218 - val_loss: 57.0029\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 18us/sample - loss: 4.8689 - val_loss: 51.4879\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 5.9901 - val_loss: 68.6883\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 4.6057 - val_loss: 54.1654\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 4.3098 - val_loss: 59.4038\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.5817 - val_loss: 53.5127\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.5798 - val_loss: 57.8862\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.5028 - val_loss: 54.2685\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 3.3731 - val_loss: 58.1551\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 3.4407 - val_loss: 55.0353\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 3.4003 - val_loss: 60.7388\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 3.7103 - val_loss: 52.8073\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 3.2233 - val_loss: 54.9012\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.1086 - val_loss: 55.8912\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.9079 - val_loss: 59.9667\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.5347 - val_loss: 56.1012\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.4877 - val_loss: 57.7831\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.3493 - val_loss: 57.8132\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.5808 - val_loss: 61.6097\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.7874 - val_loss: 58.4629\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.7980 - val_loss: 61.5425\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.7247 - val_loss: 57.3321\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.7115 - val_loss: 60.3754\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.6045 - val_loss: 58.1280\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.5660 - val_loss: 62.3516\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.9789 - val_loss: 62.8613\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.6573 - val_loss: 59.4917\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.1304 - val_loss: 58.8279\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.2620 - val_loss: 59.7337\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.0926 - val_loss: 61.5644\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.9638 - val_loss: 60.9969\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.9311 - val_loss: 64.8480\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.4009 - val_loss: 59.6815\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.8879 - val_loss: 68.7675\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.9824 - val_loss: 60.0875\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.8341 - val_loss: 68.8140\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.0913 - val_loss: 60.1542\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.0260 - val_loss: 65.1774\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.0449 - val_loss: 63.4295\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.6192 - val_loss: 62.3674\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.0427 - val_loss: 61.4161\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.0388 - val_loss: 57.0378\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 3.1481 - val_loss: 62.5544\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.8292 - val_loss: 60.5351\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.9392 - val_loss: 66.4257\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.8317 - val_loss: 61.0043\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.0034 - val_loss: 63.0054\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.8148 - val_loss: 62.7719\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.0991 - val_loss: 63.6331\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.2940 - val_loss: 60.8461\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.3274 - val_loss: 66.5296\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.3219 - val_loss: 58.4889\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.8818 - val_loss: 64.9044\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.0100 - val_loss: 58.6562\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.1062 - val_loss: 58.9329\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.8195 - val_loss: 59.5826\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.7768 - val_loss: 58.4920\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.4661 - val_loss: 63.1167\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.3870 - val_loss: 59.9125\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 1.4036 - val_loss: 61.0767\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 1.5429 - val_loss: 57.7024\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.6205 - val_loss: 55.9391\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.8057 - val_loss: 57.4656\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.7866 - val_loss: 59.1774\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.0726 - val_loss: 63.6393\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.0208 - val_loss: 56.3941\n",
      "\n",
      "Mean squared error: 2.0\n",
      "\n",
      "dropout: 3.9e-01\n",
      "filter_num: 167\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 98us/sample - loss: 63.2134 - val_loss: 51.9184\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 51.5481 - val_loss: 38.6297\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 45.1087 - val_loss: 37.0985\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 40.6504 - val_loss: 37.7703\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 39.1135 - val_loss: 34.8927\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 36.6040 - val_loss: 34.0321\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 33.0136 - val_loss: 33.5631\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 30.5767 - val_loss: 33.5389\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 29.1307 - val_loss: 34.2753\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 27.3799 - val_loss: 33.9630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 25.5446 - val_loss: 36.1839\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 25.2922 - val_loss: 37.3472\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 23.5214 - val_loss: 42.1857\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 19.6873 - val_loss: 40.8132\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 21.7323 - val_loss: 43.5842\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 19.7145 - val_loss: 49.8277\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 16.6395 - val_loss: 52.1924\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 15.6950 - val_loss: 59.4948\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 12.6066 - val_loss: 62.4115\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 12.8407 - val_loss: 62.8435\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 12.0244 - val_loss: 74.3557\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 10.7658 - val_loss: 71.3810\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 10.4606 - val_loss: 73.8093\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 9.3881 - val_loss: 82.7496\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 9.3377 - val_loss: 88.4779\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 8.2266 - val_loss: 100.8255\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 9.3994 - val_loss: 84.6334\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 8.8472 - val_loss: 92.9542\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 7.7087 - val_loss: 91.0970\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 6.7708 - val_loss: 94.8560\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 6.7296 - val_loss: 111.9257\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 6.6053 - val_loss: 100.4890\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 6.6447 - val_loss: 104.0713\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 5.9314 - val_loss: 108.4738\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 5.7609 - val_loss: 116.1486\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 11.3220 - val_loss: 93.9785\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 8.3790 - val_loss: 89.6907\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 8.0085 - val_loss: 89.8548\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 6.9126 - val_loss: 88.1749\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 6.0495 - val_loss: 103.2366\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 6.7927 - val_loss: 92.1111\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 5.3691 - val_loss: 95.9536\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 5.1715 - val_loss: 98.8722\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.6787 - val_loss: 101.0910\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.7122 - val_loss: 104.6064\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.7218 - val_loss: 97.3731\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.4127 - val_loss: 93.5863\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 4.7889 - val_loss: 87.2761\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.5369 - val_loss: 93.5062\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.1442 - val_loss: 97.0537\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.9358 - val_loss: 102.0104\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.0341 - val_loss: 104.5591\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.5380 - val_loss: 113.3055\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.8822 - val_loss: 112.9995\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.1103 - val_loss: 117.1112\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.6862 - val_loss: 117.5169\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.6446 - val_loss: 108.9152\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.7862 - val_loss: 116.9637\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.7466 - val_loss: 107.0446\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.1932 - val_loss: 107.8048\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.2275 - val_loss: 112.8739\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.6509 - val_loss: 117.7772\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.7155 - val_loss: 119.2089\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.3140 - val_loss: 118.8435\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.6140 - val_loss: 114.3845\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.2831 - val_loss: 110.5822\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.2267 - val_loss: 109.0058\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 3.2874 - val_loss: 107.5217\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.2553 - val_loss: 118.0816\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.7735 - val_loss: 126.5200\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.2453 - val_loss: 124.8277\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.8274 - val_loss: 107.6836\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.1650 - val_loss: 106.5615\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.1996 - val_loss: 99.0859\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 4.1834 - val_loss: 110.2051\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.2058 - val_loss: 101.6086\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.1324 - val_loss: 106.5038\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.2327 - val_loss: 116.1082\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.4141 - val_loss: 102.1068\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.2165 - val_loss: 115.0798\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.3213 - val_loss: 105.1579\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.5540 - val_loss: 113.5340\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.8537 - val_loss: 99.1081\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 9.0775 - val_loss: 78.7080\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 8.0674 - val_loss: 112.1719\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 17us/sample - loss: 5.9947 - val_loss: 96.5282\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.9716 - val_loss: 120.7714\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 5.2122 - val_loss: 128.9143\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.4218 - val_loss: 128.2031\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.2351 - val_loss: 134.3813\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.1335 - val_loss: 122.5634\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 2.6154 - val_loss: 112.5629\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.2127 - val_loss: 125.9402\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.6250 - val_loss: 126.0214\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.8839 - val_loss: 126.7519\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.7974 - val_loss: 142.5752\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.3242 - val_loss: 136.4641\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.0494 - val_loss: 114.3371\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.9466 - val_loss: 122.3753\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.9162 - val_loss: 121.5795\n",
      "\n",
      "Mean squared error: 2.9\n",
      "\n",
      "dropout: 3.8e-01\n",
      "filter_num: 300\n",
      "num_dense_layers: 6\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 1s 236us/sample - loss: 58.5602 - val_loss: 42.9409\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 45.8451 - val_loss: 47.3761\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 61us/sample - loss: 43.9400 - val_loss: 42.8723\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 62us/sample - loss: 40.4818 - val_loss: 37.3324\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 64us/sample - loss: 37.9764 - val_loss: 42.3884\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 61us/sample - loss: 34.8728 - val_loss: 35.5536\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 63us/sample - loss: 31.6718 - val_loss: 40.2562\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 60us/sample - loss: 29.9067 - val_loss: 38.5119\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 62us/sample - loss: 25.0445 - val_loss: 39.1173\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 60us/sample - loss: 25.0538 - val_loss: 43.6463\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 61us/sample - loss: 22.1870 - val_loss: 41.1004\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 61us/sample - loss: 24.9693 - val_loss: 43.0247\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 63us/sample - loss: 19.5527 - val_loss: 42.0222\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 61us/sample - loss: 17.4830 - val_loss: 40.5534\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 62us/sample - loss: 17.0934 - val_loss: 40.3324\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 62us/sample - loss: 16.3983 - val_loss: 38.6822\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 60us/sample - loss: 15.7263 - val_loss: 38.4741\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 63us/sample - loss: 13.9470 - val_loss: 37.5839\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 61us/sample - loss: 13.1767 - val_loss: 37.6233\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 62us/sample - loss: 15.0126 - val_loss: 38.0305\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 61us/sample - loss: 12.8653 - val_loss: 42.0239\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 62us/sample - loss: 16.1601 - val_loss: 39.6597\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 62us/sample - loss: 16.1358 - val_loss: 37.0481\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 60us/sample - loss: 15.8060 - val_loss: 38.7433\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 16.3307 - val_loss: 39.3151\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 12.7528 - val_loss: 38.9317\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 10.7205 - val_loss: 39.4724\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 65us/sample - loss: 13.3251 - val_loss: 43.8664\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 13.8806 - val_loss: 43.6944\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 12.4248 - val_loss: 44.1679\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 66us/sample - loss: 15.3009 - val_loss: 41.8843\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 68us/sample - loss: 13.0091 - val_loss: 41.5736\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 64us/sample - loss: 12.0842 - val_loss: 39.8309\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 62us/sample - loss: 11.6031 - val_loss: 39.3219\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 61us/sample - loss: 9.3906 - val_loss: 39.3376\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 61us/sample - loss: 9.6805 - val_loss: 38.1221\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 61us/sample - loss: 11.7615 - val_loss: 42.4896\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 62us/sample - loss: 12.3246 - val_loss: 38.4983\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 69us/sample - loss: 13.4000 - val_loss: 43.1270\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 65us/sample - loss: 16.1467 - val_loss: 36.6604\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 62us/sample - loss: 15.4483 - val_loss: 38.7081\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 62us/sample - loss: 13.6551 - val_loss: 38.2499\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 62us/sample - loss: 11.8244 - val_loss: 41.6624\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 62us/sample - loss: 11.6546 - val_loss: 40.2046\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 63us/sample - loss: 12.9645 - val_loss: 41.6783\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 62us/sample - loss: 11.4328 - val_loss: 38.4384\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 61us/sample - loss: 11.3482 - val_loss: 40.3786\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 62us/sample - loss: 11.1715 - val_loss: 40.7796\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 61us/sample - loss: 9.9527 - val_loss: 41.9720\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 62us/sample - loss: 10.9603 - val_loss: 38.7906\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 63us/sample - loss: 7.6062 - val_loss: 37.3632\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 62us/sample - loss: 7.9246 - val_loss: 37.5869\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 63us/sample - loss: 7.0484 - val_loss: 37.7996\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 61us/sample - loss: 7.2238 - val_loss: 37.8888\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 63us/sample - loss: 7.5171 - val_loss: 40.3010\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 62us/sample - loss: 13.8574 - val_loss: 38.5550\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 63us/sample - loss: 15.6240 - val_loss: 42.8951\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 62us/sample - loss: 19.8734 - val_loss: 39.5607\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 65us/sample - loss: 14.4753 - val_loss: 38.3270\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 62us/sample - loss: 12.2450 - val_loss: 39.7716\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 62us/sample - loss: 11.6652 - val_loss: 40.0974\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 62us/sample - loss: 9.6195 - val_loss: 40.0285\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 59us/sample - loss: 8.6167 - val_loss: 40.0856\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 61us/sample - loss: 9.5779 - val_loss: 40.4963\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 62us/sample - loss: 8.3693 - val_loss: 40.9166\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 60us/sample - loss: 8.6618 - val_loss: 40.9297\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 62us/sample - loss: 7.0249 - val_loss: 40.9173\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 62us/sample - loss: 7.1904 - val_loss: 40.9416\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 61us/sample - loss: 7.7558 - val_loss: 40.4853\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 61us/sample - loss: 7.2631 - val_loss: 40.0715\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 59us/sample - loss: 6.5221 - val_loss: 39.3083\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 65us/sample - loss: 7.6623 - val_loss: 39.3446\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 62us/sample - loss: 8.7666 - val_loss: 39.2257\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 62us/sample - loss: 7.7762 - val_loss: 40.3831\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 62us/sample - loss: 6.1055 - val_loss: 41.0290\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 60us/sample - loss: 6.6893 - val_loss: 40.7119\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 64us/sample - loss: 8.3075 - val_loss: 40.1591\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 65us/sample - loss: 7.1427 - val_loss: 39.6789\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 62us/sample - loss: 8.0715 - val_loss: 40.1434\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 62us/sample - loss: 6.9990 - val_loss: 40.3535\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 62us/sample - loss: 6.1205 - val_loss: 40.2778\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 61us/sample - loss: 8.6846 - val_loss: 38.9875\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 61us/sample - loss: 8.8570 - val_loss: 39.2105\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 62us/sample - loss: 6.8216 - val_loss: 40.0934\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 61us/sample - loss: 8.8659 - val_loss: 41.5429\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 62us/sample - loss: 6.8130 - val_loss: 40.7189\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 60us/sample - loss: 6.8680 - val_loss: 41.0642\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 62us/sample - loss: 6.4822 - val_loss: 40.9955\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 61us/sample - loss: 8.0723 - val_loss: 39.9489\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 62us/sample - loss: 5.6940 - val_loss: 40.7358\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 61us/sample - loss: 7.1849 - val_loss: 40.5232\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 61us/sample - loss: 6.0847 - val_loss: 40.1529\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 62us/sample - loss: 7.8385 - val_loss: 39.8153\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 64us/sample - loss: 9.5306 - val_loss: 39.5850\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 60us/sample - loss: 9.6025 - val_loss: 40.5176\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 63us/sample - loss: 9.6468 - val_loss: 40.2088\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 62us/sample - loss: 7.7379 - val_loss: 39.5197\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 61us/sample - loss: 6.5524 - val_loss: 38.3256\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 63us/sample - loss: 6.9890 - val_loss: 38.5782\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 61us/sample - loss: 6.9976 - val_loss: 38.7380\n",
      "\n",
      "Mean squared error: 7.0\n",
      "\n",
      "dropout: 8.0e-01\n",
      "filter_num: 300\n",
      "num_dense_layers: 4\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 186us/sample - loss: 59.4283 - val_loss: 58.4462\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 49.1312 - val_loss: 58.8926\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 49.9104 - val_loss: 58.3994\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 47.6604 - val_loss: 58.0967\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 47.6712 - val_loss: 58.2395\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 45.9630 - val_loss: 58.0291\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 45.5020 - val_loss: 57.8942\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 46.2076 - val_loss: 57.9129\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 44.1005 - val_loss: 57.5761\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 42.7926 - val_loss: 57.1935\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 42.3642 - val_loss: 57.0086\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 41.1341 - val_loss: 57.0639\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 40.1602 - val_loss: 56.9332\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 39.5433 - val_loss: 56.6892\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 57us/sample - loss: 38.1228 - val_loss: 56.5950\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 37.6529 - val_loss: 56.8131\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 36.1206 - val_loss: 56.8711\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 35.3637 - val_loss: 56.7097\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 32.9093 - val_loss: 56.3956\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 33.4912 - val_loss: 56.3510\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 31.6951 - val_loss: 56.6026\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 30.7436 - val_loss: 56.5955\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 30.7531 - val_loss: 56.6177\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 30.2486 - val_loss: 56.2836\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 29.5531 - val_loss: 56.2275\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 28.6326 - val_loss: 56.5690\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 28.6771 - val_loss: 56.5424\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 29.5150 - val_loss: 56.1170\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 27.1528 - val_loss: 55.9119\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 30.7898 - val_loss: 55.7982\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 27.6044 - val_loss: 55.4979\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 27.8369 - val_loss: 55.4345\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 55us/sample - loss: 25.1040 - val_loss: 55.2153\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 46us/sample - loss: 26.2820 - val_loss: 54.8800\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 25.8151 - val_loss: 54.8800\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 24.1829 - val_loss: 54.5823\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 25.7484 - val_loss: 54.3544\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 23.1597 - val_loss: 54.3135\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 22.3740 - val_loss: 54.0169\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 21.6318 - val_loss: 53.3075\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 21.4813 - val_loss: 52.7483\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 23.7333 - val_loss: 52.5546\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 19.7203 - val_loss: 52.6433\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 20.4501 - val_loss: 52.4382\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 20.6182 - val_loss: 52.4181\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 23.3059 - val_loss: 51.6017\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 24.5489 - val_loss: 51.8400\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 21.4119 - val_loss: 51.6313\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 49us/sample - loss: 21.6592 - val_loss: 51.3588\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 20.1068 - val_loss: 51.0615\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 20.0298 - val_loss: 50.6059\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 23.8709 - val_loss: 50.2405\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 43us/sample - loss: 20.5519 - val_loss: 50.2467\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 20.7117 - val_loss: 50.6100\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 17.6918 - val_loss: 50.1269\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 18.2646 - val_loss: 49.2082\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 18.9587 - val_loss: 48.7825\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 19.0904 - val_loss: 49.4651\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 18.5823 - val_loss: 49.6866\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 23.2157 - val_loss: 49.4588\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 21.9599 - val_loss: 49.3657\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 19.5948 - val_loss: 48.9930\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 16.8340 - val_loss: 48.6877\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 17.7592 - val_loss: 48.6074\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 19.0315 - val_loss: 48.7259\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 15.7489 - val_loss: 48.6839\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 16.4862 - val_loss: 47.9961\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 16.8398 - val_loss: 48.2905\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 14.2399 - val_loss: 48.3345\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 16.0647 - val_loss: 48.3793\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 15.3634 - val_loss: 48.6044\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 16.9008 - val_loss: 48.2259\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 16.9405 - val_loss: 48.3297\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 15.5559 - val_loss: 48.1492\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 13.7531 - val_loss: 47.7132\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 16.2565 - val_loss: 47.7407\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 23.3472 - val_loss: 47.9685\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 14.4091 - val_loss: 48.6327\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 15.3301 - val_loss: 48.1616\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 20.4196 - val_loss: 48.0770\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 15.8907 - val_loss: 48.3460\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 20.5510 - val_loss: 48.4452\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 15.6472 - val_loss: 47.7588\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 20.3580 - val_loss: 47.8735\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 16.1183 - val_loss: 48.2784\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 17.5250 - val_loss: 48.0334\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 17.3742 - val_loss: 47.2508\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 16.8174 - val_loss: 48.0867\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 17.7655 - val_loss: 48.1769\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 26.6911 - val_loss: 48.5582\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 14.7761 - val_loss: 48.2763\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 49us/sample - loss: 33.8826 - val_loss: 49.0497\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 18.7616 - val_loss: 48.4476\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 18.5436 - val_loss: 46.9835\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 14.8710 - val_loss: 47.1551\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 18.3743 - val_loss: 48.6698\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 21.4489 - val_loss: 48.8243\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 22.6669 - val_loss: 48.5161\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 16.6040 - val_loss: 48.2115\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 16.7569 - val_loss: 47.5724\n",
      "\n",
      "Mean squared error: 1.7e+01\n",
      "\n",
      "dropout: 3.3e-01\n",
      "filter_num: 300\n",
      "num_dense_layers: 4\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 183us/sample - loss: 56.6166 - val_loss: 39.9970\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 46.6551 - val_loss: 46.3981\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 44.0466 - val_loss: 36.4881\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 39.1971 - val_loss: 37.1755\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 49us/sample - loss: 36.0106 - val_loss: 33.9338\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 30.1473 - val_loss: 34.1726\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 28.1450 - val_loss: 36.5463\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 48us/sample - loss: 24.6090 - val_loss: 39.3856\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 22.8423 - val_loss: 43.2757\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 20.4242 - val_loss: 46.9195\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 16.8550 - val_loss: 45.2759\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 15.3853 - val_loss: 45.1336\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 13.2995 - val_loss: 46.1062\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 12.5896 - val_loss: 48.2483\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 13.5180 - val_loss: 44.2474\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 14.2959 - val_loss: 41.6416\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 17.0113 - val_loss: 39.4881\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 17.8412 - val_loss: 41.3675\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 13.6243 - val_loss: 43.6895\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 16.0990 - val_loss: 41.2483\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 13.7918 - val_loss: 39.7609\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 16.5437 - val_loss: 40.4980\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 13.7438 - val_loss: 48.9203\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 10.8426 - val_loss: 43.9828\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 11.8636 - val_loss: 48.9418\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 49us/sample - loss: 9.7860 - val_loss: 47.2549\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 52us/sample - loss: 8.5329 - val_loss: 48.2031\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 50us/sample - loss: 8.0486 - val_loss: 48.6183\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 49us/sample - loss: 7.9713 - val_loss: 52.1944\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 7.5370 - val_loss: 51.3356\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 8.2398 - val_loss: 49.3230\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 8.4329 - val_loss: 43.3638\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 8.7232 - val_loss: 44.0581\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 6.9558 - val_loss: 44.3898\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 7.0337 - val_loss: 48.3428\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 7.5617 - val_loss: 45.6144\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 7.0422 - val_loss: 51.6156\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 46us/sample - loss: 8.6263 - val_loss: 43.8567\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 7.4078 - val_loss: 50.3889\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 7.1397 - val_loss: 43.1656\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 49us/sample - loss: 6.6788 - val_loss: 48.2356\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 7.0955 - val_loss: 43.2982\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 7.5208 - val_loss: 46.7543\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 7.3338 - val_loss: 44.7800\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 7.1947 - val_loss: 54.3599\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 17.1539 - val_loss: 48.3957\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 16.5463 - val_loss: 45.7756\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 49us/sample - loss: 10.2543 - val_loss: 59.5857\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 9.7179 - val_loss: 43.3494\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 9.3279 - val_loss: 44.4665\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 5.7048 - val_loss: 46.7906\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 7.7174 - val_loss: 43.3309\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 20.7793 - val_loss: 43.8361\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 16.8017 - val_loss: 62.7646\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 15.1808 - val_loss: 49.4151\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 11.6435 - val_loss: 61.4794\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 10.9818 - val_loss: 52.1617\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 8.9767 - val_loss: 56.3369\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 8.8256 - val_loss: 48.9373\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 7.4373 - val_loss: 51.1277\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 7.4906 - val_loss: 48.1122\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 6.4812 - val_loss: 50.1631\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 5.6023 - val_loss: 53.5741\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 5.5751 - val_loss: 53.0067\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 5.1577 - val_loss: 54.4193\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 5.0433 - val_loss: 53.7640\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 4.6910 - val_loss: 51.0774\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 5.9627 - val_loss: 53.0391\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 4.7950 - val_loss: 52.5014\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 5.4398 - val_loss: 51.7952\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 4.5320 - val_loss: 49.6910\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 4.7520 - val_loss: 46.8711\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 4.3615 - val_loss: 49.3703\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 5.4954 - val_loss: 48.3395\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 5.2197 - val_loss: 51.2588\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 5.4084 - val_loss: 50.0212\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 4.5283 - val_loss: 51.4229\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 4.3666 - val_loss: 47.8825\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 3.9889 - val_loss: 52.6423\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 3.9026 - val_loss: 49.3705\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 5.5395 - val_loss: 51.1988\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 4.9205 - val_loss: 48.6803\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 4.1782 - val_loss: 46.6405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 4.9174 - val_loss: 48.4465\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 3.7432 - val_loss: 46.9052\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 5.0765 - val_loss: 53.5594\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 42us/sample - loss: 5.6914 - val_loss: 48.4978\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 51us/sample - loss: 8.1752 - val_loss: 51.3576\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 4.3821 - val_loss: 51.9819\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 3.8217 - val_loss: 52.6122\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 7.8415 - val_loss: 48.9103\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 6.3439 - val_loss: 47.8055\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 8.7733 - val_loss: 45.2220\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 8.0014 - val_loss: 50.1101\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 6.4779 - val_loss: 48.6030\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 6.1791 - val_loss: 58.5034\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 48us/sample - loss: 6.7203 - val_loss: 45.6950\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 5.6931 - val_loss: 48.9742\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 49us/sample - loss: 5.7918 - val_loss: 42.7362\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 47us/sample - loss: 6.1926 - val_loss: 47.1375\n",
      "\n",
      "Mean squared error: 6.2\n",
      "\n",
      "dropout: 3.4e-01\n",
      "filter_num: 228\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 108us/sample - loss: 60.6061 - val_loss: 44.2481\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 47.6018 - val_loss: 38.8103\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 42.4856 - val_loss: 37.7723\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 39.1977 - val_loss: 35.4851\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 36.3810 - val_loss: 35.5514\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 33.6982 - val_loss: 34.3009\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 32.3085 - val_loss: 34.0623\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 30.1497 - val_loss: 35.6133\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 26.6544 - val_loss: 35.2877\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 25.7751 - val_loss: 37.3485\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 21.8820 - val_loss: 38.0138\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 21.2506 - val_loss: 42.0855\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 19.2259 - val_loss: 44.2067\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 17.1809 - val_loss: 49.3084\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 14.7414 - val_loss: 52.3462\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 13.4525 - val_loss: 59.5404\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 11.8518 - val_loss: 56.3097\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 11.0784 - val_loss: 66.2025\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 9.7440 - val_loss: 63.9063\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 9.5468 - val_loss: 66.7478\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 8.7963 - val_loss: 85.1954\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 8.4769 - val_loss: 72.3532\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 7.7914 - val_loss: 79.1898\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 5.9584 - val_loss: 79.6560\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 5.6360 - val_loss: 81.4792\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 5.4519 - val_loss: 75.7561\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 5.2226 - val_loss: 81.1380\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.9669 - val_loss: 81.9052\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 4.8672 - val_loss: 78.0920\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 5.2394 - val_loss: 89.1930\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.5954 - val_loss: 74.5523\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 5.6978 - val_loss: 86.9449\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 5.2216 - val_loss: 74.4515\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 5.0393 - val_loss: 95.0878\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 5.4474 - val_loss: 79.8472\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.3092 - val_loss: 79.3312\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 5.2265 - val_loss: 78.0096\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 6.9069 - val_loss: 73.8368\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 4.9028 - val_loss: 75.3487\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.8501 - val_loss: 80.5978\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 5.6711 - val_loss: 79.4526\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 6.0801 - val_loss: 76.4519\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.7235 - val_loss: 80.5958\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 5.0014 - val_loss: 84.1286\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 5.5692 - val_loss: 81.4340\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.3391 - val_loss: 83.0368\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.3297 - val_loss: 85.8651\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 4.1696 - val_loss: 80.3479\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.6157 - val_loss: 85.9538\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.5230 - val_loss: 87.1213\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.4107 - val_loss: 90.9974\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.1820 - val_loss: 92.9985\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.1754 - val_loss: 91.8019\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.8918 - val_loss: 82.2164\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.1553 - val_loss: 84.4465\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.7433 - val_loss: 77.8449\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.0759 - val_loss: 86.6460\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.9982 - val_loss: 78.9004\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.4656 - val_loss: 82.9648\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.9495 - val_loss: 80.1964\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 3.3338 - val_loss: 76.6959\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.7439 - val_loss: 87.0453\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.6255 - val_loss: 76.9226\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.6526 - val_loss: 86.9722\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.6123 - val_loss: 76.1181\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.4726 - val_loss: 82.0121\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.4582 - val_loss: 76.0819\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 2.7066 - val_loss: 82.1708\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 2.6829 - val_loss: 73.4109\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.0226 - val_loss: 75.0591\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.8232 - val_loss: 79.7436\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.9484 - val_loss: 78.6521\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.0400 - val_loss: 79.7538\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.1982 - val_loss: 72.7427\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.8199 - val_loss: 98.6071\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.4469 - val_loss: 80.9889\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.3540 - val_loss: 80.6935\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.8377 - val_loss: 67.1077\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 5.9212 - val_loss: 78.1839\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 5.0048 - val_loss: 71.5698\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.5739 - val_loss: 94.3607\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 4.1309 - val_loss: 86.1589\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.7341 - val_loss: 89.9278\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.8389 - val_loss: 80.5881\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.2660 - val_loss: 83.2915\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.8847 - val_loss: 89.2045\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.8318 - val_loss: 83.3352\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.9395 - val_loss: 91.3354\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.8362 - val_loss: 84.7654\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.3834 - val_loss: 92.1544\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.4685 - val_loss: 83.6043\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.4065 - val_loss: 85.0384\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.1435 - val_loss: 83.9501\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.7256 - val_loss: 80.5076\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.6922 - val_loss: 93.9320\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.3969 - val_loss: 84.5492\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.3139 - val_loss: 87.1296\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.2107 - val_loss: 80.7907\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.7953 - val_loss: 83.0389\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 3.2749 - val_loss: 88.6518\n",
      "\n",
      "Mean squared error: 3.3\n",
      "\n",
      "dropout: 2.4e-01\n",
      "filter_num: 300\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 119us/sample - loss: 56.5227 - val_loss: 39.5301\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 45.9321 - val_loss: 38.6726\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 41.2765 - val_loss: 35.4160\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 38.3621 - val_loss: 34.4402\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 34.6621 - val_loss: 34.3549\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 31.3873 - val_loss: 34.6706\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 28.3882 - val_loss: 34.7145\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 26.3543 - val_loss: 36.7914\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 23.3760 - val_loss: 37.2552\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 20.6137 - val_loss: 40.1973\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 17.4730 - val_loss: 39.9609\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 15.3959 - val_loss: 43.8214\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 12.8513 - val_loss: 45.0483\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 11.0692 - val_loss: 45.3007\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 9.7876 - val_loss: 47.7744\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 8.7762 - val_loss: 49.3188\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 7.7795 - val_loss: 54.5464\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 7.6376 - val_loss: 51.3500\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 8.0032 - val_loss: 59.2868\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 9.7922 - val_loss: 49.2620\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 8.4734 - val_loss: 61.1445\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 7.3026 - val_loss: 48.6570\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.8414 - val_loss: 57.6753\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.7675 - val_loss: 51.6139\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.7317 - val_loss: 60.3246\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.7346 - val_loss: 52.6492\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.5590 - val_loss: 57.0668\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.0711 - val_loss: 54.9325\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.1387 - val_loss: 62.7468\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 11.4815 - val_loss: 56.1877\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.1051 - val_loss: 51.9988\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.0713 - val_loss: 51.4188\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.6536 - val_loss: 53.5196\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.4648 - val_loss: 53.3679\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.6115 - val_loss: 56.9243\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.2359 - val_loss: 57.2543\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.0902 - val_loss: 58.7259\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.1768 - val_loss: 55.5444\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.9280 - val_loss: 54.6283\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.0162 - val_loss: 55.1672\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.8695 - val_loss: 54.7824\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.0636 - val_loss: 52.8921\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.7857 - val_loss: 52.9614\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.5672 - val_loss: 52.3001\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.5682 - val_loss: 53.1864\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.5276 - val_loss: 53.5681\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.7037 - val_loss: 58.1467\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.5981 - val_loss: 60.9653\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.3182 - val_loss: 60.3290\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.1810 - val_loss: 57.6034\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.3831 - val_loss: 57.5959\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.2759 - val_loss: 56.5455\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.2906 - val_loss: 55.2025\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.4301 - val_loss: 55.2202\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.0304 - val_loss: 52.2535\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.4265 - val_loss: 55.0087\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.3909 - val_loss: 52.0422\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.4654 - val_loss: 56.5603\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.3128 - val_loss: 50.9770\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.6887 - val_loss: 59.2663\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.8084 - val_loss: 50.3222\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.8285 - val_loss: 52.3061\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.7169 - val_loss: 47.5272\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.2161 - val_loss: 50.2088\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.3937 - val_loss: 53.6904\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 2.5686 - val_loss: 53.3161\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.9898 - val_loss: 54.7656\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.0326 - val_loss: 51.2994\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.0978 - val_loss: 51.8816\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.0071 - val_loss: 52.6447\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.2539 - val_loss: 53.7854\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.9904 - val_loss: 51.0399\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.3258 - val_loss: 51.9194\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.4694 - val_loss: 50.9770\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.8786 - val_loss: 52.8545\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.5370 - val_loss: 53.9183\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.6088 - val_loss: 54.4836\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.7890 - val_loss: 55.0366\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.5623 - val_loss: 56.4072\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.5045 - val_loss: 56.7440\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.6360 - val_loss: 58.6657\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.7373 - val_loss: 55.2956\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.1371 - val_loss: 55.8624\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.8174 - val_loss: 57.9400\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.6536 - val_loss: 55.3410\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.1107 - val_loss: 58.6405\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.4809 - val_loss: 55.6652\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.9247 - val_loss: 56.0091\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.9009 - val_loss: 54.1472\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.4198 - val_loss: 51.8910\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 1.3779 - val_loss: 51.7271\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.4687 - val_loss: 53.1909\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.6167 - val_loss: 51.8506\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.2887 - val_loss: 55.2527\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.4664 - val_loss: 54.8504\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.2484 - val_loss: 54.1588\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.3511 - val_loss: 54.4664\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.4659 - val_loss: 50.8437\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.1884 - val_loss: 54.5773\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.2273 - val_loss: 50.6878\n",
      "\n",
      "Mean squared error: 1.2\n",
      "\n",
      "dropout: 4.7e-01\n",
      "filter_num: 196\n",
      "num_dense_layers: 2\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 128us/sample - loss: 58.2558 - val_loss: 42.6030\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 47.5627 - val_loss: 38.9480\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 43.1996 - val_loss: 40.4039\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 40.6454 - val_loss: 35.9703\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 39.0783 - val_loss: 34.4795\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 35.6430 - val_loss: 33.9088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 33.9341 - val_loss: 34.6785\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 30.9232 - val_loss: 34.0578\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 27.1124 - val_loss: 35.1339\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 25.7780 - val_loss: 37.5364\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 25.2945 - val_loss: 38.9848\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 22.0630 - val_loss: 40.0012\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 21.1240 - val_loss: 43.2305\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 17.9998 - val_loss: 43.5769\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 17.1099 - val_loss: 44.6345\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 17.6352 - val_loss: 50.1702\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 16.1410 - val_loss: 44.7121\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 15.2218 - val_loss: 48.1824\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 12.8136 - val_loss: 49.3803\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 11.9636 - val_loss: 47.1875\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 10.3772 - val_loss: 49.8717\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 10.7152 - val_loss: 51.3512\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 10.8052 - val_loss: 49.4038\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 10.9727 - val_loss: 46.4313\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 9.9963 - val_loss: 46.2495\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 10.8690 - val_loss: 46.2136\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 9.0000 - val_loss: 51.7975\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 8.8859 - val_loss: 56.7639\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 9.8094 - val_loss: 52.6226\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 9.1054 - val_loss: 53.9576\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 7.7263 - val_loss: 49.3901\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 10.0543 - val_loss: 52.2452\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 9.1106 - val_loss: 53.3516\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 8.2019 - val_loss: 53.3144\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 8.3770 - val_loss: 55.5072\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 9.4451 - val_loss: 59.5503\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 7.7709 - val_loss: 57.9828\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 7.1053 - val_loss: 61.0317\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 8.7986 - val_loss: 53.9406\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 7.6628 - val_loss: 58.0205\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 7.0060 - val_loss: 55.1297\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 8.1860 - val_loss: 57.2753\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 8.4499 - val_loss: 52.3630\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 7.6331 - val_loss: 56.7389\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 6.0660 - val_loss: 56.0626\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 5.8800 - val_loss: 55.9163\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 5.9705 - val_loss: 58.7750\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 6.4531 - val_loss: 59.0418\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 6.4023 - val_loss: 58.7199\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 11.2108 - val_loss: 50.7102\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 7.8200 - val_loss: 47.7411\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 7.6184 - val_loss: 50.6572\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 6.3005 - val_loss: 49.3241\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 7.4909 - val_loss: 53.2800\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 7.3952 - val_loss: 52.9113\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 6.3627 - val_loss: 49.8511\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 7.5320 - val_loss: 52.4631\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 8.1734 - val_loss: 50.9644\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 5.7741 - val_loss: 53.9767\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 6.6209 - val_loss: 53.0165\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 6.4734 - val_loss: 55.3807\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 6.5846 - val_loss: 50.6365\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 10.6332 - val_loss: 46.7168\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 8.6631 - val_loss: 61.8355\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 8.9954 - val_loss: 52.5513\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 8.0831 - val_loss: 54.1887\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 6.1851 - val_loss: 63.0510\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 6.3403 - val_loss: 55.3760\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 6.6742 - val_loss: 56.0036\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 6.6411 - val_loss: 57.7357\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 5.1750 - val_loss: 52.5611\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 5.8513 - val_loss: 53.4557\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 5.2612 - val_loss: 53.8077\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 5.8212 - val_loss: 54.6880\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 5.7644 - val_loss: 65.8558\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 5.9702 - val_loss: 61.5976\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 6.2801 - val_loss: 67.7657\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 9.3753 - val_loss: 64.3187\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 5.3228 - val_loss: 53.5867\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 9.4378 - val_loss: 48.7534\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 6.3981 - val_loss: 48.7078\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 23us/sample - loss: 8.6382 - val_loss: 51.0754\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 8.4018 - val_loss: 50.8137\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 6.0960 - val_loss: 60.5820\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.1603 - val_loss: 54.8608\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.7397 - val_loss: 56.5693\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 5.1580 - val_loss: 58.2820\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.2623 - val_loss: 56.6486\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.8147 - val_loss: 59.1002\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 6.1385 - val_loss: 57.0675\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 5.4124 - val_loss: 62.6033\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 4.5406 - val_loss: 62.3355\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.1376 - val_loss: 61.5345\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 4.7022 - val_loss: 66.9739\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.5720 - val_loss: 58.0756\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 4.7032 - val_loss: 61.2806\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 5.0455 - val_loss: 56.2527\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 5.0823 - val_loss: 56.3469\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.4266 - val_loss: 60.5975\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.1632 - val_loss: 60.3661\n",
      "\n",
      "Mean squared error: 4.2\n",
      "\n",
      "dropout: 2.3e-01\n",
      "filter_num: 300\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 116us/sample - loss: 56.8933 - val_loss: 39.4256\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 46.5999 - val_loss: 37.9186\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 42.3606 - val_loss: 37.5828\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 39.0165 - val_loss: 35.2885\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 36.2183 - val_loss: 33.8442\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 32.1247 - val_loss: 33.6232\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 30.6831 - val_loss: 33.7147\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 27.1933 - val_loss: 35.4550\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 24.2100 - val_loss: 37.5863\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 22.6333 - val_loss: 40.2389\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 19.8559 - val_loss: 44.0864\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 18.2091 - val_loss: 44.9714\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 17.3941 - val_loss: 51.5632\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 15.5481 - val_loss: 41.0884\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 16.3215 - val_loss: 39.9890\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 12.4144 - val_loss: 44.2379\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 9.3192 - val_loss: 48.3771\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 9.8633 - val_loss: 44.6343\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 9.3329 - val_loss: 44.6811\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 9.3052 - val_loss: 46.2507\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 8.2724 - val_loss: 52.4433\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 7.2886 - val_loss: 50.1526\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.4822 - val_loss: 47.7751\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 6.6298 - val_loss: 46.9278\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.8831 - val_loss: 48.9656\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.5343 - val_loss: 52.1607\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.2386 - val_loss: 50.5105\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.7915 - val_loss: 51.0139\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.3608 - val_loss: 48.0254\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.0413 - val_loss: 45.0900\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.0036 - val_loss: 46.3838\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.1591 - val_loss: 45.1545\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.6972 - val_loss: 47.7140\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.5921 - val_loss: 45.8309\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.4679 - val_loss: 47.9183\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.8431 - val_loss: 44.7169\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.1818 - val_loss: 48.6653\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.9288 - val_loss: 45.0463\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.8098 - val_loss: 49.8676\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 4.9765 - val_loss: 48.5907\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 6.7833 - val_loss: 47.6790\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 8.9373 - val_loss: 42.4723\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.1956 - val_loss: 41.6356\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.2146 - val_loss: 45.1969\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.5438 - val_loss: 48.0250\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.7366 - val_loss: 48.5351\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.1628 - val_loss: 45.1226\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.4927 - val_loss: 48.8318\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.3897 - val_loss: 48.3766\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.9839 - val_loss: 48.9642\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.7825 - val_loss: 45.9040\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.9790 - val_loss: 45.1261\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.9865 - val_loss: 47.3037\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.2826 - val_loss: 45.1798\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.0044 - val_loss: 46.1420\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.9000 - val_loss: 45.4322\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.7123 - val_loss: 47.2418\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.9024 - val_loss: 50.3173\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.5769 - val_loss: 49.0540\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.7979 - val_loss: 49.4323\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.4580 - val_loss: 49.1179\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.5899 - val_loss: 53.7877\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.6460 - val_loss: 52.6836\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.1972 - val_loss: 54.5426\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.2379 - val_loss: 48.4965\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.9955 - val_loss: 50.2030\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.0561 - val_loss: 47.4175\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.7968 - val_loss: 48.6479\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.7293 - val_loss: 47.7875\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.7580 - val_loss: 47.5291\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.4986 - val_loss: 48.8422\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.4515 - val_loss: 50.3159\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.4920 - val_loss: 50.8544\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.7433 - val_loss: 46.7274\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.8799 - val_loss: 47.0329\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.7313 - val_loss: 47.6724\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.6039 - val_loss: 47.9765\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.8197 - val_loss: 49.1796\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.5683 - val_loss: 50.3717\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.5437 - val_loss: 50.6920\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.4753 - val_loss: 50.8424\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.4200 - val_loss: 48.9763\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 1.3334 - val_loss: 49.1122\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.5475 - val_loss: 49.3846\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.2757 - val_loss: 49.8184\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.3393 - val_loss: 51.2231\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.4022 - val_loss: 53.1041\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 1.3529 - val_loss: 53.4999\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.2140 - val_loss: 52.4695\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.7632 - val_loss: 52.1930\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.8752 - val_loss: 52.0031\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.4654 - val_loss: 50.6088\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.4105 - val_loss: 51.9490\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.3807 - val_loss: 52.2361\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.5085 - val_loss: 54.2823\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.3127 - val_loss: 51.4608\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.3445 - val_loss: 51.8807\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.4033 - val_loss: 48.6365\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.4703 - val_loss: 50.4940\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.4355 - val_loss: 49.8422\n",
      "\n",
      "Mean squared error: 1.4\n",
      "\n",
      "dropout: 2.7e-01\n",
      "filter_num: 253\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 112us/sample - loss: 59.1652 - val_loss: 40.3745\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 46.6575 - val_loss: 37.5183\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 41.5262 - val_loss: 37.5549\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 38.4800 - val_loss: 35.1030\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 35.0324 - val_loss: 34.5096\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 31.6486 - val_loss: 35.2374\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 29.3916 - val_loss: 34.7582\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 26.8785 - val_loss: 39.2743\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 25.9227 - val_loss: 41.9708\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 23.5666 - val_loss: 43.8864\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 21.6128 - val_loss: 52.8849\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 20.4285 - val_loss: 50.0980\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 17.1136 - val_loss: 50.6019\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 15.5588 - val_loss: 58.2511\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 12.9938 - val_loss: 58.4457\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 11.8255 - val_loss: 70.5330\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 10.1405 - val_loss: 67.9531\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 10.5553 - val_loss: 79.2961\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 10.3595 - val_loss: 68.8011\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 9.4160 - val_loss: 77.0403\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 8.1323 - val_loss: 71.1564\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 7.0262 - val_loss: 79.6244\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 7.6963 - val_loss: 69.3353\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 6.8747 - val_loss: 77.0885\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 6.8260 - val_loss: 77.2824\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 5.8296 - val_loss: 84.1793\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 5.7296 - val_loss: 80.6548\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 5.5822 - val_loss: 81.6273\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 5.1493 - val_loss: 81.5577\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 21us/sample - loss: 4.7264 - val_loss: 87.0622\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 4.3825 - val_loss: 84.1759\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 4.5482 - val_loss: 91.7596\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 4.4785 - val_loss: 89.7136\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 4.6070 - val_loss: 88.5032\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 4.4564 - val_loss: 97.7286\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 4.5781 - val_loss: 85.0696\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 5.0474 - val_loss: 92.1182\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 4.2757 - val_loss: 84.6410\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 4.1343 - val_loss: 89.6577\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 4.1372 - val_loss: 85.9722\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 4.1743 - val_loss: 87.2367\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.6766 - val_loss: 93.2134\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 3.7555 - val_loss: 89.6768\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 3.7289 - val_loss: 89.4434\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.9440 - val_loss: 87.7240\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 3.3922 - val_loss: 90.5506\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 3.8454 - val_loss: 88.8150\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.8339 - val_loss: 89.7126\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.4052 - val_loss: 91.1285\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 3.8530 - val_loss: 82.5610\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 4.3681 - val_loss: 88.7926\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.8163 - val_loss: 85.7071\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.7295 - val_loss: 91.1332\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 3.0896 - val_loss: 79.0015\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.6117 - val_loss: 81.9919\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 3.5870 - val_loss: 86.0211\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.0796 - val_loss: 96.4756\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.9758 - val_loss: 94.5933\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.4533 - val_loss: 93.7566\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.3442 - val_loss: 89.0274\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.1992 - val_loss: 88.3582\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.1352 - val_loss: 85.5986\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.4905 - val_loss: 89.0456\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.5266 - val_loss: 90.3917\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.0673 - val_loss: 90.3266\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.0919 - val_loss: 93.2484\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.1415 - val_loss: 88.3381\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.3035 - val_loss: 86.9294\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.2275 - val_loss: 90.1915\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.0170 - val_loss: 93.3779\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.0561 - val_loss: 92.7181\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.9764 - val_loss: 89.2360\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.1941 - val_loss: 85.5779\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.1184 - val_loss: 82.5775\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.7568 - val_loss: 81.9426\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.1959 - val_loss: 79.5509\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.2182 - val_loss: 83.8996\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 1.8502 - val_loss: 81.2772\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 2.0281 - val_loss: 83.2053\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.7408 - val_loss: 81.5562\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 1.7434 - val_loss: 84.7169\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.5648 - val_loss: 82.8133\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 1.7309 - val_loss: 78.7223\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.6650 - val_loss: 80.9586\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 2.5920 - val_loss: 77.8271\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 2.1830 - val_loss: 86.8214\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 1.8878 - val_loss: 74.5321\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 2.2341 - val_loss: 90.8309\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.0751 - val_loss: 73.8881\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.8826 - val_loss: 92.9492\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 3.5918 - val_loss: 75.1482\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 2.5503 - val_loss: 81.0983\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 2.2737 - val_loss: 74.5018\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.0070 - val_loss: 82.1672\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.7314 - val_loss: 79.3406\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 20us/sample - loss: 1.7275 - val_loss: 83.0800\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 1.7578 - val_loss: 80.9391\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.3937 - val_loss: 87.9383\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 1.5886 - val_loss: 80.4354\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.8601 - val_loss: 83.2004\n",
      "\n",
      "Mean squared error: 1.9\n",
      "\n",
      "dropout: 3.5e-01\n",
      "filter_num: 123\n",
      "num_dense_layers: 2\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 123us/sample - loss: 63.0936 - val_loss: 51.8204\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 23us/sample - loss: 51.6480 - val_loss: 37.2689\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 44.4599 - val_loss: 36.2857\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 41.2178 - val_loss: 36.3952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 38.4637 - val_loss: 33.3098\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 34.7531 - val_loss: 32.9905\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 32.5443 - val_loss: 32.8923\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 30.1516 - val_loss: 33.4547\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 27.7894 - val_loss: 34.6556\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 26.7189 - val_loss: 35.5680\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 23.3665 - val_loss: 37.9474\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 21.7883 - val_loss: 39.8219\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 20.9028 - val_loss: 44.1915\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 19.1452 - val_loss: 49.5184\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 17.0648 - val_loss: 49.7069\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 16.4682 - val_loss: 55.2697\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 15.4154 - val_loss: 52.6722\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 13.2447 - val_loss: 55.3149\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 12.5866 - val_loss: 52.7676\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 15.4171 - val_loss: 48.7803\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 12.7782 - val_loss: 58.7243\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 12.9966 - val_loss: 57.4628\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 13.4232 - val_loss: 65.6325\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 10.6489 - val_loss: 60.6292\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 11.4631 - val_loss: 58.5465\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 11.2049 - val_loss: 59.2513\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 9.9377 - val_loss: 60.8743\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 8.3086 - val_loss: 69.1884\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 11.6877 - val_loss: 69.3534\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 10.6700 - val_loss: 61.5338\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 10.7018 - val_loss: 64.5193\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 8.9342 - val_loss: 56.5282\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 8.9978 - val_loss: 58.9686\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 6.7917 - val_loss: 63.0633\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 6.9554 - val_loss: 64.2399\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 6.5873 - val_loss: 65.2959\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 6.2370 - val_loss: 62.7530\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 5.6529 - val_loss: 66.5466\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 6.1989 - val_loss: 65.5751\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 6.7582 - val_loss: 64.5784\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 5.5601 - val_loss: 68.7261\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 5.5319 - val_loss: 69.5017\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 5.5333 - val_loss: 67.7335\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 6.8614 - val_loss: 61.0782\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 6.2451 - val_loss: 64.7246\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 5.9230 - val_loss: 66.4682\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 5.0158 - val_loss: 65.1125\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.9631 - val_loss: 70.8077\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 5.2421 - val_loss: 67.5915\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 6.2932 - val_loss: 61.9628\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.8622 - val_loss: 59.7891\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.9104 - val_loss: 63.8166\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.7353 - val_loss: 63.6288\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 5.3026 - val_loss: 58.8082\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 5.2963 - val_loss: 59.6419\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 5.4444 - val_loss: 58.2560\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.2544 - val_loss: 58.4133\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 4.5744 - val_loss: 60.7567\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 5.2151 - val_loss: 60.0446\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.2504 - val_loss: 63.8424\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 3.9807 - val_loss: 64.0684\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.7279 - val_loss: 67.6760\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.3270 - val_loss: 67.0440\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.5704 - val_loss: 63.5377\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 5.5227 - val_loss: 59.8151\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 5.2429 - val_loss: 70.4846\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 4.6494 - val_loss: 61.8634\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 5.2220 - val_loss: 73.8586\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 5.0662 - val_loss: 64.7906\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.2140 - val_loss: 61.1065\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.9295 - val_loss: 63.8814\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 4.1304 - val_loss: 61.7056\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 4.0482 - val_loss: 60.9239\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 4.4096 - val_loss: 63.6163\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.3969 - val_loss: 63.2335\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 4.4012 - val_loss: 67.6640\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 4.7991 - val_loss: 66.5731\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.3931 - val_loss: 67.4693\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.0498 - val_loss: 66.1089\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.8382 - val_loss: 68.0017\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 3.9362 - val_loss: 65.0120\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 4.4931 - val_loss: 67.3391\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.4364 - val_loss: 67.5424\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 3.7649 - val_loss: 66.2942\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 4.2499 - val_loss: 71.6356\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 3.5103 - val_loss: 63.9758\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 3.5309 - val_loss: 62.9229\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 3.7384 - val_loss: 63.1633\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.0162 - val_loss: 63.5316\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 4.2491 - val_loss: 60.5768\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.1763 - val_loss: 72.0436\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.7403 - val_loss: 69.9496\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.9730 - val_loss: 67.1908\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.4643 - val_loss: 63.2787\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 4.9947 - val_loss: 58.8309\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 5.1505 - val_loss: 64.8386\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 5.0861 - val_loss: 57.6158\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 5.4683 - val_loss: 63.2272\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 4.7969 - val_loss: 59.6296\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 18us/sample - loss: 4.7981 - val_loss: 61.5945\n",
      "\n",
      "Mean squared error: 4.8\n",
      "\n",
      "dropout: 2.9e-01\n",
      "filter_num: 300\n",
      "num_dense_layers: 9\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 1s 324us/sample - loss: 60.0230 - val_loss: 42.5733\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 82us/sample - loss: 51.4101 - val_loss: 54.3078\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 80us/sample - loss: 48.0235 - val_loss: 37.7580\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 82us/sample - loss: 45.0831 - val_loss: 45.6621\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 85us/sample - loss: 40.0274 - val_loss: 40.7507\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 83us/sample - loss: 42.4700 - val_loss: 48.5237\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 83us/sample - loss: 39.8249 - val_loss: 33.6349\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 77us/sample - loss: 36.2686 - val_loss: 41.4475\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 90us/sample - loss: 32.5361 - val_loss: 33.9165\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 81us/sample - loss: 28.3838 - val_loss: 34.3238\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 82us/sample - loss: 27.9757 - val_loss: 37.1696\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 82us/sample - loss: 23.4711 - val_loss: 38.5431\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 83us/sample - loss: 21.9237 - val_loss: 42.0206\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 85us/sample - loss: 18.8162 - val_loss: 42.6304\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 82us/sample - loss: 21.2691 - val_loss: 45.1859\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 84us/sample - loss: 24.5439 - val_loss: 40.7590\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 84us/sample - loss: 22.7283 - val_loss: 44.0839\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 80us/sample - loss: 19.1208 - val_loss: 40.8643\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 89us/sample - loss: 15.2138 - val_loss: 40.3952\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 88us/sample - loss: 16.8986 - val_loss: 41.5433\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 91us/sample - loss: 15.8978 - val_loss: 36.5268\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 86us/sample - loss: 14.3086 - val_loss: 38.3114\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 87us/sample - loss: 14.7602 - val_loss: 39.2902\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 91us/sample - loss: 13.5672 - val_loss: 40.3551\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 85us/sample - loss: 16.6254 - val_loss: 49.3647\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 91us/sample - loss: 24.1430 - val_loss: 44.7703\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 82us/sample - loss: 20.6164 - val_loss: 36.0860\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 82us/sample - loss: 18.8014 - val_loss: 41.9748\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 80us/sample - loss: 23.6995 - val_loss: 35.2151\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 87us/sample - loss: 18.0992 - val_loss: 39.3400\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 86us/sample - loss: 14.9295 - val_loss: 37.5918\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 81us/sample - loss: 18.3785 - val_loss: 42.7023\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 85us/sample - loss: 16.2337 - val_loss: 36.0761\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 85us/sample - loss: 17.4294 - val_loss: 41.8687\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 83us/sample - loss: 23.4458 - val_loss: 36.8708\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 82us/sample - loss: 12.3655 - val_loss: 35.9452\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 84us/sample - loss: 9.8093 - val_loss: 37.6673\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 83us/sample - loss: 11.5622 - val_loss: 37.8957\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 76us/sample - loss: 10.7599 - val_loss: 37.5637\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 87us/sample - loss: 10.6198 - val_loss: 37.3835\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 80us/sample - loss: 10.1622 - val_loss: 37.1557\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 81us/sample - loss: 8.6403 - val_loss: 37.4728\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 80us/sample - loss: 8.8092 - val_loss: 39.5571\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 82us/sample - loss: 10.0754 - val_loss: 37.9059\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 80us/sample - loss: 9.5280 - val_loss: 39.1773\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 86us/sample - loss: 10.3718 - val_loss: 36.9971\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 81us/sample - loss: 9.2050 - val_loss: 36.9457\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 83us/sample - loss: 8.6946 - val_loss: 38.3956\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 81us/sample - loss: 8.5906 - val_loss: 37.8580\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 80us/sample - loss: 8.1629 - val_loss: 37.0584\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 88us/sample - loss: 9.1160 - val_loss: 37.7352\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 83us/sample - loss: 8.0035 - val_loss: 36.1488\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 81us/sample - loss: 9.3670 - val_loss: 37.8514\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 84us/sample - loss: 10.6523 - val_loss: 36.2536\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 80us/sample - loss: 9.3478 - val_loss: 36.9715\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 86us/sample - loss: 8.5387 - val_loss: 37.8497\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 82us/sample - loss: 8.9732 - val_loss: 38.3646\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 81us/sample - loss: 12.7864 - val_loss: 40.2852\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 88us/sample - loss: 13.9310 - val_loss: 37.9249\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 83us/sample - loss: 15.2729 - val_loss: 38.0604\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 85us/sample - loss: 9.2843 - val_loss: 39.5660\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 85us/sample - loss: 10.2044 - val_loss: 38.5517\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 87us/sample - loss: 9.2489 - val_loss: 45.0870\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 80us/sample - loss: 19.2645 - val_loss: 42.6538\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 80us/sample - loss: 16.9925 - val_loss: 36.5364\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 82us/sample - loss: 12.7636 - val_loss: 35.6728\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 80us/sample - loss: 22.8233 - val_loss: 40.7711\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 82us/sample - loss: 18.7529 - val_loss: 38.1162\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 82us/sample - loss: 11.6933 - val_loss: 38.0695\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 81us/sample - loss: 8.8653 - val_loss: 39.8987\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 82us/sample - loss: 12.3170 - val_loss: 38.8841\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 86us/sample - loss: 9.1033 - val_loss: 38.0134\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 82us/sample - loss: 10.3477 - val_loss: 37.7877\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 76us/sample - loss: 11.3231 - val_loss: 36.3799\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 86us/sample - loss: 14.0832 - val_loss: 36.6557\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 85us/sample - loss: 8.0350 - val_loss: 36.7019\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 81us/sample - loss: 9.8148 - val_loss: 37.4641\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 81us/sample - loss: 8.2908 - val_loss: 38.2301\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 82us/sample - loss: 7.9503 - val_loss: 38.7149\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 89us/sample - loss: 6.7750 - val_loss: 39.7241\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 80us/sample - loss: 7.9204 - val_loss: 38.6338\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 78us/sample - loss: 7.8474 - val_loss: 38.1790\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 87us/sample - loss: 7.7176 - val_loss: 37.7854\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 84us/sample - loss: 6.7208 - val_loss: 38.6480\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 86us/sample - loss: 7.7847 - val_loss: 39.2943\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 81us/sample - loss: 6.2866 - val_loss: 39.6556\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 81us/sample - loss: 6.8639 - val_loss: 37.8909\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 83us/sample - loss: 8.3666 - val_loss: 38.9470\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 76us/sample - loss: 9.1275 - val_loss: 38.2159\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 91us/sample - loss: 9.1963 - val_loss: 40.0715\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 85us/sample - loss: 8.0426 - val_loss: 38.0636\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 83us/sample - loss: 7.0888 - val_loss: 37.8755\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 83us/sample - loss: 6.4137 - val_loss: 36.6067\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 77us/sample - loss: 6.8660 - val_loss: 37.8483\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 94us/sample - loss: 8.2520 - val_loss: 36.9678\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 91us/sample - loss: 8.7879 - val_loss: 35.8727\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 88us/sample - loss: 7.1723 - val_loss: 37.1737\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 89us/sample - loss: 8.5969 - val_loss: 37.3397\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 89us/sample - loss: 7.5692 - val_loss: 39.9344\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 88us/sample - loss: 7.5612 - val_loss: 38.1053\n",
      "\n",
      "Mean squared error: 7.6\n",
      "\n",
      "dropout: 5.8e-01\n",
      "filter_num: 300\n",
      "num_dense_layers: 2\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 145us/sample - loss: 57.3039 - val_loss: 41.3291\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 46.7917 - val_loss: 42.6078\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 42.9040 - val_loss: 39.4305\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 40.3796 - val_loss: 37.7163\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 38.7899 - val_loss: 36.7691\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 35.2467 - val_loss: 33.7398\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 33.3479 - val_loss: 36.3319\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 32.3455 - val_loss: 34.8007\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 29.9892 - val_loss: 33.8708\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 26.7565 - val_loss: 34.9189\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 26.8398 - val_loss: 34.9781\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 23.1103 - val_loss: 35.4958\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 22.1245 - val_loss: 35.8322\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 20.1508 - val_loss: 36.3798\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 18.6214 - val_loss: 37.3228\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 17.8653 - val_loss: 38.6302\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 16.5477 - val_loss: 38.2703\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 15.0091 - val_loss: 37.6960\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 14.3470 - val_loss: 36.5534\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 15.4571 - val_loss: 36.3087\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 13.1884 - val_loss: 37.7493\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 12.5756 - val_loss: 38.7532\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 11.7060 - val_loss: 39.0533\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 13.4864 - val_loss: 38.3200\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 10.7189 - val_loss: 37.9970\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 11.4001 - val_loss: 38.6892\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 11.3540 - val_loss: 38.4660\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 33us/sample - loss: 9.3112 - val_loss: 37.8999\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 9.1646 - val_loss: 38.6350\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 10.2759 - val_loss: 37.8303\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 10.3661 - val_loss: 38.0472\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 8.0437 - val_loss: 39.7035\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 9.0275 - val_loss: 41.5161\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 7.9173 - val_loss: 42.5051\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 9.3290 - val_loss: 42.6058\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 39us/sample - loss: 8.5884 - val_loss: 40.8539\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 41us/sample - loss: 8.3273 - val_loss: 38.5543\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 7.6318 - val_loss: 38.3448\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 8.8141 - val_loss: 38.9150\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 9.3178 - val_loss: 39.6857\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 8.7244 - val_loss: 40.1335\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 8.2117 - val_loss: 40.7961\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 10.0384 - val_loss: 42.0374\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 9.7179 - val_loss: 42.2873\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 9.8208 - val_loss: 42.3698\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 9.7462 - val_loss: 41.9308\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 38us/sample - loss: 7.9784 - val_loss: 44.1144\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 8.4648 - val_loss: 41.7432\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 7.0110 - val_loss: 42.4329\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 7.9258 - val_loss: 41.6991\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 6.5826 - val_loss: 40.1309\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 7.6095 - val_loss: 40.6492\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 8.4440 - val_loss: 40.4721\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 7.5594 - val_loss: 41.1352\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 8.0484 - val_loss: 42.1056\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 37us/sample - loss: 7.2803 - val_loss: 42.6513\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 9.8208 - val_loss: 43.4150\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 7.3669 - val_loss: 42.4973\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 6.8689 - val_loss: 42.5902\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 6.2390 - val_loss: 41.8081\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 6.6386 - val_loss: 40.5747\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 6.7133 - val_loss: 41.1966\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 8.5552 - val_loss: 41.3170\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 5.7176 - val_loss: 40.6192\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 7.2818 - val_loss: 40.1720\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 6.2246 - val_loss: 41.0797\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 6.2681 - val_loss: 42.2818\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 6.7144 - val_loss: 45.2725\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 7.0878 - val_loss: 43.5856\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 7.6719 - val_loss: 44.6385\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 36us/sample - loss: 7.3332 - val_loss: 43.0522\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 6.7834 - val_loss: 43.4385\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 6.2059 - val_loss: 43.3793\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 6.1633 - val_loss: 44.2081\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 6.1461 - val_loss: 47.9449\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 5.9840 - val_loss: 44.5843\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 35us/sample - loss: 5.4815 - val_loss: 43.8949\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 8.1504 - val_loss: 42.3472\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 32us/sample - loss: 7.9398 - val_loss: 44.4281\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 6.9175 - val_loss: 42.0235\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 6.9985 - val_loss: 41.8016\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 7.4817 - val_loss: 42.4795\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 5.6038 - val_loss: 42.8961\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 7.5194 - val_loss: 43.2570\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 7.8847 - val_loss: 43.7419\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 6.2151 - val_loss: 43.1259\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 8.0107 - val_loss: 47.5149\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 40us/sample - loss: 5.7123 - val_loss: 46.5134\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 6.7197 - val_loss: 47.8873\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 6.5601 - val_loss: 47.3630\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 6.4074 - val_loss: 44.5930\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 5.5276 - val_loss: 48.1386\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 6.4200 - val_loss: 45.0570\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 5.5367 - val_loss: 46.6079\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 5.7355 - val_loss: 47.7481\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 7.2928 - val_loss: 46.6502\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 5.9283 - val_loss: 45.4999\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 6.1285 - val_loss: 45.9492\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 33us/sample - loss: 5.7347 - val_loss: 46.4259\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 34us/sample - loss: 7.2591 - val_loss: 43.8291\n",
      "\n",
      "Mean squared error: 7.3\n",
      "\n",
      "dropout: 3.8e-01\n",
      "filter_num: 300\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 113us/sample - loss: 54.9242 - val_loss: 39.5848\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 44.8929 - val_loss: 39.1868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 42.8164 - val_loss: 37.2418\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 38.1136 - val_loss: 35.9179\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 34.6961 - val_loss: 34.2164\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 31.8928 - val_loss: 34.6554\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 29.5092 - val_loss: 34.9982\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 24.6817 - val_loss: 38.5236\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 23.8579 - val_loss: 40.5396\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 21.5348 - val_loss: 44.8566\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 18.7935 - val_loss: 46.2277\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 16.9958 - val_loss: 47.4908\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 14.1076 - val_loss: 44.4928\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 13.5317 - val_loss: 47.9253\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 12.2916 - val_loss: 42.4108\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 9.9346 - val_loss: 44.6833\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 9.8443 - val_loss: 41.8112\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 8.7490 - val_loss: 48.5938\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 8.5386 - val_loss: 42.1936\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 8.6167 - val_loss: 43.0776\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 7.7880 - val_loss: 45.4874\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 6.7167 - val_loss: 44.0242\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.2258 - val_loss: 44.4804\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.4527 - val_loss: 43.4431\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.0434 - val_loss: 43.8305\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.6113 - val_loss: 45.5470\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.2436 - val_loss: 46.9647\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 6.9413 - val_loss: 44.4492\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 7.6385 - val_loss: 48.7114\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 6.6255 - val_loss: 42.5511\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 5.8473 - val_loss: 45.3411\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 4.3085 - val_loss: 45.2178\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 4.5831 - val_loss: 48.8422\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 4.4455 - val_loss: 45.6311\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 4.6230 - val_loss: 44.9678\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 4.4097 - val_loss: 45.1512\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 4.4608 - val_loss: 48.8031\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 3.9524 - val_loss: 50.2226\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 4.4256 - val_loss: 54.4430\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 4.2832 - val_loss: 51.3381\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 3.7112 - val_loss: 46.3302\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 3.5784 - val_loss: 47.0657\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 3.5984 - val_loss: 45.8417\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 3.4845 - val_loss: 44.2859\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 3.2889 - val_loss: 43.3628\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 3.4401 - val_loss: 45.4215\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.6977 - val_loss: 44.5663\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.3881 - val_loss: 45.1271\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.1157 - val_loss: 45.6280\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.9889 - val_loss: 48.9704\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.1149 - val_loss: 46.8539\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.3868 - val_loss: 47.7174\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.3638 - val_loss: 43.9877\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.1715 - val_loss: 44.1636\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.7806 - val_loss: 45.9993\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.3457 - val_loss: 47.2551\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.9432 - val_loss: 47.6299\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.5830 - val_loss: 46.8101\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 22us/sample - loss: 3.1309 - val_loss: 51.0903\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 2.9889 - val_loss: 47.3699\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.6009 - val_loss: 46.8789\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.0367 - val_loss: 44.7287\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.9714 - val_loss: 48.8449\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 6.2083 - val_loss: 47.6927\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.6354 - val_loss: 49.5726\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.8496 - val_loss: 46.1795\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.5469 - val_loss: 49.9811\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.0973 - val_loss: 46.9855\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.8493 - val_loss: 47.9017\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.5764 - val_loss: 47.9338\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.2546 - val_loss: 49.3102\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.3395 - val_loss: 49.9142\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.3531 - val_loss: 45.6702\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.1714 - val_loss: 47.1208\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.4849 - val_loss: 45.2606\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.3588 - val_loss: 49.6456\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.2826 - val_loss: 47.1935\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 21us/sample - loss: 2.0556 - val_loss: 50.8500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 30us/sample - loss: 2.0607 - val_loss: 46.8373\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.9796 - val_loss: 47.9763\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.9524 - val_loss: 45.9551\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 1.7199 - val_loss: 47.5064\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.0421 - val_loss: 46.0822\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.8466 - val_loss: 48.0012\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.8428 - val_loss: 47.4670\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.9940 - val_loss: 49.0305\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.5247 - val_loss: 48.6078\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.1102 - val_loss: 49.0542\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.9280 - val_loss: 47.3124\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.7772 - val_loss: 49.0838\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.1273 - val_loss: 47.6654\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 2.0667 - val_loss: 49.8762\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.7497 - val_loss: 48.4775\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.0764 - val_loss: 48.3952\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.8322 - val_loss: 47.5227\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 1.9354 - val_loss: 45.5961\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.5817 - val_loss: 46.7726\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.1630 - val_loss: 45.2836\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 1.8685 - val_loss: 44.7903\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 2.0065 - val_loss: 45.4587\n",
      "\n",
      "Mean squared error: 2.0\n",
      "\n",
      "dropout: 4.4e-01\n",
      "filter_num: 10\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 90us/sample - loss: 65.5405 - val_loss: 59.9941\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 65.4675 - val_loss: 59.9359\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 65.4059 - val_loss: 59.8698\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 65.3332 - val_loss: 59.7867\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 65.2406 - val_loss: 59.6729\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 65.0957 - val_loss: 59.5051\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 13us/sample - loss: 64.8067 - val_loss: 59.2302\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 64.4844 - val_loss: 58.7574\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 63.7273 - val_loss: 57.9462\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 62.6482 - val_loss: 56.5452\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 60.6209 - val_loss: 54.2025\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 56.8069 - val_loss: 50.5728\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 53.7470 - val_loss: 45.8901\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 47.3166 - val_loss: 40.7278\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 46.2002 - val_loss: 36.6071\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 43.4763 - val_loss: 34.6945\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 40.1905 - val_loss: 33.9672\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 39.5751 - val_loss: 34.0909\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 39.1155 - val_loss: 34.8340\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 36.6623 - val_loss: 34.3673\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 39.3849 - val_loss: 34.1472\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 37.4695 - val_loss: 34.3764\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 37.8523 - val_loss: 34.4481\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 35.7004 - val_loss: 34.3034\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 38.1272 - val_loss: 34.1281\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 35.7286 - val_loss: 34.1326\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 37.1356 - val_loss: 34.2610\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 35.0459 - val_loss: 34.7519\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 32.7202 - val_loss: 34.7408\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 35.5983 - val_loss: 34.9898\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 36.1337 - val_loss: 35.1199\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 38.5077 - val_loss: 35.3065\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 32.2219 - val_loss: 35.3029\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 33.2514 - val_loss: 35.1589\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 36.9117 - val_loss: 34.9068\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 31.6909 - val_loss: 35.0498\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 34.8748 - val_loss: 35.0912\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 31.8357 - val_loss: 35.0069\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 34.1831 - val_loss: 34.9122\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 32.8960 - val_loss: 34.8085\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 30.4412 - val_loss: 34.7172\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 31.0138 - val_loss: 35.1353\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 29.3329 - val_loss: 36.2742\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 36.3442 - val_loss: 36.7667\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 34.5585 - val_loss: 36.8178\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 33.5461 - val_loss: 36.5200\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 33.7109 - val_loss: 35.8203\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 32.5270 - val_loss: 35.6416\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 12us/sample - loss: 31.3355 - val_loss: 35.6772\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 29.2618 - val_loss: 35.8184\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 28.8152 - val_loss: 35.7222\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 31.6331 - val_loss: 35.4802\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 11us/sample - loss: 32.3731 - val_loss: 35.6982\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 31.8797 - val_loss: 36.1517\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 31.4873 - val_loss: 36.8936\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 32.1012 - val_loss: 37.9681\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 30.0322 - val_loss: 38.8263\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 30.7754 - val_loss: 39.1984\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 29.6466 - val_loss: 39.4248\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 27.0343 - val_loss: 39.6351\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 29.7047 - val_loss: 40.0372\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 28.5479 - val_loss: 40.3121\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 30.6113 - val_loss: 40.5624\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 30.8217 - val_loss: 40.8208\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 29.2708 - val_loss: 41.3832\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 28.6899 - val_loss: 41.8019\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 27.2698 - val_loss: 42.1537\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 30.7930 - val_loss: 42.7788\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 25.6470 - val_loss: 43.3149\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 26.4287 - val_loss: 43.6037\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 25.8359 - val_loss: 43.9831\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 28.0944 - val_loss: 44.7186\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 27.5237 - val_loss: 45.3934\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 31.4949 - val_loss: 45.9680\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 26.7565 - val_loss: 46.6010\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 27.6086 - val_loss: 47.3752\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 28.9114 - val_loss: 48.3797\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 27.0421 - val_loss: 49.3725\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 26.9077 - val_loss: 50.1868\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 24.1698 - val_loss: 51.0975\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 26.8274 - val_loss: 53.9336\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 27.3887 - val_loss: 56.2725\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 25.8987 - val_loss: 56.7378\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 24.9262 - val_loss: 56.1004\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 25.8948 - val_loss: 56.9853\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 24.3639 - val_loss: 59.3872\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 25.0685 - val_loss: 61.8730\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 11us/sample - loss: 24.1725 - val_loss: 64.2388\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 25.4775 - val_loss: 67.1061\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 21.3994 - val_loss: 70.7496\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 25.5736 - val_loss: 73.1550\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 25.1286 - val_loss: 75.8899\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 23.2127 - val_loss: 78.0254\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 20.7782 - val_loss: 80.4784\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 28.3622 - val_loss: 83.9349\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 27.1658 - val_loss: 88.1490\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 23.2766 - val_loss: 91.4345\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 22.9319 - val_loss: 95.5251\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 10us/sample - loss: 23.3078 - val_loss: 99.3116\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 9us/sample - loss: 20.2394 - val_loss: 100.0635\n",
      "\n",
      "Mean squared error: 2e+01\n",
      "\n",
      "dropout: 4.1e-01\n",
      "filter_num: 238\n",
      "num_dense_layers: 2\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 127us/sample - loss: 60.5702 - val_loss: 42.7295\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 31us/sample - loss: 47.6476 - val_loss: 38.3317\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 44.0951 - val_loss: 39.6729\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 40.2266 - val_loss: 35.1442\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 38.1373 - val_loss: 34.6584\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 35.1844 - val_loss: 33.7954\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 31.9643 - val_loss: 33.6079\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 30.1629 - val_loss: 33.7640\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 26.8650 - val_loss: 35.4790\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 25.0124 - val_loss: 37.5067\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 23.1482 - val_loss: 40.0920\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 20.5604 - val_loss: 43.8246\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 17.7326 - val_loss: 44.5051\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 16.2141 - val_loss: 50.8717\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 16.0236 - val_loss: 48.5134\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 14.1067 - val_loss: 49.6664\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 12.6595 - val_loss: 53.0199\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 12.2339 - val_loss: 46.3160\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 12.0486 - val_loss: 61.1706\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 11.5798 - val_loss: 46.0986\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 11.1980 - val_loss: 53.7123\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 10.4200 - val_loss: 47.6633\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 10.6728 - val_loss: 59.8139\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 10.6715 - val_loss: 48.5694\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 9.1846 - val_loss: 56.7421\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 8.8304 - val_loss: 52.4674\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 26us/sample - loss: 7.3973 - val_loss: 55.9097\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.5468 - val_loss: 53.7384\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 6.3996 - val_loss: 55.7520\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 6.4253 - val_loss: 54.7382\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 6.7404 - val_loss: 53.6742\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 7.4777 - val_loss: 56.0698\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 7.4964 - val_loss: 53.6027\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.6783 - val_loss: 60.2785\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.3891 - val_loss: 54.5759\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 6.3890 - val_loss: 62.9597\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 5.3660 - val_loss: 62.1362\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.9722 - val_loss: 63.0381\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.6892 - val_loss: 64.6966\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.5106 - val_loss: 69.2840\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.5891 - val_loss: 67.5902\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.0672 - val_loss: 68.9599\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.2879 - val_loss: 63.3407\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 5.6661 - val_loss: 54.2330\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 8.4833 - val_loss: 53.5575\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 8.7990 - val_loss: 50.4187\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 8.0459 - val_loss: 62.4144\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 7.6189 - val_loss: 57.7272\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 7.3735 - val_loss: 70.1793\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 6.7443 - val_loss: 67.3635\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 5.3477 - val_loss: 76.3403\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.7783 - val_loss: 87.0278\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 5.7935 - val_loss: 87.5118\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 6.6281 - val_loss: 96.3576\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.7393 - val_loss: 86.6808\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.0029 - val_loss: 85.7197\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.6202 - val_loss: 75.7461\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.5381 - val_loss: 72.4604\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 6.7244 - val_loss: 67.9983\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.4801 - val_loss: 68.1962\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.7901 - val_loss: 68.6480\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.3382 - val_loss: 68.1654\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 5.1743 - val_loss: 63.6078\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 5.1045 - val_loss: 70.0577\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.7180 - val_loss: 75.6927\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 3.9859 - val_loss: 75.7349\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.6386 - val_loss: 78.3124\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.2250 - val_loss: 74.1627\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.8337 - val_loss: 72.6508\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.7500 - val_loss: 65.5359\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.4348 - val_loss: 64.8657\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.2603 - val_loss: 76.6895\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.2206 - val_loss: 67.8917\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 4.0995 - val_loss: 73.5877\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.0162 - val_loss: 74.4579\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 6.1129 - val_loss: 83.3243\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.1000 - val_loss: 70.8666\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 6.2390 - val_loss: 78.6901\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.0060 - val_loss: 66.5382\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 27us/sample - loss: 3.5994 - val_loss: 73.2910\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.2977 - val_loss: 67.2811\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 4.0982 - val_loss: 70.3407\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.5886 - val_loss: 74.2243\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.2275 - val_loss: 71.2169\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 28us/sample - loss: 3.7629 - val_loss: 70.2203\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 3.3000 - val_loss: 73.6173\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.3373 - val_loss: 68.1152\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 29us/sample - loss: 4.1136 - val_loss: 73.6025\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 3.7628 - val_loss: 69.4240\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 4.1044 - val_loss: 74.3887\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.8074 - val_loss: 72.4429\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.7074 - val_loss: 77.7462\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 4.3114 - val_loss: 75.6841\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 24us/sample - loss: 5.1253 - val_loss: 81.0626\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.3482 - val_loss: 82.8750\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.2766 - val_loss: 76.6195\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 4.8397 - val_loss: 79.8225\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 3.7533 - val_loss: 73.4988\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 25us/sample - loss: 3.3986 - val_loss: 86.4641\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 26us/sample - loss: 5.0640 - val_loss: 81.2246\n",
      "\n",
      "Mean squared error: 5.1\n",
      "\n",
      "dropout: 2.0e-01\n",
      "filter_num: 119\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 98us/sample - loss: 63.3607 - val_loss: 52.7125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 53.6993 - val_loss: 39.0428\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 43.8686 - val_loss: 36.5094\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 39.9496 - val_loss: 35.3451\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 37.1941 - val_loss: 34.0070\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 34.0981 - val_loss: 34.3162\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 32.7154 - val_loss: 34.3077\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 30.7011 - val_loss: 36.5032\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 29.2508 - val_loss: 35.8082\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 28.2966 - val_loss: 35.5336\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 27.3128 - val_loss: 38.3125\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 25.5188 - val_loss: 40.0141\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 23.7984 - val_loss: 42.6148\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 23.0262 - val_loss: 49.3477\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 21.1688 - val_loss: 44.3667\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 19.6586 - val_loss: 48.1594\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 17.8912 - val_loss: 53.5266\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 15.6146 - val_loss: 53.7783\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 13.8070 - val_loss: 61.3721\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 13.1106 - val_loss: 68.5835\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 11.9603 - val_loss: 73.3222\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 11.3036 - val_loss: 70.7471\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 10.4735 - val_loss: 92.1969\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 11.2113 - val_loss: 83.8948\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 9.7580 - val_loss: 90.9306\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 7.8453 - val_loss: 102.1733\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 6.8063 - val_loss: 94.8223\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 6.7794 - val_loss: 100.3080\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 6.5605 - val_loss: 93.2108\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 6.0518 - val_loss: 97.6128\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 5.8390 - val_loss: 103.8906\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 5.0234 - val_loss: 106.0809\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.7778 - val_loss: 109.8425\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.6620 - val_loss: 106.9506\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.5311 - val_loss: 109.0324\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.2958 - val_loss: 112.4331\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 4.4926 - val_loss: 114.2176\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.0551 - val_loss: 117.0990\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.8572 - val_loss: 117.9401\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.6883 - val_loss: 115.5953\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.6286 - val_loss: 120.7175\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.3893 - val_loss: 114.8624\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.1403 - val_loss: 122.1833\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 3.3477 - val_loss: 124.3308\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 3.6676 - val_loss: 128.1134\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.1336 - val_loss: 118.0994\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.0262 - val_loss: 122.0707\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 3.1536 - val_loss: 113.7962\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 3.2280 - val_loss: 121.2975\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.1808 - val_loss: 118.0839\n",
      "Epoch 51/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.9682 - val_loss: 116.4106\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.7078 - val_loss: 117.3457\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.9894 - val_loss: 125.2670\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.9282 - val_loss: 121.1495\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.7815 - val_loss: 125.0191\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.4619 - val_loss: 123.6123\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.4974 - val_loss: 129.0153\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.4226 - val_loss: 125.8915\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.4101 - val_loss: 132.6435\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.2486 - val_loss: 128.6905\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.2859 - val_loss: 135.1858\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.3130 - val_loss: 136.2949\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 2.4032 - val_loss: 135.1206\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.5789 - val_loss: 129.9768\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.4865 - val_loss: 140.6435\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.2331 - val_loss: 136.1641\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.5012 - val_loss: 145.8022\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 2.6832 - val_loss: 130.9724\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 3.0546 - val_loss: 149.1098\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.7898 - val_loss: 134.8911\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.3144 - val_loss: 138.0994\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.8018 - val_loss: 128.2834\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.0475 - val_loss: 132.1161\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.2662 - val_loss: 138.8532\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.1867 - val_loss: 130.9982\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.5001 - val_loss: 130.4263\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.1492 - val_loss: 127.4244\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.9456 - val_loss: 131.1505\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.7452 - val_loss: 134.9555\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.1637 - val_loss: 127.1166\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.8677 - val_loss: 129.8773\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.7950 - val_loss: 121.8835\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 1.8651 - val_loss: 131.9899\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.5815 - val_loss: 133.1051\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.5847 - val_loss: 130.5424\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.5704 - val_loss: 120.2940\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.0016 - val_loss: 119.0341\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.1968 - val_loss: 115.9660\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.2961 - val_loss: 112.9557\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.1095 - val_loss: 108.9628\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.3584 - val_loss: 113.2270\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 3.1006 - val_loss: 113.5350\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.8804 - val_loss: 117.3974\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.5239 - val_loss: 119.9743\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.1631 - val_loss: 117.2723\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 1.9172 - val_loss: 116.7693\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.1620 - val_loss: 109.6078\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.8333 - val_loss: 115.6532\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.5979 - val_loss: 113.6864\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.7999 - val_loss: 116.6489\n",
      "\n",
      "Mean squared error: 1.8\n",
      "\n",
      "dropout: 2.5e-01\n",
      "filter_num: 130\n",
      "num_dense_layers: 1\n",
      "\n",
      "Train on 2529 samples, validate on 281 samples\n",
      "Epoch 1/100\n",
      "2529/2529 [==============================] - 0s 104us/sample - loss: 63.8483 - val_loss: 54.0631\n",
      "Epoch 2/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 55.0055 - val_loss: 40.4417\n",
      "Epoch 3/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 43.6105 - val_loss: 38.0402\n",
      "Epoch 4/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 40.8100 - val_loss: 35.5349\n",
      "Epoch 5/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 37.3887 - val_loss: 34.7971\n",
      "Epoch 6/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 35.2265 - val_loss: 33.9999\n",
      "Epoch 7/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 33.4550 - val_loss: 33.7503\n",
      "Epoch 8/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 30.5978 - val_loss: 33.9937\n",
      "Epoch 9/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 29.2444 - val_loss: 34.5170\n",
      "Epoch 10/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 27.3582 - val_loss: 37.2486\n",
      "Epoch 11/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 25.4038 - val_loss: 35.8606\n",
      "Epoch 12/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 25.3391 - val_loss: 39.1315\n",
      "Epoch 13/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 23.8103 - val_loss: 40.8391\n",
      "Epoch 14/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 22.3280 - val_loss: 43.0438\n",
      "Epoch 15/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 20.7641 - val_loss: 47.1685\n",
      "Epoch 16/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 18.8015 - val_loss: 50.0621\n",
      "Epoch 17/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 17.8131 - val_loss: 53.5476\n",
      "Epoch 18/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 15.9780 - val_loss: 66.0806\n",
      "Epoch 19/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 14.0239 - val_loss: 68.0767\n",
      "Epoch 20/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 12.5449 - val_loss: 80.4496\n",
      "Epoch 21/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 11.7267 - val_loss: 79.9419\n",
      "Epoch 22/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 10.3552 - val_loss: 103.8525\n",
      "Epoch 23/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 9.7463 - val_loss: 97.1100\n",
      "Epoch 24/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 8.2955 - val_loss: 118.5690\n",
      "Epoch 25/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 7.7633 - val_loss: 117.3601\n",
      "Epoch 26/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 7.5464 - val_loss: 143.2585\n",
      "Epoch 27/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 7.6287 - val_loss: 128.8682\n",
      "Epoch 28/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 6.2198 - val_loss: 174.6911\n",
      "Epoch 29/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 6.4627 - val_loss: 141.2632\n",
      "Epoch 30/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 5.7251 - val_loss: 152.8124\n",
      "Epoch 31/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 5.5878 - val_loss: 144.9169\n",
      "Epoch 32/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 5.9808 - val_loss: 143.9462\n",
      "Epoch 33/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 6.1719 - val_loss: 167.7787\n",
      "Epoch 34/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 6.4742 - val_loss: 151.0213\n",
      "Epoch 35/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 6.4318 - val_loss: 166.9434\n",
      "Epoch 36/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 5.6673 - val_loss: 152.0023\n",
      "Epoch 37/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 5.6354 - val_loss: 162.3734\n",
      "Epoch 38/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 5.0746 - val_loss: 158.7786\n",
      "Epoch 39/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.2978 - val_loss: 160.5108\n",
      "Epoch 40/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.0542 - val_loss: 165.3703\n",
      "Epoch 41/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.4068 - val_loss: 159.2903\n",
      "Epoch 42/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.4138 - val_loss: 161.5948\n",
      "Epoch 43/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.5382 - val_loss: 165.8186\n",
      "Epoch 44/100\n",
      "2529/2529 [==============================] - 0s 17us/sample - loss: 3.4810 - val_loss: 156.6217\n",
      "Epoch 45/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.3754 - val_loss: 170.3327\n",
      "Epoch 46/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.4438 - val_loss: 160.7223\n",
      "Epoch 47/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.0402 - val_loss: 175.7744\n",
      "Epoch 48/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.2259 - val_loss: 169.9410\n",
      "Epoch 49/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.9985 - val_loss: 179.9517\n",
      "Epoch 50/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.9929 - val_loss: 168.4948\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.3088 - val_loss: 170.6086\n",
      "Epoch 52/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.8640 - val_loss: 155.9622\n",
      "Epoch 53/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.3290 - val_loss: 172.0036\n",
      "Epoch 54/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.4661 - val_loss: 160.9760\n",
      "Epoch 55/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 4.1547 - val_loss: 174.3811\n",
      "Epoch 56/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.8909 - val_loss: 159.6320\n",
      "Epoch 57/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.6593 - val_loss: 175.9118\n",
      "Epoch 58/100\n",
      "2529/2529 [==============================] - 0s 19us/sample - loss: 3.3801 - val_loss: 162.8948\n",
      "Epoch 59/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.2074 - val_loss: 171.7190\n",
      "Epoch 60/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.8819 - val_loss: 169.7982\n",
      "Epoch 61/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.0045 - val_loss: 175.8573\n",
      "Epoch 62/100\n",
      "2529/2529 [==============================] - 0s 14us/sample - loss: 2.6943 - val_loss: 167.4271\n",
      "Epoch 63/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.1236 - val_loss: 178.7042\n",
      "Epoch 64/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.8603 - val_loss: 162.0905\n",
      "Epoch 65/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.4545 - val_loss: 184.3336\n",
      "Epoch 66/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 3.1829 - val_loss: 168.0555\n",
      "Epoch 67/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.5689 - val_loss: 180.4395\n",
      "Epoch 68/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.2015 - val_loss: 183.8026\n",
      "Epoch 69/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.1374 - val_loss: 192.3833\n",
      "Epoch 70/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 2.2536 - val_loss: 200.4817\n",
      "Epoch 71/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.3809 - val_loss: 197.5963\n",
      "Epoch 72/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.1032 - val_loss: 190.2948\n",
      "Epoch 73/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.5011 - val_loss: 179.7650\n",
      "Epoch 74/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.5904 - val_loss: 179.8754\n",
      "Epoch 75/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.1457 - val_loss: 174.9191\n",
      "Epoch 76/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.0221 - val_loss: 184.0138\n",
      "Epoch 77/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.0513 - val_loss: 187.9035\n",
      "Epoch 78/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 1.8387 - val_loss: 195.4903\n",
      "Epoch 79/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.2279 - val_loss: 182.1575\n",
      "Epoch 80/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.7860 - val_loss: 182.4242\n",
      "Epoch 81/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.9648 - val_loss: 189.9121\n",
      "Epoch 82/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.8514 - val_loss: 196.6069\n",
      "Epoch 83/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 1.8558 - val_loss: 191.7022\n",
      "Epoch 84/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.7220 - val_loss: 186.6508\n",
      "Epoch 85/100\n",
      "2529/2529 [==============================] - 0s 16us/sample - loss: 1.7385 - val_loss: 209.5039\n",
      "Epoch 86/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.8238 - val_loss: 201.9904\n",
      "Epoch 87/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.6834 - val_loss: 210.2726\n",
      "Epoch 88/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.9374 - val_loss: 209.1385\n",
      "Epoch 89/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.0865 - val_loss: 190.4122\n",
      "Epoch 90/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.6416 - val_loss: 194.8330\n",
      "Epoch 91/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.7928 - val_loss: 185.7343\n",
      "Epoch 92/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.6825 - val_loss: 203.8887\n",
      "Epoch 93/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.7014 - val_loss: 179.9585\n",
      "Epoch 94/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.7256 - val_loss: 190.3710\n",
      "Epoch 95/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.7140 - val_loss: 179.4208\n",
      "Epoch 96/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.9474 - val_loss: 187.0345\n",
      "Epoch 97/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.8098 - val_loss: 168.0566\n",
      "Epoch 98/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.0101 - val_loss: 182.9240\n",
      "Epoch 99/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 1.8504 - val_loss: 172.8471\n",
      "Epoch 100/100\n",
      "2529/2529 [==============================] - 0s 15us/sample - loss: 2.1534 - val_loss: 199.6127\n",
      "\n",
      "Mean squared error: 2.2\n",
      "\n",
      "Best solution:\n",
      "[0.20000000000000004, 300, 1]\n",
      "\n",
      "Score:\n",
      "29.23636402622346\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_mean_squared_error = 9999999999999999\n",
    "default_parameters =[0.7, 150, 9]\n",
    "#dropout, filter_num, num_dense_layers\n",
    "print_and_plot(default_parameters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
